metadata:
  last_updated: '2025-11-16'
  total_papers: 11
  auto_update_enabled: false
  arxiv_categories:
  - cs.CV
  - cs.LG
  - cs.AI
  - eess.IV
  last_citation_update: '2025-12-08'
categories:
- id: 3d-gaussian
  name: 3D Gaussian Splatting
  description: Papers about 3D Gaussian representation and splatting
  color: '#667eea'
  icon: üåü
- id: medical-imaging
  name: Medical Image Analysis
  description: Medical image segmentation, registration, and analysis
  color: '#f093fb'
  icon: üè•
- id: cardiac-imaging
  name: Cardiac Imaging
  description: Cardiac motion tracking and analysis
  color: '#ff6b6b'
  icon: ‚ù§Ô∏è
- id: self-supervised
  name: Self-Supervised Learning
  description: Self-supervised and unsupervised learning methods
  color: '#4ecdc4'
  icon: üéØ
- id: nerf
  name: Neural Radiance Fields
  description: NeRF and related neural rendering methods
  color: '#a8e6cf'
  icon: üåà
- id: reconstruction
  name: 3D Reconstruction
  description: 3D reconstruction from 2D images
  color: '#ff8b94'
  icon: üèóÔ∏è
papers:
- id: gaussian-splatting-2023
  title: 3D Gaussian Splatting for Real-Time Radiance Field Rendering
  authors:
  - Bernhard Kerbl
  - Georgios Kopanas
  - Thomas Leimk√ºhler
  - George Drettakis
  venue: SIGGRAPH
  year: 2023
  month: 8
  categories:
  - 3d-gaussian
  - nerf
  type: Foundation
  abstract: We introduce 3D Gaussian primitives as a flexible and expressive scene
    representation for real-time rendering of neural radiance fields. Our method achieves
    state-of-the-art visual quality while maintaining competitive training times and
    enabling real-time rendering.
  links:
    paper: https://arxiv.org/abs/2308.04079
    code: https://github.com/graphdeco-inria/gaussian-splatting
    project: https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/
    video: ''
  arxiv_id: '2308.04079'
  citation_count: 5875
  starred: true
  date_added: '2025-01-07'
  notes: Seminal work introducing 3D Gaussian Splatting
  influential_citation_count: 1816
  citation_last_checked: '2025-12-01T02:51:15.737438'
- id: semanticvla-semantic-aligned-sparsification-and-en-2025
  title: 'SemanticVLA: Semantic-Aligned Sparsification and Enhancement for Efficient
    Robotic Manipulation'
  authors:
  - Wei Li
  - Renshan Zhang
  - Rui Shao
  - Zhijian Fang
  - Kaiwen Zhou
  - Zhuotao Tian
  - Liqiang Nie
  venue: arXiv
  year: 2025
  month: 11
  categories:
  - 3d-gaussian
  type: Research
  abstract: 'Vision-Language-Action (VLA) models have advanced in robotic manipulation,
    yet practical deployment remains hindered by two key limitations: 1) perceptual
    redundancy, where irrelevant visual inputs are processed inefficiently, and 2)
    superficial instruction-vision alignment, which hampers semantic grounding of
    actions. In this paper, we propose SemanticVLA, a novel VLA framework that performs
    Semantic-Aligned Sparsification and Enhancement for Efficient Robotic Manipulation.
    Specifically: 1) To '
  links:
    paper: http://arxiv.org/abs/2511.10518v1
    code: ''
    project: ''
    video: ''
  arxiv_id: 2511.10518v1
  citation_count: 1
  starred: false
  date_added: '2025-11-16'
  notes: ''
  ai_summary: 'Vision-Language-Action (VLA) models have advanced in robotic manipulation,
    yet practical deployment remains hindered by two key limitations: 1) perceptual
    redundancy, where irrelevant visual inputs are processed inefficiently, and 2)
    superficial instruction-vision alignment, which hampers semantic grounding of
    actions. In this paper, we propose SemanticVLA, a novel VLA framework that performs
    Sema...'
  key_contributions:
  - 'Vision-Language-Action (VLA) models have advanced in robotic manipulation, yet
    practical deployment remains hindered by two key limitations: 1) perceptual redundancy,
    where irrelevant visual inputs are processed inefficiently, and 2) superficial
    instruction-vision alignment, which hampers semantic grounding of actions.'
  - In this paper, we propose SemanticVLA, a novel VLA framework that performs Semantic-Aligned
    Sparsification and Enhancement for Efficient Robotic Manipulation.
  - 'Specifically: 1) To sparsify redundant perception while preserving semantic alignment,
    Semantic-guided Dual Visual Pruner (SD-Pruner) performs: Instruction-driven Pruner
    (ID-Pruner) extracts global action cues and local semantic anchors in SigLIP;
    Spatial-aggregation Pruner (SA-Pruner) compacts geometry-rich features into task-adaptive
    tokens in DINOv2.'
  relevance_score: 4.4
  influential_citation_count: 0
  citation_last_checked: '2025-12-08T02:39:28.411554'
- id: depth-anything-3-recovering-the-visual-space-from--2025
  title: 'Depth Anything 3: Recovering the Visual Space from Any Views'
  authors:
  - Haotong Lin
  - Sili Chen
  - Junhao Liew
  - Donny Y. Chen
  - Zhenyu Li
  - Guang Shi
  - Jiashi Feng
  - Bingyi Kang
  venue: arXiv
  year: 2025
  month: 11
  categories:
  - 3d-gaussian
  type: Research
  abstract: 'We present Depth Anything 3 (DA3), a model that predicts spatially consistent
    geometry from an arbitrary number of visual inputs, with or without known camera
    poses. In pursuit of minimal modeling, DA3 yields two key insights: a single plain
    transformer (e.g., vanilla DINO encoder) is sufficient as a backbone without architectural
    specialization, and a singular depth-ray prediction target obviates the need for
    complex multi-task learning. Through our teacher-student training paradigm, the
    model '
  links:
    paper: http://arxiv.org/abs/2511.10647v1
    code: ''
    project: ''
    video: ''
  arxiv_id: 2511.10647v1
  citation_count: 1
  starred: false
  date_added: '2025-11-16'
  notes: ''
  ai_summary: 'We present Depth Anything 3 (DA3), a model that predicts spatially
    consistent geometry from an arbitrary number of visual inputs, with or without
    known camera poses. In pursuit of minimal modeling, DA3 yields two key insights:
    a single plain transformer (e.g., vanilla DINO encoder) is sufficient as a backbone
    without architectural specialization, and a singular depth-ray prediction target
    obviates...'
  key_contributions:
  - We present Depth Anything 3 (DA3), a model that predicts spatially consistent
    geometry from an arbitrary number of visual inputs, with or without known camera
    poses.
  - 'In pursuit of minimal modeling, DA3 yields two key insights: a single plain transformer
    (e.'
  - g.
  relevance_score: 4.35
  influential_citation_count: 0
  citation_last_checked: '2025-12-01T02:51:20.252812'
- id: learning-to-tell-apart-weakly-supervised-video-ano-2025
  title: 'Learning to Tell Apart: Weakly Supervised Video Anomaly Detection via Disentangled
    Semantic Alignment'
  authors:
  - Wenti Yin
  - Huaxin Zhang
  - Xiang Wang
  - Yuqing Lu
  - Yicheng Zhang
  - Bingquan Gong
  - Jialong Zuo
  - Li Yu
  - Changxin Gao
  - Nong Sang
  venue: arXiv
  year: 2025
  month: 11
  categories:
  - self-supervised
  type: Research
  abstract: Recent advancements in weakly-supervised video anomaly detection have
    achieved remarkable performance by applying the multiple instance learning paradigm
    based on multimodal foundation models such as CLIP to highlight anomalous instances
    and classify categories. However, their objectives may tend to detect the most
    salient response segments, while neglecting to mine diverse normal patterns separated
    from anomalies, and are prone to category confusion due to similar appearance,
    leading to unsatis
  links:
    paper: http://arxiv.org/abs/2511.10334v1
    code: ''
    project: ''
    video: ''
  arxiv_id: 2511.10334v1
  citation_count: 0
  starred: false
  date_added: '2025-11-16'
  notes: ''
  ai_summary: Recent advancements in weakly-supervised video anomaly detection have
    achieved remarkable performance by applying the multiple instance learning paradigm
    based on multimodal foundation models such as CLIP to highlight anomalous instances
    and classify categories. However, their objectives may tend to detect the most
    salient response segments, while neglecting to mine diverse normal patterns separat...
  key_contributions:
  - Recent advancements in weakly-supervised video anomaly detection have achieved
    remarkable performance by applying the multiple instance learning paradigm based
    on multimodal foundation models such as CLIP to highlight anomalous instances
    and classify categories.
  - However, their objectives may tend to detect the most salient response segments,
    while neglecting to mine diverse normal patterns separated from anomalies, and
    are prone to category confusion due to similar appearance, leading to unsatisfactory
    fine-grained classification results.
  - Therefore, we propose a novel Disentangled Semantic Alignment Network (DSANet)
    to explicitly separate abnormal and normal features from coarse-grained and fine-grained
    aspects, enhancing the distinguishability.
  relevance_score: 4.3
  influential_citation_count: 0
  citation_last_checked: '2025-12-08T02:39:30.616729'
- id: omnivggt-omni-modality-driven-visual-geometry-grou-2025
  title: 'OmniVGGT: Omni-Modality Driven Visual Geometry Grounded'
  authors:
  - Haosong Peng
  - Hao Li
  - Yalun Dai
  - Yushi Lan
  - Yihang Luo
  - Tianyu Qi
  - Zhengshen Zhang
  - Yufeng Zhan
  - Junfei Zhang
  - Wenchao Xu
  venue: arXiv
  year: 2025
  month: 11
  categories:
  - 3d-gaussian
  type: Research
  abstract: 'General 3D foundation models have started to lead the trend of unifying
    diverse vision tasks, yet most assume RGB-only inputs and ignore readily available
    geometric cues (e.g., camera intrinsics, poses, and depth maps). To address this
    issue, we introduce OmniVGGT, a novel framework that can effectively benefit from
    an arbitrary number of auxiliary geometric modalities during both training and
    inference. In our framework, a GeoAdapter is proposed to encode depth and camera
    intrinsics/extrinsics '
  links:
    paper: http://arxiv.org/abs/2511.10560v1
    code: ''
    project: ''
    video: ''
  arxiv_id: 2511.10560v1
  citation_count: 0
  starred: false
  date_added: '2025-11-16'
  notes: ''
  ai_summary: General 3D foundation models have started to lead the trend of unifying
    diverse vision tasks, yet most assume RGB-only inputs and ignore readily available
    geometric cues (e.g., camera intrinsics, poses, and depth maps). To address this
    issue, we introduce OmniVGGT, a novel framework that can effectively benefit from
    an arbitrary number of auxiliary geometric modalities during both training and
    inf...
  key_contributions:
  - General 3D foundation models have started to lead the trend of unifying diverse
    vision tasks, yet most assume RGB-only inputs and ignore readily available geometric
    cues (e.
  - g.
  - ', camera intrinsics, poses, and depth maps).'
  relevance_score: 4.199999999999999
  influential_citation_count: 0
  citation_last_checked: '2025-12-08T02:39:32.824903'
- id: depth-consistent-3d-gaussian-splatting-via-physica-2025
  title: Depth-Consistent 3D Gaussian Splatting via Physical Defocus Modeling and
    Multi-View Geometric Supervision
  authors:
  - Yu Deng
  - Baozhu Zhao
  - Junyan Su
  - Xiaohan Zhang
  - Qi Liu
  venue: arXiv
  year: 2025
  month: 11
  categories:
  - 3d-gaussian
  - reconstruction
  type: Research
  abstract: 'Three-dimensional reconstruction in scenes with extreme depth variations
    remains challenging due to inconsistent supervisory signals between near-field
    and far-field regions. Existing methods fail to simultaneously address inaccurate
    depth estimation in distant areas and structural degradation in close-range regions.
    This paper proposes a novel computational framework that integrates depth-of-field
    supervision and multi-view consistency supervision to advance 3D Gaussian Splatting.
    Our approach '
  links:
    paper: http://arxiv.org/abs/2511.10316v1
    code: ''
    project: ''
    video: ''
  arxiv_id: 2511.10316v1
  citation_count: 0
  starred: false
  date_added: '2025-11-16'
  notes: ''
  ai_summary: Three-dimensional reconstruction in scenes with extreme depth variations
    remains challenging due to inconsistent supervisory signals between near-field
    and far-field regions. Existing methods fail to simultaneously address inaccurate
    depth estimation in distant areas and structural degradation in close-range regions.
    This paper proposes a novel computational framework that integrates depth-of-fiel...
  key_contributions:
  - Three-dimensional reconstruction in scenes with extreme depth variations remains
    challenging due to inconsistent supervisory signals between near-field and far-field
    regions.
  - Existing methods fail to simultaneously address inaccurate depth estimation in
    distant areas and structural degradation in close-range regions.
  - This paper proposes a novel computational framework that integrates depth-of-field
    supervision and multi-view consistency supervision to advance 3D Gaussian Splatting.
  relevance_score: 3.977966101694915
  influential_citation_count: 0
  citation_last_checked: '2025-12-08T02:39:35.029675'
- id: utility-of-pancreas-surface-lobularity-as-a-ct-bio-2025
  title: Utility of Pancreas Surface Lobularity as a CT Biomarker for Opportunistic
    Screening of Type 2 Diabetes
  authors:
  - Tejas Sudharshan Mathai
  - Anisa V. Prasad
  - Xinya Wang
  - Praveen T. S. Balamuralikrishna
  - Yan Zhuang
  - Abhinav Suri
  - Jianfei Liu
  - Perry J. Pickhardt
  - Ronald M. Summers
  venue: arXiv
  year: 2025
  month: 11
  categories:
  - 3d-gaussian
  type: Research
  abstract: 'Type 2 Diabetes Mellitus (T2DM) is a chronic metabolic disease that affects
    millions of people worldwide. Early detection is crucial as it can alter pancreas
    function through morphological changes and increased deposition of ectopic fat,
    eventually leading to organ damage. While studies have shown an association between
    T2DM and pancreas volume and fat content, the role of increased pancreatic surface
    lobularity (PSL) in patients with T2DM has not been fully investigated. In this
    pilot work, we '
  links:
    paper: http://arxiv.org/abs/2511.10484v1
    code: ''
    project: ''
    video: ''
  arxiv_id: 2511.10484v1
  citation_count: 0
  starred: false
  date_added: '2025-11-16'
  notes: ''
  ai_summary: Type 2 Diabetes Mellitus (T2DM) is a chronic metabolic disease that
    affects millions of people worldwide. Early detection is crucial as it can alter
    pancreas function through morphological changes and increased deposition of ectopic
    fat, eventually leading to organ damage. While studies have shown an association
    between T2DM and pancreas volume and fat content, the role of increased pancreatic
    sur...
  key_contributions:
  - Type 2 Diabetes Mellitus (T2DM) is a chronic metabolic disease that affects millions
    of people worldwide.
  - Early detection is crucial as it can alter pancreas function through morphological
    changes and increased deposition of ectopic fat, eventually leading to organ damage.
  - While studies have shown an association between T2DM and pancreas volume and fat
    content, the role of increased pancreatic surface lobularity (PSL) in patients
    with T2DM has not been fully investigated.
  relevance_score: 3.9194915254237284
- id: dermai-clinical-dermatology-acquisition-through-qu-2025
  title: 'DermAI: Clinical dermatology acquisition through quality-driven image collection
    for AI classification in mobile'
  authors:
  - Thales Bezerra
  - Emanoel Thyago
  - Kelvin Cunha
  - Rodrigo Abreu
  - F√°bio Papais
  - Francisco Mauro
  - Nat√°lia Lopes
  - √ârico Medeiros
  - J√©ssica Guido
  - Shirley Cruz
  venue: arXiv
  year: 2025
  month: 11
  categories:
  - medical-imaging
  type: Research
  abstract: 'AI-based dermatology adoption remains limited by biased datasets, variable
    image quality, and limited validation. We introduce DermAI, a lightweight, smartphone-based
    application that enables real-time capture, annotation, and classification of
    skin lesions during routine consultations. Unlike prior dermoscopy-focused tools,
    DermAI performs on-device quality checks, and local model adaptation. The DermAI
    clinical dataset, encompasses a wide range of skin tones, ethinicity and source
    devices. In '
  links:
    paper: http://arxiv.org/abs/2511.10367v1
    code: ''
    project: ''
    video: ''
  arxiv_id: 2511.10367v1
  citation_count: 0
  starred: false
  date_added: '2025-11-16'
  notes: ''
  ai_summary: AI-based dermatology adoption remains limited by biased datasets, variable
    image quality, and limited validation. We introduce DermAI, a lightweight, smartphone-based
    application that enables real-time capture, annotation, and classification of
    skin lesions during routine consultations. Unlike prior dermoscopy-focused tools,
    DermAI performs on-device quality checks, and local model adaptation. The...
  key_contributions:
  - AI-based dermatology adoption remains limited by biased datasets, variable image
    quality, and limited validation.
  - We introduce DermAI, a lightweight, smartphone-based application that enables
    real-time capture, annotation, and classification of skin lesions during routine
    consultations.
  - Unlike prior dermoscopy-focused tools, DermAI performs on-device quality checks,
    and local model adaptation.
  relevance_score: 3.85
  influential_citation_count: 0
  citation_last_checked: '2025-12-08T02:39:38.455104'
- id: revisiting-evaluation-of-deep-neural-networks-for--2025
  title: Revisiting Evaluation of Deep Neural Networks for Pedestrian Detection
  authors:
  - Patrick Feifel
  - Benedikt Franke
  - Frank Bonarens
  - Frank K√∂ster
  - Arne Raulf
  - Friedhelm Schwenker
  venue: arXiv
  year: 2025
  month: 11
  categories:
  - 3d-gaussian
  type: Research
  abstract: Reliable pedestrian detection represents a crucial step towards automated
    driving systems. However, the current performance benchmarks exhibit weaknesses.
    The currently applied metrics for various subsets of a validation dataset prohibit
    a realistic performance evaluation of a DNN for pedestrian detection. As image
    segmentation supplies fine-grained information about a street scene, it can serve
    as a starting point to automatically distinguish between different types of errors
    during the evaluat
  links:
    paper: http://arxiv.org/abs/2511.10308v1
    code: ''
    project: ''
    video: ''
  arxiv_id: 2511.10308v1
  citation_count: 0
  starred: false
  date_added: '2025-11-16'
  notes: ''
  ai_summary: Reliable pedestrian detection represents a crucial step towards automated
    driving systems. However, the current performance benchmarks exhibit weaknesses.
    The currently applied metrics for various subsets of a validation dataset prohibit
    a realistic performance evaluation of a DNN for pedestrian detection. As image
    segmentation supplies fine-grained information about a street scene, it can serve
    a...
  key_contributions:
  - Reliable pedestrian detection represents a crucial step towards automated driving
    systems.
  - However, the current performance benchmarks exhibit weaknesses.
  - The currently applied metrics for various subsets of a validation dataset prohibit
    a realistic performance evaluation of a DNN for pedestrian detection.
  relevance_score: 3.7033898305084745
- id: spot-sparsification-with-attention-dynamics-via-to-2025
  title: 'SPOT: Sparsification with Attention Dynamics via Token Relevance in Vision
    Transformers'
  authors:
  - Oded Schlesinger
  - Amirhossein Farzam
  - J. Matias Di Martino
  - Guillermo Sapiro
  venue: arXiv
  year: 2025
  month: 11
  categories:
  - 3d-gaussian
  type: Research
  abstract: While Vision Transformers (ViT) have demonstrated remarkable performance
    across diverse tasks, their computational demands are substantial, scaling quadratically
    with the number of processed tokens. Compact attention representations, reflecting
    token interaction distributions, can guide early detection and reduction of less
    salient tokens prior to attention computation. Motivated by this, we present SParsification
    with attentiOn dynamics via Token relevance (SPOT), a framework for early detectio
  links:
    paper: http://arxiv.org/abs/2511.10488v1
    code: ''
    project: ''
    video: ''
  arxiv_id: 2511.10488v1
  citation_count: 0
  starred: false
  date_added: '2025-11-16'
  notes: ''
  ai_summary: While Vision Transformers (ViT) have demonstrated remarkable performance
    across diverse tasks, their computational demands are substantial, scaling quadratically
    with the number of processed tokens. Compact attention representations, reflecting
    token interaction distributions, can guide early detection and reduction of less
    salient tokens prior to attention computation. Motivated by this, we prese...
  key_contributions:
  - While Vision Transformers (ViT) have demonstrated remarkable performance across
    diverse tasks, their computational demands are substantial, scaling quadratically
    with the number of processed tokens.
  - Compact attention representations, reflecting token interaction distributions,
    can guide early detection and reduction of less salient tokens prior to attention
    computation.
  - Motivated by this, we present SParsification with attentiOn dynamics via Token
    relevance (SPOT), a framework for early detection of redundant tokens within ViTs
    that leverages token embeddings, interactions, and attention dynamics across layers
    to infer token importance, resulting in a more context-aware and interpretable
    relevance detection process.
  relevance_score: 3.65
  influential_citation_count: 0
  citation_last_checked: '2025-12-08T02:39:41.757922'
- id: multitask-glocal-obia-mamba-for-sentinel-2-landcov-2025
  title: Multitask GLocal OBIA-Mamba for Sentinel-2 Landcover Mapping
  authors:
  - Zack Dewis
  - Yimin Zhu
  - Zhengsen Xu
  - Mabel Heffring
  - Saeid Taleghanidoozdoozan
  - Kaylee Xiao
  - Motasem Alkayid
  - Lincoln Linlin Xu
  venue: arXiv
  year: 2025
  month: 11
  categories:
  - 3d-gaussian
  type: Research
  abstract: Although Sentinel-2 based land use and land cover (LULC) classification
    is critical for various environmental monitoring applications, it is a very difficult
    task due to some key data challenges (e.g., spatial heterogeneity, context information,
    signature ambiguity). This paper presents a novel Multitask Glocal OBIA-Mamba
    (MSOM) for enhanced Sentinel-2 classification with the following contributions.
    First, an object-based image analysis (OBIA) Mamba model (OBIA-Mamba) is designed
    to reduce redu
  links:
    paper: http://arxiv.org/abs/2511.10604v1
    code: ''
    project: ''
    video: ''
  arxiv_id: 2511.10604v1
  citation_count: 0
  starred: false
  date_added: '2025-11-16'
  notes: ''
  ai_summary: Although Sentinel-2 based land use and land cover (LULC) classification
    is critical for various environmental monitoring applications, it is a very difficult
    task due to some key data challenges (e.g., spatial heterogeneity, context information,
    signature ambiguity). This paper presents a novel Multitask Glocal OBIA-Mamba
    (MSOM) for enhanced Sentinel-2 classification with the following contributio...
  key_contributions:
  - Although Sentinel-2 based land use and land cover (LULC) classification is critical
    for various environmental monitoring applications, it is a very difficult task
    due to some key data challenges (e.
  - g.
  - ', spatial heterogeneity, context information, signature ambiguity).'
  relevance_score: 3.6194915254237285
automation:
  arxiv_monitor:
    enabled: false
    keywords:
    - gaussian splatting
    - medical image
    - cardiac motion
    - self-supervised learning
    - 3D reconstruction
    check_frequency: daily
  filters:
    min_citation_count: 0
    venues:
    - CVPR
    - ICCV
    - ECCV
    - NeurIPS
    - ICML
    - ICLR
    - MICCAI
    - IPMI
    - ISBI
    - SIGGRAPH
  ai_features:
    summary_generation: false
    audio_generation: false
    qa_system: false
    mindmap_generation: false
  integrations:
    notebook_lm:
      enabled: false
      api_key: ''
    openai:
      enabled: false
      api_key: ''
      model: gpt-4
citation_history:
- date: '2025-11-17'
  papers:
    spot-sparsification-with-attention-dynamics-via-to-2025:
      citation_count: 0
      influential_count: 0
- date: '2025-11-24'
  papers:
    depth-anything-3-recovering-the-visual-space-from--2025:
      citation_count: 0
      influential_count: 0
- date: '2025-12-01'
  papers:
    gaussian-splatting-2023:
      citation_count: 5875
      influential_count: 1816
    depth-anything-3-recovering-the-visual-space-from--2025:
      citation_count: 1
      influential_count: 0
- date: '2025-12-08'
  papers:
    semanticvla-semantic-aligned-sparsification-and-en-2025:
      citation_count: 1
      influential_count: 0
    learning-to-tell-apart-weakly-supervised-video-ano-2025:
      citation_count: 0
      influential_count: 0
    omnivggt-omni-modality-driven-visual-geometry-grou-2025:
      citation_count: 0
      influential_count: 0
    depth-consistent-3d-gaussian-splatting-via-physica-2025:
      citation_count: 0
      influential_count: 0
    dermai-clinical-dermatology-acquisition-through-qu-2025:
      citation_count: 0
      influential_count: 0
    spot-sparsification-with-attention-dynamics-via-to-2025:
      citation_count: 0
      influential_count: 0
