{
  "fetched_at": "2025-12-30T00:26:32.865881",
  "total_papers": 100,
  "papers": [
    {
      "id": "2512.22120v1",
      "title": "See Less, See Right: Bi-directional Perceptual Shaping For Multimodal Reasoning",
      "authors": [
        "Shuoshuo Zhang",
        "Yizhen Zhang",
        "Jingjing Fu",
        "Lei Song",
        "Jiang Bian",
        "Yujiu Yang",
        "Rui Wang"
      ],
      "abstract": "Large vision-language models (VLMs) often benefit from intermediate visual cues, either injected via external tools or generated as latent visual tokens during reasoning, but these mechanisms still overlook fine-grained visual evidence (e.g., polylines in charts), generalize poorly across domains, and incur high inference-time cost. In this paper, we propose Bi-directional Perceptual Shaping (BiPS), which transforms question-conditioned masked views into bidirectional where-to-look signals that shape perception during training. BiPS first applies a KL-consistency constraint between the original image and an evidence-preserving view that keeps only question-relevant regions, encouraging coarse but complete coverage of supporting pixels. It then applies a KL-separation constraint between the original and an evidence-ablated view where critical pixels are masked so the image no longer supports the original answer, discouraging text-only shortcuts (i.e., answering from text alone) and enforcing fine-grained visual reliance. Across eight benchmarks, BiPS boosts Qwen2.5-VL-7B by 8.2% on average and shows strong out-of-domain generalization to unseen datasets and image types.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.22120v1",
        "pdf": "https://arxiv.org/pdf/2512.22120v1"
      },
      "arxiv_id": "2512.22120v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.22118v1",
      "title": "ProEdit: Inversion-based Editing From Prompts Done Right",
      "authors": [
        "Zhi Ouyang",
        "Dian Zheng",
        "Xiao-Ming Wu",
        "Jian-Jian Jiang",
        "Kun-Yu Lin",
        "Jingke Meng",
        "Wei-Shi Zheng"
      ],
      "abstract": "Inversion-based visual editing provides an effective and training-free way to edit an image or a video based on user instructions. Existing methods typically inject source image information during the sampling process to maintain editing consistency. However, this sampling strategy overly relies on source information, which negatively affects the edits in the target image (e.g., failing to change the subject's atributes like pose, number, or color as instructed). In this work, we propose ProEdit to address this issue both in the attention and the latent aspects. In the attention aspect, we introduce KV-mix, which mixes KV features of the source and the target in the edited region, mitigating the influence of the source image on the editing region while maintaining background consistency. In the latent aspect, we propose Latents-Shift, which perturbs the edited region of the source latent, eliminating the influence of the inverted latent on the sampling. Extensive experiments on several image and video editing benchmarks demonstrate that our method achieves SOTA performance. In addition, our design is plug-and-play, which can be seamlessly integrated into existing inversion and editing methods, such as RF-Solver, FireFlow and UniEdit.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.22118v1",
        "pdf": "https://arxiv.org/pdf/2512.22118v1"
      },
      "arxiv_id": "2512.22118v1",
      "comment": "Equal contributions from first two authors. Project page: https://isee-laboratory.github.io/ProEdit/ Code: https://github.com/iSEE-Laboratory/ProEdit",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2512.22113v1",
      "title": "Agentic Structured Graph Traversal for Root Cause Analysis of Code-related Incidents in Cloud Applications",
      "authors": [
        "Shengkun Cui",
        "Rahul Krishna",
        "Saurabh Jha",
        "Ravishankar K. Iyer"
      ],
      "abstract": "Cloud incidents pose major operational challenges in production, with unresolved production cloud incidents cost on average over $2M per hour. Prior research identifies code- and configuration-related issues as the predominant category of root causes in cloud incidents. This paper introduces PRAXIS, an orchestrator that manages and deploys an agentic workflow for diagnosing code- and configuration-caused cloud incidents. PRAXIS employs an LLM-driven structured traversal over two types of graph: (1) a service dependency graph (SDG) that captures microservice-level dependencies; and (2) a hammock-block program dependence graph (PDG) that captures code-level dependencies for each microservice. Together, these graphs encode microservice- and code-level dependencies and the LLM acts as a traversal policy over these graphs, moving between services and code dependencies to localize and explain failures. Compared to state-of-the-art ReAct baselines, PRAXIS improves RCA accuracy by up to 3.1x while reducing token consumption by 3.8x. PRAXIS is demonstrated on a set of 30 comprehensive real-world incidents that is being compiled into an RCA benchmark.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.DC",
      "links": {
        "paper": "http://arxiv.org/abs/2512.22113v1",
        "pdf": "https://arxiv.org/pdf/2512.22113v1"
      },
      "arxiv_id": "2512.22113v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.22106v1",
      "title": "Pruning as a Game: Equilibrium-Driven Sparsification of Neural Networks",
      "authors": [
        "Zubair Shah",
        "Noaman Khan"
      ],
      "abstract": "Neural network pruning is widely used to reduce model size and computational cost. Yet, most existing methods treat sparsity as an externally imposed constraint, enforced through heuristic importance scores or training-time regularization. In this work, we propose a fundamentally different perspective: pruning as an equilibrium outcome of strategic interaction among model components. We model parameter groups such as weights, neurons, or filters as players in a continuous non-cooperative game, where each player selects its level of participation in the network to balance contribution against redundancy and competition. Within this formulation, sparsity emerges naturally when continued participation becomes a dominated strategy at equilibrium. We analyze the resulting game and show that dominated players collapse to zero participation under mild conditions, providing a principled explanation for pruning behavior. Building on this insight, we derive a simple equilibrium-driven pruning algorithm that jointly updates network parameters and participation variables without relying on explicit importance scores. This work focuses on establishing a principled formulation and empirical validation of pruning as an equilibrium phenomenon, rather than exhaustive architectural or large-scale benchmarking. Experiments on standard benchmarks demonstrate that the proposed approach achieves competitive sparsity-accuracy trade-offs while offering an interpretable, theory-grounded alternative to existing pruning methods.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2512.22106v1",
        "pdf": "https://arxiv.org/pdf/2512.22106v1"
      },
      "arxiv_id": "2512.22106v1",
      "comment": "Preprint. Under review / to be submitted to a conference",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.22105v1",
      "title": "Learning Association via Track-Detection Matching for Multi-Object Tracking",
      "authors": [
        "Momir Adžemović"
      ],
      "abstract": "Multi-object tracking aims to maintain object identities over time by associating detections across video frames. Two dominant paradigms exist in literature: tracking-by-detection methods, which are computationally efficient but rely on handcrafted association heuristics, and end-to-end approaches, which learn association from data at the cost of higher computational complexity. We propose Track-Detection Link Prediction (TDLP), a tracking-by-detection method that performs per-frame association via link prediction between tracks and detections, i.e., by predicting the correct continuation of each track at every frame. TDLP is architecturally designed primarily for geometric features such as bounding boxes, while optionally incorporating additional cues, including pose and appearance. Unlike heuristic-based methods, TDLP learns association directly from data without handcrafted rules, while remaining modular and computationally efficient compared to end-to-end trackers. Extensive experiments on multiple benchmarks demonstrate that TDLP consistently surpasses state-of-the-art performance across both tracking-by-detection and end-to-end methods. Finally, we provide a detailed analysis comparing link prediction with metric learning-based association and show that link prediction is more effective, particularly when handling heterogeneous features such as detection bounding boxes. Our code is available at \\href{https://github.com/Robotmurlock/TDLP}{https://github.com/Robotmurlock/TDLP}.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.22105v1",
        "pdf": "https://arxiv.org/pdf/2512.22105v1"
      },
      "arxiv_id": "2512.22105v1",
      "comment": "14 pages (+4 for references), 8 tables, 4 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.22102v1",
      "title": "Explainable Multimodal Regression via Information Decomposition",
      "authors": [
        "Zhaozhao Ma",
        "Shujian Yu"
      ],
      "abstract": "Multimodal regression aims to predict a continuous target from heterogeneous input sources and typically relies on fusion strategies such as early or late fusion. However, existing methods lack principled tools to disentangle and quantify the individual contributions of each modality and their interactions, limiting the interpretability of multimodal fusion. We propose a novel multimodal regression framework grounded in Partial Information Decomposition (PID), which decomposes modality-specific representations into unique, redundant, and synergistic components. The basic PID framework is inherently underdetermined. To resolve this, we introduce inductive bias by enforcing Gaussianity in the joint distribution of latent representations and the transformed response variable (after inverse normal transformation), thereby enabling analytical computation of the PID terms. Additionally, we derive a closed-form conditional independence regularizer to promote the isolation of unique information within each modality. Experiments on six real-world datasets, including a case study on large-scale brain age prediction from multimodal neuroimaging data, demonstrate that our framework outperforms state-of-the-art methods in both predictive accuracy and interpretability, while also enabling informed modality selection for efficient inference. Implementation is available at https://github.com/zhaozhaoma/PIDReg.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.22102v1",
        "pdf": "https://arxiv.org/pdf/2512.22102v1"
      },
      "arxiv_id": "2512.22102v1",
      "comment": "Project Page: https://github.com/zhaozhaoma/PIDReg",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2512.22101v1",
      "title": "A2P-Vis: an Analyzer-to-Presenter Agentic Pipeline for Visual Insights Generation and Reporting",
      "authors": [
        "Shuyu Gan",
        "Renxiang Wang",
        "James Mooney",
        "Dongyeop Kang"
      ],
      "abstract": "Automating end-to-end data science pipeline with AI agents still stalls on two gaps: generating insightful, diverse visual evidence and assembling it into a coherent, professional report. We present A2P-Vis, a two-part, multi-agent pipeline that turns raw datasets into a high-quality data-visualization report. The Data Analyzer orchestrates profiling, proposes diverse visualization directions, generates and executes plotting code, filters low-quality figures with a legibility checker, and elicits candidate insights that are automatically scored for depth, correctness, specificity, depth and actionability. The Presenter then orders topics, composes chart-grounded narratives from the top-ranked insights, writes justified transitions, and revises the document for clarity and consistency, yielding a coherent, publication-ready report. Together, these agents convert raw data into curated materials (charts + vetted insights) and into a readable narrative without manual glue work. We claim that by coupling a quality-assured Analyzer with a narrative Presenter, A2P-Vis operationalizes co-analysis end-to-end, improving the real-world usefulness of automated data analysis for practitioners. For the complete dataset report, please see: https://www.visagent.org/api/output/f2a3486d-2c3b-4825-98d4-5af25a819f56.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.22101v1",
        "pdf": "https://arxiv.org/pdf/2512.22101v1"
      },
      "arxiv_id": "2512.22101v1",
      "comment": "3 pages, 3 figures; Accepted by 1st Workshop on GenAI, Agents and the Future of VIS as Mini-challenge paper and win the Honorable Mention award. Submit number is 7597 and the paper is archived on the workshop website: https://visxgenai.github.io/subs-2025/7597/7597-doc.pdf",
      "journal_ref": "1st Workshop on GenAI, Agents, and the Future of VIS (VIS x GenAI), November 2025, Vienna, Austria",
      "has_code": true
    },
    {
      "id": "2512.22100v1",
      "title": "Introducing TrGLUE and SentiTurca: A Comprehensive Benchmark for Turkish General Language Understanding and Sentiment Analysis",
      "authors": [
        "Duygu Altinok"
      ],
      "abstract": "Evaluating the performance of various model architectures, such as transformers, large language models (LLMs), and other NLP systems, requires comprehensive benchmarks that measure performance across multiple dimensions. Among these, the evaluation of natural language understanding (NLU) is particularly critical as it serves as a fundamental criterion for assessing model capabilities. Thus, it is essential to establish benchmarks that enable thorough evaluation and analysis of NLU abilities from diverse perspectives. While the GLUE benchmark has set a standard for evaluating English NLU, similar benchmarks have been developed for other languages, such as CLUE for Chinese, FLUE for French, and JGLUE for Japanese. However, no comparable benchmark currently exists for the Turkish language. To address this gap, we introduce TrGLUE, a comprehensive benchmark encompassing a variety of NLU tasks for Turkish. In addition, we present SentiTurca, a specialized benchmark for sentiment analysis. To support researchers, we also provide fine-tuning and evaluation code for transformer-based models, facilitating the effective use of these benchmarks. TrGLUE comprises Turkish-native corpora curated to mirror the domains and task formulations of GLUE-style evaluations, with labels obtained through a semi-automated pipeline that combines strong LLM-based annotation, cross-model agreement checks, and subsequent human validation. This design prioritizes linguistic naturalness, minimizes direct translation artifacts, and yields a scalable, reproducible workflow. With TrGLUE, our goal is to establish a robust evaluation framework for Turkish NLU, empower researchers with valuable resources, and provide insights into generating high-quality semi-automated datasets.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2512.22100v1",
        "pdf": "https://arxiv.org/pdf/2512.22100v1"
      },
      "arxiv_id": "2512.22100v1",
      "comment": "under review by Springer",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.22096v1",
      "title": "Yume-1.5: A Text-Controlled Interactive World Generation Model",
      "authors": [
        "Xiaofeng Mao",
        "Zhen Li",
        "Chuanhao Li",
        "Xiaojie Xu",
        "Kaining Ying",
        "Tong He",
        "Jiangmiao Pang",
        "Yu Qiao",
        "Kaipeng Zhang"
      ],
      "abstract": "Recent approaches have demonstrated the promise of using diffusion models to generate interactive and explorable worlds. However, most of these methods face critical challenges such as excessively large parameter sizes, reliance on lengthy inference steps, and rapidly growing historical context, which severely limit real-time performance and lack text-controlled generation capabilities. To address these challenges, we propose \\method, a novel framework designed to generate realistic, interactive, and continuous worlds from a single image or text prompt. \\method achieves this through a carefully designed framework that supports keyboard-based exploration of the generated worlds. The framework comprises three core components: (1) a long-video generation framework integrating unified context compression with linear attention; (2) a real-time streaming acceleration strategy powered by bidirectional attention distillation and an enhanced text embedding scheme; (3) a text-controlled method for generating world events. We have provided the codebase in the supplementary material.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.22096v1",
        "pdf": "https://arxiv.org/pdf/2512.22096v1"
      },
      "arxiv_id": "2512.22096v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.22088v1",
      "title": "Unifying Learning Dynamics and Generalization in Transformers Scaling Law",
      "authors": [
        "Chiwun Yang"
      ],
      "abstract": "The scaling law, a cornerstone of Large Language Model (LLM) development, predicts improvements in model performance with increasing computational resources. Yet, while empirically validated, its theoretical underpinnings remain poorly understood. This work formalizes the learning dynamics of transformer-based language models as an ordinary differential equation (ODE) system, then approximates this process to kernel behaviors. Departing from prior toy-model analyses, we rigorously analyze stochastic gradient descent (SGD) training for multi-layer transformers on sequence-to-sequence data with arbitrary data distribution, closely mirroring real-world conditions. Our analysis characterizes the convergence of generalization error to the irreducible risk as computational resources scale with data, especially during the optimization process.\n  We establish a theoretical upper bound on excess risk characterized by a distinct phase transition. In the initial optimization phase, the excess risk decays exponentially relative to the computational cost ${\\sf C}$. However, once a specific resource allocation threshold is crossed, the system enters a statistical phase, where the generalization error follows a power-law decay of $Θ(\\mathsf{C}^{-1/6})$. Beyond this unified framework, our theory derives isolated scaling laws for model size, training time, and dataset size, elucidating how each variable independently governs the upper bounds of generalization.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.22088v1",
        "pdf": "https://arxiv.org/pdf/2512.22088v1"
      },
      "arxiv_id": "2512.22088v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.22084v1",
      "title": "A Frobenius-Optimal Projection for Enforcing Linear Conservation in Learned Dynamical Models",
      "authors": [
        "John M. Mango",
        "Ronald Katende"
      ],
      "abstract": "We consider the problem of restoring linear conservation laws in data-driven linear dynamical models. Given a learned operator $\\widehat{A}$ and a full-rank constraint matrix $C$ encoding one or more invariants, we show that the matrix closest to $\\widehat{A}$ in the Frobenius norm and satisfying $C^\\top A = 0$ is the orthogonal projection $A^\\star = \\widehat{A} - C(C^\\top C)^{-1}C^\\top \\widehat{A}$. This correction is uniquely defined, low rank and fully determined by the violation $C^\\top \\widehat{A}$. In the single-invariant case it reduces to a rank-one update. We prove that $A^\\star$ enforces exact conservation while minimally perturbing the dynamics, and we verify these properties numerically on a Markov-type example. The projection provides an elementary and general mechanism for embedding exact invariants into any learned linear model.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "math.DS",
        "cs.LG",
        "math.NA"
      ],
      "primary_category": "math.DS",
      "links": {
        "paper": "http://arxiv.org/abs/2512.22084v1",
        "pdf": "https://arxiv.org/pdf/2512.22084v1"
      },
      "arxiv_id": "2512.22084v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.22069v1",
      "title": "Scaling Adversarial Training via Data Selection",
      "authors": [
        "Youran Ye",
        "Dejin Wang",
        "Ajinkya Bhandare"
      ],
      "abstract": "Projected Gradient Descent (PGD) is a strong and widely used first-order adversarial attack, yet its computational cost scales poorly, as all training samples undergo identical iterative inner-loop optimization despite contributing unequally to robustness. Motivated by this inefficiency, we propose \\emph{Selective Adversarial Training}, which perturbs only a subset of critical samples in each minibatch. Specifically, we introduce two principled selection criteria: (1) margin-based sampling, which prioritizes samples near the decision boundary, and (2) gradient-matching sampling, which selects samples whose gradients align with the dominant batch optimization direction. Adversarial examples are generated only for the selected subset, while the remaining samples are trained cleanly using a mixed objective. Experiments on MNIST and CIFAR-10 show that the proposed methods achieve robustness comparable to, or even exceeding, full PGD adversarial training, while reducing adversarial computation by up to $50\\%$, demonstrating that informed sample selection is sufficient for scalable adversarial robustness.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.22069v1",
        "pdf": "https://arxiv.org/pdf/2512.22069v1"
      },
      "arxiv_id": "2512.22069v1",
      "comment": "6 pages. Conference workshop paper",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.22066v1",
      "title": "Prefill vs. Decode Bottlenecks: SRAM-Frequency Tradeoffs and the Memory-Bandwidth Ceiling",
      "authors": [
        "Hannah Atmer",
        "Yuan Yao",
        "Thiemo Voigt",
        "Stefanos Kaxiras"
      ],
      "abstract": "Energy consumption dictates the cost and environmental impact of deploying Large Language Models. This paper investigates the impact of on-chip SRAM size and operating frequency on the energy efficiency and performance of LLM inference, focusing on the distinct behaviors of the compute-bound prefill and memory-bound decode phases. Our simulation methodology combines OpenRAM for energy modeling, LLMCompass for latency simulation, and ScaleSIM for systolic array operational intensity. Our findings show that total energy use is predominantly determined by SRAM size in both phases, with larger buffers significantly increasing static energy due to leakage, which is not offset by corresponding latency benefits. We quantitatively explore the memory-bandwidth bottleneck, demonstrating that while high operating frequencies reduce prefill latency, their positive impact on memory-bound decode latency is capped by the external memory bandwidth. Counter-intuitively, high compute frequency can reduce total energy by reducing execution time and consequently decreasing static energy consumption more than the resulting dynamic power increase. We identify an optimal hardware configuration for the simulated workload: high operating frequencies (1200MHz-1400MHz) and a small local buffer size of 32KB to 64KB. This combination achieves the best energy-delay product, balancing low latency with high energy efficiency. Furthermore, we demonstrate how memory bandwidth acts as a performance ceiling, and that increasing compute frequency only yields performance gains up to the point where the workload becomes memory-bound. This analysis provides concrete architectural insights for designing energy-efficient LLM accelerators, especially for datacenters aiming to minimize their energy overhead.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.AR",
        "cs.LG",
        "cs.PF"
      ],
      "primary_category": "cs.AR",
      "links": {
        "paper": "http://arxiv.org/abs/2512.22066v1",
        "pdf": "https://arxiv.org/pdf/2512.22066v1"
      },
      "arxiv_id": "2512.22066v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.22065v1",
      "title": "StreamAvatar: Streaming Diffusion Models for Real-Time Interactive Human Avatars",
      "authors": [
        "Zhiyao Sun",
        "Ziqiao Peng",
        "Yifeng Ma",
        "Yi Chen",
        "Zhengguang Zhou",
        "Zixiang Zhou",
        "Guozhen Zhang",
        "Youliang Zhang",
        "Yuan Zhou",
        "Qinglin Lu",
        "Yong-Jin Liu"
      ],
      "abstract": "Real-time, streaming interactive avatars represent a critical yet challenging goal in digital human research. Although diffusion-based human avatar generation methods achieve remarkable success, their non-causal architecture and high computational costs make them unsuitable for streaming. Moreover, existing interactive approaches are typically limited to head-and-shoulder region, limiting their ability to produce gestures and body motions. To address these challenges, we propose a two-stage autoregressive adaptation and acceleration framework that applies autoregressive distillation and adversarial refinement to adapt a high-fidelity human video diffusion model for real-time, interactive streaming. To ensure long-term stability and consistency, we introduce three key components: a Reference Sink, a Reference-Anchored Positional Re-encoding (RAPR) strategy, and a Consistency-Aware Discriminator. Building on this framework, we develop a one-shot, interactive, human avatar model capable of generating both natural talking and listening behaviors with coherent gestures. Extensive experiments demonstrate that our method achieves state-of-the-art performance, surpassing existing approaches in generation quality, real-time efficiency, and interaction naturalness. Project page: https://streamavatar.github.io .",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.22065v1",
        "pdf": "https://arxiv.org/pdf/2512.22065v1"
      },
      "arxiv_id": "2512.22065v1",
      "comment": "Project page: https://streamavatar.github.io",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2512.22055v1",
      "title": "Why Smooth Stability Assumptions Fail for ReLU Learning",
      "authors": [
        "Ronald Katende"
      ],
      "abstract": "Stability analyses of modern learning systems are frequently derived under smoothness assumptions that are violated by ReLU-type nonlinearities. In this note, we isolate a minimal obstruction by showing that no uniform smoothness-based stability proxy such as gradient Lipschitzness or Hessian control can hold globally for ReLU networks, even in simple settings where training trajectories appear empirically stable. We give a concrete counterexample demonstrating the failure of classical stability bounds and identify a minimal generalized derivative condition under which stability statements can be meaningfully restored. The result clarifies why smooth approximations of ReLU can be misleading and motivates nonsmooth-aware stability frameworks.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.LG",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.22055v1",
        "pdf": "https://arxiv.org/pdf/2512.22055v1"
      },
      "arxiv_id": "2512.22055v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.22047v1",
      "title": "MAI-UI Technical Report: Real-World Centric Foundation GUI Agents",
      "authors": [
        "Hanzhang Zhou",
        "Xu Zhang",
        "Panrong Tong",
        "Jianan Zhang",
        "Liangyu Chen",
        "Quyu Kong",
        "Chenglin Cai",
        "Chen Liu",
        "Yue Wang",
        "Jingren Zhou",
        "Steven Hoi"
      ],
      "abstract": "The development of GUI agents could revolutionize the next generation of human-computer interaction. Motivated by this vision, we present MAI-UI, a family of foundation GUI agents spanning the full spectrum of sizes, including 2B, 8B, 32B, and 235B-A22B variants. We identify four key challenges to realistic deployment: the lack of native agent-user interaction, the limits of UI-only operation, the absence of a practical deployment architecture, and brittleness in dynamic environments. MAI-UI addresses these issues with a unified methodology: a self-evolving data pipeline that expands the navigation data to include user interaction and MCP tool calls, a native device-cloud collaboration system routes execution by task state, and an online RL framework with advanced optimizations to scale parallel environments and context length. MAI-UI establishes new state-of-the-art across GUI grounding and mobile navigation. On grounding benchmarks, it reaches 73.5% on ScreenSpot-Pro, 91.3% on MMBench GUI L2, 70.9% on OSWorld-G, and 49.2% on UI-Vision, surpassing Gemini-3-Pro and Seed1.8 on ScreenSpot-Pro. On mobile GUI navigation, it sets a new SOTA of 76.7% on AndroidWorld, surpassing UI-Tars-2, Gemini-2.5-Pro and Seed1.8. On MobileWorld, MAI-UI obtains 41.7% success rate, significantly outperforming end-to-end GUI models and competitive with Gemini-3-Pro based agentic frameworks. Our online RL experiments show significant gains from scaling parallel environments from 32 to 512 (+5.2 points) and increasing environment step budget from 15 to 50 (+4.3 points). Finally, the native device-cloud collaboration system improves on-device performance by 33%, reduces cloud model calls by over 40%, and preserves user privacy.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.22047v1",
        "pdf": "https://arxiv.org/pdf/2512.22047v1"
      },
      "arxiv_id": "2512.22047v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.22046v1",
      "title": "Backdoor Attacks on Prompt-Driven Video Segmentation Foundation Models",
      "authors": [
        "Zongmin Zhang",
        "Zhen Sun",
        "Yifan Liao",
        "Wenhan Dong",
        "Xinlei He",
        "Xingshuo Han",
        "Shengmin Xu",
        "Xinyi Huang"
      ],
      "abstract": "Prompt-driven Video Segmentation Foundation Models (VSFMs) such as SAM2 are increasingly deployed in applications like autonomous driving and digital pathology, raising concerns about backdoor threats. Surprisingly, we find that directly transferring classic backdoor attacks (e.g., BadNet) to VSFMs is almost ineffective, with ASR below 5\\%. To understand this, we study encoder gradients and attention maps and observe that conventional training keeps gradients for clean and triggered samples largely aligned, while attention still focuses on the true object, preventing the encoder from learning a distinct trigger-related representation. To address this challenge, we propose BadVSFM, the first backdoor framework tailored to prompt-driven VSFMs. BadVSFM uses a two-stage strategy: (1) steer the image encoder so triggered frames map to a designated target embedding while clean frames remain aligned with a clean reference encoder; (2) train the mask decoder so that, across prompt types, triggered frame-prompt pairs produce a shared target mask, while clean outputs stay close to a reference decoder. Extensive experiments on two datasets and five VSFMs show that BadVSFM achieves strong, controllable backdoor effects under diverse triggers and prompts while preserving clean segmentation quality. Ablations over losses, stages, targets, trigger settings, and poisoning rates demonstrate robustness to reasonable hyperparameter changes and confirm the necessity of the two-stage design. Finally, gradient-conflict analysis and attention visualizations show that BadVSFM separates triggered and clean representations and shifts attention to trigger regions, while four representative defenses remain largely ineffective, revealing an underexplored vulnerability in current VSFMs.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.CV",
        "cs.CR"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.22046v1",
        "pdf": "https://arxiv.org/pdf/2512.22046v1"
      },
      "arxiv_id": "2512.22046v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.22031v1",
      "title": "From In Silico to In Vitro: Evaluating Molecule Generative Models for Hit Generation",
      "authors": [
        "Nagham Osman",
        "Vittorio Lembo",
        "Giovanni Bottegoni",
        "Laura Toni"
      ],
      "abstract": "Hit identification is a critical yet resource-intensive step in the drug discovery pipeline, traditionally relying on high-throughput screening of large compound libraries. Despite advancements in virtual screening, these methods remain time-consuming and costly. Recent progress in deep learning has enabled the development of generative models capable of learning complex molecular representations and generating novel compounds de novo. However, using ML to replace the entire drug-discovery pipeline is highly challenging. In this work, we rather investigate whether generative models can replace one step of the pipeline: hit-like molecule generation. To the best of our knowledge, this is the first study to explicitly frame hit-like molecule generation as a standalone task and empirically test whether generative models can directly support this stage of the drug discovery pipeline. Specifically, we investigate if such models can be trained to generate hit-like molecules, enabling direct incorporation into, or even substitution of, traditional hit identification workflows. We propose an evaluation framework tailored to this task, integrating physicochemical, structural, and bioactivity-related criteria within a multi-stage filtering pipeline that defines the hit-like chemical space. Two autoregressive and one diffusion-based generative models were benchmarked across various datasets and training settings, with outputs assessed using standard metrics and target-specific docking scores. Our results show that these models can generate valid, diverse, and biologically relevant compounds across multiple targets, with a few selected GSK-3$β$ hits synthesized and confirmed active in vitro. We also identify key limitations in current evaluation metrics and available training data.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.22031v1",
        "pdf": "https://arxiv.org/pdf/2512.22031v1"
      },
      "arxiv_id": "2512.22031v1",
      "comment": "",
      "journal_ref": "NeurIPS 2025 AI for Science Workshop",
      "has_code": false
    },
    {
      "id": "2512.22029v1",
      "title": "LibContinual: A Comprehensive Library towards Realistic Continual Learning",
      "authors": [
        "Wenbin Li",
        "Shangge Liu",
        "Borui Kang",
        "Yiyang Chen",
        "KaXuan Lew",
        "Yang Chen",
        "Yinghuan Shi",
        "Lei Wang",
        "Yang Gao",
        "Jiebo Luo"
      ],
      "abstract": "A fundamental challenge in Continual Learning (CL) is catastrophic forgetting, where adapting to new tasks degrades the performance on previous ones. While the field has evolved with diverse methods, this rapid surge in diverse methodologies has culminated in a fragmented research landscape. The lack of a unified framework, including inconsistent implementations, conflicting dependencies, and varying evaluation protocols, makes fair comparison and reproducible research increasingly difficult. To address this challenge, we propose LibContinual, a comprehensive and reproducible library designed to serve as a foundational platform for realistic CL. Built upon a high-cohesion, low-coupling modular architecture, LibContinual integrates 19 representative algorithms across five major methodological categories, providing a standardized execution environment. Meanwhile, leveraging this unified framework, we systematically identify and investigate three implicit assumptions prevalent in mainstream evaluation: (1) offline data accessibility, (2) unregulated memory resources, and (3) intra-task semantic homogeneity. We argue that these assumptions often overestimate the real-world applicability of CL methods. Through our comprehensive analysis using strict online CL settings, a novel unified memory budget protocol, and a proposed category-randomized setting, we reveal significant performance drops in many representative CL methods when subjected to these real-world constraints. Our study underscores the necessity of resource-aware and semantically robust CL strategies, and offers LibContinual as a foundational toolkit for future research in realistic continual learning. The source code is available from \\href{https://github.com/RL-VIG/LibContinual}{https://github.com/RL-VIG/LibContinual}.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.22029v1",
        "pdf": "https://arxiv.org/pdf/2512.22029v1"
      },
      "arxiv_id": "2512.22029v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.22027v1",
      "title": "Patch-Discontinuity Mining for Generalized Deepfake Detection",
      "authors": [
        "Huanhuan Yuan",
        "Yang Ping",
        "Zhengqin Xu",
        "Junyi Cao",
        "Shuai Jia",
        "Chao Ma"
      ],
      "abstract": "The rapid advancement of generative artificial intelligence has enabled the creation of highly realistic fake facial images, posing serious threats to personal privacy and the integrity of online information. Existing deepfake detection methods often rely on handcrafted forensic cues and complex architectures, achieving strong performance in intra-domain settings but suffering significant degradation when confronted with unseen forgery patterns. In this paper, we propose GenDF, a simple yet effective framework that transfers a powerful large-scale vision model to the deepfake detection task with a compact and neat network design. GenDF incorporates deepfake-specific representation learning to capture discriminative patterns between real and fake facial images, feature space redistribution to mitigate distribution mismatch, and a classification-invariant feature augmentation strategy to enhance generalization without introducing additional trainable parameters. Extensive experiments demonstrate that GenDF achieves state-of-the-art generalization performance in cross-domain and cross-manipulation settings while requiring only 0.28M trainable parameters, validating the effectiveness and efficiency of the proposed framework.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.22027v1",
        "pdf": "https://arxiv.org/pdf/2512.22027v1"
      },
      "arxiv_id": "2512.22027v1",
      "comment": "Our paper was accepted by the IEEE Transactions on Multimedia",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.22024v1",
      "title": "Direction Finding with Sparse Arrays Based on Variable Window Size Spatial Smoothing",
      "authors": [
        "Wesley S. Leite",
        "Rodrigo C. de Lamare",
        "Yuriy Zakharov",
        "Wei Liu",
        "Martin Haardt"
      ],
      "abstract": "In this work, we introduce a variable window size (VWS) spatial smoothing framework that enhances coarray-based direction of arrival (DOA) estimation for sparse linear arrays. By compressing the smoothing aperture, the proposed VWS Coarray MUSIC (VWS-CA-MUSIC) and VWS Coarray root-MUSIC (VWS-CA-rMUSIC) algorithms replace part of the perturbed rank-one outer products in the smoothed coarray data with unperturbed low-rank additional terms, increasing the separation between signal and noise subspaces, while preserving the signal subspace span. We also derive the bounds that guarantees identifiability, by limiting the values that can be assumed by the compression parameter. Simulations with sparse geometries reveal significant performance improvements and complexity savings relative to the fixed-window coarray MUSIC method.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.22024v1",
        "pdf": "https://arxiv.org/pdf/2512.22024v1"
      },
      "arxiv_id": "2512.22024v1",
      "comment": "2 figures, 5 pages",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.22022v1",
      "title": "Meta-Learning-Based Handover Management in NextG O-RAN",
      "authors": [
        "Michail Kalntis",
        "George Iosifidis",
        "José Suárez-Varela",
        "Andra Lutu",
        "Fernando A. Kuipers"
      ],
      "abstract": "While traditional handovers (THOs) have served as a backbone for mobile connectivity, they increasingly suffer from failures and delays, especially in dense deployments and high-frequency bands. To address these limitations, 3GPP introduced Conditional Handovers (CHOs) that enable proactive cell reservations and user-driven execution. However, both handover (HO) types present intricate trade-offs in signaling, resource usage, and reliability. This paper presents unique, countrywide mobility management datasets from a top-tier mobile network operator (MNO) that offer fresh insights into these issues and call for adaptive and robust HO control in next-generation networks. Motivated by these findings, we propose CONTRA, a framework that, for the first time, jointly optimizes THOs and CHOs within the O-RAN architecture. We study two variants of CONTRA: one where users are a priori assigned to one of the HO types, reflecting distinct service or user-specific requirements, as well as a more dynamic formulation where the controller decides on-the-fly the HO type, based on system conditions and needs. To this end, it relies on a practical meta-learning algorithm that adapts to runtime observations and guarantees performance comparable to an oracle with perfect future information (universal no-regret). CONTRA is specifically designed for near-real-time deployment as an O-RAN xApp and aligns with the 6G goals of flexible and intelligent control. Extensive evaluations leveraging crowdsourced datasets show that CONTRA improves user throughput and reduces both THO and CHO switching costs, outperforming 3GPP-compliant and Reinforcement Learning (RL) baselines in dynamic and real-world scenarios.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "links": {
        "paper": "http://arxiv.org/abs/2512.22022v1",
        "pdf": "https://arxiv.org/pdf/2512.22022v1"
      },
      "arxiv_id": "2512.22022v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.22016v1",
      "title": "SketchPlay: Intuitive Creation of Physically Realistic VR Content with Gesture-Driven Sketching",
      "authors": [
        "Xiangwen Zhang",
        "Xiaowei Dai",
        "Runnan Chen",
        "Xiaoming Chen",
        "Zeke Zexi Hu"
      ],
      "abstract": "Creating physically realistic content in VR often requires complex modeling tools or predefined 3D models, textures, and animations, which present significant barriers for non-expert users. In this paper, we propose SketchPlay, a novel VR interaction framework that transforms humans' air-drawn sketches and gestures into dynamic, physically realistic scenes, making content creation intuitive and playful like drawing. Specifically, sketches capture the structure and spatial arrangement of objects and scenes, while gestures convey physical cues such as velocity, direction, and force that define movement and behavior. By combining these complementary forms of input, SketchPlay captures both the structure and dynamics of user-created content, enabling the generation of a wide range of complex physical phenomena, such as rigid body motion, elastic deformation, and cloth dynamics. Experimental results demonstrate that, compared to traditional text-driven methods, SketchPlay offers significant advantages in expressiveness, and user experience. By providing an intuitive and engaging creation process, SketchPlay lowers the entry barrier for non-expert users and shows strong potential for applications in education, art, and immersive storytelling.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.HC",
        "cs.CV"
      ],
      "primary_category": "cs.HC",
      "links": {
        "paper": "http://arxiv.org/abs/2512.22016v1",
        "pdf": "https://arxiv.org/pdf/2512.22016v1"
      },
      "arxiv_id": "2512.22016v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.22014v1",
      "title": "HWL-HIN: A Hypergraph-Level Hypergraph Isomorphism Network as Powerful as the Hypergraph Weisfeiler-Lehman Test with Application to Higher-Order Network Robustness",
      "authors": [
        "Chengyu Tian",
        "Wenbin Pei"
      ],
      "abstract": "Robustness in complex systems is of significant engineering and economic importance. However, conventional attack-based a posteriori robustness assessments incur prohibitive computational overhead. Recently, deep learning methods, such as Convolutional Neural Networks (CNNs) and Graph Neural Networks (GNNs), have been widely employed as surrogates for rapid robustness prediction. Nevertheless, these methods neglect the complex higher-order correlations prevalent in real-world systems, which are naturally modeled as hypergraphs. Although Hypergraph Neural Networks (HGNNs) have been widely adopted for hypergraph learning, their topological expressive power has not yet reached the theoretical upper bound. To address this limitation, inspired by Graph Isomorphism Networks, this paper proposes a hypergraph-level Hypergraph Isomorphism Network framework. Theoretically, this approach is proven to possess an expressive power strictly equivalent to the Hypergraph Weisfeiler-Lehman test and is applied to predict hypergraph robustness. Experimental results demonstrate that while maintaining superior efficiency in training and prediction, the proposed method not only outperforms existing graph-based models but also significantly surpasses conventional HGNNs in tasks that prioritize topological structure representation.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.22014v1",
        "pdf": "https://arxiv.org/pdf/2512.22014v1"
      },
      "arxiv_id": "2512.22014v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.22010v1",
      "title": "LongFly: Long-Horizon UAV Vision-and-Language Navigation with Spatiotemporal Context Integration",
      "authors": [
        "Wen Jiang",
        "Li Wang",
        "Kangyao Huang",
        "Wei Fan",
        "Jinyuan Liu",
        "Shaoyu Liu",
        "Hongwei Duan",
        "Bin Xu",
        "Xiangyang Ji"
      ],
      "abstract": "Unmanned aerial vehicles (UAVs) are crucial tools for post-disaster search and rescue, facing challenges such as high information density, rapid changes in viewpoint, and dynamic structures, especially in long-horizon navigation. However, current UAV vision-and-language navigation(VLN) methods struggle to model long-horizon spatiotemporal context in complex environments, resulting in inaccurate semantic alignment and unstable path planning. To this end, we propose LongFly, a spatiotemporal context modeling framework for long-horizon UAV VLN. LongFly proposes a history-aware spatiotemporal modeling strategy that transforms fragmented and redundant historical data into structured, compact, and expressive representations. First, we propose the slot-based historical image compression module, which dynamically distills multi-view historical observations into fixed-length contextual representations. Then, the spatiotemporal trajectory encoding module is introduced to capture the temporal dynamics and spatial structure of UAV trajectories. Finally, to integrate existing spatiotemporal context with current observations, we design the prompt-guided multimodal integration module to support time-based reasoning and robust waypoint prediction. Experimental results demonstrate that LongFly outperforms state-of-the-art UAV VLN baselines by 7.89\\% in success rate and 6.33\\% in success weighted by path length, consistently across both seen and unseen environments.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.22010v1",
        "pdf": "https://arxiv.org/pdf/2512.22010v1"
      },
      "arxiv_id": "2512.22010v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.22009v1",
      "title": "iSHIFT: Lightweight Slow-Fast GUI Agent with Adaptive Perception",
      "authors": [
        "Sarthak Mehrotra",
        "Sairam V C Rebbapragada",
        "Mani Hemanth Reddy Bonthu",
        "Vineeth N Balasubramanian"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) show strong potential for interpreting and interacting with complex, pixel-rich Graphical User Interface (GUI) environments. However, building agents that are both efficient for high-level tasks and precise for fine-grained interactions remains challenging. GUI agents must perform routine actions efficiently while also handling tasks that demand exact visual grounding, yet existing approaches struggle when accuracy depends on identifying specific interface elements. These MLLMs also remain large and cannot adapt their reasoning depth to the task at hand. In this work, we introduce iSHIFT: Implicit Slow-fast Hybrid Inference with Flexible Tokens, a lightweight agent that integrates latent thinking (implicit chain-of-thought) with a perception control module. iSHIFT enables an MLLM to switch between a slow mode, which leverages detailed visual grounding for high precision and a fast mode that uses global cues for efficiency. Special perception tokens guide attention to relevant screen regions, allowing the model to decide both how to reason and where to focus. Despite its compact 2.5B size, iSHIFT matches state-of-the-art performance on multiple benchmark datasets.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.22009v1",
        "pdf": "https://arxiv.org/pdf/2512.22009v1"
      },
      "arxiv_id": "2512.22009v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.22007v1",
      "title": "DuaDeep-SeqAffinity: Dual-Stream Deep Learning Framework for Sequence-Only Antigen-Antibody Affinity Prediction",
      "authors": [
        "Aicha Boutorh",
        "Soumia Bouyahiaoui",
        "Sara Belhadj",
        "Nour El Yakine Guendouz",
        "Manel Kara Laouar"
      ],
      "abstract": "Predicting the binding affinity between antigens and antibodies is fundamental to drug discovery and vaccine development. Traditional computational approaches often rely on experimentally determined 3D structures, which are scarce and computationally expensive to obtain. This paper introduces DuaDeep-SeqAffinity, a novel sequence-only deep learning framework that predicts affinity scores solely from their amino acid sequences using a dual-stream hybrid architecture. Our approach leverages pre-trained ESM-2 protein language model embeddings, combining 1D Convolutional Neural Networks (CNNs) for local motif detection with Transformer encoders for global contextual representation. A subsequent fusion module integrates these multi-faceted features, which are then passed to a fully connected network for final score regression. Experimental results demonstrate that DuaDeep-SeqAffinity significantly outperforms individual architectural components and existing state-of-the-art (SOTA) methods. DuaDeep achieved a superior Pearson correlation of 0.688, an R^2 of 0.460, and a Root Mean Square Error (RMSE) of 0.737, surpassing single-branch variants ESM-CNN and ESM-Transformer. Notably, the model achieved an Area Under the Curve (AUC) of 0.890, outperforming sequence-only benchmarks and even surpassing structure-sequence hybrid models. These findings prove that high-fidelity sequence embeddings can capture essential binding patterns typically reserved for structural modeling. By eliminating the reliance on 3D structures, DuaDeep-SeqAffinity provides a highly scalable and efficient solution for high-throughput screening of vast sequence libraries, significantly accelerating the therapeutic discovery pipeline.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.22007v1",
        "pdf": "https://arxiv.org/pdf/2512.22007v1"
      },
      "arxiv_id": "2512.22007v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21999v1",
      "title": "Look Closer! An Adversarial Parametric Editing Framework for Hallucination Mitigation in VLMs",
      "authors": [
        "Jiayu Hu",
        "Beibei Li",
        "Jiangwei Xia",
        "Yanjun Qin",
        "Bing Ji",
        "Zhongshi He"
      ],
      "abstract": "While Vision-Language Models (VLMs) have garnered increasing attention in the AI community due to their promising practical applications, they exhibit persistent hallucination issues, generating outputs misaligned with visual inputs. Recent studies attribute these hallucinations to VLMs' over-reliance on linguistic priors and insufficient visual feature integration, proposing heuristic decoding calibration strategies to mitigate them. However, the non-trainable nature of these strategies inherently limits their optimization potential. To this end, we propose an adversarial parametric editing framework for Hallucination mitigation in VLMs, which follows an \\textbf{A}ctivate-\\textbf{L}ocate-\\textbf{E}dit \\textbf{A}dversarially paradigm. Specifically, we first construct an activation dataset that comprises grounded responses (positive samples attentively anchored in visual features) and hallucinatory responses (negative samples reflecting LLM prior bias and internal knowledge artifacts). Next, we identify critical hallucination-prone parameter clusters by analyzing differential hidden states of response pairs. Then, these clusters are fine-tuned using prompts injected with adversarial tuned prefixes that are optimized to maximize visual neglect, thereby forcing the model to prioritize visual evidence over inherent parametric biases. Evaluations on both generative and discriminative VLM tasks demonstrate the significant effectiveness of ALEAHallu in alleviating hallucinations. Our code is available at https://github.com/hujiayu1223/ALEAHallu.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21999v1",
        "pdf": "https://arxiv.org/pdf/2512.21999v1"
      },
      "arxiv_id": "2512.21999v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21988v1",
      "title": "The Color-Clinical Decoupling: Why Perceptual Calibration Fails Clinical Biomarkers in Smartphone Dermatology",
      "authors": [
        "Sungwoo Kang"
      ],
      "abstract": "Smartphone-based tele-dermatology assumes that colorimetric calibration ensures clinical reliability, yet this remains untested for underrepresented skin phototypes. We investigated whether standard calibration translates to reliable clinical biomarkers using 43,425 images from 965 Korean subjects (Fitzpatrick III-IV) across DSLR, tablet, and smartphone devices. While Linear Color Correction Matrix (CCM) normalization reduced color error by 67-77% -- achieving near-clinical accuracy (Delta E < 2.3) -- this success did not translate to biomarker reliability.\n  We identify a phenomenon termed \"color-clinical decoupling\": despite perceptual accuracy, the Individual Typology Angle (ITA) showed poor inter-device agreement (ICC = 0.40), while the Melanin Index achieved good agreement (ICC = 0.77). This decoupling is driven by the ITA formula's sensitivity to b* channel noise and is further compounded by anatomical variance. Facial region accounts for 25.2% of color variance -- 3.6x greater than device effects (7.0%) -- challenging the efficacy of single-patch calibration. Our results demonstrate that current colorimetric standards are insufficient for clinical-grade biomarker extraction, necessitating region-aware protocols for mobile dermatology.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "eess.IV",
        "cs.CV",
        "q-bio.QM"
      ],
      "primary_category": "eess.IV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21988v1",
        "pdf": "https://arxiv.org/pdf/2512.21988v1"
      },
      "arxiv_id": "2512.21988v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21985v1",
      "title": "LVLM-Aided Alignment of Task-Specific Vision Models",
      "authors": [
        "Alexander Koebler",
        "Lukas Kuhn",
        "Ingo Thon",
        "Florian Buettner"
      ],
      "abstract": "In high-stakes domains, small task-specific vision models are crucial due to their low computational requirements and the availability of numerous methods to explain their results. However, these explanations often reveal that the models do not align well with human domain knowledge, relying instead on spurious correlations. This might result in brittle behavior once deployed in the real-world. To address this issue, we introduce a novel and efficient method for aligning small task-specific vision models with human domain knowledge by leveraging the generalization capabilities of a Large Vision Language Model (LVLM). Our LVLM-Aided Visual Alignment (LVLM-VA) method provides a bidirectional interface that translates model behavior into natural language and maps human class-level specifications to image-level critiques, enabling effective interaction between domain experts and the model. Our method demonstrates substantial improvement in aligning model behavior with human specifications, as validated on both synthetic and real-world datasets. We show that it effectively reduces the model's dependence on spurious features and on group-specific biases, without requiring fine-grained feedback.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21985v1",
        "pdf": "https://arxiv.org/pdf/2512.21985v1"
      },
      "arxiv_id": "2512.21985v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21984v1",
      "title": "A Lightweight Multi-Scale Attention Framework for Real-Time Spinal Endoscopic Instance Segmentation",
      "authors": [
        "Qi Lai",
        "JunYan Li",
        "Qiang Cai",
        "Lei Wang",
        "Tao Yan",
        "XiaoKun Liang"
      ],
      "abstract": "Real-time instance segmentation for spinal endoscopy is important for identifying and protecting critical anatomy during surgery, but it is difficult because of the narrow field of view, specular highlights, smoke/bleeding, unclear boundaries, and large scale changes. Deployment is also constrained by limited surgical hardware, so the model must balance accuracy and speed and remain stable under small-batch (even batch-1) training. We propose LMSF-A, a lightweight multi-scale attention framework co-designed across backbone, neck, and head. The backbone uses a C2f-Pro module that combines RepViT-style re-parameterized convolution (RVB) with efficient multi-scale attention (EMA), enabling multi-branch training while collapsing into a single fast path for inference. The neck improves cross-scale consistency and boundary detail using Scale-Sequence Feature Fusion (SSFF) and Triple Feature Encoding (TFE), which strengthens high-resolution features. The head adopts a Lightweight Multi-task Shared Head (LMSH) with shared convolutions and GroupNorm to reduce parameters and support batch-1 stability. We also release the clinically reviewed PELD dataset (61 patients, 610 images) with instance masks for adipose tissue, bone, ligamentum flavum, and nerve. Experiments show that LMSF-A is highly competitive (or even better than) in all evaluation metrics and much lighter than most instance segmentation methods requiring only 1.8M parameters and 8.8 GFLOPs, and it generalizes well to a public teeth benchmark. Code and dataset: https://github.com/hhwmortal/PELD-Instance-segmentation.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21984v1",
        "pdf": "https://arxiv.org/pdf/2512.21984v1"
      },
      "arxiv_id": "2512.21984v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21975v1",
      "title": "RT-Focuser: A Real-Time Lightweight Model for Edge-side Image Deblurring",
      "authors": [
        "Zhuoyu Wu",
        "Wenhui Ou",
        "Qiawei Zheng",
        "Jiayan Yang",
        "Quanjun Wang",
        "Wenqi Fang",
        "Zheng Wang",
        "Yongkui Yang",
        "Heshan Li"
      ],
      "abstract": "Motion blur caused by camera or object movement severely degrades image quality and poses challenges for real-time applications such as autonomous driving, UAV perception, and medical imaging. In this paper, a lightweight U-shaped network tailored for real-time deblurring is presented and named RT-Focuser. To balance speed and accuracy, we design three key components: Lightweight Deblurring Block (LD) for edge-aware feature extraction, Multi-Level Integrated Aggregation module (MLIA) for encoder integration, and Cross-source Fusion Block (X-Fuse) for progressive decoder refinement. Trained on a single blurred input, RT-Focuser achieves 30.67 dB PSNR with only 5.85M parameters and 15.76 GMACs. It runs 6ms per frame on GPU and mobile, exceeds 140 FPS on both, showing strong potential for deployment on the edge. The official code and usage are available on: https://github.com/ReaganWu/RT-Focuser.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "eess.IV",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21975v1",
        "pdf": "https://arxiv.org/pdf/2512.21975v1"
      },
      "arxiv_id": "2512.21975v1",
      "comment": "2 pages, 2 figures, this paper already accepted by IEEE ICTA 2025",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21964v1",
      "title": "Perceive and Calibrate: Analyzing and Enhancing Robustness of Medical Multi-Modal Large Language Models",
      "authors": [
        "Dunyuan XU",
        "Xikai Yang",
        "Yaoqian Li",
        "Juzheng Miao",
        "Jinpeng Li",
        "Pheng-Ann Heng"
      ],
      "abstract": "Medical Multi-modal Large Language Models (MLLMs) have shown promising clinical performance. However, their sensitivity to real-world input perturbations, such as imaging artifacts and textual errors, critically undermines their clinical applicability. Systematic analysis of such noise impact on medical MLLMs remains largely unexplored. Furthermore, while several works have investigated the MLLMs' robustness in general domains, they primarily focus on text modality and rely on costly fine-tuning. They are inadequate to address the complex noise patterns and fulfill the strict safety standards in medicine. To bridge this gap, this work systematically analyzes the impact of various perturbations on medical MLLMs across both visual and textual modalities. Building on our findings, we introduce a training-free Inherent-enhanced Multi-modal Calibration (IMC) framework that leverages MLLMs' inherent denoising capabilities following the perceive-and-calibrate principle for cross-modal robustness enhancement. For the visual modality, we propose a Perturbation-aware Denoising Calibration (PDC) which leverages MLLMs' own vision encoder to identify noise patterns and perform prototype-guided feature calibration. For text denoising, we design a Self-instantiated Multi-agent System (SMS) that exploits the MLLMs' self-assessment capabilities to refine noisy text through a cooperative hierarchy of agents. We construct a benchmark containing 11 types of noise across both image and text modalities on 2 datasets. Experimental results demonstrate our method achieves the state-of-the-art performance across multiple modalities, showing potential to enhance MLLMs' robustness in real clinical scenarios.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21964v1",
        "pdf": "https://arxiv.org/pdf/2512.21964v1"
      },
      "arxiv_id": "2512.21964v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21960v1",
      "title": "Modeling high dimensional point clouds with the spherical cluster model",
      "authors": [
        "Frédéric Cazals",
        "Antoine Commaret",
        "Louis Goldenberg"
      ],
      "abstract": "A parametric cluster model is a statistical model providing geometric insights onto the points defining a cluster. The {\\em spherical cluster model} (SC) approximates a finite point set $P\\subset \\mathbb{R}^d$ by a sphere $S(c,r)$ as follows. Taking $r$ as a fraction $η\\in(0,1)$ (hyper-parameter) of the std deviation of distances between the center $c$ and the data points, the cost of the SC model is the sum over all data points lying outside the sphere $S$ of their power distance with respect to $S$. The center $c$ of the SC model is the point minimizing this cost. Note that $η=0$ yields the celebrated center of mass used in KMeans clustering. We make three contributions.\n  First, we show fitting a spherical cluster yields a strictly convex but not smooth combinatorial optimization problem. Second, we present an exact solver using the Clarke gradient on a suitable stratified cell complex defined from an arrangement of hyper-spheres. Finally, we present experiments on a variety of datasets ranging in dimension from $d=9$ to $d=10,000$, with two main observations. First, the exact algorithm is orders of magnitude faster than BFGS based heuristics for datasets of small/intermediate dimension and small values of $η$, and for high dimensional datasets (say $d>100$) whatever the value of $η$. Second, the center of the SC model behave as a parameterized high-dimensional median.\n  The SC model is of direct interest for high dimensional multivariate data analysis, and the application to the design of mixtures of SC will be reported in a companion paper.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "stat.ME",
        "cs.LG"
      ],
      "primary_category": "stat.ME",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21960v1",
        "pdf": "https://arxiv.org/pdf/2512.21960v1"
      },
      "arxiv_id": "2512.21960v1",
      "comment": "Main text: 4 figures, 15 pages",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21948v1",
      "title": "Automated Discovery of Parsimonious Spectral Indices via Normalized Difference Polynomials",
      "authors": [
        "Ali Lotfi",
        "Adam Carter",
        "Thuan Ha",
        "Mohammad Meysami",
        "Kwabena Nketia",
        "Steve Shirtliffe"
      ],
      "abstract": "We introduce an automated way to find compact spectral indices for vegetation classification. The idea is to take all pairwise normalized differences from the spectral bands and then build polynomial combinations up to a fixed degree, which gives a structured search space that still keeps the illumination invariance needed in remote sensing. For a sensor with $n$ bands this produces $\\binom{n}{2}$ base normalized differences, and the degree-2 polynomial expansion gives 1,080 candidate features for the 10-band Sentinel-2 configuration we use here. Feature selection methods (ANOVA filtering, recursive elimination, and $L_1$-regularized SVM) then pick out small sets of indices that reach the desired accuracy, so the final models stay simple and easy to interpret. We test the framework on Kochia (\\textit{Bassia scoparia}) detection using Sentinel-2 imagery from Saskatchewan, Canada ($N = 2{,}318$ samples, 2022--2024). A single degree-2 index, the product of two normalized differences from the red-edge bands, already reaches 96.26\\% accuracy, and using eight indices only raises this to 97.70\\%. In every case the chosen features are degree-2 products built from bands $b_4$ through $b_8$, which suggests that the discriminative signal comes from spectral \\emph{interactions} rather than individual band ratios. Because the indices involve only simple arithmetic, they can be deployed directly in platforms like Google Earth Engine. The same approach works for other sensors and classification tasks, and an open-source implementation (\\texttt{ndindex}) is available.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21948v1",
        "pdf": "https://arxiv.org/pdf/2512.21948v1"
      },
      "arxiv_id": "2512.21948v1",
      "comment": "23 pages, 5 figures, 6 tables",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21944v1",
      "title": "Data relativistic uncertainty framework for low-illumination anime scenery image enhancement",
      "authors": [
        "Yiquan Gao",
        "John See"
      ],
      "abstract": "By contrast with the prevailing works of low-light enhancement in natural images and videos, this study copes with the low-illumination quality degradation in anime scenery images to bridge the domain gap. For such an underexplored enhancement task, we first curate images from various sources and construct an unpaired anime scenery dataset with diverse environments and illumination conditions to address the data scarcity. To exploit the power of uncertainty information inherent with the diverse illumination conditions, we propose a Data Relativistic Uncertainty (DRU) framework, motivated by the idea from Relativistic GAN. By analogy with the wave-particle duality of light, our framework interpretably defines and quantifies the illumination uncertainty of dark/bright samples, which is leveraged to dynamically adjust the objective functions to recalibrate the model learning under data uncertainty. Extensive experiments demonstrate the effectiveness of DRU framework by training several versions of EnlightenGANs, yielding superior perceptual and aesthetic qualities beyond the state-of-the-art methods that are incapable of learning from data uncertainty perspective. We hope our framework can expose a novel paradigm of data-centric learning for potential visual and language domains. Code is available.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.CV",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21944v1",
        "pdf": "https://arxiv.org/pdf/2512.21944v1"
      },
      "arxiv_id": "2512.21944v1",
      "comment": "Preprint, awaiting submission to the appropriate conference or journal",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21925v1",
      "title": "Hybrid Combinatorial Multi-armed Bandits with Probabilistically Triggered Arms",
      "authors": [
        "Kongchang Zhou",
        "Tingyu Zhang",
        "Wei Chen",
        "Fang Kong"
      ],
      "abstract": "The problem of combinatorial multi-armed bandits with probabilistically triggered arms (CMAB-T) has been extensively studied. Prior work primarily focuses on either the online setting where an agent learns about the unknown environment through iterative interactions, or the offline setting where a policy is learned solely from logged data. However, each of these paradigms has inherent limitations: online algorithms suffer from high interaction costs and slow adaptation, while offline methods are constrained by dataset quality and lack of exploration capabilities. To address these complementary weaknesses, we propose hybrid CMAB-T, a new framework that integrates offline data with online interaction in a principled manner. Our proposed hybrid CUCB algorithm leverages offline data to guide exploration and accelerate convergence, while strategically incorporating online interactions to mitigate the insufficient coverage or distributional bias of the offline dataset. We provide theoretical guarantees on the algorithm's regret, demonstrating that hybrid CUCB significantly outperforms purely online approaches when high-quality offline data is available, and effectively corrects the bias inherent in offline-only methods when the data is limited or misaligned. Empirical results further demonstrate the consistent advantage of our algorithm.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21925v1",
        "pdf": "https://arxiv.org/pdf/2512.21925v1"
      },
      "arxiv_id": "2512.21925v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21924v1",
      "title": "Unsupervised Anomaly Detection in Brain MRI via Disentangled Anatomy Learning",
      "authors": [
        "Tao Yang",
        "Xiuying Wang",
        "Hao Liu",
        "Guanzhong Gong",
        "Lian-Ming Wu",
        "Yu-Ping Wang",
        "Lisheng Wang"
      ],
      "abstract": "Detection of various lesions in brain MRI is clinically critical, but challenging due to the diversity of lesions and variability in imaging conditions. Current unsupervised learning methods detect anomalies mainly through reconstructing abnormal images into pseudo-healthy images (PHIs) by normal samples learning and then analyzing differences between images. However, these unsupervised models face two significant limitations: restricted generalizability to multi-modality and multi-center MRIs due to their reliance on the specific imaging information in normal training data, and constrained performance due to abnormal residuals propagated from input images to reconstructed PHIs. To address these limitations, two novel modules are proposed, forming a new PHI reconstruction framework. Firstly, the disentangled representation module is proposed to improve generalizability by decoupling brain MRI into imaging information and essential imaging-invariant anatomical images, ensuring that the reconstruction focuses on the anatomy. Specifically, brain anatomical priors and a differentiable one-hot encoding operator are introduced to constrain the disentanglement results and enhance the disentanglement stability. Secondly, the edge-to-image restoration module is designed to reconstruct high-quality PHIs by restoring the anatomical representation from the high-frequency edge information of anatomical images, and then recoupling the disentangled imaging information. This module not only suppresses abnormal residuals in PHI by reducing abnormal pixels input through edge-only input, but also effectively reconstructs normal regions using the preserved structural details in the edges. Evaluated on nine public datasets (4,443 patients' MRIs from multiple centers), our method outperforms 17 SOTA methods, achieving absolute improvements of +18.32% in AP and +13.64% in DSC.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21924v1",
        "pdf": "https://arxiv.org/pdf/2512.21924v1"
      },
      "arxiv_id": "2512.21924v1",
      "comment": "Accepted by Medical Image Analysis (2025)",
      "journal_ref": "Medical Image Analysis (2025)",
      "has_code": false
    },
    {
      "id": "2512.21921v1",
      "title": "AutoPP: Towards Automated Product Poster Generation and Optimization",
      "authors": [
        "Jiahao Fan",
        "Yuxin Qin",
        "Wei Feng",
        "Yanyin Chen",
        "Yaoyu Li",
        "Ao Ma",
        "Yixiu Li",
        "Li Zhuang",
        "Haoyi Bian",
        "Zheng Zhang",
        "Jingjing Lv",
        "Junjie Shen",
        "Ching Law"
      ],
      "abstract": "Product posters blend striking visuals with informative text to highlight the product and capture customer attention. However, crafting appealing posters and manually optimizing them based on online performance is laborious and resource-consuming. To address this, we introduce AutoPP, an automated pipeline for product poster generation and optimization that eliminates the need for human intervention. Specifically, the generator, relying solely on basic product information, first uses a unified design module to integrate the three key elements of a poster (background, text, and layout) into a cohesive output. Then, an element rendering module encodes these elements into condition tokens, efficiently and controllably generating the product poster. Based on the generated poster, the optimizer enhances its Click-Through Rate (CTR) by leveraging online feedback. It systematically replaces elements to gather fine-grained CTR comparisons and utilizes Isolated Direct Preference Optimization (IDPO) to attribute CTR gains to isolated elements. Our work is supported by AutoPP1M, the largest dataset specifically designed for product poster generation and optimization, which contains one million high-quality posters and feedback collected from over one million users. Experiments demonstrate that AutoPP achieves state-of-the-art results in both offline and online settings. Our code and dataset are publicly available at: https://github.com/JD-GenX/AutoPP",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.CV",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21921v1",
        "pdf": "https://arxiv.org/pdf/2512.21921v1"
      },
      "arxiv_id": "2512.21921v1",
      "comment": "Accepted to AAAI 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21917v1",
      "title": "Semiparametric Preference Optimization: Your Language Model is Secretly a Single-Index Model",
      "authors": [
        "Nathan Kallus"
      ],
      "abstract": "Aligning large language models to preference data is commonly implemented by assuming a known link function between the distribution of observed preferences and the unobserved rewards (e.g., a logistic link as in Bradley-Terry). If the link is wrong, however, inferred rewards can be biased and policies be misaligned. We study policy alignment to preferences under an unknown and unrestricted link. We consider an $f$-divergence-constrained reward maximization problem and show that realizability of the solution in a policy class implies a semiparametric single-index binary choice model, where a scalar-valued index determined by a policy captures the dependence on demonstrations and the rest of the preference distribution is an unrestricted function thereof. Rather than focus on estimation of identifiable finite-dimensional structural parameters in the index as in econometrics, we focus on policy learning, focusing on error to the optimal policy and allowing unidentifiable and nonparametric indices. We develop a variety of policy learners based on profiling the link function, orthogonalizing the link function, and using link-agnostic bipartite ranking objectives. We analyze these and provide finite-sample policy error bounds that depend on generic functional complexity measures of the index class. We further consider practical implementations using first-order optimization suited to neural networks and batched data. The resulting methods are robust to unknown preference noise distribution and scale, while preserving the direct optimization of policies without explicitly fitting rewards.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.LG",
        "cs.AI",
        "econ.EM",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21917v1",
        "pdf": "https://arxiv.org/pdf/2512.21917v1"
      },
      "arxiv_id": "2512.21917v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21916v1",
      "title": "Patch as Node: Human-Centric Graph Representation Learning for Multimodal Action Recognition",
      "authors": [
        "Zeyu Liang",
        "Hailun Xia",
        "Naichuan Zheng"
      ],
      "abstract": "While human action recognition has witnessed notable achievements, multimodal methods fusing RGB and skeleton modalities still suffer from their inherent heterogeneity and fail to fully exploit the complementary potential between them. In this paper, we propose PAN, the first human-centric graph representation learning framework for multimodal action recognition, in which token embeddings of RGB patches containing human joints are represented as spatiotemporal graphs. The human-centric graph modeling paradigm suppresses the redundancy in RGB frames and aligns well with skeleton-based methods, thus enabling a more effective and semantically coherent fusion of multimodal features. Since the sampling of token embeddings heavily relies on 2D skeletal data, we further propose attention-based post calibration to reduce the dependency on high-quality skeletal data at a minimal cost interms of model performance. To explore the potential of PAN in integrating with skeleton-based methods, we present two variants: PAN-Ensemble, which employs dual-path graph convolution networks followed by late fusion, and PAN-Unified, which performs unified graph representation learning within a single network. On three widely used multimodal action recognition datasets, both PAN-Ensemble and PAN-Unified achieve state-of-the-art (SOTA) performance in their respective settings of multimodal fusion: separate and unified modeling, respectively.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21916v1",
        "pdf": "https://arxiv.org/pdf/2512.21916v1"
      },
      "arxiv_id": "2512.21916v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21915v1",
      "title": "Exploring the Heterogeneity of Tabular Data: A Diversity-aware Data Generator via LLMs",
      "authors": [
        "Yafeng Tang",
        "Xiaoou Ding",
        "Jianzhuo Du",
        "Zishuo Yan",
        "Zhuang Ma",
        "Zheng Liang",
        "Zekai Qian",
        "Hongzhi Wang"
      ],
      "abstract": "Tabular data generation has become increasingly essential for enabling robust machine learning applications, which require large-scale, high-quality data. Existing solutions leverage generative models to learn original data distributions. However, real-world data are naturally heterogeneous with diverse distributions, making it challenging to obtain a universally good model for diverse data generation. To address this limitation, we introduce Diversity-Aware Tabular data gEnerator (DATE), a framework that (i) prepares high-quality and distributionally distinct examples for in-context learning by effectively partitioning the original heterogeneous data into multiple diverse subsets; (ii) harnesses Large Language Models (LLMs) to explore the diversity of the partitioned distribution with decision tree reasoning as feedback, generating high-quality labeled data for each subset. However, the massive generated data inherently involves a trade-off between diversity and quality. To integrate this issue, existing solutions greedily select the validation-best data. However, we prove that the selection in heterogeneous settings does not possess the greedy-choice property, and design a Multi-Arm Bandit-based sampling algorithm that balances the diversity and quality of generated data. Extensive experiments on tabular classification and regression benchmarks demonstrate that DATE consistently outperforms state-of-the-art GAN-based and LLM-based methods. On average, DATE achieves a 23.75% reduction in error rate with just 100 generated data. Empirically, we demonstrate that data generated by DATE can improve the accuracy of Direct Preference Optimization (DPO) and enhance the reasoning capability of LLMs on the target data. Code is available at https://github.com/windblow32/DATE.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.LG",
        "cs.DB"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21915v1",
        "pdf": "https://arxiv.org/pdf/2512.21915v1"
      },
      "arxiv_id": "2512.21915v1",
      "comment": "This manuscript has been submitted to IEEE Transactions on Knowledge and Data Engineering (TKDE) for peer review",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21913v1",
      "title": "GQ-VAE: A gated quantized VAE for learning variable length tokens",
      "authors": [
        "Theo Datta",
        "Kayla Huang",
        "Sham Kakade",
        "David Brandfonbrener"
      ],
      "abstract": "While most frontier models still use deterministic frequency-based tokenization algorithms such as byte-pair encoding (BPE), there has been significant recent work to design learned neural tokenizers. However, these schemes generally add to underlying language model complexity and force large changes to architecture, making them hard to implement at large scales. To overcome these challenges, we propose the gated quantized variational autoencoder (GQ-VAE), a novel architecture that can be independently pre-trained to serve as a drop-in replacement for existing tokenizers. The key innovation of the architecture is to learn to encode variable-length discrete tokens. GQ-VAE improves compression and language modeling performance over a standard VQ-VAE tokenizer, and approaches the compression rate and language modeling performance of BPE. Interestingly, if we use BPE with a smaller vocabulary, such that the compression is equivalent between GQ-VAE and BPE, we find that GQ-VAE improves downstream language model learning. We conclude with a discussion of several exciting avenues for future work. Code can be found at https://github.com/Theo-Datta-115/gq-vae.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21913v1",
        "pdf": "https://arxiv.org/pdf/2512.21913v1"
      },
      "arxiv_id": "2512.21913v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21907v1",
      "title": "SpatialBench: Can Agents Analyze Real-World Spatial Biology Data?",
      "authors": [
        "Kenny Workman",
        "Zhen Yang",
        "Harihara Muralidharan",
        "Hannah Le"
      ],
      "abstract": "Spatial transcriptomics assays are rapidly increasing in scale and complexity, making computational analysis a major bottleneck in biological discovery. Although frontier AI agents have improved dramatically at software engineering and general data analysis, it remains unclear whether they can extract biological insight from messy, real-world spatial datasets. We introduce SpatialBench, a benchmark of 146 verifiable problems derived from practical spatial analysis workflows spanning five spatial technologies and seven task categories. Each problem provides a snapshot of experimental data immediately prior to an analysis step and a deterministic grader that evaluates recovery of a key biological result. Benchmark data on frontier models shows that base model accuracy remains low (20-38% across model families), with strong model-task and model-platform interactions. Harness design has a large empirical effect on performance, indicating that tools, prompts, control flow, and execution environment should be evaluated and improved as first-class objects. SpatialBench serves both as a measurement tool and a diagnostic lens for developing agents that can interact with real spatial datasets faithfully, transparently, and reproducibly.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21907v1",
        "pdf": "https://arxiv.org/pdf/2512.21907v1"
      },
      "arxiv_id": "2512.21907v1",
      "comment": "10 pages, 9 figures, 4 tables; NeurIPS 2024 format",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21905v1",
      "title": "High-Fidelity and Long-Duration Human Image Animation with Diffusion Transformer",
      "authors": [
        "Shen Zheng",
        "Jiaran Cai",
        "Yuansheng Guan",
        "Shenneng Huang",
        "Xingpei Ma",
        "Junjie Cao",
        "Hanfeng Zhao",
        "Qiang Zhang",
        "Shunsi Zhang",
        "Xiao-Ping Zhang"
      ],
      "abstract": "Recent progress in diffusion models has significantly advanced the field of human image animation. While existing methods can generate temporally consistent results for short or regular motions, significant challenges remain, particularly in generating long-duration videos. Furthermore, the synthesis of fine-grained facial and hand details remains under-explored, limiting the applicability of current approaches in real-world, high-quality applications. To address these limitations, we propose a diffusion transformer (DiT)-based framework which focuses on generating high-fidelity and long-duration human animation videos. First, we design a set of hybrid implicit guidance signals and a sharpness guidance factor, enabling our framework to additionally incorporate detailed facial and hand features as guidance. Next, we incorporate the time-aware position shift fusion module, modify the input format within the DiT backbone, and refer to this mechanism as the Position Shift Adaptive Module, which enables video generation of arbitrary length. Finally, we introduce a novel data augmentation strategy and a skeleton alignment model to reduce the impact of human shape variations across different identities. Experimental results demonstrate that our method outperforms existing state-of-the-art approaches, achieving superior performance in both high-fidelity and long-duration human image animation.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21905v1",
        "pdf": "https://arxiv.org/pdf/2512.21905v1"
      },
      "arxiv_id": "2512.21905v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21898v1",
      "title": "Flexible Multitask Learning with Factorized Diffusion Policy",
      "authors": [
        "Chaoqi Liu",
        "Haonan Chen",
        "Sigmund H. Høeg",
        "Shaoxiong Yao",
        "Yunzhu Li",
        "Kris Hauser",
        "Yilun Du"
      ],
      "abstract": "Multitask learning poses significant challenges due to the highly multimodal and diverse nature of robot action distributions. However, effectively fitting policies to these complex task distributions is often difficult, and existing monolithic models often underfit the action distribution and lack the flexibility required for efficient adaptation. We introduce a novel modular diffusion policy framework that factorizes complex action distributions into a composition of specialized diffusion models, each capturing a distinct sub-mode of the behavior space for a more effective overall policy. In addition, this modular structure enables flexible policy adaptation to new tasks by adding or fine-tuning components, which inherently mitigates catastrophic forgetting. Empirically, across both simulation and real-world robotic manipulation settings, we illustrate how our method consistently outperforms strong modular and monolithic baselines.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21898v1",
        "pdf": "https://arxiv.org/pdf/2512.21898v1"
      },
      "arxiv_id": "2512.21898v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21897v1",
      "title": "MMCTOP: A Multimodal Textualization and Mixture-of-Experts Framework for Clinical Trial Outcome Prediction",
      "authors": [
        "Carolina Aparício",
        "Qi Shi",
        "Bo Wen",
        "Tesfaye Yadete",
        "Qiwei Han"
      ],
      "abstract": "Addressing the challenge of multimodal data fusion in high-dimensional biomedical informatics, we propose MMCTOP, a MultiModal Clinical-Trial Outcome Prediction framework that integrates heterogeneous biomedical signals spanning (i) molecular structure representations, (ii) protocol metadata and long-form eligibility narratives, and (iii) disease ontologies. MMCTOP couples schema-guided textualization and input-fidelity validation with modality-aware representation learning, in which domain-specific encoders generate aligned embeddings that are fused by a transformer backbone augmented with a drug-disease-conditioned sparse Mixture-of-Experts (SMoE). This design explicitly supports specialization across therapeutic and design subspaces while maintaining scalable computation through top-k routing. MMCTOP achieves consistent improvements in precision, F1, and AUC over unimodal and multimodal baselines on benchmark datasets, and ablations show that schema-guided textualization and selective expert routing contribute materially to performance and stability. We additionally apply temperature scaling to obtain calibrated probabilities, ensuring reliable risk estimation for downstream decision support. Overall, MMCTOP advances multimodal trial modeling by combining controlled narrative normalization, context-conditioned expert fusion, and operational safeguards aimed at auditability and reproducibility in biomedical informatics.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21897v1",
        "pdf": "https://arxiv.org/pdf/2512.21897v1"
      },
      "arxiv_id": "2512.21897v1",
      "comment": "15 pages, 3 figures, 5 tables",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21890v1",
      "title": "CrownGen: Patient-customized Crown Generation via Point Diffusion Model",
      "authors": [
        "Juyoung Bae",
        "Moo Hyun Son",
        "Jiale Peng",
        "Wanting Qu",
        "Wener Chen",
        "Zelin Qiu",
        "Kaixin Li",
        "Xiaojuan Chen",
        "Yifan Lin",
        "Hao Chen"
      ],
      "abstract": "Digital crown design remains a labor-intensive bottleneck in restorative dentistry. We present \\textbf{CrownGen}, a generative framework that automates patient-customized crown design using a denoising diffusion model on a novel tooth-level point cloud representation. The system employs two core components: a boundary prediction module to establish spatial priors and a diffusion-based generative module to synthesize high-fidelity morphology for multiple teeth in a single inference pass. We validated CrownGen through a quantitative benchmark on 496 external scans and a clinical study of 26 restoration cases. Results demonstrate that CrownGen surpasses state-of-the-art models in geometric fidelity and significantly reduces active design time. Clinical assessments by trained dentists confirmed that CrownGen-assisted crowns are statistically non-inferior in quality to those produced by expert technicians using manual workflows. By automating complex prosthetic modeling, CrownGen offers a scalable solution to lower costs, shorten turnaround times, and enhance patient access to high-quality dental care.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21890v1",
        "pdf": "https://arxiv.org/pdf/2512.21890v1"
      },
      "arxiv_id": "2512.21890v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21887v1",
      "title": "Aerial World Model for Long-horizon Visual Generation and Navigation in 3D Space",
      "authors": [
        "Weichen Zhang",
        "Peizhi Tang",
        "Xin Zeng",
        "Fanhang Man",
        "Shiquan Yu",
        "Zichao Dai",
        "Baining Zhao",
        "Hongjin Chen",
        "Yu Shang",
        "Wei Wu",
        "Chen Gao",
        "Xinlei Chen",
        "Xin Wang",
        "Yong Li",
        "Wenwu Zhu"
      ],
      "abstract": "Unmanned aerial vehicles (UAVs) have emerged as powerful embodied agents. One of the core abilities is autonomous navigation in large-scale three-dimensional environments. Existing navigation policies, however, are typically optimized for low-level objectives such as obstacle avoidance and trajectory smoothness, lacking the ability to incorporate high-level semantics into planning. To bridge this gap, we propose ANWM, an aerial navigation world model that predicts future visual observations conditioned on past frames and actions, thereby enabling agents to rank candidate trajectories by their semantic plausibility and navigational utility. ANWM is trained on 4-DoF UAV trajectories and introduces a physics-inspired module: Future Frame Projection (FFP), which projects past frames into future viewpoints to provide coarse geometric priors. This module mitigates representational uncertainty in long-distance visual generation and captures the mapping between 3D trajectories and egocentric observations. Empirical results demonstrate that ANWM significantly outperforms existing world models in long-distance visual forecasting and improves UAV navigation success rates in large-scale environments.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21887v1",
        "pdf": "https://arxiv.org/pdf/2512.21887v1"
      },
      "arxiv_id": "2512.21887v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21884v1",
      "title": "Optimizing Resource Allocation for Geographically-Distributed Inference by Large Language Models",
      "authors": [
        "Tingyang Sun",
        "Ting He",
        "Bo Ji",
        "Parimal Parag"
      ],
      "abstract": "Large language models have demonstrated extraordinary performance in many AI tasks but are expensive to use, even after training, due to their requirement of high-end GPUs. Recently, a distributed system called PETALS was developed to lower the barrier for deploying LLMs by splitting the model blocks across multiple servers with low-end GPUs distributed over the Internet, which was much faster than swapping the model parameters between the GPU memory and other cheaper but slower local storage media. However, the performance of such a distributed system critically depends on the resource allocation, and how to do so optimally remains unknown. In this work, we present the first systematic study of the resource allocation problem in distributed LLM inference, with focus on two important decisions: block placement and request routing. Our main results include: experimentally validated performance models that can predict the inference performance under given block placement and request routing decisions, a formulation of the offline optimization of block placement and request routing as a mixed integer linear programming problem together with the NP-hardness proof and a polynomial-complexity algorithm with guaranteed performance, and an adaptation of the offline algorithm for the online setting with the same performance guarantee under bounded load. Through both experiments and experimentally-validated simulations, we have verified that the proposed solution can substantially reduce the inference time compared to the state-of-the-art solution in diverse settings with geographically-distributed servers. As a byproduct, we have also developed a light-weighted CPU-only simulator capable of predicting the performance of distributed LLM inference on GPU servers, which can evaluate large deployments and facilitate future research for researchers with limited GPU access.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.DC",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21884v1",
        "pdf": "https://arxiv.org/pdf/2512.21884v1"
      },
      "arxiv_id": "2512.21884v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21883v1",
      "title": "Reloc-VGGT: Visual Re-localization with Geometry Grounded Transformer",
      "authors": [
        "Tianchen Deng",
        "Wenhua Wu",
        "Kunzhen Wu",
        "Guangming Wang",
        "Siting Zhu",
        "Shenghai Yuan",
        "Xun Chen",
        "Guole Shen",
        "Zhe Liu",
        "Hesheng Wang"
      ],
      "abstract": "Visual localization has traditionally been formulated as a pair-wise pose regression problem. Existing approaches mainly estimate relative poses between two images and employ a late-fusion strategy to obtain absolute pose estimates. However, the late motion average is often insufficient for effectively integrating spatial information, and its accuracy degrades in complex environments. In this paper, we present the first visual localization framework that performs multi-view spatial integration through an early-fusion mechanism, enabling robust operation in both structured and unstructured environments. Our framework is built upon the VGGT backbone, which encodes multi-view 3D geometry, and we introduce a pose tokenizer and projection module to more effectively exploit spatial relationships from multiple database views. Furthermore, we propose a novel sparse mask attention strategy that reduces computational cost by avoiding the quadratic complexity of global attention, thereby enabling real-time performance at scale. Trained on approximately eight million posed image pairs, Reloc-VGGT demonstrates strong accuracy and remarkable generalization ability. Extensive experiments across diverse public datasets consistently validate the effectiveness and efficiency of our approach, delivering high-quality camera pose estimates in real time while maintaining robustness to unseen environments. Our code and models will be publicly released upon acceptance.https://github.com/dtc111111/Reloc-VGGT.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21883v1",
        "pdf": "https://arxiv.org/pdf/2512.21883v1"
      },
      "arxiv_id": "2512.21883v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21881v1",
      "title": "SLIM-Brain: A Data- and Training-Efficient Foundation Model for fMRI Data Analysis",
      "authors": [
        "Mo Wang",
        "Junfeng Xia",
        "Wenhao Ye",
        "Enyu Liu",
        "Kaining Peng",
        "Jianfeng Feng",
        "Quanying Liu",
        "Hongkai Wen"
      ],
      "abstract": "Foundation models are emerging as a powerful paradigm for fMRI analysis, but current approaches face a dual bottleneck of data- and training-efficiency. Atlas-based methods aggregate voxel signals into fixed regions of interest, reducing data dimensionality but discarding fine-grained spatial details, and requiring extremely large cohorts to train effectively as general-purpose foundation models. Atlas-free methods, on the other hand, operate directly on voxel-level information - preserving spatial fidelity but are prohibitively memory- and compute-intensive, making large-scale pre-training infeasible. We introduce SLIM-Brain (Sample-efficient, Low-memory fMRI Foundation Model for Human Brain), a new atlas-free foundation model that simultaneously improves both data- and training-efficiency. SLIM-Brain adopts a two-stage adaptive design: (i) a lightweight temporal extractor captures global context across full sequences and ranks data windows by saliency, and (ii) a 4D hierarchical encoder (Hiera-JEPA) learns fine-grained voxel-level representations only from the top-$k$ selected windows, while deleting about 70% masked patches. Extensive experiments across seven public benchmarks show that SLIM-Brain establishes new state-of-the-art performance on diverse tasks, while requiring only 4 thousand pre-training sessions and approximately 30% of GPU memory comparing to traditional voxel-level methods.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.CV",
        "q-bio.NC"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21881v1",
        "pdf": "https://arxiv.org/pdf/2512.21881v1"
      },
      "arxiv_id": "2512.21881v1",
      "comment": "The code will be released after review",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2512.21878v1",
      "title": "MASFIN: A Multi-Agent System for Decomposed Financial Reasoning and Forecasting",
      "authors": [
        "Marc S. Montalvo",
        "Hamed Yaghoobian"
      ],
      "abstract": "Recent advances in large language models (LLMs) are transforming data-intensive domains, with finance representing a high-stakes environment where transparent and reproducible analysis of heterogeneous signals is essential. Traditional quantitative methods remain vulnerable to survivorship bias, while many AI-driven approaches struggle with signal integration, reproducibility, and computational efficiency. We introduce MASFIN, a modular multi-agent framework that integrates LLMs with structured financial metrics and unstructured news, while embedding explicit bias-mitigation protocols. The system leverages GPT-4.1-nano for reproducability and cost-efficient inference and generates weekly portfolios of 15-30 equities with allocation weights optimized for short-term performance. In an eight-week evaluation, MASFIN delivered a 7.33% cumulative return, outperforming the S&P 500, NASDAQ-100, and Dow Jones benchmarks in six of eight weeks, albeit with higher volatility. These findings demonstrate the promise of bias-aware, generative AI frameworks for financial forecasting and highlight opportunities for modular multi-agent design to advance practical, transparent, and reproducible approaches in quantitative finance.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21878v1",
        "pdf": "https://arxiv.org/pdf/2512.21878v1"
      },
      "arxiv_id": "2512.21878v1",
      "comment": "Accepted to the NeurIPS 2025 Workshop on Generative AI in Finance",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21877v1",
      "title": "CricBench: A Multilingual Benchmark for Evaluating LLMs in Cricket Analytics",
      "authors": [
        "Vaibhav Devraj",
        "Dhruv Kumar",
        "Jagat Sesh Challa"
      ],
      "abstract": "Cricket is the second most popular sport globally, commanding a massive following of over 2.5 billion fans globally. Enthusiasts and analysts frequently seek advanced statistical insights, such as long-term historical performance trends or complex player comparisons, that are often unavailable through standard web searches. While Large Language Models (LLMs) have advanced significantly in Text-to-SQL tasks, their capability to handle the domain-specific nuances, complex schema variations, and multilingual requirements inherent to sports analytics remains under-explored. To investigate this potential capability gap, we present CricBench, a comprehensive benchmark suite for evaluating LLMs on specialized cricket data. To curate a \"Gold Standard\" dataset, we collaborate with domain experts in cricket and SQL to manually author complex queries, ensuring logical correctness. Recognizing linguistic diversity, we construct the benchmark in both English and Hindi, establishing a framework that is open for further extension to other regional languages. We evaluate six state-of-the-art models, including GPT-4o, Claude 3.7 Sonnet, and open-source models, using a strict evaluation protocol. Our results reveal that high performance on general benchmarks does not guarantee success in specialized domains. While the open-weights reasoning model DeepSeek R1 achieves state-of-the-art performance (50.6%), surpassing proprietary giants like Claude 3.7 Sonnet (47.7%) and GPT-4o (33.7%), it still exhibits a significant accuracy drop when moving from general benchmarks (BIRD) to CricBench. Furthermore, we observe that code-mixed Hindi queries frequently yield parity or higher accuracy compared to English, challenging the assumption that English is the optimal prompt language for specialized SQL tasks.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21877v1",
        "pdf": "https://arxiv.org/pdf/2512.21877v1"
      },
      "arxiv_id": "2512.21877v1",
      "comment": "Under Review",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21871v1",
      "title": "Bridging the Copyright Gap: Do Large Vision-Language Models Recognize and Respect Copyrighted Content?",
      "authors": [
        "Naen Xu",
        "Jinghuai Zhang",
        "Changjiang Li",
        "Hengyu An",
        "Chunyi Zhou",
        "Jun Wang",
        "Boyu Xu",
        "Yuyuan Li",
        "Tianyu Du",
        "Shouling Ji"
      ],
      "abstract": "Large vision-language models (LVLMs) have achieved remarkable advancements in multimodal reasoning tasks. However, their widespread accessibility raises critical concerns about potential copyright infringement. Will LVLMs accurately recognize and comply with copyright regulations when encountering copyrighted content (i.e., user input, retrieved documents) in the context? Failure to comply with copyright regulations may lead to serious legal and ethical consequences, particularly when LVLMs generate responses based on copyrighted materials (e.g., retrieved book experts, news reports). In this paper, we present a comprehensive evaluation of various LVLMs, examining how they handle copyrighted content -- such as book excerpts, news articles, music lyrics, and code documentation when they are presented as visual inputs. To systematically measure copyright compliance, we introduce a large-scale benchmark dataset comprising 50,000 multimodal query-content pairs designed to evaluate how effectively LVLMs handle queries that could lead to copyright infringement. Given that real-world copyrighted content may or may not include a copyright notice, the dataset includes query-content pairs in two distinct scenarios: with and without a copyright notice. For the former, we extensively cover four types of copyright notices to account for different cases. Our evaluation reveals that even state-of-the-art closed-source LVLMs exhibit significant deficiencies in recognizing and respecting the copyrighted content, even when presented with the copyright notice. To solve this limitation, we introduce a novel tool-augmented defense framework for copyright compliance, which reduces infringement risks in all scenarios. Our findings underscore the importance of developing copyright-aware LVLMs to ensure the responsible and lawful use of copyrighted content.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21871v1",
        "pdf": "https://arxiv.org/pdf/2512.21871v1"
      },
      "arxiv_id": "2512.21871v1",
      "comment": "AAAI 2026 (Oral)",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21867v1",
      "title": "DPAR: Dynamic Patchification for Efficient Autoregressive Visual Generation",
      "authors": [
        "Divyansh Srivastava",
        "Akshay Mehra",
        "Pranav Maneriker",
        "Debopam Sanyal",
        "Vishnu Raj",
        "Vijay Kamarshi",
        "Fan Du",
        "Joshua Kimball"
      ],
      "abstract": "Decoder-only autoregressive image generation typically relies on fixed-length tokenization schemes whose token counts grow quadratically with resolution, substantially increasing the computational and memory demands of attention. We present DPAR, a novel decoder-only autoregressive model that dynamically aggregates image tokens into a variable number of patches for efficient image generation. Our work is the first to demonstrate that next-token prediction entropy from a lightweight and unsupervised autoregressive model provides a reliable criterion for merging tokens into larger patches based on information content. DPAR makes minimal modifications to the standard decoder architecture, ensuring compatibility with multimodal generation frameworks and allocating more compute to generation of high-information image regions. Further, we demonstrate that training with dynamically sized patches yields representations that are robust to patch boundaries, allowing DPAR to scale to larger patch sizes at inference. DPAR reduces token count by 1.81x and 2.06x on Imagenet 256 and 384 generation resolution respectively, leading to a reduction of up to 40% FLOPs in training costs. Further, our method exhibits faster convergence and improves FID by up to 27.1% relative to baseline models.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21867v1",
        "pdf": "https://arxiv.org/pdf/2512.21867v1"
      },
      "arxiv_id": "2512.21867v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21866v1",
      "title": "Secure and Explainable Fraud Detection in Finance via Hierarchical Multi-source Dataset Distillation",
      "authors": [
        "Yiming Qian",
        "Thorsten Neumann",
        "Xueyining Huang",
        "David Hardoon",
        "Fei Gao",
        "Yong Liu",
        "Siow Mong Rick Goh"
      ],
      "abstract": "We propose an explainable, privacy-preserving dataset distillation framework for collaborative financial fraud detection. A trained random forest is converted into transparent, axis-aligned rule regions (leaf hyperrectangles), and synthetic transactions are generated by uniformly sampling within each region. This produces a compact, auditable surrogate dataset that preserves local feature interactions without exposing sensitive original records. The rule regions also support explainability: aggregated rule statistics (for example, support and lift) describe global patterns, while assigning each case to its generating region gives concise human-readable rationales and calibrated uncertainty based on tree-vote disagreement.\n  On the IEEE-CIS fraud dataset (590k transactions across three institution-like clusters), distilled datasets reduce data volume by 85% to 93% (often under 15% of the original) while maintaining competitive precision and micro-F1, with only a modest AUC drop. Sharing and augmenting with synthesized data across institutions improves cross-cluster precision, recall, and AUC. Real vs. synthesized structure remains highly similar (over 93% by nearest-neighbor cosine analysis). Membership-inference attacks perform at chance level (about 0.50) when distinguishing training from hold-out records, suggesting low memorization risk. Removing high-uncertainty synthetic points using disagreement scores further boosts AUC (up to 0.687) and improves calibration. Sensitivity tests show weak dependence on the distillation ratio (AUC about 0.641 to 0.645 from 6% to 60%).\n  Overall, tree-region distillation enables trustworthy, deployable fraud analytics with interpretable global rules, per-case rationales with quantified uncertainty, and strong privacy properties suitable for multi-institution settings and regulatory audit.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21866v1",
        "pdf": "https://arxiv.org/pdf/2512.21866v1"
      },
      "arxiv_id": "2512.21866v1",
      "comment": "",
      "journal_ref": "The ACM International Conference on AI in Finance (ICAIF) Workshop, 2025",
      "has_code": false
    },
    {
      "id": "2512.21865v1",
      "title": "EasyOmnimatte: Taming Pretrained Inpainting Diffusion Models for End-to-End Video Layered Decomposition",
      "authors": [
        "Yihan Hu",
        "Xuelin Chen",
        "Xiaodong Cun"
      ],
      "abstract": "Existing video omnimatte methods typically rely on slow, multi-stage, or inference-time optimization pipelines that fail to fully exploit powerful generative priors, producing suboptimal decompositions. Our key insight is that, if a video inpainting model can be finetuned to remove the foreground-associated effects, then it must be inherently capable of perceiving these effects, and hence can also be finetuned for the complementary task: foreground layer decomposition with associated effects. However, although naïvely finetuning the inpainting model with LoRA applied to all blocks can produce high-quality alpha mattes, it fails to capture associated effects. Our systematic analysis reveals this arises because effect-related cues are primarily encoded in specific DiT blocks and become suppressed when LoRA is applied across all blocks. To address this, we introduce EasyOmnimatte, the first unified, end-to-end video omnimatte method. Concretely, we finetune a pretrained video inpainting diffusion model to learn dual complementary experts while keeping its original weights intact: an Effect Expert, where LoRA is applied only to effect-sensitive DiT blocks to capture the coarse structure of the foreground and associated effects, and a fully LoRA-finetuned Quality Expert learns to refine the alpha matte. During sampling, Effect Expert is used for denoising at early, high-noise steps, while Quality Expert takes over at later, low-noise steps. This design eliminates the need for two full diffusion passes, significantly reducing computational cost without compromising output quality. Ablation studies validate the effectiveness of this Dual-Expert strategy. Experiments demonstrate that EasyOmnimatte sets a new state-of-the-art for video omnimatte and enables various downstream tasks, significantly outperforming baselines in both quality and efficiency.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21865v1",
        "pdf": "https://arxiv.org/pdf/2512.21865v1"
      },
      "arxiv_id": "2512.21865v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21861v1",
      "title": "Balancing Accuracy and Efficiency: CNN Fusion Models for Diabetic Retinopathy Screening",
      "authors": [
        "Md Rafid Islam",
        "Rafsan Jany",
        "Akib Ahmed",
        "Mohammad Ashrafuzzaman Khan"
      ],
      "abstract": "Diabetic retinopathy (DR) remains a leading cause of preventable blindness, yet large-scale screening is constrained by limited specialist availability and variable image quality across devices and populations. This work investigates whether feature-level fusion of complementary convolutional neural network (CNN) backbones can deliver accurate and efficient binary DR screening on globally sourced fundus images. Using 11,156 images pooled from five public datasets (APTOS, EyePACS, IDRiD, Messidor, and ODIR), we frame DR detection as a binary classification task and compare three pretrained models (ResNet50, EfficientNet-B0, and DenseNet121) against pairwise and tri-fusion variants. Across five independent runs, fusion consistently outperforms single backbones. The EfficientNet-B0 + DenseNet121 (Eff+Den) fusion model achieves the best overall mean performance (accuracy: 82.89\\%) with balanced class-wise F1-scores for normal (83.60\\%) and diabetic (82.60\\%) cases. While the tri-fusion is competitive, it incurs a substantially higher computational cost. Inference profiling highlights a practical trade-off: EfficientNet-B0 is the fastest (approximately 1.16 ms/image at batch size 1000), whereas the Eff+Den fusion offers a favorable accuracy--latency balance. These findings indicate that lightweight feature fusion can enhance generalization across heterogeneous datasets, supporting scalable binary DR screening workflows where both accuracy and throughput are critical.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21861v1",
        "pdf": "https://arxiv.org/pdf/2512.21861v1"
      },
      "arxiv_id": "2512.21861v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21860v1",
      "title": "Training-free Conditional Image Embedding Framework Leveraging Large Vision Language Models",
      "authors": [
        "Masayuki Kawarada",
        "Kosuke Yamada",
        "Antonio Tejero-de-Pablos",
        "Naoto Inoue"
      ],
      "abstract": "Conditional image embeddings are feature representations that focus on specific aspects of an image indicated by a given textual condition (e.g., color, genre), which has been a challenging problem. Although recent vision foundation models, such as CLIP, offer rich representations of images, they are not designed to focus on a specified condition. In this paper, we propose DIOR, a method that leverages a large vision-language model (LVLM) to generate conditional image embeddings. DIOR is a training-free approach that prompts the LVLM to describe an image with a single word related to a given condition. The hidden state vector of the LVLM's last token is then extracted as the conditional image embedding. DIOR provides a versatile solution that can be applied to any image and condition without additional training or task-specific priors. Comprehensive experimental results on conditional image similarity tasks demonstrate that DIOR outperforms existing training-free baselines, including CLIP. Furthermore, DIOR achieves superior performance compared to methods that require additional training across multiple settings.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21860v1",
        "pdf": "https://arxiv.org/pdf/2512.21860v1"
      },
      "arxiv_id": "2512.21860v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21857v1",
      "title": "Fast Inference of Visual Autoregressive Model with Adjacency-Adaptive Dynamical Draft Trees",
      "authors": [
        "Haodong Lei",
        "Hongsong Wang",
        "Xin Geng",
        "Liang Wang",
        "Pan Zhou"
      ],
      "abstract": "Autoregressive (AR) image models achieve diffusion-level quality but suffer from sequential inference, requiring approximately 2,000 steps for a 576x576 image. Speculative decoding with draft trees accelerates LLMs yet underperforms on visual AR models due to spatially varying token prediction difficulty. We identify a key obstacle in applying speculative decoding to visual AR models: inconsistent acceptance rates across draft trees due to varying prediction difficulties in different image regions. We propose Adjacency-Adaptive Dynamical Draft Trees (ADT-Tree), an adjacency-adaptive dynamic draft tree that dynamically adjusts draft tree depth and width by leveraging adjacent token states and prior acceptance rates. ADT-Tree initializes via horizontal adjacency, then refines depth/width via bisectional adaptation, yielding deeper trees in simple regions and wider trees in complex ones. The empirical evaluations on MS-COCO 2017 and PartiPrompts demonstrate that ADT-Tree achieves speedups of 3.13xand 3.05x, respectively. Moreover, it integrates seamlessly with relaxed sampling methods such as LANTERN, enabling further acceleration. Code is available at https://github.com/Haodong-Lei-Ray/ADT-Tree.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21857v1",
        "pdf": "https://arxiv.org/pdf/2512.21857v1"
      },
      "arxiv_id": "2512.21857v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21856v1",
      "title": "Breaking Alignment Barriers: TPS-Driven Semantic Correlation Learning for Alignment-Free RGB-T Salient Object Detection",
      "authors": [
        "Lupiao Hu",
        "Fasheng Wang",
        "Fangmei Chen",
        "Fuming Sun",
        "Haojie Li"
      ],
      "abstract": "Existing RGB-T salient object detection methods predominantly rely on manually aligned and annotated datasets, struggling to handle real-world scenarios with raw, unaligned RGB-T image pairs. In practical applications, due to significant cross-modal disparities such as spatial misalignment, scale variations, and viewpoint shifts, the performance of current methods drastically deteriorates on unaligned datasets. To address this issue, we propose an efficient RGB-T SOD method for real-world unaligned image pairs, termed Thin-Plate Spline-driven Semantic Correlation Learning Network (TPS-SCL). We employ a dual-stream MobileViT as the encoder, combined with efficient Mamba scanning mechanisms, to effectively model correlations between the two modalities while maintaining low parameter counts and computational overhead. To suppress interference from redundant background information during alignment, we design a Semantic Correlation Constraint Module (SCCM) to hierarchically constrain salient features. Furthermore, we introduce a Thin-Plate Spline Alignment Module (TPSAM) to mitigate spatial discrepancies between modalities. Additionally, a Cross-Modal Correlation Module (CMCM) is incorporated to fully explore and integrate inter-modal dependencies, enhancing detection performance. Extensive experiments on various datasets demonstrate that TPS-SCL attains state-of-the-art (SOTA) performance among existing lightweight SOD methods and outperforms mainstream RGB-T SOD approaches.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21856v1",
        "pdf": "https://arxiv.org/pdf/2512.21856v1"
      },
      "arxiv_id": "2512.21856v1",
      "comment": "Accepted by AAAI2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21853v1",
      "title": "MoonBot: Modular and On-Demand Reconfigurable Robot Toward Moon Base Construction",
      "authors": [
        "Kentaro Uno",
        "Elian Neppel",
        "Gustavo H. Diaz",
        "Ashutosh Mishra",
        "Shamistan Karimov",
        "A. Sejal Jain",
        "Ayesha Habib",
        "Pascal Pama",
        "Hazal Gozbasi",
        "Shreya Santra",
        "Kazuya Yoshida"
      ],
      "abstract": "The allure of lunar surface exploration and development has recently captured widespread global attention. Robots have proved to be indispensable for exploring uncharted terrains, uncovering and leveraging local resources, and facilitating the construction of future human habitats. In this article, we introduce the modular and on-demand reconfigurable robot (MoonBot), a modular and reconfigurable robotic system engineered to maximize functionality while operating within the stringent mass constraints of lunar payloads and adapting to varying environmental conditions and task requirements. This article details the design and development of MoonBot and presents a preliminary field demonstration that validates the proof of concept through the execution of milestone tasks simulating the establishment of lunar infrastructure. These tasks include essential civil engineering operations, infrastructural component transportation and deployment, and assistive operations with inflatable modules. Furthermore, we systematically summarize the lessons learned during testing, focusing on the connector design and providing valuable insights for the advancement of modular robotic systems in future lunar missions.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21853v1",
        "pdf": "https://arxiv.org/pdf/2512.21853v1"
      },
      "arxiv_id": "2512.21853v1",
      "comment": "This is the authors' version of a paper accepted for publication in IEEE Transactions on Field Robotics, (c) IEEE. The final published version is available at https://doi.org/10.1109/TFR.2025.3624346",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21852v1",
      "title": "A Comedy of Estimators: On KL Regularization in RL Training of LLMs",
      "authors": [
        "Vedant Shah",
        "Johan Obando-Ceron",
        "Vineet Jain",
        "Brian Bartoldson",
        "Bhavya Kailkhura",
        "Sarthak Mittal",
        "Glen Berseth",
        "Pablo Samuel Castro",
        "Yoshua Bengio",
        "Nikolay Malkin",
        "Moksh Jain",
        "Siddarth Venkatraman",
        "Aaron Courville"
      ],
      "abstract": "The reasoning performance of large language models (LLMs) can be substantially improved by training them with reinforcement learning (RL). The RL objective for LLM training involves a regularization term, which is the reverse Kullback-Leibler (KL) divergence between the trained policy and the reference policy. Since computing the KL divergence exactly is intractable, various estimators are used in practice to estimate it from on-policy samples. Despite its wide adoption, including in several open-source libraries, there is no systematic study analyzing the numerous ways of incorporating KL estimators in the objective and their effect on the downstream performance of RL-trained models. Recent works show that prevailing practices for incorporating KL regularization do not provide correct gradients for stated objectives, creating a discrepancy between the objective and its implementation. In this paper, we further analyze these practices and study the gradients of several estimators configurations, revealing how design choices shape gradient bias. We substantiate these findings with empirical observations by RL fine-tuning \\texttt{Qwen2.5-7B}, \\texttt{Llama-3.1-8B-Instruct} and \\texttt{Qwen3-4B-Instruct-2507} with different configurations and evaluating their performance on both in- and out-of-distribution tasks. Through our analysis, we observe that, in on-policy settings: (1) estimator configurations with biased gradients can result in training instabilities; and (2) using estimator configurations resulting in unbiased gradients leads to better performance on in-domain as well as out-of-domain tasks. We also investigate the performance resulting from different KL configurations in off-policy settings and observe that KL regularization can help stabilize off-policy RL training resulting from asynchronous setups.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21852v1",
        "pdf": "https://arxiv.org/pdf/2512.21852v1"
      },
      "arxiv_id": "2512.21852v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21849v1",
      "title": "HeartBench: Probing Core Dimensions of Anthropomorphic Intelligence in LLMs",
      "authors": [
        "Jiaxin Liu",
        "Peiyi Tu",
        "Wenyu Chen",
        "Yihong Zhuang",
        "Xinxia Ling",
        "Anji Zhou",
        "Chenxi Wang",
        "Zhuo Han",
        "Zhengkai Yang",
        "Junbo Zhao",
        "Zenan Huang",
        "Yuanyuan Wang"
      ],
      "abstract": "While Large Language Models (LLMs) have achieved remarkable success in cognitive and reasoning benchmarks, they exhibit a persistent deficit in anthropomorphic intelligence-the capacity to navigate complex social, emotional, and ethical nuances. This gap is particularly acute in the Chinese linguistic and cultural context, where a lack of specialized evaluation frameworks and high-quality socio-emotional data impedes progress. To address these limitations, we present HeartBench, a framework designed to evaluate the integrated emotional, cultural, and ethical dimensions of Chinese LLMs. Grounded in authentic psychological counseling scenarios and developed in collaboration with clinical experts, the benchmark is structured around a theory-driven taxonomy comprising five primary dimensions and 15 secondary capabilities. We implement a case-specific, rubric-based methodology that translates abstract human-like traits into granular, measurable criteria through a ``reasoning-before-scoring'' evaluation protocol. Our assessment of 13 state-of-the-art LLMs indicates a substantial performance ceiling: even leading models achieve only 60% of the expert-defined ideal score. Furthermore, analysis using a difficulty-stratified ``Hard Set'' reveals a significant performance decay in scenarios involving subtle emotional subtexts and complex ethical trade-offs. HeartBench establishes a standardized metric for anthropomorphic AI evaluation and provides a methodological blueprint for constructing high-quality, human-aligned training data.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21849v1",
        "pdf": "https://arxiv.org/pdf/2512.21849v1"
      },
      "arxiv_id": "2512.21849v1",
      "comment": "10 pages",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21845v1",
      "title": "Scalable Class-Incremental Learning Based on Parametric Neural Collapse",
      "authors": [
        "Chuangxin Zhang",
        "Guangfeng Lin",
        "Enhui Zhao",
        "Kaiyang Liao",
        "Yajun Chen"
      ],
      "abstract": "Incremental learning often encounter challenges such as overfitting to new data and catastrophic forgetting of old data. Existing methods can effectively extend the model for new tasks while freezing the parameters of the old model, but ignore the necessity of structural efficiency to lead to the feature difference between modules and the class misalignment due to evolving class distributions. To address these issues, we propose scalable class-incremental learning based on parametric neural collapse (SCL-PNC) that enables demand-driven, minimal-cost backbone expansion by adapt-layer and refines the static into a dynamic parametric Equiangular Tight Frame (ETF) framework according to incremental class. This method can efficiently handle the model expansion question with the increasing number of categories in real-world scenarios. Additionally, to counteract feature drift in serial expansion models, the parallel expansion framework is presented with a knowledge distillation algorithm to align features across expansion modules. Therefore, SCL-PNC can not only design a dynamic and extensible ETF classifier to address class misalignment due to evolving class distributions, but also ensure feature consistency by an adapt-layer with knowledge distillation between extended modules. By leveraging neural collapse, SCL-PNC induces the convergence of the incremental expansion model through a structured combination of the expandable backbone, adapt-layer, and the parametric ETF classifier. Experiments on standard benchmarks demonstrate the effectiveness and efficiency of our proposed method. Our code is available at https://github.com/zhangchuangxin71-cyber/dynamic_ ETF2. Keywords: Class incremental learning; Catastrophic forgetting; Neural collapse;Knowledge distillation; Expanded model.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21845v1",
        "pdf": "https://arxiv.org/pdf/2512.21845v1"
      },
      "arxiv_id": "2512.21845v1",
      "comment": "42 pages, 8 figures, submitted to Pattern Recognition (PR)",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21831v1",
      "title": "End-to-End 3D Spatiotemporal Perception with Multimodal Fusion and V2X Collaboration",
      "authors": [
        "Zhenwei Yang",
        "Yibo Ai",
        "Weidong Zhang"
      ],
      "abstract": "Multi-view cooperative perception and multimodal fusion are essential for reliable 3D spatiotemporal understanding in autonomous driving, especially under occlusions, limited viewpoints, and communication delays in V2X scenarios. This paper proposes XET-V2X, a multi-modal fused end-to-end tracking framework for v2x collaboration that unifies multi-view multimodal sensing within a shared spatiotemporal representation. To efficiently align heterogeneous viewpoints and modalities, XET-V2X introduces a dual-layer spatial cross-attention module based on multi-scale deformable attention. Multi-view image features are first aggregated to enhance semantic consistency, followed by point cloud fusion guided by the updated spatial queries, enabling effective cross-modal interaction while reducing computational overhead. Experiments on the real-world V2X-Seq-SPD dataset and the simulated V2X-Sim-V2V and V2X-Sim-V2I benchmarks demonstrate consistent improvements in detection and tracking performance under varying communication delays. Both quantitative results and qualitative visualizations indicate that XET-V2X achieves robust and temporally stable perception in complex traffic scenarios.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21831v1",
        "pdf": "https://arxiv.org/pdf/2512.21831v1"
      },
      "arxiv_id": "2512.21831v1",
      "comment": "19 pages, 19 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21829v1",
      "title": "Tilt Matching for Scalable Sampling and Fine-Tuning",
      "authors": [
        "Peter Potaptchik",
        "Cheuk-Kit Lee",
        "Michael S. Albergo"
      ],
      "abstract": "We propose a simple, scalable algorithm for using stochastic interpolants to sample from unnormalized densities and for fine-tuning generative models. The approach, Tilt Matching, arises from a dynamical equation relating the flow matching velocity to one targeting the same distribution tilted by a reward, implicitly solving a stochastic optimal control problem. The new velocity inherits the regularity of stochastic interpolant transports while also being the minimizer of an objective with strictly lower variance than flow matching itself. The update to the velocity field can be interpreted as the sum of all joint cumulants of the stochastic interpolant and copies of the reward, and to first order is their covariance. The algorithms do not require any access to gradients of the reward or backpropagating through trajectories of the flow or diffusion. We empirically verify that the approach is efficient and highly scalable, providing state-of-the-art results on sampling under Lennard-Jones potentials and is competitive on fine-tuning Stable Diffusion, without requiring reward multipliers. It can also be straightforwardly applied to tilting few-step flow map models.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21829v1",
        "pdf": "https://arxiv.org/pdf/2512.21829v1"
      },
      "arxiv_id": "2512.21829v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21815v1",
      "title": "Few Tokens Matter: Entropy Guided Attacks on Vision-Language Models",
      "authors": [
        "Mengqi He",
        "Xinyu Tian",
        "Xin Shen",
        "Jinhong Ni",
        "Shu Zou",
        "Zhaoyuan Yang",
        "Jing Zhang"
      ],
      "abstract": "Vision-language models (VLMs) achieve remarkable performance but remain vulnerable to adversarial attacks. Entropy, a measure of model uncertainty, is strongly correlated with the reliability of VLM. Prior entropy-based attacks maximize uncertainty at all decoding steps, implicitly assuming that every token contributes equally to generation instability. We show instead that a small fraction (about 20%) of high-entropy tokens, i.e., critical decision points in autoregressive generation, disproportionately governs output trajectories. By concentrating adversarial perturbations on these positions, we achieve semantic degradation comparable to global methods while using substantially smaller budgets. More importantly, across multiple representative VLMs, such selective attacks convert 35-49% of benign outputs into harmful ones, exposing a more critical safety risk. Remarkably, these vulnerable high-entropy forks recur across architecturally diverse VLMs, enabling feasible transferability (17-26% harmful rates on unseen targets). Motivated by these findings, we propose Entropy-bank Guided Adversarial attacks (EGA), which achieves competitive attack success rates (93-95%) alongside high harmful conversion, thereby revealing new weaknesses in current VLM safety mechanisms.",
      "published": "2025-12-26",
      "updated": "2025-12-26",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21815v1",
        "pdf": "https://arxiv.org/pdf/2512.21815v1"
      },
      "arxiv_id": "2512.21815v1",
      "comment": "19 Pages,11 figures,8 tables",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21804v1",
      "title": "S&P 500 Stock's Movement Prediction using CNN",
      "authors": [
        "Rahul Gupta"
      ],
      "abstract": "This paper is about predicting the movement of stock consist of S&P 500 index. Historically there are many approaches have been tried using various methods to predict the stock movement and being used in the market currently for algorithm trading and alpha generating systems using traditional mathematical approaches [1, 2].\n  The success of artificial neural network recently created a lot of interest and paved the way to enable prediction using cutting-edge research in the machine learning and deep learning. Some of these papers have done a great job in implementing and explaining benefits of these new technologies. Although most these papers do not go into the complexity of the financial data and mostly utilize single dimension data, still most of these papers were successful in creating the ground for future research in this comparatively new phenomenon. In this paper, I am trying to use multivariate raw data including stock split/dividend events (as-is) present in real-world market data instead of engineered financial data. Convolution Neural Network (CNN), the best-known tool so far for image classification, is used on the multi-dimensional stock numbers taken from the market mimicking them as a vector of historical data matrices (read images) and the model achieves promising results. The predictions can be made stock by stock, i.e., a single stock, sector-wise or for the portfolio of stocks.",
      "published": "2025-12-25",
      "updated": "2025-12-25",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21804v1",
        "pdf": "https://arxiv.org/pdf/2512.21804v1"
      },
      "arxiv_id": "2512.21804v1",
      "comment": "9 pages, 19 diagrams. Originally submitted as a part of my Stanford University program taught by Dr. Fei Fei Lee and Andrej Karpathy CS231N 2018",
      "journal_ref": "ADaSci Lattice Journal, Vol. 1, January 10, 2021",
      "has_code": false
    },
    {
      "id": "2512.21803v1",
      "title": "CellMamba: Adaptive Mamba for Accurate and Efficient Cell Detection",
      "authors": [
        "Ruochen Liu",
        "Yi Tian",
        "Jiahao Wang",
        "Hongbin Liu",
        "Xianxu Hou",
        "Jingxin Liu"
      ],
      "abstract": "Cell detection in pathological images presents unique challenges due to densely packed objects, subtle inter-class differences, and severe background clutter. In this paper, we propose CellMamba, a lightweight and accurate one-stage detector tailored for fine-grained biomedical instance detection. Built upon a VSSD backbone, CellMamba integrates CellMamba Blocks, which couple either NC-Mamba or Multi-Head Self-Attention (MSA) with a novel Triple-Mapping Adaptive Coupling (TMAC) module. TMAC enhances spatial discriminability by splitting channels into two parallel branches, equipped with dual idiosyncratic and one consensus attention map, adaptively fused to preserve local sensitivity and global consistency. Furthermore, we design an Adaptive Mamba Head that fuses multi-scale features via learnable weights for robust detection under varying object sizes. Extensive experiments on two public datasets-CoNSeP and CytoDArk0-demonstrate that CellMamba outperforms both CNN-based, Transformer-based, and Mamba-based baselines in accuracy, while significantly reducing model size and inference latency. Our results validate CellMamba as an efficient and effective solution for high-resolution cell detection.",
      "published": "2025-12-25",
      "updated": "2025-12-25",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21803v1",
        "pdf": "https://arxiv.org/pdf/2512.21803v1"
      },
      "arxiv_id": "2512.21803v1",
      "comment": "36th British Machine Vision Conference (BMVC 2025)",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21801v1",
      "title": "Smart IoT-Based Leak Forecasting and Detection for Energy-Efficient Liquid Cooling in AI Data Centers",
      "authors": [
        "Krishna Chaitanya Sunkara",
        "Rambabu Konakanchi"
      ],
      "abstract": "AI data centers which are GPU centric, have adopted liquid cooling to handle extreme heat loads, but coolant leaks result in substantial energy loss through unplanned shutdowns and extended repair periods. We present a proof-of-concept smart IoT monitoring system combining LSTM neural networks for probabilistic leak forecasting with Random Forest classifiers for instant detection. Testing on synthetic data aligned with ASHRAE 2021 standards, our approach achieves 96.5% detection accuracy and 87% forecasting accuracy at 90% probability within plus or minus 30-minute windows. Analysis demonstrates that humidity, pressure, and flow rate deliver strong predictive signals, while temperature exhibits minimal immediate response due to thermal inertia in server hardware. The system employs MQTT streaming, InfluxDB storage, and Streamlit dashboards, forecasting leaks 2-4 hours ahead while identifying sudden events within 1 minute. For a typical 47-rack facility, this approach could prevent roughly 1,500 kWh annual energy waste through proactive maintenance rather than reactive emergency procedures. While validation remains synthetic-only, results establish feasibility for future operational deployment in sustainable data center operations.",
      "published": "2025-12-25",
      "updated": "2025-12-25",
      "categories": [
        "cs.LG",
        "cs.DC",
        "cs.NI",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21801v1",
        "pdf": "https://arxiv.org/pdf/2512.21801v1"
      },
      "arxiv_id": "2512.21801v1",
      "comment": "7 pages, 6 figures, IEEE conference format",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21798v1",
      "title": "Applications of synthetic financial data in portfolio and risk modeling",
      "authors": [
        "Christophe D. Hounwanou",
        "Yae Ulrich Gaba"
      ],
      "abstract": "Synthetic financial data offers a practical way to address the privacy and accessibility challenges that limit research in quantitative finance. This paper examines the use of generative models, in particular TimeGAN and Variational Autoencoders (VAEs), for creating synthetic return series that support portfolio construction, trading analysis, and risk modeling. Using historical daily returns from the S and P 500 as a benchmark, we generate synthetic datasets under comparable market conditions and evaluate them using statistical similarity metrics, temporal structure tests, and downstream financial tasks. The study shows that TimeGAN produces synthetic data with distributional shapes, volatility patterns, and autocorrelation behaviour that are close to those observed in real returns. When applied to mean-variance portfolio optimization, the resulting synthetic datasets lead to portfolio weights, Sharpe ratios, and risk levels that remain close to those obtained from real data. The VAE provides more stable training but tends to smooth extreme market movements, which affects risk estimation. Finally, the analysis supports the use of synthetic datasets as substitutes for real financial data in portfolio analysis and risk simulation, particularly when models are able to capture temporal dynamics. Synthetic data therefore provides a privacy-preserving, cost-effective, and reproducible tool for financial experimentation and model development.",
      "published": "2025-12-25",
      "updated": "2025-12-25",
      "categories": [
        "q-fin.ST",
        "cs.AI"
      ],
      "primary_category": "q-fin.ST",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21798v1",
        "pdf": "https://arxiv.org/pdf/2512.21798v1"
      },
      "arxiv_id": "2512.21798v1",
      "comment": "14 pages, submitted as a preprint. This study examines generative models (TimeGAN and VAE) for creating synthetic financial data to support portfolio construction, trading analysis, and risk modeling",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21797v1",
      "title": "Diffusion Posterior Sampling for Super-Resolution under Gaussian Measurement Noise",
      "authors": [
        "Abu Hanif Muhammad Syarubany"
      ],
      "abstract": "This report studies diffusion posterior sampling (DPS) for single-image super-resolution (SISR) under a known degradation model. We implement a likelihood-guided sampling procedure that combines an unconditional diffusion prior with gradient-based conditioning to enforce measurement consistency for $4\\times$ super-resolution with additive Gaussian noise. We evaluate posterior sampling (PS) conditioning across guidance scales and noise levels, using PSNR and SSIM as fidelity metrics and a combined selection score $(\\mathrm{PSNR}/40)+\\mathrm{SSIM}$. Our ablation shows that moderate guidance improves reconstruction quality, with the best configuration achieved at PS scale $0.95$ and noise standard deviation $σ=0.01$ (score $1.45231$). Qualitative results confirm that the selected PS setting restores sharper edges and more coherent facial details compared to the downsampled inputs, while alternative conditioning strategies (e.g., MCG and PS-annealed) exhibit different texture fidelity trade-offs. These findings highlight the importance of balancing diffusion priors and measurement-gradient strength to obtain stable, high-quality reconstructions without retraining the diffusion model for each operator.",
      "published": "2025-12-25",
      "updated": "2025-12-25",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21797v1",
        "pdf": "https://arxiv.org/pdf/2512.21797v1"
      },
      "arxiv_id": "2512.21797v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21794v1",
      "title": "Multi-agent Adaptive Mechanism Design",
      "authors": [
        "Qiushi Han",
        "David Simchi-Levi",
        "Renfei Tan",
        "Zishuo Zhao"
      ],
      "abstract": "We study a sequential mechanism design problem in which a principal seeks to elicit truthful reports from multiple rational agents while starting with no prior knowledge of agents' beliefs. We introduce Distributionally Robust Adaptive Mechanism (DRAM), a general framework combining insights from both mechanism design and online learning to jointly address truthfulness and cost-optimality. Throughout the sequential game, the mechanism estimates agents' beliefs and iteratively updates a distributionally robust linear program with shrinking ambiguity sets to reduce payments while preserving truthfulness. Our mechanism guarantees truthful reporting with high probability while achieving $\\tilde{O}(\\sqrt{T})$ cumulative regret, and we establish a matching lower bound showing that no truthful adaptive mechanism can asymptotically do better. The framework generalizes to plug-in estimators, supporting structured priors and delayed feedback. To our knowledge, this is the first adaptive mechanism under general settings that maintains truthfulness and achieves optimal regret when incentive constraints are unknown and must be learned.",
      "published": "2025-12-25",
      "updated": "2025-12-25",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.LG",
        "cs.MA",
        "econ.TH"
      ],
      "primary_category": "cs.GT",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21794v1",
        "pdf": "https://arxiv.org/pdf/2512.21794v1"
      },
      "arxiv_id": "2512.21794v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21792v1",
      "title": "AI for Mycetoma Diagnosis in Histopathological Images: The MICCAI 2024 Challenge",
      "authors": [
        "Hyam Omar Ali",
        "Sahar Alhesseen",
        "Lamis Elkhair",
        "Adrian Galdran",
        "Ming Feng",
        "Zhixiang Xiong",
        "Zengming Lin",
        "Kele Xu",
        "Liang Hu",
        "Benjamin Keel",
        "Oliver Mills",
        "James Battye",
        "Akshay Kumar",
        "Asra Aslam",
        "Prasad Dutande",
        "Ujjwal Baid",
        "Bhakti Baheti",
        "Suhas Gajre",
        "Aravind Shrenivas Murali",
        "Eung-Joo Lee",
        "Ahmed Fahal",
        "Rachid Jennane"
      ],
      "abstract": "Mycetoma is a neglected tropical disease caused by fungi or bacteria leading to severe tissue damage and disabilities. It affects poor and rural communities and presents medical challenges and socioeconomic burdens on patients and healthcare systems in endemic regions worldwide. Mycetoma diagnosis is a major challenge in mycetoma management, particularly in low-resource settings where expert pathologists are limited. To address this challenge, this paper presents an overview of the Mycetoma MicroImage: Detect and Classify Challenge (mAIcetoma) which was organized to advance mycetoma diagnosis through AI solutions. mAIcetoma focused on developing automated models for segmenting mycetoma grains and classifying mycetoma types from histopathological images. The challenge attracted the attention of several teams worldwide to participate and five finalist teams fulfilled the challenge objectives. The teams proposed various deep learning architectures for the ultimate goal of this challenge. Mycetoma database (MyData) was provided to participants as a standardized dataset to run the proposed models. Those models were evaluated using evaluation metrics. Results showed that all the models achieved high segmentation accuracy, emphasizing the necessitate of grain detection as a critical step in mycetoma diagnosis. In addition, the top-performing models show a significant performance in classifying mycetoma types.",
      "published": "2025-12-25",
      "updated": "2025-12-25",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21792v1",
        "pdf": "https://arxiv.org/pdf/2512.21792v1"
      },
      "arxiv_id": "2512.21792v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21791v1",
      "title": "Synthetic Financial Data Generation for Enhanced Financial Modelling",
      "authors": [
        "Christophe D. Hounwanou",
        "Yae Ulrich Gaba",
        "Pierre Ntakirutimana"
      ],
      "abstract": "Data scarcity and confidentiality in finance often impede model development and robust testing. This paper presents a unified multi-criteria evaluation framework for synthetic financial data and applies it to three representative generative paradigms: the statistical ARIMA-GARCH baseline, Variational Autoencoders (VAEs), and Time-series Generative Adversarial Networks (TimeGAN). Using historical S and P 500 daily data, we evaluate fidelity (Maximum Mean Discrepancy, MMD), temporal structure (autocorrelation and volatility clustering), and practical utility in downstream tasks, specifically mean-variance portfolio optimization and volatility forecasting. Empirical results indicate that ARIMA-GARCH captures linear trends and conditional volatility but fails to reproduce nonlinear dynamics; VAEs produce smooth trajectories that underestimate extreme events; and TimeGAN achieves the best trade-off between realism and temporal coherence (e.g., TimeGAN attained the lowest MMD: 1.84e-3, average over 5 seeds). Finally, we articulate practical guidelines for selecting generative models according to application needs and computational constraints. Our unified evaluation protocol and reproducible codebase aim to standardize benchmarking in synthetic financial data research.",
      "published": "2025-12-25",
      "updated": "2025-12-25",
      "categories": [
        "cs.LG",
        "q-fin.CP"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21791v1",
        "pdf": "https://arxiv.org/pdf/2512.21791v1"
      },
      "arxiv_id": "2512.21791v1",
      "comment": "23 pages, 7 figures, 6 tables. Submitted as a preprint. This work presents a unified multi-criteria evaluation framework for synthetic financial data, applied to ARIMA-GARCH, VAEs, and TimeGAN models",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21789v1",
      "title": "Five Years of SciCap: What We Learned and Future Directions for Scientific Figure Captioning",
      "authors": [
        "Ting-Hao K. Huang",
        "Ryan A. Rossi",
        "Sungchul Kim",
        "Tong Yu",
        "Ting-Yao E. Hsu",
        "Ho Yin",
        "Ng",
        "C. Lee Giles"
      ],
      "abstract": "Between 2021 and 2025, the SciCap project grew from a small seed-funded idea at The Pennsylvania State University (Penn State) into one of the central efforts shaping the scientific figure-captioning landscape. Supported by a Penn State seed grant, Adobe, and the Alfred P. Sloan Foundation, what began as our attempt to test whether domain-specific training, which was successful in text models like SciBERT, could also work for figure captions expanded into a multi-institution collaboration. Over these five years, we curated, released, and continually updated a large collection of figure-caption pairs from arXiv papers, conducted extensive automatic and human evaluations on both generated and author-written captions, navigated the rapid rise of large language models (LLMs), launched annual challenges, and built interactive systems that help scientists write better captions. In this piece, we look back at the first five years of SciCap and summarize the key technical and methodological lessons we learned. We then outline five major unsolved challenges and propose directions for the next phase of research in scientific figure captioning.",
      "published": "2025-12-25",
      "updated": "2025-12-25",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21789v1",
        "pdf": "https://arxiv.org/pdf/2512.21789v1"
      },
      "arxiv_id": "2512.21789v1",
      "comment": "Accepted to the 5th Annual AAAI Workshop on AI to Accelerate Science and Engineering (AI2ASE 2026)",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21788v1",
      "title": "InstructMoLE: Instruction-Guided Mixture of Low-rank Experts for Multi-Conditional Image Generation",
      "authors": [
        "Jinqi Xiao",
        "Qing Yan",
        "Liming Jiang",
        "Zichuan Liu",
        "Hao Kang",
        "Shen Sang",
        "Tiancheng Zhi",
        "Jing Liu",
        "Cheng Yang",
        "Xin Lu",
        "Bo Yuan"
      ],
      "abstract": "Parameter-Efficient Fine-Tuning of Diffusion Transformers (DiTs) for diverse, multi-conditional tasks often suffers from task interference when using monolithic adapters like LoRA. The Mixture of Low-rank Experts (MoLE) architecture offers a modular solution, but its potential is usually limited by routing policies that operate at a token level. Such local routing can conflict with the global nature of user instructions, leading to artifacts like spatial fragmentation and semantic drift in complex image generation tasks. To address these limitations, we introduce InstructMoLE, a novel framework that employs an Instruction-Guided Mixture of Low-Rank Experts. Instead of per-token routing, InstructMoLE utilizes a global routing signal, Instruction-Guided Routing (IGR), derived from the user's comprehensive instruction. This ensures that a single, coherently chosen expert council is applied uniformly across all input tokens, preserving the global semantics and structural integrity of the generation process. To complement this, we introduce an output-space orthogonality loss, which promotes expert functional diversity and mitigates representational collapse. Extensive experiments demonstrate that InstructMoLE significantly outperforms existing LoRA adapters and MoLE variants across challenging multi-conditional generation benchmarks. Our work presents a robust and generalizable framework for instruction-driven fine-tuning of generative models, enabling superior compositional control and fidelity to user intent.",
      "published": "2025-12-25",
      "updated": "2025-12-25",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21788v1",
        "pdf": "https://arxiv.org/pdf/2512.21788v1"
      },
      "arxiv_id": "2512.21788v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21786v1",
      "title": "VAMP-Net: An Interpretable Multi-Path Framework of Genomic Permutation-Invariant Set Attention and Quality-Aware 1D-CNN for MTB Drug Resistance",
      "authors": [
        "Aicha Boutorh",
        "Kamar Hibatallah Baghdadi",
        "Anais Daoud"
      ],
      "abstract": "Genomic prediction of drug resistance in Mycobacterium tuberculosis remains challenging due to complex epistatic interactions and highly variable sequencing data quality. We present a novel Interpretable Variant-Aware Multi-Path Network (VAMP-Net) that addresses both challenges through complementary machine learning pathways. Path-1 employs a Set Attention Transformer processing permutation-invariant variant sets to capture epistatic interactions between genomic loci. Path-2 utilizes a 1D Convolutional Neural Network that analyzes Variant Call Format quality metrics to learn adaptive confidence scores. A fusion module combines both pathways for final resistance classification. We conduct comparative evaluations of unmasked versus padding-masked Set Attention Blocks, and demonstrate that our multi-path architecture achieves superior performance over baseline CNN and MLP models, with accuracy exceeding 95% and AUC around 97% for Rifampicin (RIF) and Rifabutin (RFB) resistance prediction. The framework provides dual-layer interpretability: Attention Weight Analysis reveals Epistatic networks, and Integrated Gradients (IG) was applied for critical resistance loci (notably rpoB), while gradient-based feature importance from the CNN pathway uncovers drug-specific dependencies on data quality metrics. This architecture advances clinical genomics by delivering state-of-the-art predictive performance alongside auditable interpretability at two distinct levels, genetic causality of mutation sets and technical confidence of sequencing evidence, establishing a new paradigm for robust, clinically-actionable resistance prediction.",
      "published": "2025-12-25",
      "updated": "2025-12-25",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21786v1",
        "pdf": "https://arxiv.org/pdf/2512.21786v1"
      },
      "arxiv_id": "2512.21786v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21782v1",
      "title": "Accelerating Scientific Discovery with Autonomous Goal-evolving Agents",
      "authors": [
        "Yuanqi Du",
        "Botao Yu",
        "Tianyu Liu",
        "Tony Shen",
        "Junwu Chen",
        "Jan G. Rittig",
        "Kunyang Sun",
        "Yikun Zhang",
        "Zhangde Song",
        "Bo Zhou",
        "Cassandra Masschelein",
        "Yingze Wang",
        "Haorui Wang",
        "Haojun Jia",
        "Chao Zhang",
        "Hongyu Zhao",
        "Martin Ester",
        "Teresa Head-Gordon",
        "Carla P. Gomes",
        "Huan Sun",
        "Chenru Duan",
        "Philippe Schwaller",
        "Wengong Jin"
      ],
      "abstract": "There has been unprecedented interest in developing agents that expand the boundary of scientific discovery, primarily by optimizing quantitative objective functions specified by scientists. However, for grand challenges in science , these objectives are only imperfect proxies. We argue that automating objective function design is a central, yet unmet requirement for scientific discovery agents. In this work, we introduce the Scientific Autonomous Goal-evolving Agent (SAGA) to amend this challenge. SAGA employs a bi-level architecture in which an outer loop of LLM agents analyzes optimization outcomes, proposes new objectives, and converts them into computable scoring functions, while an inner loop performs solution optimization under the current objectives. This bi-level design enables systematic exploration of the space of objectives and their trade-offs, rather than treating them as fixed inputs. We demonstrate the framework through a broad spectrum of applications, including antibiotic design, inorganic materials design, functional DNA sequence design, and chemical process design, showing that automating objective formulation can substantially improve the effectiveness of scientific discovery agents.",
      "published": "2025-12-25",
      "updated": "2025-12-25",
      "categories": [
        "cs.AI",
        "cond-mat.mtrl-sci",
        "cs.LG",
        "physics.chem-ph"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21782v1",
        "pdf": "https://arxiv.org/pdf/2512.21782v1"
      },
      "arxiv_id": "2512.21782v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21778v1",
      "title": "Scene-VLM: Multimodal Video Scene Segmentation via Vision-Language Models",
      "authors": [
        "Nimrod Berman",
        "Adam Botach",
        "Emanuel Ben-Baruch",
        "Shunit Haviv Hakimi",
        "Asaf Gendler",
        "Ilan Naiman",
        "Erez Yosef",
        "Igor Kviatkovsky"
      ],
      "abstract": "Segmenting long-form videos into semantically coherent scenes is a fundamental task in large-scale video understanding. Existing encoder-based methods are limited by visual-centric biases, classify each shot in isolation without leveraging sequential dependencies, and lack both narrative understanding and explainability. In this paper, we present Scene-VLM, the first fine-tuned vision-language model (VLM) framework for video scene segmentation. Scene-VLM jointly processes visual and textual cues including frames, transcriptions, and optional metadata to enable multimodal reasoning across consecutive shots. The model generates predictions sequentially with causal dependencies among shots and introduces a context-focus window mechanism to ensure sufficient temporal context for each shot-level decision. In addition, we propose a scheme to extract confidence scores from the token-level logits of the VLM, enabling controllable precision-recall trade-offs that were previously limited to encoder-based methods. Furthermore, we demonstrate that our model can be aligned to generate coherent natural-language rationales for its boundary decisions through minimal targeted supervision. Our approach achieves state-of-the-art performance on standard scene segmentation benchmarks. On MovieNet, for example, Scene-VLM yields significant improvements of +6 AP and +13.7 F1 over the previous leading method.",
      "published": "2025-12-25",
      "updated": "2025-12-25",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21778v1",
        "pdf": "https://arxiv.org/pdf/2512.21778v1"
      },
      "arxiv_id": "2512.21778v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21776v1",
      "title": "Inference-based GAN Video Generation",
      "authors": [
        "Jingbo Yang",
        "Adrian G. Bors"
      ],
      "abstract": "Video generation has seen remarkable progresses thanks to advancements in generative deep learning. Generated videos should not only display coherent and continuous movement but also meaningful movement in successions of scenes. Generating models such as Generative Adversarial Networks (GANs) or Variational Autoencoders (VAEs) and more recently Diffusion Networks have been used for generating short video sequences, usually of up to 16 frames. In this paper, we first propose a new type of video generator by enabling adversarial-based unconditional video generators with a variational encoder, akin to a VAE-GAN hybrid structure, in order to enable the generation process with inference capabilities. The proposed model, as in other video deep learning-based processing frameworks, incorporates two processing branches, one for content and another for movement. However, existing models struggle with the temporal scaling of the generated videos. In classical approaches when aiming to increase the generated video length, the resulting video quality degrades, particularly when considering generating significantly long sequences. To overcome this limitation, our research study extends the initially proposed VAE-GAN video generation model by employing a novel, memory-efficient approach to generate long videos composed of hundreds or thousands of frames ensuring their temporal continuity, consistency and dynamics. Our approach leverages a Markov chain framework with a recall mechanism, with each state representing a VAE-GAN short-length video generator. This setup allows for the sequential connection of generated video sub-sequences, enabling temporal dependencies, resulting in meaningful long video sequences.",
      "published": "2025-12-25",
      "updated": "2025-12-25",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21776v1",
        "pdf": "https://arxiv.org/pdf/2512.21776v1"
      },
      "arxiv_id": "2512.21776v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21775v1",
      "title": "Compliance Rating Scheme: A Data Provenance Framework for Generative AI Datasets",
      "authors": [
        "Matyas Bohacek",
        "Ignacio Vilanova Echavarri"
      ],
      "abstract": "Generative Artificial Intelligence (GAI) has experienced exponential growth in recent years, partly facilitated by the abundance of large-scale open-source datasets. These datasets are often built using unrestricted and opaque data collection practices. While most literature focuses on the development and applications of GAI models, the ethical and legal considerations surrounding the creation of these datasets are often neglected. In addition, as datasets are shared, edited, and further reproduced online, information about their origin, legitimacy, and safety often gets lost. To address this gap, we introduce the Compliance Rating Scheme (CRS), a framework designed to evaluate dataset compliance with critical transparency, accountability, and security principles. We also release an open-source Python library built around data provenance technology to implement this framework, allowing for seamless integration into existing dataset-processing and AI training pipelines. The library is simultaneously reactive and proactive, as in addition to evaluating the CRS of existing datasets, it equally informs responsible scraping and construction of new datasets.",
      "published": "2025-12-25",
      "updated": "2025-12-25",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.DB"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21775v1",
        "pdf": "https://arxiv.org/pdf/2512.21775v1"
      },
      "arxiv_id": "2512.21775v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21769v1",
      "title": "BertsWin: Resolving Topological Sparsity in 3D Masked Autoencoders via Component-Balanced Structural Optimization",
      "authors": [
        "Evgeny Alves Limarenko",
        "Anastasiia Studenikina"
      ],
      "abstract": "The application of self-supervised learning (SSL) and Vision Transformers (ViTs) approaches demonstrates promising results in the field of 2D medical imaging, but the use of these methods on 3D volumetric images is fraught with difficulties. Standard Masked Autoencoders (MAE), which are state-of-the-art solution for 2D, have a hard time capturing three-dimensional spatial relationships, especially when 75% of tokens are discarded during pre-training. We propose BertsWin, a hybrid architecture combining full BERT-style token masking using Swin Transformer windows, to enhance spatial context learning in 3D during SSL pre-training. Unlike the classic MAE, which processes only visible areas, BertsWin introduces a complete 3D grid of tokens (masked and visible), preserving the spatial topology. And to smooth out the quadratic complexity of ViT, single-level local Swin windows are used. We introduce a structural priority loss function and evaluate the results of cone beam computed tomography of the temporomandibular joints. The subsequent assessment includes TMJ segmentation on 3D CT scans. We demonstrate that the BertsWin architecture, by maintaining a complete three-dimensional spatial topology, inherently accelerates semantic convergence by a factor of 5.8x compared to standard ViT-MAE baselines. Furthermore, when coupled with our proposed GradientConductor optimizer, the full BertsWin framework achieves a 15-fold reduction in training epochs (44 vs 660) required to reach state-of-the-art reconstruction fidelity. Analysis reveals that BertsWin achieves this acceleration without the computational penalty typically associated with dense volumetric processing. At canonical input resolutions, the architecture maintains theoretical FLOP parity with sparse ViT baselines, resulting in a significant net reduction in total computational resources due to faster convergence.",
      "published": "2025-12-25",
      "updated": "2025-12-25",
      "categories": [
        "cs.CV",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21769v1",
        "pdf": "https://arxiv.org/pdf/2512.21769v1"
      },
      "arxiv_id": "2512.21769v1",
      "comment": "Code available at https://github.com/AlevLab-dev/BertsWinMAE and https://github.com/AlevLab-dev/GCond. Zenodo repository (DOI: 10.5281/zenodo.17916932) contains source images, training logs, trained models, and code",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2512.21762v1",
      "title": "Assessing the Effectiveness of Membership Inference on Generative Music",
      "authors": [
        "Kurtis Chow",
        "Omar Samiullah",
        "Vinesh Sridhar",
        "Hewen Zhang"
      ],
      "abstract": "Generative AI systems are quickly improving, now able to produce believable output in several modalities including images, text, and audio. However, this fast development has prompted increased scrutiny concerning user privacy and the use of copyrighted works in training. A recent attack on machine-learning models called membership inference lies at the crossroads of these two concerns. The attack is given as input a set of records and a trained model and seeks to identify which of those records may have been used to train the model. On one hand, this attack can be used to identify user data used to train a model, which may violate their privacy especially in sensitive applications such as models trained on medical data. On the other hand, this attack can be used by rights-holders as evidence that a company used their works without permission to train a model.\n  Remarkably, it appears that no work has studied the effect of membership inference attacks (MIA) on generative music. Given that the music industry is worth billions of dollars and artists would stand to gain from being able to determine if their works were being used without permission, we believe this is a pressing issue to study. As such, in this work we begin a preliminary study into whether MIAs are effective on generative music. We study the effect of several existing attacks on MuseGAN, a popular and influential generative music model. Similar to prior work on generative audio MIAs, our findings suggest that music data is fairly resilient to known membership inference techniques.",
      "published": "2025-12-25",
      "updated": "2025-12-25",
      "categories": [
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21762v1",
        "pdf": "https://arxiv.org/pdf/2512.21762v1"
      },
      "arxiv_id": "2512.21762v1",
      "comment": "10 pages, 3 figures, 3 tables",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21760v1",
      "title": "A-QCF-Net: An Adaptive Quaternion Cross-Fusion Network for Multimodal Liver Tumor Segmentation from Unpaired Datasets",
      "authors": [
        "Arunkumar V",
        "Firos V M",
        "Senthilkumar S",
        "Gangadharan G R"
      ],
      "abstract": "Multimodal medical imaging provides complementary information that is crucial for accurate delineation of pathology, but the development of deep learning models is limited by the scarcity of large datasets in which different modalities are paired and spatially aligned. This paper addresses this fundamental limitation by proposing an Adaptive Quaternion Cross-Fusion Network (A-QCF-Net) that learns a single unified segmentation model from completely separate and unpaired CT and MRI cohorts. The architecture exploits the parameter efficiency and expressive power of Quaternion Neural Networks to construct a shared feature space. At its core is the Adaptive Quaternion Cross-Fusion (A-QCF) block, a data driven attention module that enables bidirectional knowledge transfer between the two streams. By learning to modulate the flow of information dynamically, the A-QCF block allows the network to exchange abstract modality specific expertise, such as the sharp anatomical boundary information available in CT and the subtle soft tissue contrast provided by MRI. This mutual exchange regularizes and enriches the feature representations of both streams. We validate the framework by jointly training a single model on the unpaired LiTS (CT) and ATLAS (MRI) datasets. The jointly trained model achieves Tumor Dice scores of 76.7% on CT and 78.3% on MRI, significantly exceeding the strong unimodal nnU-Net baseline by margins of 5.4% and 4.7% respectively. Furthermore, comprehensive explainability analysis using Grad-CAM and Grad-CAM++ confirms that the model correctly focuses on relevant pathological structures, ensuring the learned representations are clinically meaningful. This provides a robust and clinically viable paradigm for unlocking the large unpaired imaging archives that are common in healthcare.",
      "published": "2025-12-25",
      "updated": "2025-12-25",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21760v1",
        "pdf": "https://arxiv.org/pdf/2512.21760v1"
      },
      "arxiv_id": "2512.21760v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21757v1",
      "title": "How Do Agents Perform Code Optimization? An Empirical Study",
      "authors": [
        "Huiyun Peng",
        "Antonio Zhong",
        "Ricardo Andrés Calvo Méndez",
        "Kelechi G. Kalu",
        "James C. Davis"
      ],
      "abstract": "Performance optimization is a critical yet challenging aspect of software development, often requiring a deep understanding of system behavior, algorithmic tradeoffs, and careful code modifications. Although recent advances in AI coding agents have accelerated code generation and bug fixing, little is known about how these agents perform on real-world performance optimization tasks. We present the first empirical study comparing agent- and human-authored performance optimization commits, analyzing 324 agent-generated and 83 human-authored PRs from the AIDev dataset across adoption, maintainability, optimization patterns, and validation practices. We find that AI-authored performance PRs are less likely to include explicit performance validation than human-authored PRs (45.7\\% vs. 63.6\\%, $p=0.007$). In addition, AI-authored PRs largely use the same optimization patterns as humans. We further discuss limitations and opportunities for advancing agentic code optimization.",
      "published": "2025-12-25",
      "updated": "2025-12-25",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21757v1",
        "pdf": "https://arxiv.org/pdf/2512.21757v1"
      },
      "arxiv_id": "2512.21757v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21749v1",
      "title": "Approximation Capabilities of Feedforward Neural Networks with GELU Activations",
      "authors": [
        "Konstantin Yakovlev",
        "Nikita Puchkin"
      ],
      "abstract": "We derive an approximation error bound that holds simultaneously for a function and all its derivatives up to any prescribed order. The bounds apply to elementary functions, including multivariate polynomials, the exponential function, and the reciprocal function, and are obtained using feedforward neural networks with the Gaussian Error Linear Unit (GELU) activation. In addition, we report the network size, weight magnitudes, and behavior at infinity. Our analysis begins with a constructive approximation of multiplication, where we prove the simultaneous validity of error bounds over domains of increasing size for a given approximator. Leveraging this result, we obtain approximation guarantees for division and the exponential function, ensuring that all higher-order derivatives of the resulting approximators remain globally bounded.",
      "published": "2025-12-25",
      "updated": "2025-12-25",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21749v1",
        "pdf": "https://arxiv.org/pdf/2512.21749v1"
      },
      "arxiv_id": "2512.21749v1",
      "comment": "42 pages",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21747v1",
      "title": "Modified TSception for Analyzing Driver Drowsiness and Mental Workload from EEG",
      "authors": [
        "Gourav Siddhad",
        "Anurag Singh",
        "Rajkumar Saini",
        "Partha Pratim Roy"
      ],
      "abstract": "Driver drowsiness remains a primary cause of traffic accidents, necessitating the development of real-time, reliable detection systems to ensure road safety. This study presents a Modified TSception architecture designed for the robust assessment of driver fatigue using Electroencephalography (EEG). The model introduces a novel hierarchical architecture that surpasses the original TSception by implementing a five-layer temporal refinement strategy to capture multi-scale brain dynamics. A key innovation is the use of Adaptive Average Pooling, which provides the structural flexibility to handle varying EEG input dimensions, and a two - stage fusion mechanism that optimizes the integration of spatiotemporal features for improved stability. When evaluated on the SEED-VIG dataset and compared against established methods - including SVM, Transformer, EEGNet, ConvNeXt, LMDA-Net, and the original TSception - the Modified TSception achieves a comparable accuracy of 83.46% (vs. 83.15% for the original). Critically, the proposed model exhibits a substantially reduced confidence interval (0.24 vs. 0.36), signifying a marked improvement in performance stability. Furthermore, the architecture's generalizability is validated on the STEW mental workload dataset, where it achieves state-of-the-art results with 95.93% and 95.35% accuracy for 2-class and 3-class classification, respectively. These improvements in consistency and cross-task generalizability underscore the effectiveness of the proposed modifications for reliable EEG-based monitoring of drowsiness and mental workload.",
      "published": "2025-12-25",
      "updated": "2025-12-25",
      "categories": [
        "cs.HC",
        "cs.CV"
      ],
      "primary_category": "cs.HC",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21747v1",
        "pdf": "https://arxiv.org/pdf/2512.21747v1"
      },
      "arxiv_id": "2512.21747v1",
      "comment": "8 Pages, 3 Figures, 1 Table",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21746v1",
      "title": "A Model of Causal Explanation on Neural Networks for Tabular Data",
      "authors": [
        "Takashi Isozaki",
        "Masahiro Yamamoto",
        "Atsushi Noda"
      ],
      "abstract": "The problem of explaining the results produced by machine learning methods continues to attract attention. Neural network (NN) models, along with gradient boosting machines, are expected to be utilized even in tabular data with high prediction accuracy. This study addresses the related issues of pseudo-correlation, causality, and combinatorial reasons for tabular data in NN predictors. We propose a causal explanation method, CENNET, and a new explanation power index using entropy for the method. CENNET provides causal explanations for predictions by NNs and uses structural causal models (SCMs) effectively combined with the NNs although SCMs are usually not used as predictive models on their own in terms of predictive accuracy. We show that CEN-NET provides such explanations through comparative experiments with existing methods on both synthetic and quasi-real data in classification tasks.",
      "published": "2025-12-25",
      "updated": "2025-12-25",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21746v1",
        "pdf": "https://arxiv.org/pdf/2512.21746v1"
      },
      "arxiv_id": "2512.21746v1",
      "comment": "\\c{opyright}2025. This manuscript version is made available under the CC-BY-NC-ND 4.0 license https://creativecommons.org/licenses/by-nc-nd/4.0/",
      "journal_ref": "Procedia Computer Science, Volume 264, 2025, Pages 65-79",
      "has_code": false
    },
    {
      "id": "2512.21743v1",
      "title": "Dynamic Feedback Engines: Layer-Wise Control for Self-Regulating Continual Learning",
      "authors": [
        "Hengyi Wu",
        "Zhenyi Wang",
        "Heng Huang"
      ],
      "abstract": "Continual learning aims to acquire new tasks while preserving performance on previously learned ones, but most methods struggle with catastrophic forgetting. Existing approaches typically treat all layers uniformly, often trading stability for plasticity or vice versa. However, different layers naturally exhibit varying levels of uncertainty (entropy) when classifying tasks. High-entropy layers tend to underfit by failing to capture task-specific patterns, while low-entropy layers risk overfitting by becoming overly confident and specialized. To address this imbalance, we propose an entropy-aware continual learning method that employs a dynamic feedback mechanism to regulate each layer based on its entropy. Specifically, our approach reduces entropy in high-entropy layers to mitigate underfitting and increases entropy in overly confident layers to alleviate overfitting. This adaptive regulation encourages the model to converge to wider local minima, which have been shown to improve generalization. Our method is general and can be seamlessly integrated with both replay- and regularization-based approaches. Experiments on various datasets demonstrate substantial performance gains over state-of-the-art continual learning baselines.",
      "published": "2025-12-25",
      "updated": "2025-12-25",
      "categories": [
        "cs.LG",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21743v1",
        "pdf": "https://arxiv.org/pdf/2512.21743v1"
      },
      "arxiv_id": "2512.21743v1",
      "comment": "14 pages",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21736v1",
      "title": "SyncAnyone: Implicit Disentanglement via Progressive Self-Correction for Lip-Syncing in the wild",
      "authors": [
        "Xindi Zhang",
        "Dechao Meng",
        "Steven Xiao",
        "Qi Wang",
        "Peng Zhang",
        "Bang Zhang"
      ],
      "abstract": "High-quality AI-powered video dubbing demands precise audio-lip synchronization, high-fidelity visual generation, and faithful preservation of identity and background. Most existing methods rely on a mask-based training strategy, where the mouth region is masked in talking-head videos, and the model learns to synthesize lip movements from corrupted inputs and target audios. While this facilitates lip-sync accuracy, it disrupts spatiotemporal context, impairing performance on dynamic facial motions and causing instability in facial structure and background consistency. To overcome this limitation, we propose SyncAnyone, a novel two-stage learning framework that achieves accurate motion modeling and high visual fidelity simultaneously. In Stage 1, we train a diffusion-based video transformer for masked mouth inpainting, leveraging its strong spatiotemporal modeling to generate accurate, audio-driven lip movements. However, due to input corruption, minor artifacts may arise in the surrounding facial regions and the background. In Stage 2, we develop a mask-free tuning pipeline to address mask-induced artifacts. Specifically, on the basis of the Stage 1 model, we develop a data generation pipeline that creates pseudo-paired training samples by synthesizing lip-synced videos from the source video and random sampled audio. We further tune the stage 2 model on this synthetic data, achieving precise lip editing and better background consistency. Extensive experiments show that our method achieves state-of-the-art results in visual quality, temporal coherence, and identity preservation under in-the wild lip-syncing scenarios.",
      "published": "2025-12-25",
      "updated": "2025-12-25",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21736v1",
        "pdf": "https://arxiv.org/pdf/2512.21736v1"
      },
      "arxiv_id": "2512.21736v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21734v1",
      "title": "Knot Forcing: Taming Autoregressive Video Diffusion Models for Real-time Infinite Interactive Portrait Animation",
      "authors": [
        "Steven Xiao",
        "XIndi Zhang",
        "Dechao Meng",
        "Qi Wang",
        "Peng Zhang",
        "Bang Zhang"
      ],
      "abstract": "Real-time portrait animation is essential for interactive applications such as virtual assistants and live avatars, requiring high visual fidelity, temporal coherence, ultra-low latency, and responsive control from dynamic inputs like reference images and driving signals. While diffusion-based models achieve strong quality, their non-causal nature hinders streaming deployment. Causal autoregressive video generation approaches enable efficient frame-by-frame generation but suffer from error accumulation, motion discontinuities at chunk boundaries, and degraded long-term consistency. In this work, we present a novel streaming framework named Knot Forcing for real-time portrait animation that addresses these challenges through three key designs: (1) a chunk-wise generation strategy with global identity preservation via cached KV states of the reference image and local temporal modeling using sliding window attention; (2) a temporal knot module that overlaps adjacent chunks and propagates spatio-temporal cues via image-to-video conditioning to smooth inter-chunk motion transitions; and (3) A \"running ahead\" mechanism that dynamically updates the reference frame's temporal coordinate during inference, keeping its semantic context ahead of the current rollout frame to support long-term coherence. Knot Forcing enables high-fidelity, temporally consistent, and interactive portrait animation over infinite sequences, achieving real-time performance with strong visual stability on consumer-grade GPUs.",
      "published": "2025-12-25",
      "updated": "2025-12-25",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21734v1",
        "pdf": "https://arxiv.org/pdf/2512.21734v1"
      },
      "arxiv_id": "2512.21734v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21723v1",
      "title": "HELP: Hierarchical Embodied Language Planner for Household Tasks",
      "authors": [
        "Alexandr V. Korchemnyi",
        "Anatoly O. Onishchenko",
        "Eva A. Bakaeva",
        "Alexey K. Kovalev",
        "Aleksandr I. Panov"
      ],
      "abstract": "Embodied agents tasked with complex scenarios, whether in real or simulated environments, rely heavily on robust planning capabilities. When instructions are formulated in natural language, large language models (LLMs) equipped with extensive linguistic knowledge can play this role. However, to effectively exploit the ability of such models to handle linguistic ambiguity, to retrieve information from the environment, and to be based on the available skills of an agent, an appropriate architecture must be designed. We propose a Hierarchical Embodied Language Planner, called HELP, consisting of a set of LLM-based agents, each dedicated to solving a different subtask. We evaluate the proposed approach on a household task and perform real-world experiments with an embodied agent. We also focus on the use of open source LLMs with a relatively small number of parameters, to enable autonomous deployment.",
      "published": "2025-12-25",
      "updated": "2025-12-25",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21723v1",
        "pdf": "https://arxiv.org/pdf/2512.21723v1"
      },
      "arxiv_id": "2512.21723v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21720v1",
      "title": "An Information Theoretic Perspective on Agentic System Design",
      "authors": [
        "Shizhe He",
        "Avanika Narayan",
        "Ishan S. Khare",
        "Scott W. Linderman",
        "Christopher Ré",
        "Dan Biderman"
      ],
      "abstract": "Agentic language model (LM) systems power modern applications like \"Deep Research\" and \"Claude Code,\" and leverage multi-LM architectures to overcome context limitations. Beneath their apparent diversity lies a recurring pattern: smaller \"compressor\" LMs (that can even run locally) distill raw context into compact text that is then consumed by larger \"predictor\" LMs. Despite their popularity, the design of compressor-predictor systems remains largely ad hoc, with little guidance on how compressor and predictor choices shape downstream performance. In practice, attributing gains to compression versus prediction requires costly, task-specific pairwise sweeps. We argue that these agentic system design questions are, at root, information-theoretic. Viewing the compressor LM as a noisy channel, we introduce a simple estimator of mutual information between the context and its compression to quantify compression quality in a task-independent way. We show that mutual information strongly predicts downstream performance, independent of any specific task. Through an information-theoretic framework, we perform a comprehensive empirical analysis across five datasets and three model families. Results reveal that larger compressors not only are more accurate, but also more token-efficient, conveying more bits of information per token. A 7B Qwen-2.5 compressor, for instance, is $1.6\\times$ more accurate, $4.6\\times$ more concise, and conveys $5.5\\times$ more bits of mutual information per token than its 1.5B sibling. Across datasets, scaling compressors is substantially more effective than scaling predictors, enabling larger on-device compressors to pair with smaller cloud predictors. Applied to a Deep Research system, these principles enable local compressors as small as 3B parameters to recover $99\\%$ of frontier-LM accuracy at $26\\%$ of API costs.",
      "published": "2025-12-25",
      "updated": "2025-12-25",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.IT"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21720v1",
        "pdf": "https://arxiv.org/pdf/2512.21720v1"
      },
      "arxiv_id": "2512.21720v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21717v1",
      "title": "Multiconnectivity for SAGIN: Current Trends, Challenges, AI-driven Solutions, and Opportunities",
      "authors": [
        "Abd Ullah Khan",
        "Adnan Shahid",
        "Haejoon Jung",
        "Hyundong Shin"
      ],
      "abstract": "Space-air-ground-integrated network (SAGIN)-enabled multiconnectivity (MC) is emerging as a key enabler for next-generation networks, enabling users to simultaneously utilize multiple links across multi-layer non-terrestrial networks (NTN) and multi-radio access technology (multi-RAT) terrestrial networks (TN). However, the heterogeneity of TN and NTN introduces complex architectural challenges that complicate MC implementation. Specifically, the diversity of link types, spanning air-to-air, air-to-space, space-to-space, space-to-ground, and ground-to-ground communications, renders optimal resource allocation highly complex. Recent advancements in reinforcement learning (RL) and agentic artificial intelligence (AI) have shown remarkable effectiveness in optimal decision-making in complex and dynamic environments. In this paper, we review the current developments in SAGIN-enabled MC and outline the key challenges associated with its implementation. We further highlight the transformative potential of AI-driven approaches for resource optimization in a heterogeneous SAGIN environment. To this end, we present a case study on resource allocation optimization enabled by agentic RL for SAGIN-enabled MC involving diverse radio access technologies (RATs). Results show that learning-based methods can effectively handle complex scenarios and substantially enhance network performance in terms of latency and capacity while incurring a moderate increase in power consumption as an acceptable tradeoff. Finally, open research problems and future directions are presented to realize efficient SAGIN-enabled MC.",
      "published": "2025-12-25",
      "updated": "2025-12-25",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.NI",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21717v1",
        "pdf": "https://arxiv.org/pdf/2512.21717v1"
      },
      "arxiv_id": "2512.21717v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21715v1",
      "title": "CATCH: A Controllable Theme Detection Framework with Contextualized Clustering and Hierarchical Generation",
      "authors": [
        "Rui Ke",
        "Jiahui Xu",
        "Shenghao Yang",
        "Kuang Wang",
        "Feng Jiang",
        "Haizhou Li"
      ],
      "abstract": "Theme detection is a fundamental task in user-centric dialogue systems, aiming to identify the latent topic of each utterance without relying on predefined schemas. Unlike intent induction, which operates within fixed label spaces, theme detection requires cross-dialogue consistency and alignment with personalized user preferences, posing significant challenges. Existing methods often struggle with sparse, short utterances for accurate topic representation and fail to capture user-level thematic preferences across dialogues. To address these challenges, we propose CATCH (Controllable Theme Detection with Contextualized Clustering and Hierarchical Generation), a unified framework that integrates three core components: (1) context-aware topic representation, which enriches utterance-level semantics using surrounding topic segments; (2) preference-guided topic clustering, which jointly models semantic proximity and personalized feedback to align themes across dialogue; and (3) a hierarchical theme generation mechanism designed to suppress noise and produce robust, coherent topic labels. Experiments on a multi-domain customer dialogue benchmark (DSTC-12) demonstrate the effectiveness of CATCH with 8B LLM in both theme clustering and topic generation quality.",
      "published": "2025-12-25",
      "updated": "2025-12-25",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21715v1",
        "pdf": "https://arxiv.org/pdf/2512.21715v1"
      },
      "arxiv_id": "2512.21715v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21714v1",
      "title": "AstraNav-World: World Model for Foresight Control and Consistency",
      "authors": [
        "Junjun Hu",
        "Jintao Chen",
        "Haochen Bai",
        "Minghua Luo",
        "Shichao Xie",
        "Ziyi Chen",
        "Fei Liu",
        "Zedong Chu",
        "Xinda Xue",
        "Botao Ren",
        "Xiaolong Wu",
        "Mu Xu",
        "Shanghang Zhang"
      ],
      "abstract": "Embodied navigation in open, dynamic environments demands accurate foresight of how the world will evolve and how actions will unfold over time. We propose AstraNav-World, an end-to-end world model that jointly reasons about future visual states and action sequences within a unified probabilistic framework. Our framework integrates a diffusion-based video generator with a vision-language policy, enabling synchronized rollouts where predicted scenes and planned actions are updated simultaneously. Training optimizes two complementary objectives: generating action-conditioned multi-step visual predictions and deriving trajectories conditioned on those predicted visuals. This bidirectional constraint makes visual predictions executable and keeps decisions grounded in physically consistent, task-relevant futures, mitigating cumulative errors common in decoupled \"envision-then-plan\" pipelines. Experiments across diverse embodied navigation benchmarks show improved trajectory accuracy and higher success rates. Ablations confirm the necessity of tight vision-action coupling and unified training, with either branch removal degrading both prediction quality and policy reliability. In real-world testing, AstraNav-World demonstrated exceptional zero-shot capabilities, adapting to previously unseen scenarios without any real-world fine-tuning. These results suggest that AstraNav-World captures transferable spatial understanding and planning-relevant navigation dynamics, rather than merely overfitting to simulation-specific data distribution. Overall, by unifying foresight vision and control within a single generative model, we move closer to reliable, interpretable, and general-purpose embodied agents that operate robustly in open-ended real-world settings.",
      "published": "2025-12-25",
      "updated": "2025-12-25",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21714v1",
        "pdf": "https://arxiv.org/pdf/2512.21714v1"
      },
      "arxiv_id": "2512.21714v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.21711v1",
      "title": "Do Latent Tokens Think? A Causal and Adversarial Analysis of Chain-of-Continuous-Thought",
      "authors": [
        "Yuyi Zhang",
        "Boyu Tang",
        "Tianjie Ju",
        "Sufeng Duan",
        "Gongshen Liu"
      ],
      "abstract": "Latent tokens are gaining attention for enhancing reasoning in large language models (LLMs), yet their internal mechanisms remain unclear. This paper examines the problem from a reliability perspective, uncovering fundamental weaknesses: latent tokens function as uninterpretable placeholders rather than encoding faithful reasoning. While resistant to perturbation, they promote shortcut usage over genuine reasoning. We focus on Chain-of-Continuous-Thought (COCONUT), which claims better efficiency and stability than explicit Chain-of-Thought (CoT) while maintaining performance. We investigate this through two complementary approaches. First, steering experiments perturb specific token subsets, namely COCONUT and explicit CoT. Unlike CoT tokens, COCONUT tokens show minimal sensitivity to steering and lack reasoning-critical information. Second, shortcut experiments evaluate models under biased and out-of-distribution settings. Results on MMLU and HotpotQA demonstrate that COCONUT consistently exploits dataset artifacts, inflating benchmark performance without true reasoning. These findings reposition COCONUT as a pseudo-reasoning mechanism: it generates plausible traces that conceal shortcut dependence rather than faithfully representing reasoning processes.",
      "published": "2025-12-25",
      "updated": "2025-12-25",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2512.21711v1",
        "pdf": "https://arxiv.org/pdf/2512.21711v1"
      },
      "arxiv_id": "2512.21711v1",
      "comment": "13 pages, 5 figures",
      "journal_ref": "",
      "has_code": false
    }
  ]
}