{
  "fetched_at": "2026-02-11T00:38:34.541844",
  "total_papers": 100,
  "papers": [
    {
      "id": "2602.09024v1",
      "title": "Autoregressive Image Generation with Masked Bit Modeling",
      "authors": [
        "Qihang Yu",
        "Qihao Liu",
        "Ju He",
        "Xinyang Zhang",
        "Yang Liu",
        "Liang-Chieh Chen",
        "Xi Chen"
      ],
      "abstract": "This paper challenges the dominance of continuous pipelines in visual generation. We systematically investigate the performance gap between discrete and continuous methods. Contrary to the belief that discrete tokenizers are intrinsically inferior, we demonstrate that the disparity arises primarily from the total number of bits allocated in the latent space (i.e., the compression ratio). We show that scaling up the codebook size effectively bridges this gap, allowing discrete tokenizers to match or surpass their continuous counterparts. However, existing discrete generation methods struggle to capitalize on this insight, suffering from performance degradation or prohibitive training costs with scaled codebook. To address this, we propose masked Bit AutoRegressive modeling (BAR), a scalable framework that supports arbitrary codebook sizes. By equipping an autoregressive transformer with a masked bit modeling head, BAR predicts discrete tokens through progressively generating their constituent bits. BAR achieves a new state-of-the-art gFID of 0.99 on ImageNet-256, outperforming leading methods across both continuous and discrete paradigms, while significantly reducing sampling costs and converging faster than prior continuous approaches. Project page is available at https://bar-gen.github.io/",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.09024v1",
        "pdf": "https://arxiv.org/pdf/2602.09024v1"
      },
      "arxiv_id": "2602.09024v1",
      "comment": "SOTA discrete visual generation defeats diffusion models with 0.99 FID score, project page is available at https://bar-gen.github.io/",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2602.09022v1",
      "title": "WorldCompass: Reinforcement Learning for Long-Horizon World Models",
      "authors": [
        "Zehan Wang",
        "Tengfei Wang",
        "Haiyu Zhang",
        "Xuhui Zuo",
        "Junta Wu",
        "Haoyuan Wang",
        "Wenqiang Sun",
        "Zhenwei Wang",
        "Chenjie Cao",
        "Hengshuang Zhao",
        "Chunchao Guo",
        "Zhou Zhao"
      ],
      "abstract": "This work presents WorldCompass, a novel Reinforcement Learning (RL) post-training framework for the long-horizon, interactive video-based world models, enabling them to explore the world more accurately and consistently based on interaction signals. To effectively \"steer\" the world model's exploration, we introduce three core innovations tailored to the autoregressive video generation paradigm: 1) Clip-level rollout Strategy: We generate and evaluate multiple samples at a single target clip, which significantly boosts rollout efficiency and provides fine-grained reward signals. 2) Complementary Reward Functions: We design reward functions for both interaction-following accuracy and visual quality, which provide direct supervision and effectively suppress reward-hacking behaviors. 3) Efficient RL Algorithm: We employ the negative-aware fine-tuning strategy coupled with various efficiency optimizations to efficiently and effectively enhance model capacity. Evaluations on the SoTA open-source world model, WorldPlay, demonstrate that WorldCompass significantly improves interaction accuracy and visual fidelity across various scenarios.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.09022v1",
        "pdf": "https://arxiv.org/pdf/2602.09022v1"
      },
      "arxiv_id": "2602.09022v1",
      "comment": "Project page: \\url{https://3d-models.hunyuan.tencent.com/world/}",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.09021v1",
      "title": "$χ_{0}$: Resource-Aware Robust Manipulation via Taming Distributional Inconsistencies",
      "authors": [
        "Checheng Yu",
        "Chonghao Sima",
        "Gangcheng Jiang",
        "Hai Zhang",
        "Haoguang Mai",
        "Hongyang Li",
        "Huijie Wang",
        "Jin Chen",
        "Kaiyang Wu",
        "Li Chen",
        "Lirui Zhao",
        "Modi Shi",
        "Ping Luo",
        "Qingwen Bu",
        "Shijia Peng",
        "Tianyu Li",
        "Yibo Yuan"
      ],
      "abstract": "High-reliability long-horizon robotic manipulation has traditionally relied on large-scale data and compute to understand complex real-world dynamics. However, we identify that the primary bottleneck to real-world robustness is not resource scale alone, but the distributional shift among the human demonstration distribution, the inductive bias learned by the policy, and the test-time execution distribution -- a systematic inconsistency that causes compounding errors in multi-stage tasks. To mitigate these inconsistencies, we propose $χ_{0}$, a resource-efficient framework with effective modules designated to achieve production-level robustness in robotic manipulation. Our approach builds off three technical pillars: (i) Model Arithmetic, a weight-space merging strategy that efficiently soaks up diverse distributions of different demonstrations, varying from object appearance to state variations; (ii) Stage Advantage, a stage-aware advantage estimator that provides stable, dense progress signals, overcoming the numerical instability of prior non-stage approaches; and (iii) Train-Deploy Alignment, which bridges the distribution gap via spatio-temporal augmentation, heuristic DAgger corrections, and temporal chunk-wise smoothing. $χ_{0}$ enables two sets of dual-arm robots to collaboratively orchestrate long-horizon garment manipulation, spanning tasks from flattening, folding, to hanging different clothes. Our method exhibits high-reliability autonomy; we are able to run the system from arbitrary initial state for consecutive 24 hours non-stop. Experiments validate that $χ_{0}$ surpasses the state-of-the-art $π_{0.5}$ in success rate by nearly 250%, with only 20-hour data and 8 A100 GPUs. Code, data and models will be released to facilitate the community.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.RO",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "links": {
        "paper": "http://arxiv.org/abs/2602.09021v1",
        "pdf": "https://arxiv.org/pdf/2602.09021v1"
      },
      "arxiv_id": "2602.09021v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.09018v1",
      "title": "Robustness Is a Function, Not a Number: A Factorized Comprehensive Study of OOD Robustness in Vision-Based Driving",
      "authors": [
        "Amir Mallak",
        "Alaa Maalouf"
      ],
      "abstract": "Out of distribution (OOD) robustness in autonomous driving is often reduced to a single number, hiding what breaks a policy. We decompose environments along five axes: scene (rural/urban), season, weather, time (day/night), and agent mix; and measure performance under controlled $k$-factor perturbations ($k \\in \\{0,1,2,3\\}$). Using closed loop control in VISTA, we benchmark FC, CNN, and ViT policies, train compact ViT heads on frozen foundation-model (FM) features, and vary ID support in scale, diversity, and temporal context. (1) ViT policies are markedly more OOD-robust than comparably sized CNN/FC, and FM features yield state-of-the-art success at a latency cost. (2) Naive temporal inputs (multi-frame) do not beat the best single-frame baseline. (3) The largest single factor drops are rural $\\rightarrow$ urban and day $\\rightarrow$ night ($\\sim 31\\%$ each); actor swaps $\\sim 10\\%$, moderate rain $\\sim 7\\%$; season shifts can be drastic, and combining a time flip with other changes further degrades performance. (4) FM-feature policies stay above $85\\%$ under three simultaneous changes; non-FM single-frame policies take a large first-shift hit, and all no-FM models fall below $50\\%$ by three changes. (5) Interactions are non-additive: some pairings partially offset, whereas season-time combinations are especially harmful. (6) Training on winter/snow is most robust to single-factor shifts, while a rural+summer baseline gives the best overall OOD performance. (7) Scaling traces/views improves robustness ($+11.8$ points from $5$ to $14$ traces), yet targeted exposure to hard conditions can substitute for scale. (8) Using multiple ID environments broadens coverage and strengthens weak cases (urban OOD $60.6\\% \\rightarrow 70.1\\%$) with a small ID drop; single-ID preserves peak performance but in a narrow domain. These results yield actionable design rules for OOD-robust driving policies.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "links": {
        "paper": "http://arxiv.org/abs/2602.09018v1",
        "pdf": "https://arxiv.org/pdf/2602.09018v1"
      },
      "arxiv_id": "2602.09018v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.09017v1",
      "title": "Contact-Anchored Policies: Contact Conditioning Creates Strong Robot Utility Models",
      "authors": [
        "Zichen Jeff Cui",
        "Omar Rayyan",
        "Haritheja Etukuru",
        "Bowen Tan",
        "Zavier Andrianarivo",
        "Zicheng Teng",
        "Yihang Zhou",
        "Krish Mehta",
        "Nicholas Wojno",
        "Kevin Yuanbo Wu",
        "Manan H Anjaria",
        "Ziyuan Wu",
        "Manrong Mao",
        "Guangxun Zhang",
        "Binit Shah",
        "Yejin Kim",
        "Soumith Chintala",
        "Lerrel Pinto",
        "Nur Muhammad Mahi Shafiullah"
      ],
      "abstract": "The prevalent paradigm in robot learning attempts to generalize across environments, embodiments, and tasks with language prompts at runtime. A fundamental tension limits this approach: language is often too abstract to guide the concrete physical understanding required for robust manipulation. In this work, we introduce Contact-Anchored Policies (CAP), which replace language conditioning with points of physical contact in space. Simultaneously, we structure CAP as a library of modular utility models rather than a monolithic generalist policy. This factorization allows us to implement a real-to-sim iteration cycle: we build EgoGym, a lightweight simulation benchmark, to rapidly identify failure modes and refine our models and datasets prior to real-world deployment. We show that by conditioning on contact and iterating via simulation, CAP generalizes to novel environments and embodiments out of the box on three fundamental manipulation skills while using only 23 hours of demonstration data, and outperforms large, state-of-the-art VLAs in zero-shot evaluations by 56%. All model checkpoints, codebase, hardware, simulation, and datasets will be open-sourced. Project page: https://cap-policy.github.io/",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.RO",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "links": {
        "paper": "http://arxiv.org/abs/2602.09017v1",
        "pdf": "https://arxiv.org/pdf/2602.09017v1"
      },
      "arxiv_id": "2602.09017v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.09016v1",
      "title": "Raster2Seq: Polygon Sequence Generation for Floorplan Reconstruction",
      "authors": [
        "Hao Phung",
        "Hadar Averbuch-Elor"
      ],
      "abstract": "Reconstructing a structured vector-graphics representation from a rasterized floorplan image is typically an important prerequisite for computational tasks involving floorplans such as automated understanding or CAD workflows. However, existing techniques struggle in faithfully generating the structure and semantics conveyed by complex floorplans that depict large indoor spaces with many rooms and a varying numbers of polygon corners. To this end, we propose Raster2Seq, framing floorplan reconstruction as a sequence-to-sequence task in which floorplan elements--such as rooms, windows, and doors--are represented as labeled polygon sequences that jointly encode geometry and semantics. Our approach introduces an autoregressive decoder that learns to predict the next corner conditioned on image features and previously generated corners using guidance from learnable anchors. These anchors represent spatial coordinates in image space, hence allowing for effectively directing the attention mechanism to focus on informative image regions. By embracing the autoregressive mechanism, our method offers flexibility in the output format, enabling for efficiently handling complex floorplans with numerous rooms and diverse polygon structures. Our method achieves state-of-the-art performance on standard benchmarks such as Structure3D, CubiCasa5K, and Raster2Graph, while also demonstrating strong generalization to more challenging datasets like WAFFLE, which contain diverse room structures and complex geometric variations.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.09016v1",
        "pdf": "https://arxiv.org/pdf/2602.09016v1"
      },
      "arxiv_id": "2602.09016v1",
      "comment": "Code: https://anonymous.4open.science/r/Raster2Seq-BE73/",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2602.09015v1",
      "title": "CIC-Trap4Phish: A Unified Multi-Format Dataset for Phishing and Quishing Attachment Detection",
      "authors": [
        "Fatemeh Nejati",
        "Mahdi Rabbani",
        "Mansur Mirani",
        "Gunjan Piya",
        "Igor Opushnyev",
        "Ali A. Ghorbani",
        "Sajjad Dadkhah"
      ],
      "abstract": "Phishing attacks represents one of the primary attack methods which is used by cyber attackers. In many cases, attackers use deceptive emails along with malicious attachments to trick users into giving away sensitive information or installing malware while compromising entire systems. The flexibility of malicious email attachments makes them stand out as a preferred vector for attackers as they can embed harmful content such as malware or malicious URLs inside standard document formats. Although phishing email defenses have improved a lot, attackers continue to abuse attachments, enabling malicious content to bypass security measures. Moreover, another challenge that researches face in training advance models, is lack of an unified and comprehensive dataset that covers the most prevalent data types. To address this gap, we generated CIC-Trap4Phish, a multi-format dataset containing both malicious and benign samples across five categories commonly used in phishing campaigns: Microsoft Word documents, Excel spreadsheets, PDF files, HTML pages, and QR code images. For the first four file types, a set of execution-free static feature pipeline was proposed, designed to capture structural, lexical, and metadata-based indicators without the need to open or execute files. Feature selection was performed using a combination of SHAP analysis and feature importance, yielding compact, discriminative feature subsets for each file type. The selected features were evaluated by using lightweight machine learning models, including Random Forest, XGBoost, and Decision Tree. All models demonstrate high detection accuracy across formats. For QR code-based phishing (quishing), two complementary methods were implemented: image-based detection by employing Convolutional Neural Networks (CNNs) and lexical analysis of decoded URLs using recent lightweight language models.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "links": {
        "paper": "http://arxiv.org/abs/2602.09015v1",
        "pdf": "https://arxiv.org/pdf/2602.09015v1"
      },
      "arxiv_id": "2602.09015v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.09014v1",
      "title": "ArcFlow: Unleashing 2-Step Text-to-Image Generation via High-Precision Non-Linear Flow Distillation",
      "authors": [
        "Zihan Yang",
        "Shuyuan Tu",
        "Licheng Zhang",
        "Qi Dai",
        "Yu-Gang Jiang",
        "Zuxuan Wu"
      ],
      "abstract": "Diffusion models have achieved remarkable generation quality, but they suffer from significant inference cost due to their reliance on multiple sequential denoising steps, motivating recent efforts to distill this inference process into a few-step regime. However, existing distillation methods typically approximate the teacher trajectory by using linear shortcuts, which makes it difficult to match its constantly changing tangent directions as velocities evolve across timesteps, thereby leading to quality degradation. To address this limitation, we propose ArcFlow, a few-step distillation framework that explicitly employs non-linear flow trajectories to approximate pre-trained teacher trajectories. Concretely, ArcFlow parameterizes the velocity field underlying the inference trajectory as a mixture of continuous momentum processes. This enables ArcFlow to capture velocity evolution and extrapolate coherent velocities to form a continuous non-linear trajectory within each denoising step. Importantly, this parameterization admits an analytical integration of this non-linear trajectory, which circumvents numerical discretization errors and results in high-precision approximation of the teacher trajectory. To train this parameterization into a few-step generator, we implement ArcFlow via trajectory distillation on pre-trained teacher models using lightweight adapters. This strategy ensures fast, stable convergence while preserving generative diversity and quality. Built on large-scale models (Qwen-Image-20B and FLUX.1-dev), ArcFlow only fine-tunes on less than 5% of original parameters and achieves a 40x speedup with 2 NFEs over the original multi-step teachers without significant quality degradation. Experiments on benchmarks show the effectiveness of ArcFlow both qualitatively and quantitatively.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.09014v1",
        "pdf": "https://arxiv.org/pdf/2602.09014v1"
      },
      "arxiv_id": "2602.09014v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.09013v1",
      "title": "Dexterous Manipulation Policies from RGB Human Videos via 4D Hand-Object Trajectory Reconstruction",
      "authors": [
        "Hongyi Chen",
        "Tony Dong",
        "Tiancheng Wu",
        "Liquan Wang",
        "Yash Jangir",
        "Yaru Niu",
        "Yufei Ye",
        "Homanga Bharadhwaj",
        "Zackory Erickson",
        "Jeffrey Ichnowski"
      ],
      "abstract": "Multi-finger robotic hand manipulation and grasping are challenging due to the high-dimensional action space and the difficulty of acquiring large-scale training data. Existing approaches largely rely on human teleoperation with wearable devices or specialized sensing equipment to capture hand-object interactions, which limits scalability. In this work, we propose VIDEOMANIP, a device-free framework that learns dexterous manipulation directly from RGB human videos. Leveraging recent advances in computer vision, VIDEOMANIP reconstructs explicit 4D robot-object trajectories from monocular videos by estimating human hand poses, object meshes, and retargets the reconstructed human motions to robotic hands for manipulation learning. To make the reconstructed robot data suitable for dexterous manipulation training, we introduce hand-object contact optimization with interaction-centric grasp modeling, as well as a demonstration synthesis strategy that generates diverse training trajectories from a single video, enabling generalizable policy learning without additional robot demonstrations. In simulation, the learned grasping model achieves a 70.25% success rate across 20 diverse objects using the Inspire Hand. In the real world, manipulation policies trained from RGB videos achieve an average 62.86% success rate across seven tasks using the LEAP Hand, outperforming retargeting-based methods by 15.87%. Project videos are available at videomanip.github.io.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.RO",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "links": {
        "paper": "http://arxiv.org/abs/2602.09013v1",
        "pdf": "https://arxiv.org/pdf/2602.09013v1"
      },
      "arxiv_id": "2602.09013v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.09012v1",
      "title": "Next-Gen CAPTCHAs: Leveraging the Cognitive Gap for Scalable and Diverse GUI-Agent Defense",
      "authors": [
        "Jiacheng Liu",
        "Yaxin Luo",
        "Jiacheng Cui",
        "Xinyi Shang",
        "Xiaohan Zhao",
        "Zhiqiang Shen"
      ],
      "abstract": "The rapid evolution of GUI-enabled agents has rendered traditional CAPTCHAs obsolete. While previous benchmarks like OpenCaptchaWorld established a baseline for evaluating multimodal agents, recent advancements in reasoning-heavy models, such as Gemini3-Pro-High and GPT-5.2-Xhigh have effectively collapsed this security barrier, achieving pass rates as high as 90% on complex logic puzzles like \"Bingo\". In response, we introduce Next-Gen CAPTCHAs, a scalable defense framework designed to secure the next-generation web against the advanced agents. Unlike static datasets, our benchmark is built upon a robust data generation pipeline, allowing for large-scale and easily scalable evaluations, notably, for backend-supported types, our system is capable of generating effectively unbounded CAPTCHA instances. We exploit the persistent human-agent \"Cognitive Gap\" in interactive perception, memory, decision-making, and action. By engineering dynamic tasks that require adaptive intuition rather than granular planning, we re-establish a robust distinction between biological users and artificial agents, offering a scalable and diverse defense mechanism for the agentic era.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.09012v1",
        "pdf": "https://arxiv.org/pdf/2602.09012v1"
      },
      "arxiv_id": "2602.09012v1",
      "comment": "Project page at https://greenoso.github.io/NextGen-CAPTCHAs_webpage/",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2602.09009v1",
      "title": "ANCRe: Adaptive Neural Connection Reassignment for Efficient Depth Scaling",
      "authors": [
        "Yilang Zhang",
        "Bingcong Li",
        "Niao He",
        "Georgios B. Giannakis"
      ],
      "abstract": "Scaling network depth has been a central driver behind the success of modern foundation models, yet recent investigations suggest that deep layers are often underutilized. This paper revisits the default mechanism for deepening neural networks, namely residual connections, from an optimization perspective. Rigorous analysis proves that the layout of residual connections can fundamentally shape convergence behavior, and even induces an exponential gap in convergence rates. Prompted by this insight, we introduce adaptive neural connection reassignment (ANCRe), a principled and lightweight framework that parameterizes and learns residual connectivities from the data. ANCRe adaptively reassigns residual connections with negligible computational and memory overhead ($<1\\%$), while enabling more effective utilization of network depth. Extensive numerical tests across pre-training of large language models, diffusion models, and deep ResNets demonstrate consistently accelerated convergence, boosted performance, and enhanced depth efficiency over conventional residual connections.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.09009v1",
        "pdf": "https://arxiv.org/pdf/2602.09009v1"
      },
      "arxiv_id": "2602.09009v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.09008v1",
      "title": "ShapeCond: Fast Shapelet-Guided Dataset Condensation for Time Series Classification",
      "authors": [
        "Sijia Peng",
        "Yun Xiong",
        "Xi Chen",
        "Yi Xie",
        "Guanzhi Li",
        "Yanwei Yu",
        "Yangyong Zhu",
        "Zhiqiang Shen"
      ],
      "abstract": "Time series data supports many domains (e.g., finance and climate science), but its rapid growth strains storage and computation. Dataset condensation can alleviate this by synthesizing a compact training set that preserves key information. Yet most condensation methods are image-centric and often fail on time series because they miss time-series-specific temporal structure, especially local discriminative motifs such as shapelets. In this work, we propose ShapeCond, a novel and efficient condensation framework for time series classification that leverages shapelet-based dataset knowledge via a shapelet-guided optimization strategy. Our shapelet-assisted synthesis cost is independent of sequence length: longer series yield larger speedups in synthesis (e.g., 29$\\times$ faster over prior state-of-the-art method CondTSC for time-series condensation, and up to 10,000$\\times$ over naively using shapelets on the Sleep dataset with 3,000 timesteps). By explicitly preserving critical local patterns, ShapeCond improves downstream accuracy and consistently outperforms all prior state-of-the-art time series dataset condensation methods across extensive experiments. Code is available at https://github.com/lunaaa95/ShapeCond.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.09008v1",
        "pdf": "https://arxiv.org/pdf/2602.09008v1"
      },
      "arxiv_id": "2602.09008v1",
      "comment": "Code at: https://github.com/lunaaa95/ShapeCond",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2602.09007v1",
      "title": "GEBench: Benchmarking Image Generation Models as GUI Environments",
      "authors": [
        "Haodong Li",
        "Jingwei Wu",
        "Quan Sun",
        "Guopeng Li",
        "Juanxi Tian",
        "Huanyu Zhang",
        "Yanlin Lai",
        "Ruichuan An",
        "Hongbo Peng",
        "Yuhong Dai",
        "Chenxi Li",
        "Chunmei Qing",
        "Jia Wang",
        "Ziyang Meng",
        "Zheng Ge",
        "Xiangyu Zhang",
        "Daxin Jiang"
      ],
      "abstract": "Recent advancements in image generation models have enabled the prediction of future Graphical User Interface (GUI) states based on user instructions. However, existing benchmarks primarily focus on general domain visual fidelity, leaving the evaluation of state transitions and temporal coherence in GUI-specific contexts underexplored. To address this gap, we introduce GEBench, a comprehensive benchmark for evaluating dynamic interaction and temporal coherence in GUI generation. GEBench comprises 700 carefully curated samples spanning five task categories, covering both single-step interactions and multi-step trajectories across real-world and fictional scenarios, as well as grounding point localization. To support systematic evaluation, we propose GE-Score, a novel five-dimensional metric that assesses Goal Achievement, Interaction Logic, Content Consistency, UI Plausibility, and Visual Quality. Extensive evaluations on current models indicate that while they perform well on single-step transitions, they struggle significantly with maintaining temporal coherence and spatial grounding over longer interaction sequences. Our findings identify icon interpretation, text rendering, and localization precision as critical bottlenecks. This work provides a foundation for systematic assessment and suggests promising directions for future research toward building high-fidelity generative GUI environments. The code is available at: https://github.com/stepfun-ai/GEBench.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.09007v1",
        "pdf": "https://arxiv.org/pdf/2602.09007v1"
      },
      "arxiv_id": "2602.09007v1",
      "comment": "23 pages, 5 figures, 4 tables",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.09006v1",
      "title": "ARO: A New Lens On Matrix Optimization For Large Models",
      "authors": [
        "Wenbo Gong",
        "Javier Zazo",
        "Qijun Luo",
        "Puqian Wang",
        "James Hensman",
        "Chao Ma"
      ],
      "abstract": "Matrix-based optimizers have attracted growing interest for improving LLM training efficiency, with significant progress centered on orthogonalization/whitening based methods. While yielding substantial performance gains, a fundamental question arises: can we develop new paradigms beyond orthogonalization, pushing the efficiency frontier further? We present \\textbf{Adaptively Rotated Optimization (ARO}, a new matrix optimization framework that treats gradient rotation as a first class design principle. ARO accelerates LLM training by performing normed steepest descent in a rotated coordinate system, where the rotation is determined by a novel norm-informed policy. This perspective yields update rules that go beyond existing orthogonalization and whitening optimizers, improving sample efficiency in practice. To make comparisons reliable, we propose a rigorously controlled benchmarking protocol that reduces confounding and bias. Under this protocol, ARO consistently outperforms AdamW (by 1.3 $\\sim$1.35$\\times$) and orthogonalization methods (by 1.1$\\sim$1.15$\\times$) in LLM pretraining at up to 8B activated parameters, and up to $8\\times$ overtrain budget, without evidence of diminishing returns. Finally, we discuss how ARO can be reformulated as a symmetry-aware optimizer grounded in rotational symmetries of residual streams, motivating advanced designs that enable computationally efficient exploitation of cross-layer/cross module couplings.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.09006v1",
        "pdf": "https://arxiv.org/pdf/2602.09006v1"
      },
      "arxiv_id": "2602.09006v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.09003v1",
      "title": "Data Science and Technology Towards AGI Part I: Tiered Data Management",
      "authors": [
        "Yudong Wang",
        "Zixuan Fu",
        "Hengyu Zhao",
        "Chen Zhao",
        "Chuyue Zhou",
        "Xinle Lin",
        "Hongya Lyu",
        "Shuaikang Xue",
        "Yi Yi",
        "Yingjiao Wang",
        "Zhi Zheng",
        "Yuzhou Zhang",
        "Jie Zhou",
        "Chaojun Xiao",
        "Xu Han",
        "Zhiyuan Liu",
        "Maosong Sun"
      ],
      "abstract": "The development of artificial intelligence can be viewed as an evolution of data-driven learning paradigms, with successive shifts in data organization and utilization continuously driving advances in model capability. Current LLM research is dominated by a paradigm that relies heavily on unidirectional scaling of data size, increasingly encountering bottlenecks in data availability, acquisition cost, and training efficiency. In this work, we argue that the development of AGI is entering a new phase of data-model co-evolution, in which models actively guide data management while high-quality data, in turn, amplifies model capabilities. To implement this vision, we propose a tiered data management framework, designed to support the full LLM training lifecycle across heterogeneous learning objectives and cost constraints. Specifically, we introduce an L0-L4 tiered data management framework, ranging from raw uncurated resources to organized and verifiable knowledge. Importantly, LLMs are fully used in data management processes, such as quality scoring and content editing, to refine data across tiers. Each tier is characterized by distinct data properties, management strategies, and training roles, enabling data to be strategically allocated across LLM training stages, including pre-training, mid-training, and alignment. The framework balances data quality, acquisition cost, and marginal training benefit, providing a systematic approach to scalable and sustainable data management. We validate the effectiveness of the proposed framework through empirical studies, in which tiered datasets are constructed from raw corpora and used across multiple training phases. Experimental results demonstrate that tier-aware data utilization significantly improves training efficiency and model performance. To facilitate further research, we release our tiered datasets and processing tools to the community.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.09003v1",
        "pdf": "https://arxiv.org/pdf/2602.09003v1"
      },
      "arxiv_id": "2602.09003v1",
      "comment": "16 pages, 3 figures, 7 tables",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.09002v1",
      "title": "From Obstacles to Etiquette: Robot Social Navigation with VLM-Informed Path Selection",
      "authors": [
        "Zilin Fang",
        "Anxing Xiao",
        "David Hsu",
        "Gim Hee Lee"
      ],
      "abstract": "Navigating socially in human environments requires more than satisfying geometric constraints, as collision-free paths may still interfere with ongoing activities or conflict with social norms. Addressing this challenge calls for analyzing interactions between agents and incorporating common-sense reasoning into planning. This paper presents a social robot navigation framework that integrates geometric planning with contextual social reasoning. The system first extracts obstacles and human dynamics to generate geometrically feasible candidate paths, then leverages a fine-tuned vision-language model (VLM) to evaluate these paths, informed by contextually grounded social expectations, selecting a socially optimized path for the controller. This task-specific VLM distills social reasoning from large foundation models into a smaller and efficient model, allowing the framework to perform real-time adaptation in diverse human-robot interaction contexts. Experiments in four social navigation contexts demonstrate that our method achieves the best overall performance with the lowest personal space violation duration, the minimal pedestrian-facing time, and no social zone intrusions. Project page: https://path-etiquette.github.io",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "links": {
        "paper": "http://arxiv.org/abs/2602.09002v1",
        "pdf": "https://arxiv.org/pdf/2602.09002v1"
      },
      "arxiv_id": "2602.09002v1",
      "comment": "Accepted to IEEE Robotics and Automation Letters (RA-L)",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.09001v1",
      "title": "DirMoE: Dirichlet-routed Mixture of Experts",
      "authors": [
        "Amirhossein Vahidi",
        "Hesam Asadollahzadeh",
        "Navid Akhavan Attar",
        "Marie Moullet",
        "Kevin Ly",
        "Xingyi Yang",
        "Mohammad Lotfollahi"
      ],
      "abstract": "Mixture-of-Experts (MoE) models have demonstrated exceptional performance in large-scale language models. Existing routers typically rely on non-differentiable Top-$k$+Softmax, limiting their performance and scalability. We argue that two distinct decisions, which experts to activate and how to distribute expert contributions among them, are conflated in standard Top-$k$+Softmax. We introduce Dirichlet-Routed MoE (DirMoE), a novel end-to-end differentiable routing mechanism built on a Dirichlet variational autoencoder framework. This design fundamentally disentangles the core routing problems: expert selection, modeled by a Bernoulli component, and expert contribution among chosen experts, handled by a Dirichlet component. The entire forward pass remains fully differentiable through the use of Gumbel-Sigmoid relaxation for the expert selection and implicit reparameterization for the Dirichlet distribution. Our training objective, a variational ELBO, includes a direct sparsity penalty that precisely controls the number of active experts in expectation, alongside a schedule for key hyperparameters that guides the model from an exploratory to a definitive routing state. Moreover, our DirMoE router matches or exceeds other methods while improving expert specialization.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.09001v1",
        "pdf": "https://arxiv.org/pdf/2602.09001v1"
      },
      "arxiv_id": "2602.09001v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.09000v1",
      "title": "iGRPO: Self-Feedback-Driven LLM Reasoning",
      "authors": [
        "Ali Hatamizadeh",
        "Shrimai Prabhumoye",
        "Igor Gitman",
        "Ximing Lu",
        "Seungju Han",
        "Wei Ping",
        "Yejin Choi",
        "Jan Kautz"
      ],
      "abstract": "Large Language Models (LLMs) have shown promise in solving complex mathematical problems, yet they still fall short of producing accurate and consistent solutions. Reinforcement Learning (RL) is a framework for aligning these models with task-specific rewards, improving overall quality and reliability. Group Relative Policy Optimization (GRPO) is an efficient, value-function-free alternative to Proximal Policy Optimization (PPO) that leverages group-relative reward normalization. We introduce Iterative Group Relative Policy Optimization (iGRPO), a two-stage extension of GRPO that adds dynamic self-conditioning through model-generated drafts. In Stage 1, iGRPO samples multiple exploratory drafts and selects the highest-reward draft using the same scalar reward signal used for optimization. In Stage 2, it appends this best draft to the original prompt and applies a GRPO-style update on draft-conditioned refinements, training the policy to improve beyond its strongest prior attempt. Under matched rollout budgets, iGRPO consistently outperforms GRPO across base models (e.g., Nemotron-H-8B-Base-8K and DeepSeek-R1 Distilled), validating its effectiveness on diverse reasoning benchmarks. Moreover, applying iGRPO to OpenReasoning-Nemotron-7B trained on AceReason-Math achieves new state-of-the-art results of 85.62\\% and 79.64\\% on AIME24 and AIME25, respectively. Ablations further show that the refinement wrapper generalizes beyond GRPO variants, benefits from a generative judge, and alters learning dynamics by delaying entropy collapse. These results underscore the potential of iterative, self-feedback-based RL for advancing verifiable mathematical reasoning.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.09000v1",
        "pdf": "https://arxiv.org/pdf/2602.09000v1"
      },
      "arxiv_id": "2602.09000v1",
      "comment": "Tech report",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08998v1",
      "title": "Universal Coefficients and Mayer-Vietoris Sequence for Groupoid Homology",
      "authors": [
        "Luciano Melodia"
      ],
      "abstract": "We study homology of ample groupoids via the compactly supported Moore complex of the nerve. Let $A$ be a topological abelian group. For $n\\ge 0$ set $C_n(\\mathcal G;A) := C_c(\\mathcal G_n,A)$ and define $\\partial_n^A=\\sum_{i=0}^n(-1)^i(d_i)_*$. This defines $H_n(\\mathcal G;A)$. The theory is functorial for continuous étale homomorphisms. It is compatible with standard reductions, including restriction to saturated clopen subsets. In the ample setting it is invariant under Kakutani equivalence. We reprove Matui type long exact sequences and identify the comparison maps at chain level. For discrete $A$ we prove a natural universal coefficient short exact sequence $$0\\to H_n(\\mathcal G)\\otimes_{\\mathbb Z}A\\xrightarrow{\\ ι_n^{\\mathcal G}\\ }H_n(\\mathcal G;A)\\xrightarrow{\\ κ_n^{\\mathcal G}\\ }\\operatorname{Tor}_1^{\\mathbb Z}\\bigl(H_{n-1}(\\mathcal G),A\\bigr)\\to 0.$$ The key input is the chain level isomorphism $C_c(\\mathcal G_n,\\mathbb Z)\\otimes_{\\mathbb Z}A\\cong C_c(\\mathcal G_n,A)$, which reduces the groupoid statement to the classical algebraic UCT for the free complex $C_c(\\mathcal G_\\bullet,\\mathbb Z)$. We also isolate the obstruction for non-discrete coefficients. For a locally compact totally disconnected Hausdorff space $X$ with a basis of compact open sets, the image of $Φ_X:C_c(X,\\mathbb Z)\\otimes_{\\mathbb Z}A\\to C_c(X,A)$ is exactly the compactly supported functions with finite image. Thus $Φ_X$ is surjective if and only if every $f\\in C_c(X,A)$ has finite image, and for suitable $X$ one can produce compactly supported continuous maps $X\\to A$ with infinite image. Finally, for a clopen saturated cover $\\mathcal G_0=U_1\\cup U_2$ we construct a short exact sequence of Moore complexes and derive a Mayer-Vietoris long exact sequence for $H_\\bullet(\\mathcal G;A)$ for explicit computations.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "math.AT",
        "cs.LG",
        "math.OA",
        "stat.ML"
      ],
      "primary_category": "math.AT",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08998v1",
        "pdf": "https://arxiv.org/pdf/2602.08998v1"
      },
      "arxiv_id": "2602.08998v1",
      "comment": "Master's thesis",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08996v1",
      "title": "Generalizing Sports Feedback Generation by Watching Competitions and Reading Books: A Rock Climbing Case Study",
      "authors": [
        "Arushi Rai",
        "Adriana Kovashka"
      ],
      "abstract": "While there is rapid progress in video-LLMs with advanced reasoning capabilities, prior work shows that these models struggle on the challenging task of sports feedback generation and require expensive and difficult-to-collect finetuning feedback data for each sport. This limitation is evident from the poor generalization to sports unseen during finetuning. Furthermore, traditional text generation evaluation metrics (e.g., BLEU-4, METEOR, ROUGE-L, BERTScore), originally developed for machine translation and summarization, fail to capture the unique aspects of sports feedback quality. To address the first problem, using rock climbing as our case study, we propose using auxiliary freely-available web data from the target domain, such as competition videos and coaching manuals, in addition to existing sports feedback from a disjoint, source domain to improve sports feedback generation performance on the target domain. To improve evaluation, we propose two evaluation metrics: (1) specificity and (2) actionability. Together, our approach enables more meaningful and practical generation of sports feedback under limited annotations.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08996v1",
        "pdf": "https://arxiv.org/pdf/2602.08996v1"
      },
      "arxiv_id": "2602.08996v1",
      "comment": "to appear WACV 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08990v1",
      "title": "InternAgent-1.5: A Unified Agentic Framework for Long-Horizon Autonomous Scientific Discovery",
      "authors": [
        "Shiyang Feng",
        "Runmin Ma",
        "Xiangchao Yan",
        "Yue Fan",
        "Yusong Hu",
        "Songtao Huang",
        "Shuaiyu Zhang",
        "Zongsheng Cao",
        "Tianshuo Peng",
        "Jiakang Yuan",
        "Zijie Guo",
        "Zhijie Zhong",
        "Shangheng Du",
        "Weida Wang",
        "Jinxin Shi",
        "Yuhao Zhou",
        "Xiaohan He",
        "Zhiyin Yu",
        "Fangchen Yu",
        "Qihao Zheng",
        "Jiamin Wu",
        "Mianxin Liu",
        "Chi Zhang",
        "Shaowei Hou",
        "Shuya Li",
        "Yankai Jiang",
        "Wenjie Lou",
        "Lilong Wang",
        "Zifu Wang",
        "Jiong Wang",
        "Wanghan Xu",
        "Yue Deng",
        "Dongrui Liu",
        "Yiheng Wang",
        "Wenlong Zhang",
        "Fenghua Ling",
        "Shufei Zhang",
        "Xiaosong Wang",
        "Shuangjia Zheng",
        "Xun Huang",
        "Siqi Sun",
        "Shuyue Hu",
        "Peng Ye",
        "Chunfeng Song",
        "Bin Wang",
        "Conghui He",
        "Yihao Liu",
        "Xin Li",
        "Qibin Hou",
        "Tao Chen",
        "Xiangyu Yue",
        "Bin Wang",
        "Liang He",
        "Dahua Lin",
        "Bowen Zhou",
        "Bo Zhang",
        "Lei Bai"
      ],
      "abstract": "We introduce InternAgent-1.5, a unified system designed for end-to-end scientific discovery across computational and empirical domains. The system is built on a structured architecture composed of three coordinated subsystems for generation, verification, and evolution. These subsystems are supported by foundational capabilities for deep research, solution optimization, and long horizon memory. The architecture allows InternAgent-1.5 to operate continuously across extended discovery cycles while maintaining coherent and improving behavior. It also enables the system to coordinate computational modeling and laboratory experimentation within a single unified system. We evaluate InternAgent-1.5 on scientific reasoning benchmarks such as GAIA, HLE, GPQA, and FrontierScience, and the system achieves leading performance that demonstrates strong foundational capabilities. Beyond these benchmarks, we further assess two categories of discovery tasks. In algorithm discovery tasks, InternAgent-1.5 autonomously designs competitive methods for core machine learning problems. In empirical discovery tasks, it executes complete computational or wet lab experiments and produces scientific findings in earth, life, biological, and physical domains. Overall, these results show that InternAgent-1.5 provides a general and scalable framework for autonomous scientific discovery.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08990v1",
        "pdf": "https://arxiv.org/pdf/2602.08990v1"
      },
      "arxiv_id": "2602.08990v1",
      "comment": "Code and project page: https://github.com/InternScience/InternAgent",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2602.08986v1",
      "title": "Improving Detection of Rare Nodes in Hierarchical Multi-Label Learning",
      "authors": [
        "Isaac Xu",
        "Martin Gillis",
        "Ayushi Sharma",
        "Benjamin Misiuk",
        "Craig J. Brown",
        "Thomas Trappenberg"
      ],
      "abstract": "In hierarchical multi-label classification, a persistent challenge is enabling model predictions to reach deeper levels of the hierarchy for more detailed or fine-grained classifications. This difficulty partly arises from the natural rarity of certain classes (or hierarchical nodes) and the hierarchical constraint that ensures child nodes are almost always less frequent than their parents. To address this, we propose a weighted loss objective for neural networks that combines node-wise imbalance weighting with focal weighting components, the latter leveraging modern quantification of ensemble uncertainties. By emphasizing rare nodes rather than rare observations (data points), and focusing on uncertain nodes for each model output distribution during training, we observe improvements in recall by up to a factor of five on benchmark datasets, along with statistically significant gains in $F_{1}$ score. We also show our approach aids convolutional networks on challenging tasks, as in situations with suboptimal encoders or limited data.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08986v1",
        "pdf": "https://arxiv.org/pdf/2602.08986v1"
      },
      "arxiv_id": "2602.08986v1",
      "comment": "Accepted for publication in Transactions on Machine Learning Research (TMLR), 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08984v1",
      "title": "Next Concept Prediction in Discrete Latent Space Leads to Stronger Language Models",
      "authors": [
        "Yuliang Liu",
        "Yunchong Song",
        "Yixuan Wang",
        "Kewen Ge",
        "Alex Lamb",
        "Qipeng Guo",
        "Kai Chen",
        "Bowen Zhou",
        "Zhouhan Lin"
      ],
      "abstract": "We propose Next Concept Prediction (NCP), a generative pretraining paradigm built on top of Next Token Prediction (NTP). NCP predicts discrete concepts that span multiple tokens, thereby forming a more challenging pretraining objective. Our model, ConceptLM, quantizes hidden states using Vector Quantization and constructs a concept vocabulary. It leverages both NCP and NTP to drive parameter updates and generates a concept to guide the generation of the following tokens. We train ConceptLM from scratch at scales ranging from 70M to 1.5B parameters with up to 300B training data, including Pythia and GPT-2 backbones. Results on 13 benchmarks show that NCP yields consistent performance gains over traditional token-level models. Furthermore, continual pretraining experiments on an 8B-parameter Llama model indicate that NCP can further improve an NTP-trained model. Our analysis suggests that NCP leads to more powerful language models by introducing a harder pretraining task, providing a promising path toward better language modeling.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08984v1",
        "pdf": "https://arxiv.org/pdf/2602.08984v1"
      },
      "arxiv_id": "2602.08984v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08983v1",
      "title": "StretchTime: Adaptive Time Series Forecasting via Symplectic Attention",
      "authors": [
        "Yubin Kim",
        "Viresh Pati",
        "Jevon Twitty",
        "Vinh Pham",
        "Shihao Yang",
        "Jiecheng Lu"
      ],
      "abstract": "Transformer architectures have established strong baselines in time series forecasting, yet they typically rely on positional encodings that assume uniform, index-based temporal progression. However, real-world systems, from shifting financial cycles to elastic biological rhythms, frequently exhibit \"time-warped\" dynamics where the effective flow of time decouples from the sampling index. In this work, we first formalize this misalignment and prove that rotary position embedding (RoPE) is mathematically incapable of representing non-affine temporal warping. To address this, we propose Symplectic Positional Embeddings (SyPE), a learnable encoding framework derived from Hamiltonian mechanics. SyPE strictly generalizes RoPE by extending the rotation group $\\mathrm{SO}(2)$ to the symplectic group $\\mathrm{Sp}(2,\\mathbb{R})$, modulated by a novel input-dependent adaptive warp module. By allowing the attention mechanism to adaptively dilate or contract temporal coordinates end-to-end, our approach captures locally varying periodicities without requiring pre-defined warping functions. We implement this mechanism in StretchTime, a multivariate forecasting architecture that achieves state-of-the-art performance on standard benchmarks, demonstrating superior robustness on datasets exhibiting non-stationary temporal dynamics.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08983v1",
        "pdf": "https://arxiv.org/pdf/2602.08983v1"
      },
      "arxiv_id": "2602.08983v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08980v1",
      "title": "When do neural ordinary differential equations generalize on complex networks?",
      "authors": [
        "Moritz Laber",
        "Tina Eliassi-Rad",
        "Brennan Klein"
      ],
      "abstract": "Neural ordinary differential equations (neural ODEs) can effectively learn dynamical systems from time series data, but their behavior on graph-structured data remains poorly understood, especially when applied to graphs with different size or structure than encountered during training. We study neural ODEs ($\\mathtt{nODE}$s) with vector fields following the Barabási-Barzel form, trained on synthetic data from five common dynamical systems on graphs. Using the $\\mathbb{S}^1$-model to generate graphs with realistic and tunable structure, we find that degree heterogeneity and the type of dynamical system are the primary factors in determining $\\mathtt{nODE}$s' ability to generalize across graph sizes and properties. This extends to $\\mathtt{nODE}$s' ability to capture fixed points and maintain performance amid missing data. Average clustering plays a secondary role in determining $\\mathtt{nODE}$ performance. Our findings highlight $\\mathtt{nODE}$s as a powerful approach to understanding complex systems but underscore challenges emerging from degree heterogeneity and clustering in realistic graphs.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "physics.soc-ph",
        "cs.LG",
        "cs.SI",
        "stat.ML"
      ],
      "primary_category": "physics.soc-ph",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08980v1",
        "pdf": "https://arxiv.org/pdf/2602.08980v1"
      },
      "arxiv_id": "2602.08980v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08976v1",
      "title": "Distributionally Robust Optimization via Generative Ambiguity Modeling",
      "authors": [
        "Jiaqi Wen",
        "Jianyi Yang"
      ],
      "abstract": "This paper studies Distributionally Robust Optimization (DRO), a fundamental framework for enhancing the robustness and generalization of statistical learning and optimization. An effective ambiguity set for DRO must involve distributions that remain consistent to the nominal distribution while being diverse enough to account for a variety of potential scenarios. Moreover, it should lead to tractable DRO solutions. To this end, we propose generative model-based ambiguity sets that capture various adversarial distributions beyond the nominal support space while maintaining consistency with the nominal distribution. Building on this generative ambiguity modeling, we propose DRO with Generative Ambiguity Set (GAS-DRO), a tractable DRO algorithm that solves the inner maximization over the parameterized generative model space. We formally establish the stationary convergence performance of GAS-DRO. We implement GAS-DRO with a diffusion model and empirically demonstrate its superior Out-of-Distribution (OOD) generalization performance in ML tasks.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08976v1",
        "pdf": "https://arxiv.org/pdf/2602.08976v1"
      },
      "arxiv_id": "2602.08976v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08971v1",
      "title": "WorldArena: A Unified Benchmark for Evaluating Perception and Functional Utility of Embodied World Models",
      "authors": [
        "Yu Shang",
        "Zhuohang Li",
        "Yiding Ma",
        "Weikang Su",
        "Xin Jin",
        "Ziyou Wang",
        "Xin Zhang",
        "Yinzhou Tang",
        "Chen Gao",
        "Wei Wu",
        "Xihui Liu",
        "Dhruv Shah",
        "Zhaoxiang Zhang",
        "Zhibo Chen",
        "Jun Zhu",
        "Yonghong Tian",
        "Tat-Seng Chua",
        "Wenwu Zhu",
        "Yong Li"
      ],
      "abstract": "While world models have emerged as a cornerstone of embodied intelligence by enabling agents to reason about environmental dynamics through action-conditioned prediction, their evaluation remains fragmented. Current evaluation of embodied world models has largely focused on perceptual fidelity (e.g., video generation quality), overlooking the functional utility of these models in downstream decision-making tasks. In this work, we introduce WorldArena, a unified benchmark designed to systematically evaluate embodied world models across both perceptual and functional dimensions. WorldArena assesses models through three dimensions: video perception quality, measured with 16 metrics across six sub-dimensions; embodied task functionality, which evaluates world models as data engines, policy evaluators, and action planners integrating with subjective human evaluation. Furthermore, we propose EWMScore, a holistic metric integrating multi-dimensional performance into a single interpretable index. Through extensive experiments on 14 representative models, we reveal a significant perception-functionality gap, showing that high visual quality does not necessarily translate into strong embodied task capability. WorldArena benchmark with the public leaderboard is released at https://worldarena.ai, providing a framework for tracking progress toward truly functional world models in embodied AI.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08971v1",
        "pdf": "https://arxiv.org/pdf/2602.08971v1"
      },
      "arxiv_id": "2602.08971v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08968v1",
      "title": "stable-worldmodel-v1: Reproducible World Modeling Research and Evaluation",
      "authors": [
        "Lucas Maes",
        "Quentin Le Lidec",
        "Dan Haramati",
        "Nassim Massaudi",
        "Damien Scieur",
        "Yann LeCun",
        "Randall Balestriero"
      ],
      "abstract": "World Models have emerged as a powerful paradigm for learning compact, predictive representations of environment dynamics, enabling agents to reason, plan, and generalize beyond direct experience. Despite recent interest in World Models, most available implementations remain publication-specific, severely limiting their reusability, increasing the risk of bugs, and reducing evaluation standardization. To mitigate these issues, we introduce stable-worldmodel (SWM), a modular, tested, and documented world-model research ecosystem that provides efficient data-collection tools, standardized environments, planning algorithms, and baseline implementations. In addition, each environment in SWM enables controllable factors of variation, including visual and physical properties, to support robustness and continual learning research. Finally, we demonstrate the utility of SWM by using it to study zero-shot robustness in DINO-WM.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08968v1",
        "pdf": "https://arxiv.org/pdf/2602.08968v1"
      },
      "arxiv_id": "2602.08968v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08965v1",
      "title": "Learning to Coordinate via Quantum Entanglement in Multi-Agent Reinforcement Learning",
      "authors": [
        "John Gardiner",
        "Orlando Romero",
        "Brendan Tivnan",
        "Nicolò Dal Fabbro",
        "George J. Pappas"
      ],
      "abstract": "The inability to communicate poses a major challenge to coordination in multi-agent reinforcement learning (MARL). Prior work has explored correlating local policies via shared randomness, sometimes in the form of a correlation device, as a mechanism to assist in decentralized decision-making. In contrast, this work introduces the first framework for training MARL agents to exploit shared quantum entanglement as a coordination resource, which permits a larger class of communication-free correlated policies than shared randomness alone. This is motivated by well-known results in quantum physics which posit that, for certain single-round cooperative games with no communication, shared quantum entanglement enables strategies that outperform those that only use shared randomness. In such cases, we say that there is quantum advantage. Our framework is based on a novel differentiable policy parameterization that enables optimization over quantum measurements, together with a novel policy architecture that decomposes joint policies into a quantum coordinator and decentralized local actors. To illustrate the effectiveness of our proposed method, we first show that we can learn, purely from experience, strategies that attain quantum advantage in single-round games that are treated as black box oracles. We then demonstrate how our machinery can learn policies with quantum advantage in an illustrative multi-agent sequential decision-making problem formulated as a decentralized partially observable Markov decision process (Dec-POMDP).",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.MA",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08965v1",
        "pdf": "https://arxiv.org/pdf/2602.08965v1"
      },
      "arxiv_id": "2602.08965v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08964v1",
      "title": "A Behavioural and Representational Evaluation of Goal-Directedness in Language Model Agents",
      "authors": [
        "Raghu Arghal",
        "Fade Chen",
        "Niall Dalton",
        "Evgenii Kortukov",
        "Calum McNamara",
        "Angelos Nalmpantis",
        "Moksh Nirvaan",
        "Gabriele Sarti",
        "Mario Giulianelli"
      ],
      "abstract": "Understanding an agent's goals helps explain and predict its behaviour, yet there is no established methodology for reliably attributing goals to agentic systems. We propose a framework for evaluating goal-directedness that integrates behavioural evaluation with interpretability-based analyses of models' internal representations. As a case study, we examine an LLM agent navigating a 2D grid world toward a goal state. Behaviourally, we evaluate the agent against an optimal policy across varying grid sizes, obstacle densities, and goal structures, finding that performance scales with task difficulty while remaining robust to difficulty-preserving transformations and complex goal structures. We then use probing methods to decode the agent's internal representations of the environment state and its multi-step action plans. We find that the LLM agent non-linearly encodes a coarse spatial map of the environment, preserving approximate task-relevant cues about its position and the goal location; that its actions are broadly consistent with these internal representations; and that reasoning reorganises them, shifting from broader environment structural cues toward information supporting immediate action selection. Our findings support the view that introspective examination is required beyond behavioural evaluations to characterise how agents represent and pursue their objectives.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08964v1",
        "pdf": "https://arxiv.org/pdf/2602.08964v1"
      },
      "arxiv_id": "2602.08964v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08962v1",
      "title": "Modeling 3D Pedestrian-Vehicle Interactions for Vehicle-Conditioned Pose Forecasting",
      "authors": [
        "Guangxun Zhu",
        "Xuan Liu",
        "Nicolas Pugeault",
        "Chongfeng Wei",
        "Edmond S. L. Ho"
      ],
      "abstract": "Accurately predicting pedestrian motion is crucial for safe and reliable autonomous driving in complex urban environments. In this work, we present a 3D vehicle-conditioned pedestrian pose forecasting framework that explicitly incorporates surrounding vehicle information. To support this, we enhance the Waymo-3DSkelMo dataset with aligned 3D vehicle bounding boxes, enabling realistic modeling of multi-agent pedestrian-vehicle interactions. We introduce a sampling scheme to categorize scenes by pedestrian and vehicle count, facilitating training across varying interaction complexities. Our proposed network adapts the TBIFormer architecture with a dedicated vehicle encoder and pedestrian-vehicle interaction cross-attention module to fuse pedestrian and vehicle features, allowing predictions to be conditioned on both historical pedestrian motion and surrounding vehicles. Extensive experiments demonstrate substantial improvements in forecasting accuracy and validate different approaches for modeling pedestrian-vehicle interactions, highlighting the importance of vehicle-aware 3D pose prediction for autonomous driving. Code is available at: https://github.com/GuangxunZhu/VehCondPose3D",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08962v1",
        "pdf": "https://arxiv.org/pdf/2602.08962v1"
      },
      "arxiv_id": "2602.08962v1",
      "comment": "Accepted for IEEE International Conference on Robotics and Automation (ICRA) 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08961v1",
      "title": "MotionCrafter: Dense Geometry and Motion Reconstruction with a 4D VAE",
      "authors": [
        "Ruijie Zhu",
        "Jiahao Lu",
        "Wenbo Hu",
        "Xiaoguang Han",
        "Jianfei Cai",
        "Ying Shan",
        "Chuanxia Zheng"
      ],
      "abstract": "We introduce MotionCrafter, a video diffusion-based framework that jointly reconstructs 4D geometry and estimates dense motion from a monocular video. The core of our method is a novel joint representation of dense 3D point maps and 3D scene flows in a shared coordinate system, and a novel 4D VAE to effectively learn this representation. Unlike prior work that forces the 3D value and latents to align strictly with RGB VAE latents-despite their fundamentally different distributions-we show that such alignment is unnecessary and leads to suboptimal performance. Instead, we introduce a new data normalization and VAE training strategy that better transfers diffusion priors and greatly improves reconstruction quality. Extensive experiments across multiple datasets demonstrate that MotionCrafter achieves state-of-the-art performance in both geometry reconstruction and dense scene flow estimation, delivering 38.64% and 25.0% improvements in geometry and motion reconstruction, respectively, all without any post-optimization. Project page: https://ruijiezhu94.github.io/MotionCrafter_Page",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CG",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08961v1",
        "pdf": "https://arxiv.org/pdf/2602.08961v1"
      },
      "arxiv_id": "2602.08961v1",
      "comment": "Project page: https://ruijiezhu94.github.io/MotionCrafter_Page",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2602.08958v1",
      "title": "Grow with the Flow: 4D Reconstruction of Growing Plants with Gaussian Flow Fields",
      "authors": [
        "Weihan Luo",
        "Lily Goli",
        "Sherwin Bahmani",
        "Felix Taubner",
        "Andrea Tagliasacchi",
        "David B. Lindell"
      ],
      "abstract": "Modeling the time-varying 3D appearance of plants during their growth poses unique challenges: unlike many dynamic scenes, plants generate new geometry over time as they expand, branch, and differentiate. Recent motion modeling techniques are ill-suited to this problem setting. For example, deformation fields cannot introduce new geometry, and 4D Gaussian splatting constrains motion to a linear trajectory in space and time and cannot track the same set of Gaussians over time. Here, we introduce a 3D Gaussian flow field representation that models plant growth as a time-varying derivative over Gaussian parameters -- position, scale, orientation, color, and opacity -- enabling nonlinear and continuous-time growth dynamics. To initialize a sufficient set of Gaussian primitives, we reconstruct the mature plant and learn a process of reverse growth, effectively simulating the plant's developmental history in reverse. Our approach achieves superior image quality and geometric accuracy compared to prior methods on multi-view timelapse datasets of plant growth, providing a new approach for appearance modeling of growing 3D structures.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08958v1",
        "pdf": "https://arxiv.org/pdf/2602.08958v1"
      },
      "arxiv_id": "2602.08958v1",
      "comment": "Project page: https://weihanluo.ca/growflow/",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08949v1",
      "title": "Digital Twin and Agentic AI for Wild Fire Disaster Management: Intelligent Virtual Situation Room",
      "authors": [
        "Mohammad Morsali",
        "Siavash H. Khajavi"
      ],
      "abstract": "According to the United Nations, wildfire frequency and intensity are projected to increase by approximately 14% by 2030 and 30% by 2050 due to global warming, posing critical threats to life, infrastructure, and ecosystems. Conventional disaster management frameworks rely on static simulations and passive data acquisition, hindering their ability to adapt to arbitrarily evolving wildfire episodes in real-time. To address these limitations, we introduce the Intelligent Virtual Situation Room (IVSR), a bidirectional Digital Twin (DT) platform augmented by autonomous AI agents. The IVSR continuously ingests multisource sensor imagery, weather data, and 3D forest models to create a live virtual replica of the fire environment. A similarity engine powered by AI aligns emerging conditions with a precomputed Disaster Simulation Library, retrieving and calibrating intervention tactics under the watchful eyes of experts. Authorized action-ranging from UAV redeployment to crew reallocation-is cycled back through standardized procedures to the physical layer, completing the loop between response and analysis. We validate IVSR through detailed case-study simulations provided by an industrial partner, demonstrating capabilities in localized incident detection, privacy-preserving playback, collider-based fire-spread projection, and site-specific ML retraining. Our results indicate marked reductions in detection-to-intervention latency and more effective resource coordination versus traditional systems. By uniting real-time bidirectional DTs with agentic AI, IVSR offers a scalable, semi-automated decision-support paradigm for proactive, adaptive wildfire disaster management.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08949v1",
        "pdf": "https://arxiv.org/pdf/2602.08949v1"
      },
      "arxiv_id": "2602.08949v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08948v1",
      "title": "CoRefine: Confidence-Guided Self-Refinement for Adaptive Test-Time Compute",
      "authors": [
        "Chen Jin",
        "Ryutaro Tanno",
        "Tom Diethe",
        "Philip Teare"
      ],
      "abstract": "Large Language Models (LLMs) often rely on test-time scaling via parallel decoding (for example, 512 samples) to boost reasoning accuracy, but this incurs substantial compute. We introduce CoRefine, a confidence-guided self-refinement method that achieves competitive accuracy using a fraction of the tokens via a lightweight 211k-parameter Conv1D controller atop a frozen LLM. The controller consumes full-trace confidence to decide whether to halt, re-examine, or try a different approach, enabling targeted self-correction with an average of 2.7 refinement steps per problem and roughly 190-fold token reduction relative to 512-sample baselines. Across diverse reasoning benchmarks and three open-source models, the controller achieves 92.6 percent precision when it confidently halts, indicating that confidence dynamics reliably signal correctness without ground-truth verification. We extend this to CoRefine-Tree, a hybrid sequential-parallel variant that adaptively balances exploration and exploitation, with easy serving integration and verifier compatibility. By treating confidence as a control signal rather than a correctness guarantee, CoRefine provides a modular primitive for scalable reasoning and agentic settings with imperfect verifiers.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08948v1",
        "pdf": "https://arxiv.org/pdf/2602.08948v1"
      },
      "arxiv_id": "2602.08948v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08941v1",
      "title": "pixelLOG: Logging of Online Gameplay for Cognitive Research",
      "authors": [
        "Zeyu Lu",
        "Dennis L. Barbour"
      ],
      "abstract": "Traditional cognitive assessments often rely on isolated, output-focused measurements that may fail to capture the complexity of human cognition in naturalistic settings. We present pixelLOG, a high-performance data collection framework for Spigot-based Minecraft servers designed specifically for process-based cognitive research. Unlike existing frameworks tailored only for artificial intelligence agents, pixelLOG also enables human behavioral tracking in multi-player/multi-agent environments. Operating at configurable frequencies up to and exceeding 20 updates per second, the system captures comprehensive behavioral data through a hybrid approach of active state polling and passive event monitoring. By leveraging Spigot's extensible API, pixelLOG facilitates robust session isolation and produces structured JSON outputs integrable with standard analytical pipelines. This framework bridges the gap between decontextualized laboratory assessments and richer, more ecologically valid tasks, enabling high-resolution analysis of cognitive processes as they unfold in complex, virtual environments.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08941v1",
        "pdf": "https://arxiv.org/pdf/2602.08941v1"
      },
      "arxiv_id": "2602.08941v1",
      "comment": "9 pages, 1 figure",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08939v1",
      "title": "CausalT5K: Diagnosing and Informing Refusal for Trustworthy Causal Reasoning of Skepticism, Sycophancy, Detection-Correction, and Rung Collapse",
      "authors": [
        "Longling Geng",
        "Andy Ouyang",
        "Theodore Wu",
        "Daphne Barretto",
        "Matthew John Hayes",
        "Rachael Cooper",
        "Yuqiao Zeng",
        "Sameer Vijay",
        "Gia Ancone",
        "Ankit Rai",
        "Matthew Wolfman",
        "Patrick Flanagan",
        "Edward Y. Chang"
      ],
      "abstract": "LLM failures in causal reasoning, including sycophancy, rung collapse, and miscalibrated refusal, are well-documented, yet progress on remediation is slow because no benchmark enables systematic diagnosis. We introduce CausalT5K, a diagnostic benchmark of over 5,000 cases across 10 domains that tests three critical capabilities: (1) detecting rung collapse, where models answer interventional queries with associational evidence; (2) resisting sycophantic drift under adversarial pressure; and (3) generating Wise Refusals that specify missing information when evidence is underdetermined. Unlike synthetic benchmarks, CausalT5K embeds causal traps in realistic narratives and decomposes performance into Utility (sensitivity) and Safety (specificity), revealing failure modes invisible to aggregate accuracy. Developed through a rigorous human-machine collaborative pipeline involving 40 domain experts, iterative cross-validation cycles, and composite verification via rule-based, LLM, and human scoring, CausalT5K implements Pearl's Ladder of Causation as research infrastructure. Preliminary experiments reveal a Four-Quadrant Control Landscape where static audit policies universally fail, a finding that demonstrates CausalT5K's value for advancing trustworthy reasoning systems. Repository: https://github.com/genglongling/CausalT5kBench",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08939v1",
        "pdf": "https://arxiv.org/pdf/2602.08939v1"
      },
      "arxiv_id": "2602.08939v1",
      "comment": "17 pages, 20 tables, figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08934v1",
      "title": "StealthRL: Reinforcement Learning Paraphrase Attacks for Multi-Detector Evasion of AI-Text Detectors",
      "authors": [
        "Suraj Ranganath",
        "Atharv Ramesh"
      ],
      "abstract": "AI-text detectors face a critical robustness challenge: adversarial paraphrasing attacks that preserve semantics while evading detection. We introduce StealthRL, a reinforcement learning framework that stress-tests detector robustness under realistic adversarial conditions. StealthRL trains a paraphrase policy against a multi-detector ensemble using Group Relative Policy Optimization (GRPO) with LoRA adapters on Qwen3-4B, optimizing a composite reward that balances detector evasion with semantic preservation. We evaluate six attack settings (M0-M5) against three detector families (RoBERTa, FastDetectGPT, and Binoculars) at the security-relevant 1% false positive rate operating point. StealthRL achieves near-zero detection (0.001 mean TPR@1%FPR), reduces mean AUROC from 0.74 to 0.27, and attains a 99.9% attack success rate. Critically, attacks transfer to a held-out detector family not seen during training, revealing shared architectural vulnerabilities rather than detector-specific brittleness. We additionally conduct LLM-based quality evaluation via Likert scoring, analyze detector score distributions to explain why evasion succeeds, and provide per-detector AUROC with bootstrap confidence intervals. Our results expose significant robustness gaps in current AI-text detection and establish StealthRL as a principled adversarial evaluation protocol. Code and evaluation pipeline are publicly available at https://github.com/suraj-ranganath/StealthRL.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08934v1",
        "pdf": "https://arxiv.org/pdf/2602.08934v1"
      },
      "arxiv_id": "2602.08934v1",
      "comment": "Expanded version of a workshop submission. Code available",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2602.08933v1",
      "title": "Provably robust learning of regression neural networks using $β$-divergences",
      "authors": [
        "Abhik Ghosh",
        "Suryasis Jana"
      ],
      "abstract": "Regression neural networks (NNs) are most commonly trained by minimizing the mean squared prediction error, which is highly sensitive to outliers and data contamination. Existing robust training methods for regression NNs are often limited in scope and rely primarily on empirical validation, with only a few offering partial theoretical guarantees. In this paper, we propose a new robust learning framework for regression NNs based on the $β$-divergence (also known as the density power divergence) which we call `rRNet'. It applies to a broad class of regression NNs, including models with non-smooth activation functions and error densities, and recovers the classical maximum likelihood learning as a special case. The rRNet is implemented via an alternating optimization scheme, for which we establish convergence guarantees to stationary points under mild, verifiable conditions. The (local) robustness of rRNet is theoretically characterized through the influence functions of both the parameter estimates and the resulting rRNet predictor, which are shown to be bounded for suitable choices of the tuning parameter $β$, depending on the error density. We further prove that rRNet attains the optimal 50\\% asymptotic breakdown point at the assumed model for all $β\\in(0, 1]$, providing a strong global robustness guarantee that is largely absent for existing NN learning methods. Our theoretical results are complemented by simulation experiments and real-data analyses, illustrating practical advantages of rRNet over existing approaches in both function approximation problems and prediction tasks with noisy observations.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "stat.ML",
        "cs.LG",
        "cs.NE",
        "stat.ME"
      ],
      "primary_category": "stat.ML",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08933v1",
        "pdf": "https://arxiv.org/pdf/2602.08933v1"
      },
      "arxiv_id": "2602.08933v1",
      "comment": "Pre-print, under review",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08927v1",
      "title": "Online monotone density estimation and log-optimal calibration",
      "authors": [
        "Rohan Hore",
        "Ruodu Wang",
        "Aaditya Ramdas"
      ],
      "abstract": "We study the problem of online monotone density estimation, where density estimators must be constructed in a predictable manner from sequentially observed data. We propose two online estimators: an online analogue of the classical Grenander estimator, and an expert aggregation estimator inspired by exponential weighting methods from the online learning literature. In the well-specified stochastic setting, where the underlying density is monotone, we show that the expected cumulative log-likelihood gap between the online estimators and the true density admits an $O(n^{1/3})$ bound. We further establish a $\\sqrt{n\\log{n}}$ pathwise regret bound for the expert aggregation estimator relative to the best offline monotone estimator chosen in hindsight, under minimal regularity assumptions on the observed sequence. As an application of independent interest, we show that the problem of constructing log-optimal p-to-e calibrators for sequential hypothesis testing can be formulated as an online monotone density estimation problem. We adapt the proposed estimators to build empirically adaptive p-to-e calibrators and establish their optimality. Numerical experiments illustrate the theoretical results.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "stat.ML",
        "cs.LG",
        "stat.ME"
      ],
      "primary_category": "stat.ML",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08927v1",
        "pdf": "https://arxiv.org/pdf/2602.08927v1"
      },
      "arxiv_id": "2602.08927v1",
      "comment": "28 pages, 1 figure",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08923v1",
      "title": "DynamiQ: Accelerating Gradient Synchronization using Compressed Multi-hop All-reduce",
      "authors": [
        "Wenchen Han",
        "Shay Vargaftik",
        "Michael Mitzenmacher",
        "Ran Ben Basat"
      ],
      "abstract": "Multi-hop all-reduce is the de facto backbone of large model training. As the training scale increases, the network often becomes a bottleneck, motivating reducing the volume of transmitted data. Accordingly, recent systems demonstrated significant acceleration of the training process using gradient quantization. However, these systems are not optimized for multi-hop aggregation, where entries are partially summed multiple times along their aggregation topology.\n  This paper presents DynamiQ, a quantization framework that bridges the gap between quantization best practices and multi-hop aggregation. DynamiQ introduces novel techniques to better represent partial sums, co-designed with a decompress-accumulate-recompress fused kernel to facilitate fast execution.\n  We extended PyTorch DDP to support DynamiQ over NCCL P2P, and across different LLMs, tasks, and scales, we demonstrate consistent improvement of up to 34.2% over the best among state-of-the-art methods such as Omni-Reduce, THC, and emerging standards such as MXFP4, MXFP6, and MXFP8. Further, DynamiQ is the only evaluated method that consistently reaches near-baseline accuracy (e.g., 99.9% of the BF16 baseline) and does so while significantly accelerating the training.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.LG",
        "cs.DC",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08923v1",
        "pdf": "https://arxiv.org/pdf/2602.08923v1"
      },
      "arxiv_id": "2602.08923v1",
      "comment": "18 pages, 18 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08920v1",
      "title": "Diffusion-Inspired Reconfiguration of Transformers for Uncertainty Calibration",
      "authors": [
        "Manh Cuong Dao",
        "Quang Hung Pham",
        "Phi Le Nguyen",
        "Thao Nguyen Truong",
        "Bryan Kian Hsiang Low",
        "Trong Nghia Hoang"
      ],
      "abstract": "Uncertainty calibration in pre-trained transformers is critical for their reliable deployment in risk-sensitive applications. Yet, most existing pre-trained transformers do not have a principled mechanism for uncertainty propagation through their feature transformation stack. In this work, we propose a diffusion-inspired reconfiguration of transformers in which each feature transformation block is modeled as a probabilistic mapping. Composing these probabilistic mappings reveals a probability path that mimics the structure of a diffusion process, transporting data mass from the input distribution to the pre-trained feature distribution. This probability path can then be recompiled on a diffusion process with a unified transition model to enable principled propagation of representation uncertainty throughout the pre-trained model's architecture while maintaining its original predictive performance. Empirical results across a variety of vision and language benchmarks demonstrate that our method achieves superior calibration and predictive accuracy compared to existing uncertainty-aware transformers.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08920v1",
        "pdf": "https://arxiv.org/pdf/2602.08920v1"
      },
      "arxiv_id": "2602.08920v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08917v1",
      "title": "Automatic In-Domain Exemplar Construction and LLM-Based Refinement of Multi-LLM Expansions for Query Expansion",
      "authors": [
        "Minghan Li",
        "Ercong Nie",
        "Siqi Zhao",
        "Tongna Chen",
        "Huiping Huang",
        "Guodong Zhou"
      ],
      "abstract": "Query expansion with large language models is promising but often relies on hand-crafted prompts, manually chosen exemplars, or a single LLM, making it non-scalable and sensitive to domain shift. We present an automated, domain-adaptive QE framework that builds in-domain exemplar pools by harvesting pseudo-relevant passages using a BM25-MonoT5 pipeline. A training-free cluster-based strategy selects diverse demonstrations, yielding strong and stable in-context QE without supervision. To further exploit model complementarity, we introduce a two-LLM ensemble in which two heterogeneous LLMs independently generate expansions and a refinement LLM consolidates them into one coherent expansion. Across TREC DL20, DBPedia, and SciFact, the refined ensemble delivers consistent and statistically significant gains over BM25, Rocchio, zero-shot, and fixed few-shot baselines. The framework offers a reproducible testbed for exemplar selection and multi-LLM generation, and a practical, label-free solution for real-world QE.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08917v1",
        "pdf": "https://arxiv.org/pdf/2602.08917v1"
      },
      "arxiv_id": "2602.08917v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08916v1",
      "title": "AMS-HD: Hyperdimensional Computing for Real-Time and Energy-Efficient Acute Mountain Sickness Detection",
      "authors": [
        "Abu Masum",
        "Mehran Moghadam",
        "M. Hassan Najafi",
        "Bige Unluturk",
        "Ulkuhan Guler",
        "Sercan Aygun"
      ],
      "abstract": "Altitude sickness is a potentially life-threatening condition that impacts many individuals traveling to elevated altitudes. Timely detection is critical as symptoms can escalate rapidly. Early recognition enables simple interventions such as descent, oxygen, or medication, and prompt treatment can save lives by significantly lowering the risk of severe complications. Although conventional machine learning (ML) techniques have been applied to identify altitude sickness using physiological signals, such as heart rate, oxygen saturation, respiration rate, blood pressure, and body temperature, they often struggle to balance predictive performance with low hardware demands. In contrast, hyperdimensional computing (HDC) remains under-explored for this task with limited biomedical features, where it may offer a compelling alternative to existing classification models. Its vector symbolic framework is inherently suited to hardware-efficient design, making it a strong candidate for low-power systems like wearables. Leveraging lightweight computation and efficient streamlined memory usage, HDC enables real-time detection of altitude sickness from physiological parameters collected by wearable devices, achieving accuracy comparable to that of traditional ML models. We present AMS-HD, a novel system that integrates tailored feature extraction and Hadamard HV encoding to enhance both the precision and efficiency of HDC-based detection. This framework is well-positioned for deployment in wearable health monitoring platforms, enabling continuous, on-the-go tracking of acute altitude sickness.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.SC",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "cs.SC",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08916v1",
        "pdf": "https://arxiv.org/pdf/2602.08916v1"
      },
      "arxiv_id": "2602.08916v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08914v1",
      "title": "Gesturing Toward Abstraction: Multimodal Convention Formation in Collaborative Physical Tasks",
      "authors": [
        "Kiyosu Maeda",
        "William P. McCarthy",
        "Ching-Yi Tsai",
        "Jeffrey Mu",
        "Haoliang Wang",
        "Robert D. Hawkins",
        "Judith E. Fan",
        "Parastoo Abtahi"
      ],
      "abstract": "A quintessential feature of human intelligence is the ability to create ad hoc conventions over time to achieve shared goals efficiently. We investigate how communication strategies evolve through repeated collaboration as people coordinate on shared procedural abstractions. To this end, we conducted an online unimodal study (n = 98) using natural language to probe abstraction hierarchies. In a follow-up lab study (n = 40), we examined how multimodal communication (speech and gestures) changed during physical collaboration. Pairs used augmented reality to isolate their partner's hand and voice; one participant viewed a 3D virtual tower and sent instructions to the other, who built the physical tower. Participants became faster and more accurate by establishing linguistic and gestural abstractions and using cross-modal redundancy to emphasize key changes from previous interactions. Based on these findings, we extend probabilistic models of convention formation to multimodal settings, capturing shifts in modality preferences. Our findings and model provide building blocks for designing convention-aware intelligent agents situated in the physical world.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08914v1",
        "pdf": "https://arxiv.org/pdf/2602.08914v1"
      },
      "arxiv_id": "2602.08914v1",
      "comment": "Accepted at the 2026 CHI Conference on Human Factors in Computing Systems (CHI 2026). 15 pages",
      "journal_ref": "Proceedings of the 2026 CHI Conference on Human Factors in Computing Systems (CHI '26), ACM, 2026",
      "has_code": false
    },
    {
      "id": "2602.08913v1",
      "title": "GEMSS: A Variational Bayesian Method for Discovering Multiple Sparse Solutions in Classification and Regression Problems",
      "authors": [
        "Kateřina Henclová",
        "Václav Šmídl"
      ],
      "abstract": "Selecting interpretable feature sets in underdetermined ($n \\ll p$) and highly correlated regimes constitutes a fundamental challenge in data science, particularly when analyzing physical measurements. In such settings, multiple distinct sparse subsets may explain the response equally well. Identifying these alternatives is crucial for generating domain-specific insights into the underlying mechanisms, yet conventional methods typically isolate a single solution, obscuring the full spectrum of plausible explanations.\n  We present GEMSS (Gaussian Ensemble for Multiple Sparse Solutions), a variational Bayesian framework specifically designed to simultaneously discover multiple, diverse sparse feature combinations. The method employs a structured spike-and-slab prior for sparsity, a mixture of Gaussians to approximate the intractable multimodal posterior, and a Jaccard-based penalty to further control solution diversity. Unlike sequential greedy approaches, GEMSS optimizes the entire ensemble of solutions within a single objective function via stochastic gradient descent.\n  The method is validated on a comprehensive benchmark comprising 128 synthetic experiments across classification and regression tasks. Results demonstrate that GEMSS scales effectively to high-dimensional settings ($p=5000$) with sample size as small as $n = 50$, generalizes seamlessly to continuous targets, handles missing data natively, and exhibits remarkable robustness to class imbalance and Gaussian noise.\n  GEMSS is available as a Python package 'gemss' at PyPI. The full GitHub repository at https://github.com/kat-er-ina/gemss/ also includes a free, easy-to-use application suitable for non-coders.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08913v1",
        "pdf": "https://arxiv.org/pdf/2602.08913v1"
      },
      "arxiv_id": "2602.08913v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08909v1",
      "title": "Analysis of Converged 3D Gaussian Splatting Solutions: Density Effects and Prediction Limit",
      "authors": [
        "Zhendong Wang",
        "Cihan Ruan",
        "Jingchuan Xiao",
        "Chuqing Shi",
        "Wei Jiang",
        "Wei Wang",
        "Wenjie Liu",
        "Nam Ling"
      ],
      "abstract": "We investigate what structure emerges in 3D Gaussian Splatting (3DGS) solutions from standard multi-view optimization. We term these Rendering-Optimal References (RORs) and analyze their statistical properties, revealing stable patterns: mixture-structured scales and bimodal radiance across diverse scenes. To understand what determines these parameters, we apply learnability probes by training predictors to reconstruct RORs from point clouds without rendering supervision. Our analysis uncovers fundamental density-stratification. Dense regions exhibit geometry-correlated parameters amenable to render-free prediction, while sparse regions show systematic failure across architectures. We formalize this through variance decomposition, demonstrating that visibility heterogeneity creates covariance-dominated coupling between geometric and appearance parameters in sparse regions. This reveals the dual character of RORs: geometric primitives where point clouds suffice, and view synthesis primitives where multi-view constraints are essential. We provide density-aware strategies that improve training robustness and discuss architectural implications for systems that adaptively balance feed-forward prediction and rendering-based refinement.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08909v1",
        "pdf": "https://arxiv.org/pdf/2602.08909v1"
      },
      "arxiv_id": "2602.08909v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08907v1",
      "title": "Positive Distribution Shift as a Framework for Understanding Tractable Learning",
      "authors": [
        "Marko Medvedev",
        "Idan Attias",
        "Elisabetta Cornacchia",
        "Theodor Misiakiewicz",
        "Gal Vardi",
        "Nathan Srebro"
      ],
      "abstract": "We study a setting where the goal is to learn a target function f(x) with respect to a target distribution D(x), but training is done on i.i.d. samples from a different training distribution D'(x), labeled by the true target f(x). Such a distribution shift (here in the form of covariate shift) is usually viewed negatively, as hurting or making learning harder, and the traditional distribution shift literature is mostly concerned with limiting or avoiding this negative effect. In contrast, we argue that with a well-chosen D'(x), the shift can be positive and make learning easier -- a perspective called Positive Distribution Shift (PDS). Such a perspective is central to contemporary machine learning, where much of the innovation is in finding good training distributions D'(x), rather than changing the training algorithm. We further argue that the benefit is often computational rather than statistical, and that PDS allows computationally hard problems to become tractable even using standard gradient-based training. We formalize different variants of PDS, show how certain hard classes are easily learnable under PDS, and make connections with membership query learning.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08907v1",
        "pdf": "https://arxiv.org/pdf/2602.08907v1"
      },
      "arxiv_id": "2602.08907v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08905v1",
      "title": "Efficient and Stable Reinforcement Learning for Diffusion Language Models",
      "authors": [
        "Jiawei Liu",
        "Xiting Wang",
        "Yuanyuan Zhong",
        "Defu Lian",
        "Yu Yang"
      ],
      "abstract": "Reinforcement Learning (RL) is crucial for unlocking the complex reasoning capabilities of Diffusion-based Large Language Models (dLLMs). However, applying RL to dLLMs faces unique challenges in efficiency and stability. To address these challenges, we propose Spatio-Temporal Pruning (STP), a framework designed to simultaneously improve the efficiency and stability of RL for dLLMs. STP compresses the redundancy in the generative process through: (1) \\textit{spatial pruning}, which constrains the exploration space using static priors; and (2) \\textit{temporal pruning}, which bypasses redundant late-stage refinement steps. Our theoretical analysis demonstrates that STP strictly reduces the variance of the log-likelihood estimation, thereby ensuring more stable policy updates. Extensive experiments demonstrate that STP surpasses state-of-the-art baselines in both efficiency and accuracy. Our code is available at https://github.com/Lolo1222/STP.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08905v1",
        "pdf": "https://arxiv.org/pdf/2602.08905v1"
      },
      "arxiv_id": "2602.08905v1",
      "comment": "13 pages, 3 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08901v1",
      "title": "GSS: Gated Subspace Steering for Selective Memorization Mitigation in LLMs",
      "authors": [
        "Xuanqi Zhang",
        "Haoyang Shang",
        "Xiaoxiao Li"
      ],
      "abstract": "Large language models (LLMs) can memorize and reproduce training sequences verbatim -- a tendency that undermines both generalization and privacy. Existing mitigation methods apply interventions uniformly, degrading performance on the majority of tokens that generalize normally. We show empirically that memorization is sparse, intermittent, and token-conditioned, suggesting that effective mitigation requires context-aware intervention rather than static parameter modification. To this end, we propose a novel and effective selective memorization mitigation method -- Gated Subspace Steering (GSS), which decomposes intervention into a probe (detecting memorization-relevant activations) and a steer (applying targeted correction only when the probe exceeds a threshold). The optimal probe-steer pair emerges from a principled optimization framework based on optimal subspace steering. Experiments on four benchmarks show GSS matches or exceeds state-of-the-art memorization reduction while requiring $100-1000 \\times$ less compute than optimization-based alternatives. Furthermore, we provide new theoretical insights into the geometry of memorization in neural representations.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08901v1",
        "pdf": "https://arxiv.org/pdf/2602.08901v1"
      },
      "arxiv_id": "2602.08901v1",
      "comment": "34 pages, 12 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08896v1",
      "title": "OmniReview: A Large-scale Benchmark and LLM-enhanced Framework for Realistic Reviewer Recommendation",
      "authors": [
        "Yehua Huang",
        "Penglei Sun",
        "Zebin Chen",
        "Zhenheng Tang",
        "Xiaowen Chu"
      ],
      "abstract": "Academic peer review remains the cornerstone of scholarly validation, yet the field faces some challenges in data and methods. From the data perspective, existing research is hindered by the scarcity of large-scale, verified benchmarks and oversimplified evaluation metrics that fail to reflect real-world editorial workflows. To bridge this gap, we present OmniReview, a comprehensive dataset constructed by integrating multi-source academic platforms encompassing comprehensive scholarly profiles through the disambiguation pipeline, yielding 202, 756 verified review records. Based on this data, we introduce a three-tier hierarchical evaluaion framework to assess recommendations from recall to precise expert identification. From the method perspective, existing embedding-based approaches suffer from the information bottleneck of semantic compression and limited interpretability. To resolve these method limitations, we propose Profiling Scholars with Multi-gate Mixture-of-Experts (Pro-MMoE), a novel framework that synergizes Large Language Models (LLMs) with Multi-task Learning. Specifically, it utilizes LLM-generated semantic profiles to preserve fine-grained expertise nuances and interpretability, while employing a Task-Adaptive MMoE architecture to dynamically balance conflicting evaluation goals. Comprehensive experiments demonstrate that Pro-MMoE achieves state-of-the-art performance across six of seven metrics, establishing a new benchmark for realistic reviewer recommendation.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08896v1",
        "pdf": "https://arxiv.org/pdf/2602.08896v1"
      },
      "arxiv_id": "2602.08896v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08894v1",
      "title": "Discrete Bridges for Mutual Information Estimation",
      "authors": [
        "Iryna Zabarianska",
        "Sergei Kholkin",
        "Grigoriy Ksenofontov",
        "Ivan Butakov",
        "Alexander Korotin"
      ],
      "abstract": "Diffusion bridge models in both continuous and discrete state spaces have recently become powerful tools in the field of generative modeling. In this work, we leverage the discrete state space formulation of bridge matching models to address another important problem in machine learning and information theory: the estimation of the mutual information (MI) between discrete random variables. By neatly framing MI estimation as a domain transfer problem, we construct a Discrete Bridge Mutual Information (DBMI) estimator suitable for discrete data, which poses difficulties for conventional MI estimators. We showcase the performance of our estimator on two MI estimation settings: low-dimensional and image-based.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08894v1",
        "pdf": "https://arxiv.org/pdf/2602.08894v1"
      },
      "arxiv_id": "2602.08894v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08892v1",
      "title": "Winner's Curse Drives False Promises in Data-Driven Decisions: A Case Study in Refugee Matching",
      "authors": [
        "Hamsa Bastani",
        "Osbert Bastani",
        "Bryce McLaughlin"
      ],
      "abstract": "A major challenge in data-driven decision-making is accurate policy evaluation-i.e., guaranteeing that a learned decision-making policy achieves the promised benefits. A popular strategy is model-based policy evaluation, which estimates a model from data to infer counterfactual outcomes. This strategy is known to produce unwarrantedly optimistic estimates of the true benefit due to the winner's curse. We searched the recent literature on data-driven decision-making, identifying a sample of 55 papers published in the Management Science in the past decade; all but two relied on this flawed methodology. Several common justifications are provided: (1) the estimated models are accurate, stable, and well-calibrated, (2) the historical data uses random treatment assignment, (3) the model family is well-specified, and (4) the evaluation methodology uses sample splitting. Unfortunately, we show that no combination of these justifications avoids the winner's curse. First, we provide a theoretical analysis demonstrating that the winner's curse can cause large, spurious reported benefits even when all these justifications hold. Second, we perform a simulation study based on the recent and consequential data-driven refugee matching problem. We construct a synthetic refugee matching environment (calibrated to closely match the real setting) but designed so that no assignment policy can improve expected employment compared to random assignment. Model-based methods report large, stable gains of around 60% even when the true effect is zero; these gains are on par with improvements of 22-75% reported in the literature. Our results provide strong evidence against model-based evaluation.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "stat.ML",
        "cs.LG",
        "econ.EM"
      ],
      "primary_category": "stat.ML",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08892v1",
        "pdf": "https://arxiv.org/pdf/2602.08892v1"
      },
      "arxiv_id": "2602.08892v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08889v1",
      "title": "Scalable Delphi: Large Language Models for Structured Risk Estimation",
      "authors": [
        "Tobias Lorenz",
        "Mario Fritz"
      ],
      "abstract": "Quantitative risk assessment in high-stakes domains relies on structured expert elicitation to estimate unobservable properties. The gold standard - the Delphi method - produces calibrated, auditable judgments but requires months of coordination and specialist time, placing rigorous risk assessment out of reach for most applications. We investigate whether Large Language Models (LLMs) can serve as scalable proxies for structured expert elicitation. We propose Scalable Delphi, adapting the classical protocol for LLMs with diverse expert personas, iterative refinement, and rationale sharing. Because target quantities are typically unobservable, we develop an evaluation framework based on necessary conditions: calibration against verifiable proxies, sensitivity to evidence, and alignment with human expert judgment. We evaluate in the domain of AI-augmented cybersecurity risk, using three capability benchmarks and independent human elicitation studies. LLM panels achieve strong correlations with benchmark ground truth (Pearson r=0.87-0.95), improve systematically as evidence is added, and align with human expert panels - in one comparison, closer to a human panel than the two human panels are to each other. This demonstrates that LLM-based elicitation can extend structured expert judgment to settings where traditional methods are infeasible, reducing elicitation time from months to minutes.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08889v1",
        "pdf": "https://arxiv.org/pdf/2602.08889v1"
      },
      "arxiv_id": "2602.08889v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08887v1",
      "title": "DeepQuali: Initial results of a study on the use of large language models for assessing the quality of user stories",
      "authors": [
        "Adam Trendowicz",
        "Daniel Seifert",
        "Andreas Jedlitschka",
        "Marcus Ciolkowski",
        "Anton Strahilov"
      ],
      "abstract": "Generative artificial intelligence (GAI), specifically large language models (LLMs), are increasingly used in software engineering, mainly for coding tasks. However, requirements engineering - particularly requirements validation - has seen limited application of GAI. The current focus of using GAI for requirements is on eliciting, transforming, and classifying requirements, not on quality assessment. We propose and evaluate the LLM-based (GPT-4o) approach \"DeepQuali\", for assessing and improving requirements quality in agile software development. We applied it to projects in two small companies, where we compared LLM-based quality assessments with expert judgments. Experts also participated in walkthroughs of the solution, provided feedback, and rated their acceptance of the approach. Experts largely agreed with the LLM's quality assessments, especially regarding overall ratings and explanations. However, they did not always agree with the other experts on detailed ratings, suggesting that expertise and experience may influence judgments. Experts recognized the usefulness of the approach but criticized the lack of integration into their workflow. LLMs show potential in supporting software engineers with the quality assessment and improvement of requirements. The explicit use of quality models and explanatory feedback increases acceptance.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08887v1",
        "pdf": "https://arxiv.org/pdf/2602.08887v1"
      },
      "arxiv_id": "2602.08887v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08886v1",
      "title": "Contrastive Learning for Diversity-Aware Product Recommendations in Retail",
      "authors": [
        "Vasileios Karlis",
        "Ezgi Yıldırım",
        "David Vos",
        "Maarten de Rijke"
      ],
      "abstract": "Recommender systems often struggle with long-tail distributions and limited item catalog exposure, where a small subset of popular items dominates recommendations. This challenge is especially critical in large-scale online retail settings with extensive and diverse product assortments. This paper introduces an approach to enhance catalog coverage without compromising recommendation quality in the existing digital recommendation pipeline at IKEA Retail. Drawing inspiration from recent advances in negative sampling to address popularity bias, we integrate contrastive learning with carefully selected negative samples. Through offline and online evaluations, we demonstrate that our method improves catalog coverage, ensuring a more diverse set of recommendations yet preserving strong recommendation performance.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08886v1",
        "pdf": "https://arxiv.org/pdf/2602.08886v1"
      },
      "arxiv_id": "2602.08886v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08885v1",
      "title": "Breaking the Simplification Bottleneck in Amortized Neural Symbolic Regression",
      "authors": [
        "Paul Saegert",
        "Ullrich Köthe"
      ],
      "abstract": "Symbolic regression (SR) aims to discover interpretable analytical expressions that accurately describe observed data. Amortized SR promises to be much more efficient than the predominant genetic programming SR methods, but currently struggles to scale to realistic scientific complexity. We find that a key obstacle is the lack of a fast reduction of equivalent expressions to a concise normalized form. Amortized SR has addressed this by general-purpose Computer Algebra Systems (CAS) like SymPy, but the high computational cost severely limits training and inference speed. We propose SimpliPy, a rule-based simplification engine achieving a 100-fold speed-up over SymPy at comparable quality. This enables substantial improvements in amortized SR, including scalability to much larger training sets, more efficient use of the per-expression token budget, and systematic training set decontamination with respect to equivalent test expressions. We demonstrate these advantages in our Flash-ANSR framework, which achieves much better accuracy than amortized baselines (NeSymReS, E2E) on the FastSRB benchmark. Moreover, it performs on par with state-of-the-art direct optimization (PySR) while recovering more concise instead of more complex expressions with increasing inference budget.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SC"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08885v1",
        "pdf": "https://arxiv.org/pdf/2602.08885v1"
      },
      "arxiv_id": "2602.08885v1",
      "comment": "main text: 8 pages, 7 figures appendix: 12 pages, 11 figures code available at https://github.com/psaegert/simplipy and https://github.com/psaegert/flash-ansr",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2602.08882v1",
      "title": "Designing Multi-Robot Ground Video Sensemaking with Public Safety Professionals",
      "authors": [
        "Puqi Zhou",
        "Ali Asgarov",
        "Aafiya Hussain",
        "Wonjoon Park",
        "Amit Paudyal",
        "Sameep Shrestha",
        "Chia-wei Tang",
        "Michael F. Lighthiser",
        "Michael R. Hieb",
        "Xuesu Xiao",
        "Chris Thomas",
        "Sungsoo Ray Hong"
      ],
      "abstract": "Videos from fleets of ground robots can advance public safety by providing scalable situational awareness and reducing professionals' burden. Yet little is known about how to design and integrate multi-robot videos into public safety workflows. Collaborating with six police agencies, we examined how such videos could be made practical. In Study 1, we presented the first testbed for multi-robot ground video sensemaking. The testbed includes 38 events-of-interest (EoI) relevant to public safety, a dataset of 20 robot patrol videos (10 day/night pairs) covering EoI types, and 6 design requirements aimed at improving current video sensemaking practices. In Study 2, we built MRVS, a tool that augments multi-robot patrol video streams with a prompt-engineered video understanding model. Participants reported reduced manual workload and greater confidence with LLM-based explanations, while noting concerns about false alarms and privacy. We conclude with implications for designing future multi-robot video sensemaking tools. The testbed is available at https://github.com/Puqi7/MRVS\\_VideoSensemaking",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.HC",
        "cs.CV"
      ],
      "primary_category": "cs.HC",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08882v1",
        "pdf": "https://arxiv.org/pdf/2602.08882v1"
      },
      "arxiv_id": "2602.08882v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08880v1",
      "title": "Differentiable Logical Programming for Quantum Circuit Discovery and Optimization",
      "authors": [
        "Antonin Sulc"
      ],
      "abstract": "Designing high-fidelity quantum circuits remains challenging, and current paradigms often depend on heuristic, fixed-ansatz structures or rule-based compilers that can be suboptimal or lack generality. We introduce a neuro-symbolic framework that reframes quantum circuit design as a differentiable logic programming problem. Our model represents a scaffold of potential quantum gates and parameterized operations as a set of learnable, continuous ``truth values'' or ``switches,'' $s \\in [0, 1]^N$. These switches are optimized via standard gradient descent to satisfy a user-defined set of differentiable, logical axioms (e.g., correctness, simplicity, robustness). We provide a theoretical formulation bridging continuous logic (via T-norms) and unitary evolution (via geodesic interpolation), while addressing the barren plateau problem through biased initialization. We illustrate the approach on tasks including discovery of a 4-qubit Quantum Fourier Transform (QFT) from a scaffold of 21 candidate gates. We also report a hardware-aware adaptation experiment on the 133-qubit IBM Torino processor, where the method improved fidelity by 59.3 percentage points in a localized routing task while adapting to hardware failures.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "quant-ph",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08880v1",
        "pdf": "https://arxiv.org/pdf/2602.08880v1"
      },
      "arxiv_id": "2602.08880v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08878v1",
      "title": "Learning Potentials for Dynamic Matching and Application to Heart Transplantation",
      "authors": [
        "Itai Zilberstein",
        "Ioannis Anagnostides",
        "Zachary W. Sollie",
        "Arman Kilic",
        "Tuomas Sandholm"
      ],
      "abstract": "Each year, thousands of patients in need of heart transplants face life-threatening wait times due to organ scarcity. While allocation policies aim to maximize population-level outcomes, current approaches often fail to account for the dynamic arrival of organs and the composition of waitlisted candidates, thereby hampering efficiency. The United States is transitioning from rigid, rule-based allocation to more flexible data-driven models. In this paper, we propose a novel framework for non-myopic policy optimization in general online matching relying on potentials, a concept originally introduced for kidney exchange. We develop scalable and accurate ways of learning potentials that are higher-dimensional and more expressive than prior approaches. Our approach is a form of self-supervised imitation learning: the potentials are trained to mimic an omniscient algorithm that has perfect foresight. We focus on the application of heart transplant allocation and demonstrate, using real historical data, that our policies significantly outperform prior approaches -- including the current US status quo policy and the proposed continuous distribution framework -- in optimizing for population-level outcomes. Our analysis and methods come at a pivotal moment in US policy, as the current heart transplant allocation system is under review. We propose a scalable and theoretically grounded path toward more effective organ allocation.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08878v1",
        "pdf": "https://arxiv.org/pdf/2602.08878v1"
      },
      "arxiv_id": "2602.08878v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08877v1",
      "title": "Stress-Testing Alignment Audits With Prompt-Level Strategic Deception",
      "authors": [
        "Oliver Daniels",
        "Perusha Moodley",
        "Ben Marlin",
        "David Lindner"
      ],
      "abstract": "Alignment audits aim to robustly identify hidden goals from strategic, situationally aware misaligned models. Despite this threat model, existing auditing methods have not been systematically stress-tested against deception strategies. We address this gap, implementing an automatic red-team pipeline that generates deception strategies (in the form of system prompts) tailored to specific white-box and black-box auditing methods. Stress-testing assistant prefills, user persona sampling, sparse autoencoders, and token embedding similarity methods against secret-keeping model organisms, our automatic red-team pipeline finds prompts that deceive both the black-box and white-box methods into confident, incorrect guesses. Our results provide the first documented evidence of activation-based strategic deception, and suggest that current black-box and white-box methods would not be robust to a sufficiently capable misaligned model.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08877v1",
        "pdf": "https://arxiv.org/pdf/2602.08877v1"
      },
      "arxiv_id": "2602.08877v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08873v1",
      "title": "Whose Name Comes Up? Benchmarking and Intervention-Based Auditing of LLM-Based Scholar Recommendation",
      "authors": [
        "Lisette Espin-Noboa",
        "Gonzalo Gabriel Mendez"
      ],
      "abstract": "Large language models (LLMs) are increasingly used for academic expert recommendation. Existing audits typically evaluate model outputs in isolation, largely ignoring end-user inference-time interventions. As a result, it remains unclear whether failures such as refusals, hallucinations, and uneven coverage stem from model choice or deployment decisions. We introduce LLMScholarBench, a benchmark for auditing LLM-based scholar recommendation that jointly evaluates model infrastructure and end-user interventions across multiple tasks. LLMScholarBench measures both technical quality and social representation using nine metrics. We instantiate the benchmark in physics expert recommendation and audit 22 LLMs under temperature variation, representation-constrained prompting, and retrieval-augmented generation (RAG) via web search. Our results show that end-user interventions do not yield uniform improvements but instead redistribute error across dimensions. Higher temperature degrades validity, consistency, and factuality. Representation-constrained prompting improves diversity at the expense of factuality, while RAG primarily improves technical quality while reducing diversity and parity. Overall, end-user interventions reshape trade-offs rather than providing a general fix. We release code and data that can be adapted to other disciplines by replacing domain-specific ground truth and metrics.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CY",
        "cs.SI",
        "physics.soc-ph"
      ],
      "primary_category": "cs.IR",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08873v1",
        "pdf": "https://arxiv.org/pdf/2602.08873v1"
      },
      "arxiv_id": "2602.08873v1",
      "comment": "28 pages: 8 pages in main (5 figures, 1 table), 20 pages in appendix (18 figures, 2 tables). under-review",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08868v1",
      "title": "AnomSeer: Reinforcing Multimodal LLMs to Reason for Time-Series Anomaly Detection",
      "authors": [
        "Junru Zhang",
        "Lang Feng",
        "Haoran Shi",
        "Xu Guo",
        "Han Yu",
        "Yabo Dong",
        "Duanqing Xu"
      ],
      "abstract": "Time-series anomaly detection (TSAD) with multimodal large language models (MLLMs) is an emerging area, yet a persistent challenge remains: MLLMs rely on coarse time-series heuristics but struggle with multi-dimensional, detailed reasoning, which is vital for understanding complex time-series data. We present AnomSeer to address this by reinforcing the model to ground its reasoning in precise, structural details of time series, unifying anomaly classification, localization, and explanation. At its core, an expert chain-of-thought trace is generated to provide a verifiable, fine-grained reasoning from classical analyses (e.g., statistical measures, frequency transforms). Building on this, we propose a novel time-series grounded policy optimization (TimerPO) that incorporates two additional components beyond standard reinforcement learning: a time-series grounded advantage based on optimal transport and an orthogonal projection to ensure this auxiliary granular signal does not interfere with the primary detection objective. Across diverse anomaly scenarios, AnomSeer, with Qwen2.5-VL-3B/7B-Instruct, outperforms larger commercial baselines (e.g., GPT-4o) in classification and localization accuracy, particularly on point- and frequency-driven exceptions. Moreover, it produces plausible time-series reasoning traces that support its conclusions.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08868v1",
        "pdf": "https://arxiv.org/pdf/2602.08868v1"
      },
      "arxiv_id": "2602.08868v1",
      "comment": "Preprint",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08864v1",
      "title": "Understanding Dynamic Compute Allocation in Recurrent Transformers",
      "authors": [
        "Ibraheem Muhammad Moosa",
        "Suhas Lohit",
        "Ye Wang",
        "Moitreya Chatterjee",
        "Wenpeng Yin"
      ],
      "abstract": "Token-level adaptive computation seeks to reduce inference cost by allocating more computation to harder tokens and less to easier ones. However, prior work is primarily evaluated on natural-language benchmarks using task-level metrics, where token-level difficulty is unobservable and confounded with architectural factors, making it unclear whether compute allocation truly aligns with underlying complexity. We address this gap through three contributions. First, we introduce a complexity-controlled evaluation paradigm using algorithmic and synthetic language tasks with parameterized difficulty, enabling direct testing of token-level compute allocation. Second, we propose ANIRA, a unified recurrent Transformer framework that supports per-token variable-depth computation while isolating compute allocation decisions from other model factors. Third, we use this framework to conduct a systematic analysis of token-level adaptive computation across alignment with complexity, generalization, and decision timing. Our results show that compute allocation aligned with task complexity can emerge without explicit difficulty supervision, but such alignment does not imply algorithmic generalization: models fail to extrapolate to unseen input sizes despite allocating additional computation. We further find that early compute decisions rely on static structural cues, whereas online halting more closely tracks algorithmic execution state.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08864v1",
        "pdf": "https://arxiv.org/pdf/2602.08864v1"
      },
      "arxiv_id": "2602.08864v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08862v1",
      "title": "Near-optimal Swap Regret Minimization for Convex Losses",
      "authors": [
        "Lunjia Hu",
        "Jon Schneider",
        "Yifan Wu"
      ],
      "abstract": "We give a randomized online algorithm that guarantees near-optimal $\\widetilde O(\\sqrt T)$ expected swap regret against any sequence of $T$ adaptively chosen Lipschitz convex losses on the unit interval. This improves the previous best bound of $\\widetilde O(T^{2/3})$ and answers an open question of Fishelson et al. [2025b]. In addition, our algorithm is efficient: it runs in $\\mathsf{poly}(T)$ time. A key technical idea we develop to obtain this result is to discretize the unit interval into bins at multiple scales of granularity and simultaneously use all scales to make randomized predictions, which we call multi-scale binning and may be of independent interest. A direct corollary of our result is an efficient online algorithm for minimizing the calibration error for general elicitable properties. This result does not require the Lipschitzness assumption of the identification function needed in prior work, making it applicable to median calibration, for which we achieve the first $\\widetilde O(\\sqrt T)$ calibration error guarantee.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.LG",
        "cs.DS",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08862v1",
        "pdf": "https://arxiv.org/pdf/2602.08862v1"
      },
      "arxiv_id": "2602.08862v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08861v1",
      "title": "TiFRe: Text-guided Video Frame Reduction for Efficient Video Multi-modal Large Language Models",
      "authors": [
        "Xiangtian Zheng",
        "Zishuo Wang",
        "Yuxin Peng"
      ],
      "abstract": "With the rapid development of Large Language Models (LLMs), Video Multi-Modal Large Language Models (Video MLLMs) have achieved remarkable performance in video-language tasks such as video understanding and question answering. However, Video MLLMs face high computational costs, particularly in processing numerous video frames as input, which leads to significant attention computation overhead. A straightforward approach to reduce computational costs is to decrease the number of input video frames. However, simply selecting key frames at a fixed frame rate (FPS) often overlooks valuable information in non-key frames, resulting in notable performance degradation. To address this, we propose Text-guided Video Frame Reduction (TiFRe), a framework that reduces input frames while preserving essential video information. TiFRe uses a Text-guided Frame Sampling (TFS) strategy to select key frames based on user input, which is processed by an LLM to generate a CLIP-style prompt. Pre-trained CLIP encoders calculate the semantic similarity between the prompt and each frame, selecting the most relevant frames as key frames. To preserve video semantics, TiFRe employs a Frame Matching and Merging (FMM) mechanism, which integrates non-key frame information into the selected key frames, minimizing information loss. Experiments show that TiFRe effectively reduces computational costs while improving performance on video-language tasks.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08861v1",
        "pdf": "https://arxiv.org/pdf/2602.08861v1"
      },
      "arxiv_id": "2602.08861v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08859v1",
      "title": "Magnitude Distance: A Geometric Measure of Dataset Similarity",
      "authors": [
        "Sahel Torkamani",
        "Henry Gouk",
        "Rik Sarkar"
      ],
      "abstract": "Quantifying the distance between datasets is a fundamental question in mathematics and machine learning. We propose \\textit{magnitude distance}, a novel distance metric defined on finite datasets using the notion of the \\emph{magnitude} of a metric space. The proposed distance incorporates a tunable scaling parameter, $t$, that controls the sensitivity to global structure (small $t$) and finer details (large $t$). We prove several theoretical properties of magnitude distance, including its limiting behavior across scales and conditions under which it satisfies key metric properties. In contrast to classical distances, we show that magnitude distance remains discriminative in high-dimensional settings when the scale is appropriately tuned. We further demonstrate how magnitude distance can be used as a training objective for push-forward generative models. Our experimental results support our theoretical analysis and demonstrate that magnitude distance provides meaningful signals, comparable to established distance-based generative approaches.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08859v1",
        "pdf": "https://arxiv.org/pdf/2602.08859v1"
      },
      "arxiv_id": "2602.08859v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08858v1",
      "title": "FlattenGPT: Depth Compression for Transformer with Layer Flattening",
      "authors": [
        "Ruihan Xu",
        "Qingpei Guo",
        "Yao Zhu",
        "Xiangyang Ji",
        "Ming Yang",
        "Shiliang Zhang"
      ],
      "abstract": "Recent works have indicated redundancy across transformer blocks, prompting the research of depth compression to prune less crucial blocks. However, current ways of entire-block pruning suffer from risks of discarding meaningful cues learned in those blocks, leading to substantial performance degradation. As another line of model compression, channel pruning can better preserve performance, while it cannot reduce model depth and is challenged by inconsistent pruning ratios for individual layers. To pursue better model compression and acceleration, this paper proposes \\textbf{FlattenGPT}, a novel way to detect and reduce depth-wise redundancies. By flatting two adjacent blocks into one, it compresses the network depth, meanwhile enables more effective parameter redundancy detection and removal. FlattenGPT allows to preserve the knowledge learned in all blocks, and remains consistent with the original transformer architecture. Extensive experiments demonstrate that FlattenGPT enhances model efficiency with a decent trade-off to performance. It outperforms existing pruning methods in both zero-shot accuracies and WikiText-2 perplexity across various model types and parameter sizes. On LLaMA-2/3 and Qwen-1.5 models, FlattenGPT retains 90-96\\% of zero-shot performance with a compression ratio of 20\\%. It also outperforms other pruning methods in accelerating LLM inference, making it promising for enhancing the efficiency of transformers.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08858v1",
        "pdf": "https://arxiv.org/pdf/2602.08858v1"
      },
      "arxiv_id": "2602.08858v1",
      "comment": "Submitted to ICML 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08857v1",
      "title": "Discovering Interpretable Algorithms by Decompiling Transformers to RASP",
      "authors": [
        "Xinting Huang",
        "Aleksandra Bakalova",
        "Satwik Bhattamishra",
        "William Merrill",
        "Michael Hahn"
      ],
      "abstract": "Recent work has shown that the computations of Transformers can be simulated in the RASP family of programming languages. These findings have enabled improved understanding of the expressive capacity and generalization abilities of Transformers. In particular, Transformers have been suggested to length-generalize exactly on problems that have simple RASP programs. However, it remains open whether trained models actually implement simple interpretable programs. In this paper, we present a general method to extract such programs from trained Transformers. The idea is to faithfully re-parameterize a Transformer as a RASP program and then apply causal interventions to discover a small sufficient sub-program. In experiments on small Transformers trained on algorithmic and formal language tasks, we show that our method often recovers simple and interpretable RASP programs from length-generalizing transformers. Our results provide the most direct evidence so far that Transformers internally implement simple RASP programs.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08857v1",
        "pdf": "https://arxiv.org/pdf/2602.08857v1"
      },
      "arxiv_id": "2602.08857v1",
      "comment": "101 pages, 92 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08855v1",
      "title": "Rethinking Graph Generalization through the Lens of Sharpness-Aware Minimization",
      "authors": [
        "Yang Qiu",
        "Yixiong Zou",
        "Jun Wang"
      ],
      "abstract": "Graph Neural Networks (GNNs) have achieved remarkable success across various graph-based tasks but remain highly sensitive to distribution shifts. In this work, we focus on a prevalent yet under-explored phenomenon in graph generalization, Minimal Shift Flip (MSF),where test samples that slightly deviate from the training distribution are abruptly misclassified. To interpret this phenomenon, we revisit MSF through the lens of Sharpness-Aware Minimization (SAM), which characterizes the local stability and sharpness of the loss landscape while providing a theoretical foundation for modeling generalization error. To quantify loss sharpness, we introduce the concept of Local Robust Radius, measuring the smallest perturbation required to flip a prediction and establishing a theoretical link between local stability and generalization. Building on this perspective, we further observe a continual decrease in the robust radius during training, indicating weakened local stability and an increasingly sharp loss landscape that gives rise to MSF. To jointly solve the MSF phenomenon and the intractability of radius, we develop an energy-based formulation that is theoretically proven to be monotonically correlated with the robust radius, offering a tractable and principled objective for modeling flatness and stability. Building on these insights, we propose an energy-driven generative augmentation framework (E2A) that leverages energy-guided latent perturbations to generate pseudo-OOD samples and enhance model generalization. Extensive experiments across multiple benchmarks demonstrate that E2A consistently improves graph OOD generalization, outperforming state-of-the-art baselines.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08855v1",
        "pdf": "https://arxiv.org/pdf/2602.08855v1"
      },
      "arxiv_id": "2602.08855v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08849v1",
      "title": "Cutting Through the Noise: On-the-fly Outlier Detection for Robust Training of Machine Learning Interatomic Potentials",
      "authors": [
        "Terry C. W. Lam",
        "Niamh O'Neill",
        "Christoph Schran",
        "Lars L. Schaaf"
      ],
      "abstract": "The accuracy of machine learning interatomic potentials suffers from reference data that contains numerical noise. Often originating from unconverged or inconsistent electronic-structure calculations, this noise is challenging to identify. Existing mitigation strategies such as manual filtering or iterative refinement of outliers, require either substantial expert effort or multiple expensive retraining cycles, making them difficult to scale to large datasets. Here, we introduce an on-the-fly outlier detection scheme that automatically down-weights noisy samples, without requiring additional reference calculations. By tracking the loss distribution via an exponential moving average, this unsupervised method identifies outliers throughout a single training run. We show that this approach prevents overfitting and matches the performance of iterative refinement baselines with significantly reduced overhead. The method's effectiveness is demonstrated by recovering accurate physical observables for liquid water from unconverged reference data, including diffusion coefficients. Furthermore, we validate its scalability by training a foundation model for organic chemistry on the SPICE dataset, where it reduces energy errors by a factor of three. This framework provides a simple, automated solution for training robust models on imperfect datasets across dataset sizes.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "stat.ML",
        "cond-mat.mtrl-sci",
        "cs.LG",
        "physics.chem-ph"
      ],
      "primary_category": "stat.ML",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08849v1",
        "pdf": "https://arxiv.org/pdf/2602.08849v1"
      },
      "arxiv_id": "2602.08849v1",
      "comment": "12 pages, 6 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08848v1",
      "title": "Deciding the Satisfiability of Combined Qualitative Constraint Networks",
      "authors": [
        "Quentin Cohen-Solal",
        "Alexandre Niveau",
        "Maroua Bouzid"
      ],
      "abstract": "Among the various forms of reasoning studied in the context of artificial intelligence, qualitative reasoning makes it possible to infer new knowledge in the context of imprecise, incomplete information without numerical values. In this paper, we propose a formal framework unifying several forms of extensions and combinations of qualitative formalisms, including multi-scale reasoning, temporal sequences, and loose integrations. This framework makes it possible to reason in the context of each of these combinations and extensions, but also to study in a unified way the satisfiability decision and its complexity. In particular, we establish two complementary theorems guaranteeing that the satisfiability decision is polynomial, and we use them to recover the known results of the size-topology combination. We also generalize the main definition of qualitative formalism to include qualitative formalisms excluded from the definitions of the literature, important in the context of combinations.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08848v1",
        "pdf": "https://arxiv.org/pdf/2602.08848v1"
      },
      "arxiv_id": "2602.08848v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08847v1",
      "title": "Dr. MAS: Stable Reinforcement Learning for Multi-Agent LLM Systems",
      "authors": [
        "Lang Feng",
        "Longtao Zheng",
        "Shuo He",
        "Fuxiang Zhang",
        "Bo An"
      ],
      "abstract": "Multi-agent LLM systems enable advanced reasoning and tool use via role specialization, yet reliable reinforcement learning (RL) post-training for such systems remains difficult. In this work, we theoretically pinpoint a key reason for training instability when extending group-based RL to multi-agent LLM systems. We show that under GRPO-style optimization, a global normalization baseline may deviate from diverse agents' reward distributions, which ultimately leads to gradient-norm instability. Based on this finding, we propose Dr. MAS, a simple and stable RL training recipe for multi-agent LLM systems. Dr. MAS uses an agent-wise remedy: normalizing advantages per agent using each agent's own reward statistics, which calibrates gradient scales and dramatically stabilizes training, both theoretically and empirically. Beyond the algorithm, Dr. MAS provides an end-to-end RL training framework for multi-agent LLM systems, supporting scalable orchestration, flexible per-agent LLM serving and optimization configs, and shared resource scheduling of LLM actor backends. We evaluate Dr. MAS on multi-agent math reasoning and multi-turn search benchmarks using Qwen2.5 and Qwen3 series models. Dr. MAS achieves clear gains over vanilla GRPO (e.g., +5.6\\% avg@16 and +4.6\\% pass@16 on math, and +15.2\\% avg@16 and +13.1\\% pass@16 on search) while largely eliminating gradient spikes. Moreover, it remains highly effective under heterogeneous agent-model assignments while improving efficiency.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08847v1",
        "pdf": "https://arxiv.org/pdf/2602.08847v1"
      },
      "arxiv_id": "2602.08847v1",
      "comment": "Preprint",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08837v1",
      "title": "AMEM4Rec: Leveraging Cross-User Similarity for Memory Evolution in Agentic LLM Recommenders",
      "authors": [
        "Minh-Duc Nguyen",
        "Hai-Dang Kieu",
        "Dung D. Le"
      ],
      "abstract": "Agentic systems powered by Large Language Models (LLMs) have shown strong potential in recommender systems but remain hindered by several challenges. Fine-tuning LLMs is parameter-inefficient, and prompt-based agentic reasoning is limited by context length and hallucination risk. Moreover, existing agentic recommendation systems predominantly leverages semantic knowledge while neglecting the collaborative filtering (CF) signals essential for implicit preference modeling. To address these limitations, we propose AMEM4Rec, an agentic LLM-based recommender that learns collaborative signals in an end-to-end manner through cross-user memory evolution. AMEM4Rec stores abstract user behavior patterns from user histories in a global memory pool. Within this pool, memories are linked to similar existing ones and iteratively evolved to reinforce shared cross-user patterns, enabling the system to become aware of CF signals without relying on a pre-trained CF model. Extensive experiments on Amazon and MIND datasets show that AMEM4Rec consistently outperforms state-of-the-art LLM-based recommenders, demonstrating the effectiveness of evolving memory-guided collaborative filtering.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08837v1",
        "pdf": "https://arxiv.org/pdf/2602.08837v1"
      },
      "arxiv_id": "2602.08837v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08835v1",
      "title": "Learning the Value Systems of Societies with Preference-based Multi-objective Reinforcement Learning",
      "authors": [
        "Andrés Holgado-Sánchez",
        "Peter Vamplew",
        "Richard Dazeley",
        "Sascha Ossowski",
        "Holger Billhardt"
      ],
      "abstract": "Value-aware AI should recognise human values and adapt to the value systems (value-based preferences) of different users. This requires operationalization of values, which can be prone to misspecification. The social nature of values demands their representation to adhere to multiple users while value systems are diverse, yet exhibit patterns among groups. In sequential decision making, efforts have been made towards personalization for different goals or values from demonstrations of diverse agents. However, these approaches demand manually designed features or lack value-based interpretability and/or adaptability to diverse user preferences.\n  We propose algorithms for learning models of value alignment and value systems for a society of agents in Markov Decision Processes (MDPs), based on clustering and preference-based multi-objective reinforcement learning (PbMORL). We jointly learn socially-derived value alignment models (groundings) and a set of value systems that concisely represent different groups of users (clusters) in a society. Each cluster consists of a value system representing the value-based preferences of its members and an approximately Pareto-optimal policy that reflects behaviours aligned with this value system. We evaluate our method against a state-of-the-art PbMORL algorithm and baselines on two MDPs with human values.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08835v1",
        "pdf": "https://arxiv.org/pdf/2602.08835v1"
      },
      "arxiv_id": "2602.08835v1",
      "comment": "18 pages, 3 figures. To be published in proceedings of the 25th International Conference on Autonomous Agents and Multi-Agent Systems (AAMAS 2026). This is a full version that includes the supplementary material",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08829v1",
      "title": "WildReward: Learning Reward Models from In-the-Wild Human Interactions",
      "authors": [
        "Hao Peng",
        "Yunjia Qi",
        "Xiaozhi Wang",
        "Zijun Yao",
        "Lei Hou",
        "Juanzi Li"
      ],
      "abstract": "Reward models (RMs) are crucial for the training of large language models (LLMs), yet they typically rely on large-scale human-annotated preference pairs. With the widespread deployment of LLMs, in-the-wild interactions have emerged as a rich source of implicit reward signals. This raises the question: Can we develop reward models directly from in-the-wild interactions? In this work, we explore this possibility by adopting WildChat as an interaction source and proposing a pipeline to extract reliable human feedback, yielding 186k high-quality instances for training WildReward via ordinal regression directly on user feedback without preference pairs. Extensive experiments demonstrate that WildReward achieves comparable or even superior performance compared to conventional reward models, with improved calibration and cross-sample consistency. We also observe that WildReward benefits directly from user diversity, where more users yield stronger reward models. Finally, we apply WildReward to online DPO training and observe significant improvements across various tasks. Code and data are released at https://github.com/THU-KEG/WildReward.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08829v1",
        "pdf": "https://arxiv.org/pdf/2602.08829v1"
      },
      "arxiv_id": "2602.08829v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08828v1",
      "title": "VideoVeritas: AI-Generated Video Detection via Perception Pretext Reinforcement Learning",
      "authors": [
        "Hao Tan",
        "Jun Lan",
        "Senyuan Shi",
        "Zichang Tan",
        "Zijian Yu",
        "Huijia Zhu",
        "Weiqiang Wang",
        "Jun Wan",
        "Zhen Lei"
      ],
      "abstract": "The growing capability of video generation poses escalating security risks, making reliable detection increasingly essential. In this paper, we introduce VideoVeritas, a framework that integrates fine-grained perception and fact-based reasoning. We observe that while current multi-modal large language models (MLLMs) exhibit strong reasoning capacity, their granular perception ability remains limited. To mitigate this, we introduce Joint Preference Alignment and Perception Pretext Reinforcement Learning (PPRL). Specifically, rather than directly optimizing for detection task, we adopt general spatiotemporal grounding and self-supervised object counting in the RL stage, enhancing detection performance with simple perception pretext tasks. To facilitate robust evaluation, we further introduce MintVid, a light yet high-quality dataset containing 3K videos from 9 state-of-the-art generators, along with a real-world collected subset that has factual errors in content. Experimental results demonstrate that existing methods tend to bias towards either superficial reasoning or mechanical analysis, while VideoVeritas achieves more balanced performance across diverse benchmarks.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08828v1",
        "pdf": "https://arxiv.org/pdf/2602.08828v1"
      },
      "arxiv_id": "2602.08828v1",
      "comment": "Project: https://github.com/EricTan7/VideoVeritas",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2602.08826v1",
      "title": "Affective Flow Language Model for Emotional Support Conversation",
      "authors": [
        "Chenghui Zou",
        "Ning Wang",
        "Tiesunlong Shen",
        "Luwei Xiao",
        "Chuan Ma",
        "Xiangpeng Li",
        "Rui Mao",
        "Erik Cambria"
      ],
      "abstract": "Large language models (LLMs) have been widely applied to emotional support conversation (ESC). However, complex multi-turn support remains challenging.This is because existing alignment schemes rely on sparse outcome-level signals, thus offering limited supervision for intermediate strategy decisions. To fill this gap, this paper proposes affective flow language model for emotional support conversation (AFlow), a framework that introduces fine-grained supervision on dialogue prefixes by modeling a continuous affective flow along multi-turn trajectories. AFlow can estimate intermediate utility over searched trajectories and learn preference-consistent strategy transitions. To improve strategy coherence and empathetic response quality, a subpath-level flow-balance objective is presented to propagate preference signals to intermediate states. Experiment results show consistent and significant improvements over competitive baselines in diverse emotional contexts. Remarkably, AFlow with a compact open-source backbone outperforms proprietary LMMs such as GPT-4o and Claude-3.5 on major ESC metrics. Our code is available at https://github.com/chzou25-lgtm/AffectiveFlow.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08826v1",
        "pdf": "https://arxiv.org/pdf/2602.08826v1"
      },
      "arxiv_id": "2602.08826v1",
      "comment": "19 pages, 7 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08822v1",
      "title": "Any-to-All MRI Synthesis: A Unified Foundation Model for Nasopharyngeal Carcinoma and Its Downstream Applications",
      "authors": [
        "Yao Pu",
        "Yiming Shi",
        "Zhenxi Zhang",
        "Peixin Yu",
        "Yitao Zhuang",
        "Xiang Wang",
        "Hongzhao Chen",
        "Jing Cai",
        "Ge Ren"
      ],
      "abstract": "Magnetic resonance imaging (MRI) is essential for nasopharyngeal carcinoma (NPC) radiotherapy (RT), but practical constraints, such as patient discomfort, long scan times, and high costs often lead to incomplete modalities in clinical practice, compromising RT planning accuracy. Traditional MRI synthesis methods are modality-specific, limited in anatomical adaptability, and lack clinical interpretability-failing to meet NPC's RT needs. Here, we developed a unified foundation model integrating contrastive visual representation learning and vision-language alignment (VLA) to enable any-to-all MRI synthesis. The model uses a contrastive encoder for modality-invariant representations and a CLIP-based text-informed decoder for semantically consistent synthesis, supporting any-to-all MRI synthesis via one unified foundation model. Trained on 40,825 images from 13 institutions, it achieves consistently high performance (average SSIM 0.90, PSNR 27) across 26 internal/external validation sites (15,748 images), with superior synthesis fidelity and robustness to noise and domain shifts. Meanwhile, its unified representation enhances downstream RT-relevant tasks (e.g., segmentation). This work advances digital medicine solutions for NPC care by leveraging foundation models to bridge technical synthesis and clinical utility.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08822v1",
        "pdf": "https://arxiv.org/pdf/2602.08822v1"
      },
      "arxiv_id": "2602.08822v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08820v1",
      "title": "Omni-Video 2: Scaling MLLM-Conditioned Diffusion for Unified Video Generation and Editing",
      "authors": [
        "Hao Yang",
        "Zhiyu Tan",
        "Jia Gong",
        "Luozheng Qin",
        "Hesen Chen",
        "Xiaomeng Yang",
        "Yuqing Sun",
        "Yuetan Lin",
        "Mengping Yang",
        "Hao Li"
      ],
      "abstract": "We present Omni-Video 2, a scalable and computationally efficient model that connects pretrained multimodal large-language models (MLLMs) with video diffusion models for unified video generation and editing. Our key idea is to exploit the understanding and reasoning capabilities of MLLMs to produce explicit target captions to interpret user instructions. In this way, the rich contextual representations from the understanding model are directly used to guide the generative process, thereby improving performance on complex and compositional editing. Moreover, a lightweight adapter is developed to inject multimodal conditional tokens into pretrained text-to-video diffusion models, allowing maximum reuse of their powerful generative priors in a parameter-efficient manner. Benefiting from these designs, we scale up Omni-Video 2 to a 14B video diffusion model on meticulously curated training data with quality, supporting high quality text-to-video generation and various video editing tasks such as object removal, addition, background change, complex motion editing, \\emph{etc.} We evaluate the performance of Omni-Video 2 on the FiVE benchmark for fine-grained video editing and the VBench benchmark for text-to-video generation. The results demonstrate its superior ability to follow complex compositional instructions in video editing, while also achieving competitive or superior quality in video generation tasks.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08820v1",
        "pdf": "https://arxiv.org/pdf/2602.08820v1"
      },
      "arxiv_id": "2602.08820v1",
      "comment": "Technical Report, Project: https://howellyoung-s.github.io/Omni-Video2-project/",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2602.08819v1",
      "title": "Bayesian Preference Learning for Test-Time Steerable Reward Models",
      "authors": [
        "Jiwoo Hong",
        "Shao Tang",
        "Zhipeng Wang"
      ],
      "abstract": "Reward models are central to aligning language models with human preferences via reinforcement learning (RL). As RL is increasingly applied to settings such as verifiable rewards and multi-objective alignment, RMs are expected to encode more complex and multifaceted preference distributions. However, classifier RMs remain static once trained, limiting their adaptability at test time. We propose Variational In-Context Reward Modeling (ICRM), a novel Bayesian reward modeling objective that enables test-time steerability via in-context preference demonstrations. ICRM casts reward modeling as amortized variational inference over a latent preference probability under the Bradley-Terry model using a conjugate Beta prior. We show that ICRM adapt to unseen preference distributions at test time for both single and multi-objective settings. With more in-context demonstrations, ICRM gains 34% accuracy on SafeRLHF and 9% accuracy on RM-Bench in the single-objective setting, while widening the Pareto frontier with a 4% gain in hypervolume on helpfulness and refusal benchmarks. We further study the practical applicability of ICRM for RL training, showing that it can effectively encode verifiable rewards by outperforming a conventional RM in math reasoning. Finally, we provide theoretical guarantees that the variational objective admits a global interior optimum with finite confidence, and we analyze how KL regularization mitigates reward over-optimization.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08819v1",
        "pdf": "https://arxiv.org/pdf/2602.08819v1"
      },
      "arxiv_id": "2602.08819v1",
      "comment": "Preprint",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08818v1",
      "title": "FlexMoRE: A Flexible Mixture of Rank-heterogeneous Experts for Efficient Federatedly-trained Large Language Models",
      "authors": [
        "Annemette Brok Pirchert",
        "Jacob Nielsen",
        "Mogens Henrik From",
        "Lukas Galke Poech",
        "Peter Schneider-Kamp"
      ],
      "abstract": "Recent advances in mixture-of-experts architectures have shown that individual experts models can be trained federatedly, i.e., in isolation from other experts by using a common base model to facilitate coordination. However, we hypothesize that full-sized experts may not be necessary for all domains and that instead low-rank adapters may be sufficient. Here, we introduce FlexMoRE, a Flexible Mixture of Rank-heterogenous Experts, which may be either full-sized experts or adapters of a suitable rank. We systematically investigate the trade-off between expert rank and downstream task performance by evaluating $6$ experts with ranks $2^0$ to $2^{14}$ resulting in experiments covering 150 mixtures (96 with 2 experts, 54 with 7 experts) that are evaluated across $120$ tasks. For our experiments, we build on FlexOlmo and turn its pre-trained experts into low-rank versions. Our regression analysis from expert rank to downstream task performance reveals that the best-performing rank is substantially higher for reasoning-heavy benchmarks than for knowledge-heavy benchmarks. These findings on rank sensitivity come with direct implications for memory efficiency: Using optimal ranks, FlexMoRE yields improved downstream task performance (average score $47.18$) compared to the baseline FlexOlmo-style mixture of full-sized experts (average score $45.46$) at less than one third the parameters ($10.75$B for FlexMoRE vs. $33.27$B for FlexOlmo). All code will be made available.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08818v1",
        "pdf": "https://arxiv.org/pdf/2602.08818v1"
      },
      "arxiv_id": "2602.08818v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08817v1",
      "title": "Kirin: Improving ANN efficiency with SNN Hybridization",
      "authors": [
        "Chenyu Wang",
        "Zhanglu Yan",
        "Zhi Zhou",
        "Xu Chen",
        "Weng-Fai Wong"
      ],
      "abstract": "Artificial neural networks (ANNs), particularly large language models (LLMs), demonstrate powerful inference capabilities but consume substantial energy. Conversely, spiking neural networks (SNNs) exhibit exceptional energy efficiency due to their binary and event-driven characteristics, thus motivating the study of ANN-to-SNN conversion. In this process, quantization plays a pivotal role, mapping LLMs' floating-point parameters to discrete SNN parameters via the temporal dimension of the time window. However, several challenges remain in the conversion process: (i) converting high bit-width quantization values into binary spikes requires longer time windows, increasing system latency; and (ii) the inherent trade-off between the information loss of single-spike schemes and the energy costs of multi-spike ones in SNN. To address these challenges, we propose Kirin, a integer and spike hybrid based SNN to achieve accuracy lossless ANN-to-SNN conversion with time and energy efficiency. Specifically, we first propose a Spike Matrix Hybridization strategy that encoding low bit-width parameters that leading to small time window size into binary spikes while preserving the rest in integer format, thereby reducing the overall latency of SNN execution. Second, we introduce a silence threshold mechanism to regulate the timing of single-spike firing, ensuring the output is mathematically equivalent to the LLM's output and preserves accuracy. Experimental results demonstrate that Kirin, under a W4A4\\&8 quantization setting, achieves near-FP16 accuracy while reducing energy consumption by up to 84.66\\% and shortening time steps by 93.75\\%.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08817v1",
        "pdf": "https://arxiv.org/pdf/2602.08817v1"
      },
      "arxiv_id": "2602.08817v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08816v1",
      "title": "Permissive-Washing in the Open AI Supply Chain: A Large-Scale Audit of License Integrity",
      "authors": [
        "James Jewitt",
        "Gopi Krishnan Rajbahadur",
        "Hao Li",
        "Bram Adams",
        "Ahmed E. Hassan"
      ],
      "abstract": "Permissive licenses like MIT, Apache-2.0, and BSD-3-Clause dominate open-source AI, signaling that artifacts like models, datasets, and code can be freely used, modified, and redistributed. However, these licenses carry mandatory requirements: include the full license text, provide a copyright notice, and preserve upstream attribution, that remain unverified at scale. Failure to meet these conditions can place reuse outside the scope of the license, effectively leaving AI artifacts under default copyright for those uses and exposing downstream users to litigation. We call this phenomenon ``permissive washing'': labeling AI artifacts as free to use, while omitting the legal documentation required to make that label actionable. To assess how widespread permissive washing is in the AI supply chain, we empirically audit 124,278 dataset $\\rightarrow$ model $\\rightarrow$ application supply chains, spanning 3,338 datasets, 6,664 models, and 28,516 applications across Hugging Face and GitHub. We find that an astonishing 96.5\\% of datasets and 95.8\\% of models lack the required license text, only 2.3\\% of datasets and 3.2\\% of models satisfy both license text and copyright requirements, and even when upstream artifacts provide complete licensing evidence, attribution rarely propagates downstream: only 27.59\\% of models preserve compliant dataset notices and only 5.75\\% of applications preserve compliant model notices (with just 6.38\\% preserving any linked upstream notice). Practitioners cannot assume permissive labels confer the rights they claim: license files and notices, not metadata, are the source of legal truth. To support future research, we release our full audit dataset and reproducible pipeline.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "cs.SE"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08816v1",
        "pdf": "https://arxiv.org/pdf/2602.08816v1"
      },
      "arxiv_id": "2602.08816v1",
      "comment": "13 pages, 2 figures, 10 tables",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08815v1",
      "title": "Negative-Aware Diffusion Process for Temporal Knowledge Graph Extrapolation",
      "authors": [
        "Yanglei Gan",
        "Peng He",
        "Yuxiang Cai",
        "Run Lin",
        "Guanyu Zhou",
        "Qiao Liu"
      ],
      "abstract": "Temporal Knowledge Graph (TKG) reasoning seeks to predict future missing facts from historical evidence. While diffusion models (DM) have recently gained attention for their ability to capture complex predictive distributions, two gaps remain: (i) the generative path is conditioned only on positive evidence, overlooking informative negative context, and (ii) training objectives are dominated by cross-entropy ranking, which improves candidate ordering but provides little supervision over the calibration of the denoised embedding. To bridge this gap, we introduce Negative-Aware Diffusion model for TKG Extrapolation (NADEx). Specifically, NADEx encodes subject-centric histories of entities, relations and temporal intervals into sequential embeddings. NADEx perturbs the query object in the forward process and reconstructs it in reverse with a Transformer denoiser conditioned on the temporal-relational context. We further derive a cosine-alignment regularizer derived from batch-wise negative prototypes, which tightens the decision boundary against implausible candidates. Comprehensive experiments on four public TKG benchmarks demonstrate that NADEx delivers state-of-the-art performance.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08815v1",
        "pdf": "https://arxiv.org/pdf/2602.08815v1"
      },
      "arxiv_id": "2602.08815v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08813v1",
      "title": "Robust Policy Optimization to Prevent Catastrophic Forgetting",
      "authors": [
        "Mahdi Sabbaghi",
        "George Pappas",
        "Adel Javanmard",
        "Hamed Hassani"
      ],
      "abstract": "Large language models are commonly trained through multi-stage post-training: first via RLHF, then fine-tuned for other downstream objectives. Yet even small downstream updates can compromise earlier learned behaviors (e.g., safety), exposing a brittleness known as catastrophic forgetting. This suggests standard RLHF objectives do not guarantee robustness to future adaptation. To address it, most prior work designs downstream-time methods to preserve previously learned behaviors. We argue that preventing this requires pre-finetuning robustness: the base policy should avoid brittle high-reward solutions whose reward drops sharply under standard fine-tuning.\n  We propose Fine-tuning Robust Policy Optimization (FRPO), a robust RLHF framework that optimizes reward not only at the current policy, but across a KL-bounded neighborhood of policies reachable by downstream adaptation. The key idea is to ensure reward stability under policy shifts via a max-min formulation. By modifying GRPO, we develop an algorithm with no extra computation, and empirically show it substantially reduces safety degradation across multiple base models and downstream fine-tuning regimes (SFT and RL) while preserving downstream task performance. We further study a math-focused RL setting, demonstrating that FRPO preserves accuracy under subsequent fine-tuning.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08813v1",
        "pdf": "https://arxiv.org/pdf/2602.08813v1"
      },
      "arxiv_id": "2602.08813v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08810v1",
      "title": "$\\texttt{lrnnx}$: A library for Linear RNNs",
      "authors": [
        "Karan Bania",
        "Soham Kalburgi",
        "Manit Tanwar",
        "Dhruthi",
        "Aditya Nagarsekar",
        "Harshvardhan Mestha",
        "Naman Chibber",
        "Raj Deshmukh",
        "Anish Sathyanarayanan",
        "Aarush Rathore",
        "Pratham Chheda"
      ],
      "abstract": "Linear recurrent neural networks (LRNNs) provide a structured approach to sequence modeling that bridges classical linear dynamical systems and modern deep learning, offering both expressive power and theoretical guarantees on stability and trainability. In recent years, multiple LRNN-based architectures have been proposed, each introducing distinct parameterizations, discretization schemes, and implementation constraints. However, existing implementations are fragmented across different software frameworks, often rely on framework-specific optimizations, and in some cases require custom CUDA kernels or lack publicly available code altogether. As a result, using, comparing, or extending LRNNs requires substantial implementation effort. To address this, we introduce $\\texttt{lrnnx}$, a unified software library that implements several modern LRNN architectures under a common interface. The library exposes multiple levels of control, allowing users to work directly with core components or higher-level model abstractions. $\\texttt{lrnnx}$ aims to improve accessibility, reproducibility, and extensibility of LRNN research and applications. We make our code available under a permissive MIT license.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08810v1",
        "pdf": "https://arxiv.org/pdf/2602.08810v1"
      },
      "arxiv_id": "2602.08810v1",
      "comment": "EACL Student Research Workshop 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08809v1",
      "title": "Efficient Deep Learning for Biometrics: Overview, Challenges and Trends in Ear of Frugal AI",
      "authors": [
        "Karim Haroun",
        "Aya Zitouni",
        "Aicha Zenakhri",
        "Meriem Amel Guessoum",
        "Larbi Boubchir"
      ],
      "abstract": "Recent advances in deep learning, whether on discriminative or generative tasks have been beneficial for various applications, among which security and defense. However, their increasing computational demands during training and deployment translates directly into high energy consumption. As a consequence, this induces a heavy carbon footprint which hinders their widespread use and scalability, but also a limitation when deployed on resource-constrained edge devices for real-time use. In this paper, we briefly survey efficient deep learning methods for biometric applications. Specifically, we tackle the challenges one might incur when training and deploying deep learning approaches, and provide a taxonomy of the various efficient deep learning families. Additionally, we discuss complementary metrics for evaluating the efficiency of these models such as memory, computation, latency, throughput, and advocate for universal and reproducible metrics for better comparison. Last, we give future research directions to consider.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08809v1",
        "pdf": "https://arxiv.org/pdf/2602.08809v1"
      },
      "arxiv_id": "2602.08809v1",
      "comment": "8 pages, 2 figures, accepted at the 2025 IEEE SDS conference",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08808v1",
      "title": "How2Everything: Mining the Web for How-To Procedures to Evaluate and Improve LLMs",
      "authors": [
        "Yapei Chang",
        "Kyle Lo",
        "Mohit Iyyer",
        "Luca Soldaini"
      ],
      "abstract": "Generating step-by-step \"how-to\" procedures is a key LLM capability: how-to advice is commonly requested in chatbots, and step-by-step planning is critical for reasoning over complex tasks. Yet, measuring and improving procedural validity at scale on real-world tasks remains challenging and understudied. To address this, we introduce How2Everything, a scalable framework to evaluate and improve goal-conditioned procedure generation. Our framework includes How2Mine, which mines 351K procedures from 980K web pages across 14 topics and readily scales to larger corpora. From this pool we build How2Bench, a 7K-example evaluation set balanced across topics. To reliably score model outputs, we develop How2Score, an evaluation protocol that uses an LLM judge to detect whether a generation contains any critical failure that would prevent achieving the goal. For low-cost, reproducible evaluation, we distill a frontier model into an open 8B model, achieving 80.5% agreement with human annotators. How2Bench reveals clear scaling trends across model sizes and training stages, providing signal early in pretraining. Finally, RL using How2Score as a reward improves performance on How2Bench by >10 points across three models without systematic regressions on standard benchmarks, with gains robust to superficial source-document memorization or format compliance. Taken together, How2Everything shows how pretraining web data can support a closed loop of capability evaluation and improvement at scale.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08808v1",
        "pdf": "https://arxiv.org/pdf/2602.08808v1"
      },
      "arxiv_id": "2602.08808v1",
      "comment": "53 pages, 22 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08804v1",
      "title": "Root Cause Analysis Method Based on Large Language Models with Residual Connection Structures",
      "authors": [
        "Liming Zhou",
        "Ailing Liu",
        "Hongwei Liu",
        "Min He",
        "Heng Zhang"
      ],
      "abstract": "Root cause localization remain challenging in complex and large-scale microservice architectures. The complex fault propagation among microservices and the high dimensionality of telemetry data, including metrics, logs, and traces, limit the effectiveness of existing root cause analysis (RCA) methods. In this paper, a residual-connection-based RCA method using large language model (LLM), named RC-LLM, is proposed. A residual-like hierarchical fusion structure is designed to integrate multi-source telemetry data, while the contextual reasoning capability of large language models is leveraged to model temporal and cross-microservice causal dependencies. Experimental results on CCF-AIOps microservice datasets demonstrate that RC-LLM achieves strong accuracy and efficiency in root cause analysis.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08804v1",
        "pdf": "https://arxiv.org/pdf/2602.08804v1"
      },
      "arxiv_id": "2602.08804v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08797v1",
      "title": "Addressing data annotation scarcity in Brain Tumor Segmentation on 3D MRI scan Using a Semi-Supervised Teacher-Student Framework",
      "authors": [
        "Jiaming Liu",
        "Cheng Ding",
        "Daoqiang Zhang"
      ],
      "abstract": "Accurate brain tumor segmentation from MRI is limited by expensive annotations and data heterogeneity across scanners and sites. We propose a semi-supervised teacher-student framework that combines an uncertainty-aware pseudo-labeling teacher with a progressive, confidence-based curriculum for the student. The teacher produces probabilistic masks and per-pixel uncertainty; unlabeled scans are ranked by image-level confidence and introduced in stages, while a dual-loss objective trains the student to learn from high-confidence regions and unlearn low-confidence ones. Agreement-based refinement further improves pseudo-label quality. On BraTS 2021, validation DSC increased from 0.393 (10% data) to 0.872 (100%), with the largest gains in early stages, demonstrating data efficiency. The teacher reached a validation DSC of 0.922, and the student surpassed the teacher on tumor subregions (e.g., NCR/NET 0.797 and Edema 0.980); notably, the student recovered the Enhancing class (DSC 0.620) where the teacher failed. These results show that confidence-driven curricula and selective unlearning provide robust segmentation under limited supervision and noisy pseudo-labels.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08797v1",
        "pdf": "https://arxiv.org/pdf/2602.08797v1"
      },
      "arxiv_id": "2602.08797v1",
      "comment": "10 pages, 7 figures. Submitted to IEEE Journal of Biomedical and Health Informatics (JBHI)",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08796v1",
      "title": "The Use of AI Tools to Develop and Validate Q-Matrices",
      "authors": [
        "Kevin Fan",
        "Jacquelyn A. Bialo",
        "Hongli Li"
      ],
      "abstract": "Constructing a Q-matrix is a critical but labor-intensive step in cognitive diagnostic modeling (CDM). This study investigates whether AI tools (i.e., general language models) can support Q-matrix development by comparing AI-generated Q-matrices with a validated Q-matrix from Li and Suen (2013) for a reading comprehension test. In May 2025, multiple AI models were provided with the same training materials as human experts. Agreement among AI-generated Q-matrices, the validated Q-matrix, and human raters' Q-matrices was assessed using Cohen's kappa. Results showed substantial variation across AI models, with Google Gemini 2.5 Pro achieving the highest agreement (Kappa = 0.63) with the validated Q-matrix, exceeding that of all human experts. A follow-up analysis in January 2026 using newer AI versions, however, revealed lower agreement with the validated Q-matrix. Implications and directions for future research are discussed.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08796v1",
        "pdf": "https://arxiv.org/pdf/2602.08796v1"
      },
      "arxiv_id": "2602.08796v1",
      "comment": "An earlier version of this study was presented at the Psychometric Society Meeting held in July 2025 in Minneapolis, USA",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08794v1",
      "title": "MOVA: Towards Scalable and Synchronized Video-Audio Generation",
      "authors": [
        "SII-OpenMOSS Team",
        ":",
        "Donghua Yu",
        "Mingshu Chen",
        "Qi Chen",
        "Qi Luo",
        "Qianyi Wu",
        "Qinyuan Cheng",
        "Ruixiao Li",
        "Tianyi Liang",
        "Wenbo Zhang",
        "Wenming Tu",
        "Xiangyu Peng",
        "Yang Gao",
        "Yanru Huo",
        "Ying Zhu",
        "Yinze Luo",
        "Yiyang Zhang",
        "Yuerong Song",
        "Zhe Xu",
        "Zhiyu Zhang",
        "Chenchen Yang",
        "Cheng Chang",
        "Chushu Zhou",
        "Hanfu Chen",
        "Hongnan Ma",
        "Jiaxi Li",
        "Jingqi Tong",
        "Junxi Liu",
        "Ke Chen",
        "Shimin Li",
        "Songlin Wang",
        "Wei Jiang",
        "Zhaoye Fei",
        "Zhiyuan Ning",
        "Chunguo Li",
        "Chenhui Li",
        "Ziwei He",
        "Zengfeng Huang",
        "Xie Chen",
        "Xipeng Qiu"
      ],
      "abstract": "Audio is indispensable for real-world video, yet generation models have largely overlooked audio components. Current approaches to producing audio-visual content often rely on cascaded pipelines, which increase cost, accumulate errors, and degrade overall quality. While systems such as Veo 3 and Sora 2 emphasize the value of simultaneous generation, joint multimodal modeling introduces unique challenges in architecture, data, and training. Moreover, the closed-source nature of existing systems limits progress in the field. In this work, we introduce MOVA (MOSS Video and Audio), an open-source model capable of generating high-quality, synchronized audio-visual content, including realistic lip-synced speech, environment-aware sound effects, and content-aligned music. MOVA employs a Mixture-of-Experts (MoE) architecture, with a total of 32B parameters, of which 18B are active during inference. It supports IT2VA (Image-Text to Video-Audio) generation task. By releasing the model weights and code, we aim to advance research and foster a vibrant community of creators. The released codebase features comprehensive support for efficient inference, LoRA fine-tuning, and prompt enhancement.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.CV",
        "cs.SD"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08794v1",
        "pdf": "https://arxiv.org/pdf/2602.08794v1"
      },
      "arxiv_id": "2602.08794v1",
      "comment": "Technical report for MOVA (open-source video-audio generation model). 38 pages, 10 figures, 22 tables. Project page: https://mosi.cn/models/mova Code: https://github.com/OpenMOSS/MOVA Models: https://huggingface.co/collections/OpenMOSS-Team/mova. Qinyuan Cheng and Tianyi Liang are project leader. Xie Chen and Xipeng Qiu are corresponding authors",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2602.08792v1",
      "title": "Multimodal Learning for Arcing Detection in Pantograph-Catenary Systems",
      "authors": [
        "Hao Dong",
        "Eleni Chatzi",
        "Olga Fink"
      ],
      "abstract": "The pantograph-catenary interface is essential for ensuring uninterrupted and reliable power delivery in electrified rail systems. However, electrical arcing at this interface poses serious risks, including accelerated wear of contact components, degraded system performance, and potential service disruptions. Detecting arcing events at the pantograph-catenary interface is challenging due to their transient nature, noisy operating environment, data scarcity, and the difficulty of distinguishing arcs from other similar transient phenomena. To address these challenges, we propose a novel multimodal framework that combines high-resolution image data with force measurements to more accurately and robustly detect arcing events. First, we construct two arcing detection datasets comprising synchronized visual and force measurements. One dataset is built from data provided by the Swiss Federal Railways (SBB), and the other is derived from publicly available videos of arcing events in different railway systems and synthetic force data that mimic the characteristics observed in the real dataset. Leveraging these datasets, we propose MultiDeepSAD, an extension of the DeepSAD algorithm for multiple modalities with a new loss formulation. Additionally, we introduce tailored pseudo-anomaly generation techniques specific to each data type, such as synthetic arc-like artifacts in images and simulated force irregularities, to augment training data and improve the discriminative ability of the model. Through extensive experiments and ablation studies, we demonstrate that our framework significantly outperforms baseline approaches, exhibiting enhanced sensitivity to real arcing events even under domain shifts and limited availability of real arcing observations.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08792v1",
        "pdf": "https://arxiv.org/pdf/2602.08792v1"
      },
      "arxiv_id": "2602.08792v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08786v1",
      "title": "Empirically Understanding the Value of Prediction in Allocation",
      "authors": [
        "Unai Fischer-Abaigar",
        "Emily Aiken",
        "Christoph Kern",
        "Juan Carlos Perdomo"
      ],
      "abstract": "Institutions increasingly use prediction to allocate scarce resources. From a design perspective, better predictions compete with other investments, such as expanding capacity or improving treatment quality. Here, the big question is not how to solve a specific allocation problem, but rather which problem to solve. In this work, we develop an empirical toolkit to help planners form principled answers to this question and quantify the bottom-line welfare impact of investments in prediction versus other policy levers such as expanding capacity and improving treatment quality. Applying our framework in two real-world case studies on German employment services and poverty targeting in Ethiopia, we illustrate how decision-makers can reliably derive context-specific conclusions about the relative value of prediction in their allocation problem. We make our software toolkit, rvp, and parts of our data available in order to enable future empirical work in this area.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08786v1",
        "pdf": "https://arxiv.org/pdf/2602.08786v1"
      },
      "arxiv_id": "2602.08786v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08785v1",
      "title": "A Graphop Analysis of Graph Neural Networks on Sparse Graphs: Generalization and Universal Approximation",
      "authors": [
        "Ofek Amran",
        "Tom Gilat",
        "Ron Levie"
      ],
      "abstract": "Generalization and approximation capabilities of message passing graph neural networks (MPNNs) are often studied by defining a compact metric on a space of input graphs under which MPNNs are Hölder continuous. Such analyses are of two varieties: 1) when the metric space includes graphs of unbounded sizes, the theory is only appropriate for dense graphs, and, 2) when studying sparse graphs, the metric space only includes graphs of uniformly bounded size. In this work, we present a unified approach, defining a compact metric on the space of graphs of all sizes, both sparse and dense, under which MPNNs are Hölder continuous. This leads to more powerful universal approximation theorems and generalization bounds than previous works. The theory is based on, and extends, a recent approach to graph limit theory called graphop analysis.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08785v1",
        "pdf": "https://arxiv.org/pdf/2602.08785v1"
      },
      "arxiv_id": "2602.08785v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08783v1",
      "title": "Dynamics Within Latent Chain-of-Thought: An Empirical Study of Causal Structure",
      "authors": [
        "Zirui Li",
        "Xuefeng Bai",
        "Kehai Chen",
        "Yizhi Li",
        "Jian Yang",
        "Chenghua Lin",
        "Min Zhang"
      ],
      "abstract": "Latent or continuous chain-of-thought methods replace explicit textual rationales with a number of internal latent steps, but these intermediate computations are difficult to evaluate beyond correlation-based probes. In this paper, we view latent chain-of-thought as a manipulable causal process in representation space by modeling latent steps as variables in a structural causal model (SCM) and analyzing their effects through step-wise $\\mathrm{do}$-interventions. We study two representative paradigms (i.e., Coconut and CODI) on both mathematical and general reasoning tasks to investigate three key questions: (1) which steps are causally necessary for correctness and when answers become decidable early; (2) how does influence propagate across steps, and how does this structure compare to explicit CoT; and (3) do intermediate trajectories retain competing answer modes, and how does output-level commitment differ from representational commitment across steps. We find that latent-step budgets behave less like homogeneous extra depth and more like staged functionality with non-local routing, and we identify a persistent gap between early output bias and late representational commitment. These results motivate mode-conditional and stability-aware analyses -- and corresponding training/decoding objectives -- as more reliable tools for interpreting and improving latent reasoning systems.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08783v1",
        "pdf": "https://arxiv.org/pdf/2602.08783v1"
      },
      "arxiv_id": "2602.08783v1",
      "comment": "22 pages",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08782v1",
      "title": "Amortising Inference and Meta-Learning Priors in Neural Networks",
      "authors": [
        "Tommy Rochussen",
        "Vincent Fortuin"
      ],
      "abstract": "One of the core facets of Bayesianism is in the updating of prior beliefs in light of new evidence$\\text{ -- }$so how can we maintain a Bayesian approach if we have no prior beliefs in the first place? This is one of the central challenges in the field of Bayesian deep learning, where it is not clear how to represent beliefs about a prediction task by prior distributions over model parameters. Bridging the fields of Bayesian deep learning and probabilistic meta-learning, we introduce a way to $\\textit{learn}$ a weights prior from a collection of datasets by introducing a way to perform per-dataset amortised variational inference. The model we develop can be viewed as a neural process whose latent variable is the set of weights of a BNN and whose decoder is the neural network parameterised by a sample of the latent variable itself. This unique model allows us to study the behaviour of Bayesian neural networks under well-specified priors, use Bayesian neural networks as flexible generative models, and perform desirable but previously elusive feats in neural processes such as within-task minibatching or meta-learning under extreme data-starvation.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08782v1",
        "pdf": "https://arxiv.org/pdf/2602.08782v1"
      },
      "arxiv_id": "2602.08782v1",
      "comment": "Accepted at ICLR 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08775v1",
      "title": "VedicTHG: Symbolic Vedic Computation for Low-Resource Talking-Head Generation in Educational Avatars",
      "authors": [
        "Vineet Kumar Rakesh",
        "Ahana Bhattacharjee",
        "Soumya Mazumdar",
        "Tapas Samanta",
        "Hemendra Kumar Pandey",
        "Amitabha Das",
        "Sarbajit Pal"
      ],
      "abstract": "Talking-head avatars are increasingly adopted in educational technology to deliver content with social presence and improved engagement. However, many recent talking-head generation (THG) methods rely on GPU-centric neural rendering, large training sets, or high-capacity diffusion models, which limits deployment in offline or resource-constrained learning environments. A deterministic and CPU-oriented THG framework is described, termed Symbolic Vedic Computation, that converts speech to a time-aligned phoneme stream, maps phonemes to a compact viseme inventory, and produces smooth viseme trajectories through symbolic coarticulation inspired by Vedic sutra Urdhva Tiryakbhyam. A lightweight 2D renderer performs region-of-interest (ROI) warping and mouth compositing with stabilization to support real-time synthesis on commodity CPUs. Experiments report synchronization accuracy, temporal stability, and identity consistency under CPU-only execution, alongside benchmarking against representative CPU-feasible baselines. Results indicate that acceptable lip-sync quality can be achieved while substantially reducing computational load and latency, supporting practical educational avatars on low-end hardware. GitHub: https://vineetkumarrakesh.github.io/vedicthg",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.CV",
        "cs.CG"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08775v1",
        "pdf": "https://arxiv.org/pdf/2602.08775v1"
      },
      "arxiv_id": "2602.08775v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.08774v1",
      "title": "Default Machine Learning Hyperparameters Do Not Provide Informative Initialization for Bayesian Optimization",
      "authors": [
        "Nicolás Villagrán Prieto",
        "Eduardo C. Garrido-Merchán"
      ],
      "abstract": "Bayesian Optimization (BO) is a standard tool for hyperparameter tuning thanks to its sample efficiency on expensive black-box functions. While most BO pipelines begin with uniform random initialization, default hyperparameter values shipped with popular ML libraries such as scikit-learn encode implicit expert knowledge and could serve as informative starting points that accelerate convergence. This hypothesis, despite its intuitive appeal, has remained largely unexamined. We formalize the idea by initializing BO with points drawn from truncated Gaussian distributions centered at library defaults and compare the resulting trajectories against a uniform-random baseline. We conduct an extensive empirical evaluation spanning three BO back-ends (BoTorch, Optuna, Scikit-Optimize), three model families (Random Forests, Support Vector Machines, Multilayer Perceptrons), and five benchmark datasets covering classification and regression tasks. Performance is assessed through convergence speed and final predictive quality, and statistical significance is determined via one-sided binomial tests. Across all conditions, default-informed initialization yields no statistically significant advantage over purely random sampling, with p-values ranging from 0.141 to 0.908. A sensitivity analysis on the prior variance confirms that, while tighter concentration around the defaults improves early evaluations, this transient benefit vanishes as optimization progresses, leaving final performance unchanged. Our results provide no evidence that default hyperparameters encode useful directional information for optimization. We therefore recommend that practitioners treat hyperparameter tuning as an integral part of model development and favor principled, data-driven search strategies over heuristic reliance on library defaults.",
      "published": "2026-02-09",
      "updated": "2026-02-09",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.08774v1",
        "pdf": "https://arxiv.org/pdf/2602.08774v1"
      },
      "arxiv_id": "2602.08774v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    }
  ]
}