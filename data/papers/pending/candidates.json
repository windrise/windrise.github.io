{
  "fetched_at": "2025-12-05T00:26:55.915330",
  "total_papers": 100,
  "papers": [
    {
      "id": "2512.04085v1",
      "title": "Unique Lives, Shared World: Learning from Single-Life Videos",
      "authors": [
        "Tengda Han",
        "Sayna Ebrahimi",
        "Dilara Gokay",
        "Li Yang Ku",
        "Maks Ovsjanikov",
        "Iva Babukova",
        "Daniel Zoran",
        "Viorica Patraucean",
        "Joao Carreira",
        "Andrew Zisserman",
        "Dima Damen"
      ],
      "abstract": "We introduce the \"single-life\" learning paradigm, where we train a distinct vision model exclusively on egocentric videos captured by one individual. We leverage the multiple viewpoints naturally captured within a single life to learn a visual encoder in a self-supervised manner. Our experiments demonstrate three key findings. First, models trained independently on different lives develop a highly aligned geometric understanding. We demonstrate this by training visual encoders on distinct datasets each capturing a different life, both indoors and outdoors, as well as introducing a novel cross-attention-based metric to quantify the functional alignment of the internal representations developed by different models. Second, we show that single-life models learn generalizable geometric representations that effectively transfer to downstream tasks, such as depth estimation, in unseen environments. Third, we demonstrate that training on up to 30 hours from one week of the same person's life leads to comparable performance to training on 30 hours of diverse web data, highlighting the strength of single-life representation learning. Overall, our results establish that the shared structure of the world, both leads to consistency in models trained on individual lives, and provides a powerful signal for visual representation learning.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.04085v1",
        "pdf": "https://arxiv.org/pdf/2512.04085v1"
      },
      "arxiv_id": "2512.04085v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.04084v1",
      "title": "SimFlow: Simplified and End-to-End Training of Latent Normalizing Flows",
      "authors": [
        "Qinyu Zhao",
        "Guangting Zheng",
        "Tao Yang",
        "Rui Zhu",
        "Xingjian Leng",
        "Stephen Gould",
        "Liang Zheng"
      ],
      "abstract": "Normalizing Flows (NFs) learn invertible mappings between the data and a Gaussian distribution. Prior works usually suffer from two limitations. First, they add random noise to training samples or VAE latents as data augmentation, introducing complex pipelines including extra noising and denoising steps. Second, they use a pretrained and frozen VAE encoder, resulting in suboptimal reconstruction and generation quality. In this paper, we find that the two issues can be solved in a very simple way: just fixing the variance (which would otherwise be predicted by the VAE encoder) to a constant (e.g., 0.5). On the one hand, this method allows the encoder to output a broader distribution of tokens and the decoder to learn to reconstruct clean images from the augmented token distribution, avoiding additional noise or denoising design. On the other hand, fixed variance simplifies the VAE evidence lower bound, making it stable to train an NF with a VAE jointly. On the ImageNet $256 \\times 256$ generation task, our model SimFlow obtains a gFID score of 2.15, outperforming the state-of-the-art method STARFlow (gFID 2.40). Moreover, SimFlow can be seamlessly integrated with the end-to-end representation alignment (REPA-E) method and achieves an improved gFID of 1.91, setting a new state of the art among NFs.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.04084v1",
        "pdf": "https://arxiv.org/pdf/2512.04084v1"
      },
      "arxiv_id": "2512.04084v1",
      "comment": "Project Page: https://qinyu-allen-zhao.github.io/SimFlow/",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2512.04082v1",
      "title": "PosterCopilot: Toward Layout Reasoning and Controllable Editing for Professional Graphic Design",
      "authors": [
        "Jiazhe Wei",
        "Ken Li",
        "Tianyu Lao",
        "Haofan Wang",
        "Liang Wang",
        "Caifeng Shan",
        "Chenyang Si"
      ],
      "abstract": "Graphic design forms the cornerstone of modern visual communication, serving as a vital medium for promoting cultural and commercial events. Recent advances have explored automating this process using Large Multimodal Models (LMMs), yet existing methods often produce geometrically inaccurate layouts and lack the iterative, layer-specific editing required in professional workflows. To address these limitations, we present PosterCopilot, a framework that advances layout reasoning and controllable editing for professional graphic design. Specifically, we introduce a progressive three-stage training strategy that equips LMMs with geometric understanding and aesthetic reasoning for layout design, consisting of Perturbed Supervised Fine-Tuning, Reinforcement Learning for Visual-Reality Alignment, and Reinforcement Learning from Aesthetic Feedback. Furthermore, we develop a complete workflow that couples the trained LMM-based design model with generative models, enabling layer-controllable, iterative editing for precise element refinement while maintaining global visual consistency. Extensive experiments demonstrate that PosterCopilot achieves geometrically accurate and aesthetically superior layouts, offering unprecedented controllability for professional iterative design.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.04082v1",
        "pdf": "https://arxiv.org/pdf/2512.04082v1"
      },
      "arxiv_id": "2512.04082v1",
      "comment": "Project page: https://postercopilot.github.io/",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2512.04076v1",
      "title": "Radiance Meshes for Volumetric Reconstruction",
      "authors": [
        "Alexander Mai",
        "Trevor Hedstrom",
        "George Kopanas",
        "Janne Kontkanen",
        "Falko Kuester",
        "Jonathan T. Barron"
      ],
      "abstract": "We introduce radiance meshes, a technique for representing radiance fields with constant density tetrahedral cells produced with a Delaunay tetrahedralization. Unlike a Voronoi diagram, a Delaunay tetrahedralization yields simple triangles that are natively supported by existing hardware. As such, our model is able to perform exact and fast volume rendering using both rasterization and ray-tracing. We introduce a new rasterization method that achieves faster rendering speeds than all prior radiance field representations (assuming an equivalent number of primitives and resolution) across a variety of platforms. Optimizing the positions of Delaunay vertices introduces topological discontinuities (edge flips). To solve this, we use a Zip-NeRF-style backbone which allows us to express a smoothly varying field even when the topology changes. Our rendering method exactly evaluates the volume rendering equation and enables high quality, real-time view synthesis on standard consumer hardware. Our tetrahedral meshes also lend themselves to a variety of exciting applications including fisheye lens distortion, physics-based simulation, editing, and mesh extraction.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.GR",
        "cs.CV"
      ],
      "primary_category": "cs.GR",
      "links": {
        "paper": "http://arxiv.org/abs/2512.04076v1",
        "pdf": "https://arxiv.org/pdf/2512.04076v1"
      },
      "arxiv_id": "2512.04076v1",
      "comment": "Website: half-potato.gitlab.io/rm",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.04072v1",
      "title": "SkillFactory: Self-Distillation For Learning Cognitive Behaviors",
      "authors": [
        "Zayne Sprague",
        "Jack Lu",
        "Manya Wadhwa",
        "Sedrick Keh",
        "Mengye Ren",
        "Greg Durrett"
      ],
      "abstract": "Reasoning models leveraging long chains of thought employ various cognitive skills, such as verification of their answers, backtracking, retrying by an alternate method, and more. Previous work has shown that when a base language model exhibits these skills, training that model further with reinforcement learning (RL) can learn to leverage them. How can we get models to leverage skills that aren't exhibited by base models? Our work, SkillFactory, is a method for fine-tuning models to roughly learn these skills during a supervised fine-tuning (SFT) stage prior to RL. Our approach does not rely on distillation from a stronger model, but instead uses samples from the model itself, rearranged to provide training data in the format of those skills. These \"silver\" SFT traces may be imperfect, but are nevertheless effective for priming a model to acquire skills during RL. Our evaluation shows that (1) starting from SkillFactory SFT initialization helps a model to generalize to harder variants of a task post-RL, despite lower performance pre-RL; (2) cognitive skills are indeed used by the model; (3) RLed SkillFactory models are more robust to regression on out-of-domain tasks than RLed base models. Our work suggests that inductive biases learned prior to RL help models learn robust cognitive skill use.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2512.04072v1",
        "pdf": "https://arxiv.org/pdf/2512.04072v1"
      },
      "arxiv_id": "2512.04072v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.04069v1",
      "title": "SpaceTools: Tool-Augmented Spatial Reasoning via Double Interactive RL",
      "authors": [
        "Siyi Chen",
        "Mikaela Angelina Uy",
        "Chan Hee Song",
        "Faisal Ladhak",
        "Adithyavairavan Murali",
        "Qing Qu",
        "Stan Birchfield",
        "Valts Blukis",
        "Jonathan Tremblay"
      ],
      "abstract": "Vision Language Models (VLMs) demonstrate strong qualitative visual understanding, but struggle with metrically precise spatial reasoning required for embodied applications. The agentic paradigm promises that VLMs can use a wide variety of tools that could augment these capabilities, such as depth estimators, segmentation models, and pose estimators. Yet it remains an open challenge how to realize this vision without solely relying on handcrafted prompting strategies or enforcing fixed, predefined tool pipelines that limit VLMs' ability to discover optimal tool-use patterns. Reinforcement Learning could overcome this gap, but has so far been limited to reasoning with a single visual tool due to the large search space in multi-tool reasoning. We introduce Double Interactive Reinforcement Learning (DIRL), a two-phase training framework where VLMs learn to coordinate multiple tools through interactive exploration and feedback. In the teaching phase, we combine demonstrations from a single tool specialist trained via interactive RL with traces from a frontier model using all tools. In the exploration phase, the model further refines multi-tool coordination through continued RL. Our model, SpaceTools, with tool-augmented spatial reasoning ability, achieves state-of-the-art performance on spatial understanding benchmarks (RoboSpatial-Home, BLINK, BOP-ASK) and demonstrates reliable real-world manipulation using a 7-DOF robot as a tool. DIRL provides substantial improvements over the vanilla SFT (+12% on RoboSpatial) and RL (+16% on RoboSpatial) baselines. Project page: https://spacetools.github.io/.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.04069v1",
        "pdf": "https://arxiv.org/pdf/2512.04069v1"
      },
      "arxiv_id": "2512.04069v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.04068v1",
      "title": "Learning Steerable Clarification Policies with Collaborative Self-play",
      "authors": [
        "Jonathan Berant",
        "Maximillian Chen",
        "Adam Fisch",
        "Reza Aghajani",
        "Fantine Huot",
        "Mirella Lapata",
        "Jacob Eisenstein"
      ],
      "abstract": "To handle underspecified or ambiguous queries, AI assistants need a policy for managing their uncertainty to determine (a) when to guess the user intent and answer directly, (b) when to enumerate and answer multiple possible intents, and (c) when to ask a clarifying question. However, such policies are contextually dependent on factors such as user preferences or modality. For example, enumerating multiple possible user intentions is cumbersome on small screens or in a voice setting. In this work, we propose to train steerable policies for managing this uncertainty using self-play. Given two agents, one simulating a user and the other an AI assistant, we generate conversations where the user issues a potentially ambiguous query, and the assistant needs to determine how to respond. Importantly, the model takes as input the numerical cost of each clarification question, and each generated word, and is asked to take the action that will maximize its final reward, which is the cost-penalized accuracy. We use Reinforced Self-Training (ReST) to train our model to achieve high reward and show this leads to a steerable policy that changes its behavior predictably conditioned on the provided costs, leading to higher reward and accuracy. Moreover, our procedure also generalizes to numerical cost values that were unobserved at training time.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.04068v1",
        "pdf": "https://arxiv.org/pdf/2512.04068v1"
      },
      "arxiv_id": "2512.04068v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.04065v1",
      "title": "Fare Comparison App of Uber, Ola and Rapido",
      "authors": [
        "Ashlesha Gopinath Sawant",
        "Sahil S. Jadhav",
        "Vidhan R. Jain",
        "Shriraj S. Jagtap",
        "Prachi Jadhav",
        "Soham Jadhav",
        "Ichha Raina"
      ],
      "abstract": "In todays increasing world, it is very important to have good hailing services like Ola, Uber, and Rapido as it is very essential for our daily transportation. Users often face difficulties in choosing the most appropriate and efficient ride that would lead to both cost-effective and would take us to our destination in less time. This project provides you with the web application that helps you to select the most beneficial ride for you by providing users with the fare comparison between Ola, Uber, Rapido for the destination entered by the user. The backend is use to fetch the data, providing users with the fare comparison for the ride and finally providing with the best option using Python. This research paper also addresses the problem and challenges faced in accessing the data using APIs, Android Studios emulator, Appium and location comparison. Thus, the aim of the project is to provide transparency to the users in ride-hailing services and increase efficiency and provide users with better experience.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.04065v1",
        "pdf": "https://arxiv.org/pdf/2512.04065v1"
      },
      "arxiv_id": "2512.04065v1",
      "comment": "4 pages",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.04062v1",
      "title": "Eval Factsheets: A Structured Framework for Documenting AI Evaluations",
      "authors": [
        "Florian Bordes",
        "Candace Ross",
        "Justine T Kao",
        "Evangelia Spiliopoulou",
        "Adina Williams"
      ],
      "abstract": "The rapid proliferation of benchmarks has created significant challenges in reproducibility, transparency, and informed decision-making. However, unlike datasets and models -- which benefit from structured documentation frameworks like Datasheets and Model Cards -- evaluation methodologies lack systematic documentation standards. We introduce Eval Factsheets, a structured, descriptive framework for documenting AI system evaluations through a comprehensive taxonomy and questionnaire-based approach. Our framework organizes evaluation characteristics across five fundamental dimensions: Context (Who made the evaluation and when?), Scope (What does it evaluate?), Structure (With what the evaluation is built?), Method (How does it work?) and Alignment (In what ways is it reliable/valid/robust?). We implement this taxonomy as a practical questionnaire spanning five sections with mandatory and recommended documentation elements. Through case studies on multiple benchmarks, we demonstrate that Eval Factsheets effectively captures diverse evaluation paradigms -- from traditional benchmarks to LLM-as-judge methodologies -- while maintaining consistency and comparability. We hope Eval Factsheets are incorporated into both existing and newly released evaluation frameworks and lead to more transparency and reproducibility.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.04062v1",
        "pdf": "https://arxiv.org/pdf/2512.04062v1"
      },
      "arxiv_id": "2512.04062v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.04058v1",
      "title": "Closing the problem of which causal structures of up to six total nodes have a classical-quantum gap",
      "authors": [
        "Shashaank Khanna",
        "Matthew Pusey",
        "Roger Colbeck"
      ],
      "abstract": "The discovery of Bell that there exist quantum correlations that cannot be reproduced classically is one of the most important in the foundations of quantum mechanics, as well as having practical implications. Bell's result was originally proven in a simple bipartite causal structure, but analogous results have also been shown in further causal structures. Here we study the only causal structure with six or fewer nodes in which the question of whether or not there exist quantum correlations that cannot be achieved classically was open. In this causal structure we show that such quantum correlations exist using a method that involves imposing additional restrictions on the correlations. This hence completes the picture of which causal structures of up to six nodes support non-classical quantum correlations. We also provide further illustrations of our method using other causal structures.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "quant-ph",
        "cs.LG",
        "math.ST"
      ],
      "primary_category": "quant-ph",
      "links": {
        "paper": "http://arxiv.org/abs/2512.04058v1",
        "pdf": "https://arxiv.org/pdf/2512.04058v1"
      },
      "arxiv_id": "2512.04058v1",
      "comment": "5 pages, 3 figures, 1 table",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.04051v1",
      "title": "Convergence for Discrete Parameter Updates",
      "authors": [
        "Paul Wilson",
        "Fabio Zanasi",
        "George Constantinides"
      ],
      "abstract": "Modern deep learning models require immense computational resources, motivating research into low-precision training. Quantised training addresses this by representing training components in low-bit integers, but typically relies on discretising real-valued updates. We introduce an alternative approach where the update rule itself is discrete, avoiding the quantisation of continuous updates by design. We establish convergence guarantees for a general class of such discrete schemes, and present a multinomial update rule as a concrete example, supported by empirical evaluation. This perspective opens new avenues for efficient training, particularly for models with inherently discrete structure.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.LG",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.04051v1",
        "pdf": "https://arxiv.org/pdf/2512.04051v1"
      },
      "arxiv_id": "2512.04051v1",
      "comment": "opt-ml 2025 workshop at NeurIPS",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.04048v1",
      "title": "Stable Signer: Hierarchical Sign Language Generative Model",
      "authors": [
        "Sen Fang",
        "Yalin Feng",
        "Hongbin Zhong",
        "Yanxin Zhang",
        "Dimitris N. Metaxas"
      ],
      "abstract": "Sign Language Production (SLP) is the process of converting the complex input text into a real video. Most previous works focused on the Text2Gloss, Gloss2Pose, Pose2Vid stages, and some concentrated on Prompt2Gloss and Text2Avatar stages. However, this field has made slow progress due to the inaccuracy of text conversion, pose generation, and the rendering of poses into real human videos in these stages, resulting in gradually accumulating errors. Therefore, in this paper, we streamline the traditional redundant structure, simplify and optimize the task objective, and design a new sign language generative model called Stable Signer. It redefines the SLP task as a hierarchical generation end-to-end task that only includes text understanding (Prompt2Gloss, Text2Gloss) and Pose2Vid, and executes text understanding through our proposed new Sign Language Understanding Linker called SLUL, and generates hand gestures through the named SLP-MoE hand gesture rendering expert block to end-to-end generate high-quality and multi-style sign language videos. SLUL is trained using the newly developed Semantic-Aware Gloss Masking Loss (SAGM Loss). Its performance has improved by 48.6% compared to the current SOTA generation methods.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CV",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.04048v1",
        "pdf": "https://arxiv.org/pdf/2512.04048v1"
      },
      "arxiv_id": "2512.04048v1",
      "comment": "12 pages, 7 figures. More Demo at https://stablesigner.github.io",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2512.04047v1",
      "title": "Polarization by Design: How Elites Could Shape Mass Preferences as AI Reduces Persuasion Costs",
      "authors": [
        "Nadav Kunievsky"
      ],
      "abstract": "In democracies, major policy decisions typically require some form of majority or consensus, so elites must secure mass support to govern. Historically, elites could shape support only through limited instruments like schooling and mass media; advances in AI-driven persuasion sharply reduce the cost and increase the precision of shaping public opinion, making the distribution of preferences itself an object of deliberate design. We develop a dynamic model in which elites choose how much to reshape the distribution of policy preferences, subject to persuasion costs and a majority rule constraint. With a single elite, any optimal intervention tends to push society toward more polarized opinion profiles - a ``polarization pull'' - and improvements in persuasion technology accelerate this drift. When two opposed elites alternate in power, the same technology also creates incentives to park society in ``semi-lock'' regions where opinions are more cohesive and harder for a rival to overturn, so advances in persuasion can either heighten or dampen polarization depending on the environment. Taken together, cheaper persuasion technologies recast polarization as a strategic instrument of governance rather than a purely emergent social byproduct, with important implications for democratic stability as AI capabilities advance.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "econ.GN",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "econ.GN",
      "links": {
        "paper": "http://arxiv.org/abs/2512.04047v1",
        "pdf": "https://arxiv.org/pdf/2512.04047v1"
      },
      "arxiv_id": "2512.04047v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.04044v1",
      "title": "MarkTune: Improving the Quality-Detectability Trade-off in Open-Weight LLM Watermarking",
      "authors": [
        "Yizhou Zhao",
        "Zhiwei Steven Wu",
        "Adam Block"
      ],
      "abstract": "Watermarking aims to embed hidden signals in generated text that can be reliably detected when given access to a secret key. Open-weight language models pose acute challenges for such watermarking schemes because the inference-time interventions that dominate contemporary approaches cannot be enforced once model weights are public. Existing watermaking techniques for open-weight models, such as the recently proposed GaussMark, typically rely on small modifications to model weights, which can yield signals detectable to those equipped with a secret key, but achieving detection power comparable to inference-time watermarks generally requires weight perturbations that noticeably reduce generation quality. We introduce MarkTune, a theoretically principled, on-policy fine-tuning framework that treats the GaussMark signal as a reward while simultaneously regularizing against degradation in text quality. We derive MarkTune as an improvement on GaussMark and demonstrate that MarkTune consistently improves the quality-detectability trade-off over GaussMark by steering finer-grained, watermark-aware weight updates within the model's representation space while preserving generation quality. Empirically, we show that MarkTune pushes the quality-detectability frontier of GaussMark close to that of inference-time watermarking, remains robust to paraphrasing and fine-tuning attacks, and exhibits strong generalization: a model fine-tuned on one dataset retains substantial watermark detection power on unseen datasets. Together, these results establish MarkTune as a general strategy for embedding robust, high-quality watermarks into open-weight LMs.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.04044v1",
        "pdf": "https://arxiv.org/pdf/2512.04044v1"
      },
      "arxiv_id": "2512.04044v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.04040v1",
      "title": "RELIC: Interactive Video World Model with Long-Horizon Memory",
      "authors": [
        "Yicong Hong",
        "Yiqun Mei",
        "Chongjian Ge",
        "Yiran Xu",
        "Yang Zhou",
        "Sai Bi",
        "Yannick Hold-Geoffroy",
        "Mike Roberts",
        "Matthew Fisher",
        "Eli Shechtman",
        "Kalyan Sunkavalli",
        "Feng Liu",
        "Zhengqi Li",
        "Hao Tan"
      ],
      "abstract": "A truly interactive world model requires three key ingredients: real-time long-horizon streaming, consistent spatial memory, and precise user control. However, most existing approaches address only one of these aspects in isolation, as achieving all three simultaneously is highly challenging-for example, long-term memory mechanisms often degrade real-time performance. In this work, we present RELIC, a unified framework that tackles these three challenges altogether. Given a single image and a text description, RELIC enables memory-aware, long-duration exploration of arbitrary scenes in real time. Built upon recent autoregressive video-diffusion distillation techniques, our model represents long-horizon memory using highly compressed historical latent tokens encoded with both relative actions and absolute camera poses within the KV cache. This compact, camera-aware memory structure supports implicit 3D-consistent content retrieval and enforces long-term coherence with minimal computational overhead. In parallel, we fine-tune a bidirectional teacher video model to generate sequences beyond its original 5-second training horizon, and transform it into a causal student generator using a new memory-efficient self-forcing paradigm that enables full-context distillation over long-duration teacher as well as long student self-rollouts. Implemented as a 14B-parameter model and trained on a curated Unreal Engine-rendered dataset, RELIC achieves real-time generation at 16 FPS while demonstrating more accurate action following, more stable long-horizon streaming, and more robust spatial-memory retrieval compared with prior work. These capabilities establish RELIC as a strong foundation for the next generation of interactive world modeling.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.04040v1",
        "pdf": "https://arxiv.org/pdf/2512.04040v1"
      },
      "arxiv_id": "2512.04040v1",
      "comment": "22 pages",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.04039v1",
      "title": "Fast & Efficient Normalizing Flows and Applications of Image Generative Models",
      "authors": [
        "Sandeep Nagar"
      ],
      "abstract": "This thesis presents novel contributions in two primary areas: advancing the efficiency of generative models, particularly normalizing flows, and applying generative models to solve real-world computer vision challenges. The first part introduce significant improvements to normalizing flow architectures through six key innovations: 1) Development of invertible 3x3 Convolution layers with mathematically proven necessary and sufficient conditions for invertibility, (2) introduction of a more efficient Quad-coupling layer, 3) Design of a fast and efficient parallel inversion algorithm for kxk convolutional layers, 4) Fast & efficient backpropagation algorithm for inverse of convolution, 5) Using inverse of convolution, in Inverse-Flow, for the forward pass and training it using proposed backpropagation algorithm, and 6) Affine-StableSR, a compact and efficient super-resolution model that leverages pre-trained weights and Normalizing Flow layers to reduce parameter count while maintaining performance.\n  The second part: 1) An automated quality assessment system for agricultural produce using Conditional GANs to address class imbalance, data scarcity and annotation challenges, achieving good accuracy in seed purity testing; 2) An unsupervised geological mapping framework utilizing stacked autoencoders for dimensionality reduction, showing improved feature extraction compared to conventional methods; 3) We proposed a privacy preserving method for autonomous driving datasets using on face detection and image inpainting; 4) Utilizing Stable Diffusion based image inpainting for replacing the detected face and license plate to advancing privacy-preserving techniques and ethical considerations in the field.; and 5) An adapted diffusion model for art restoration that effectively handles multiple types of degradation through unified fine-tuning.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.04039v1",
        "pdf": "https://arxiv.org/pdf/2512.04039v1"
      },
      "arxiv_id": "2512.04039v1",
      "comment": "PhD Thesis",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.04034v1",
      "title": "Domain Feature Collapse: Implications for Out-of-Distribution Detection and Solutions",
      "authors": [
        "Hong Yang",
        "Devroop Kar",
        "Qi Yu",
        "Alex Ororbia",
        "Travis Desell"
      ],
      "abstract": "Why do state-of-the-art OOD detection methods exhibit catastrophic failure when models are trained on single-domain datasets? We provide the first theoretical explanation for this phenomenon through the lens of information theory. We prove that supervised learning on single-domain data inevitably produces domain feature collapse -- representations where I(x_d; z) = 0, meaning domain-specific information is completely discarded. This is a fundamental consequence of information bottleneck optimization: models trained on single domains (e.g., medical images) learn to rely solely on class-specific features while discarding domain features, leading to catastrophic failure when detecting out-of-domain samples (e.g., achieving only 53% FPR@95 on MNIST). We extend our analysis using Fano's inequality to quantify partial collapse in practical scenarios. To validate our theory, we introduce Domain Bench, a benchmark of single-domain datasets, and demonstrate that preserving I(x_d; z) > 0 through domain filtering (using pretrained representations) resolves the failure mode. While domain filtering itself is conceptually straightforward, its effectiveness provides strong empirical evidence for our information-theoretic framework. Our work explains a puzzling empirical phenomenon, reveals fundamental limitations of supervised learning in narrow domains, and has broader implications for transfer learning and when to fine-tune versus freeze pretrained models.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.04034v1",
        "pdf": "https://arxiv.org/pdf/2512.04034v1"
      },
      "arxiv_id": "2512.04034v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.04032v1",
      "title": "Jina-VLM: Small Multilingual Vision Language Model",
      "authors": [
        "Andreas Koukounas",
        "Georgios Mastrapas",
        "Florian HÃ¶nicke",
        "Sedigheh Eslami",
        "Guillaume Roncari",
        "Scott Martens",
        "Han Xiao"
      ],
      "abstract": "We present Jina-VLM, a 2.4B parameter vision-language model that achieves state-of-the-art multilingual visual question answering among open 2B-scale VLMs. The model couples a SigLIP2 vision encoder with a Qwen3 language backbone through an attention-pooling connector that enables token-efficient processing of arbitrary-resolution images. Across standard VQA benchmarks and multilingual evaluations, Jina-VLM outperforms comparable models while preserving competitive text-only performance.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2512.04032v1",
        "pdf": "https://arxiv.org/pdf/2512.04032v1"
      },
      "arxiv_id": "2512.04032v1",
      "comment": "18 pages, 1-7 main content",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.04031v1",
      "title": "Large Language Models for Limited Noisy Data: A Gravitational Wave Identification Study",
      "authors": [
        "Yixuan Li",
        "Yuhao Lu",
        "Yang Liu",
        "Liang Li",
        "R. Ruffini",
        "Di Li",
        "Rong-Gen Cai",
        "Xiaoyan Zhu",
        "Wenbin Lin",
        "Yu Wang"
      ],
      "abstract": "This work investigates whether large language models (LLMs) offer advantages over traditional neural networks for astronomical data processing, in regimes with non-Gaussian, non-stationary noise and limited labeled samples. Gravitational wave observations provide an suitable test case, using only 90 LIGO events, finetuned LLMs achieve 97.4\\% accuracy for identifying signals. Further experiments show that, in contrast to traditional networks that rely on large simulated datasets, additional simulated samples do not improve LLM performance, while scaling studies reveal predictable gains with increasing model size and dataset size. These results indicate that LLMs can extract discriminative structure directly from observational data and provide an efficient assessment for gravitational wave identification. The same strategy may extend to other astronomical domains with similar noise properties, such as radio or pulsar observations.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "astro-ph.IM",
        "astro-ph.HE",
        "cs.AI"
      ],
      "primary_category": "astro-ph.IM",
      "links": {
        "paper": "http://arxiv.org/abs/2512.04031v1",
        "pdf": "https://arxiv.org/pdf/2512.04031v1"
      },
      "arxiv_id": "2512.04031v1",
      "comment": "10 pages, 5 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.04025v1",
      "title": "PSA: Pyramid Sparse Attention for Efficient Video Understanding and Generation",
      "authors": [
        "Xiaolong Li",
        "Youping Gu",
        "Xi Lin",
        "Weijie Wang",
        "Bohan Zhuang"
      ],
      "abstract": "Attention mechanisms are the core of foundation models, but their quadratic complexity remains a critical bottleneck for scaling. This challenge has driven the development of efficient attention mechanisms, with sparsity emerging as the dominant paradigm. Current methods typically retain or discard entire key-value blocks with binary masks, resulting in substantial information loss under high sparsity. To mitigate this gap, we present Pyramid Sparse Attention (PSA), a versatile module applicable to both video understanding and generation tasks. Instead of binary masking, PSA introduces multi-level pooled KV representations, enabling finer mask granularity. Specifically, each query block dynamically allocates lower pooling levels to critical KV blocks and higher levels to less important ones, creating an informative interpolation between full retention and complete pruning. This design, analogous to fixed-point quantization and classical feature pyramid networks in computer vision, effectively mitigates information loss while preserving computational efficiency under a low compute budget. It works with a native, hardware-friendly kernel that leverages decoupled block-tile design to ensure efficient execution. Across video understanding and generation benchmarks, PSA preserves contextual information and visual fidelity, consistently outperforming or achieving comparable performance over existing sparse attention baselines with superior efficiency-quality trade-offs. Our code and model weights are publicly available at: http://ziplab.co/PSA",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.04025v1",
        "pdf": "https://arxiv.org/pdf/2512.04025v1"
      },
      "arxiv_id": "2512.04025v1",
      "comment": "Tech report",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.04021v1",
      "title": "C3G: Learning Compact 3D Representations with 2K Gaussians",
      "authors": [
        "Honggyu An",
        "Jaewoo Jung",
        "Mungyeom Kim",
        "Sunghwan Hong",
        "Chaehyun Kim",
        "Kazumi Fukuda",
        "Minkyeong Jeon",
        "Jisang Han",
        "Takuya Narihira",
        "Hyuna Ko",
        "Junsu Kim",
        "Yuki Mitsufuji",
        "Seungryong Kim"
      ],
      "abstract": "Reconstructing and understanding 3D scenes from unposed sparse views in a feed-forward manner remains as a challenging task in 3D computer vision. Recent approaches use per-pixel 3D Gaussian Splatting for reconstruction, followed by a 2D-to-3D feature lifting stage for scene understanding. However, they generate excessive redundant Gaussians, causing high memory overhead and sub-optimal multi-view feature aggregation, leading to degraded novel view synthesis and scene understanding performance. We propose C3G, a novel feed-forward framework that estimates compact 3D Gaussians only at essential spatial locations, minimizing redundancy while enabling effective feature lifting. We introduce learnable tokens that aggregate multi-view features through self-attention to guide Gaussian generation, ensuring each Gaussian integrates relevant visual features across views. We then exploit the learned attention patterns for Gaussian decoding to efficiently lift features. Extensive experiments on pose-free novel view synthesis, 3D open-vocabulary segmentation, and view-invariant feature aggregation demonstrate our approach's effectiveness. Results show that a compact yet geometrically meaningful representation is sufficient for high-quality scene reconstruction and understanding, achieving superior memory efficiency and feature fidelity compared to existing methods.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.04021v1",
        "pdf": "https://arxiv.org/pdf/2512.04021v1"
      },
      "arxiv_id": "2512.04021v1",
      "comment": "Project Page : https://cvlab-kaist.github.io/C3G/",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2512.04019v1",
      "title": "Ultra-lightweight Neural Video Representation Compression",
      "authors": [
        "Ho Man Kwan",
        "Tianhao Peng",
        "Ge Gao",
        "Fan Zhang",
        "Mike Nilsson",
        "Andrew Gower",
        "David Bull"
      ],
      "abstract": "Recent works have demonstrated the viability of utilizing over-fitted implicit neural representations (INRs) as alternatives to autoencoder-based models for neural video compression. Among these INR-based video codecs, Neural Video Representation Compression (NVRC) was the first to adopt a fully end-to-end compression framework that compresses INRs, achieving state-of-the-art performance. Moreover, some recently proposed lightweight INRs have shown comparable performance to their baseline codecs with computational complexity lower than 10kMACs/pixel. In this work, we extend NVRC toward lightweight representations, and propose NVRC-Lite, which incorporates two key changes. Firstly, we integrated multi-scale feature grids into our lightweight neural representation, and the use of higher resolution grids significantly improves the performance of INRs at low complexity. Secondly, we address the issue that existing INRs typically leverage autoregressive models for entropy coding: these are effective but impractical due to their slow coding speed. In this work, we propose an octree-based context model for entropy coding high-dimensional feature grids, which accelerates the entropy coding module of the model. Our experimental results demonstrate that NVRC-Lite outperforms C3, one of the best lightweight INR-based video codecs, with up to 21.03% and 23.06% BD-rate savings when measured in PSNR and MS-SSIM, respectively, while achieving 8.4x encoding and 2.5x decoding speedup. The implementation of NVRC-Lite will be made available.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CV",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.04019v1",
        "pdf": "https://arxiv.org/pdf/2512.04019v1"
      },
      "arxiv_id": "2512.04019v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.04016v1",
      "title": "TARA Test-by-Adaptive-Ranks for Quantum Anomaly Detection with Conformal Prediction Guarantees",
      "authors": [
        "Davut Emre Tasar",
        "Ceren Ocal Tasar"
      ],
      "abstract": "Quantum key distribution (QKD) security fundamentally relies on the ability to distinguish genuine quantum correlations from classical eavesdropper simulations, yet existing certification methods lack rigorous statistical guarantees under finite-sample conditions and adversarial scenarios. We introduce TARA (Test by Adaptive Ranks), a novel framework combining conformal prediction with sequential martingale testing for quantum anomaly detection that provides distribution-free validity guarantees. TARA offers two complementary approaches. TARA k, based on Kolmogorov Smirnov calibration against local hidden variable (LHV) null distributions, achieving ROC AUC = 0.96 for quantum-classical discrimination. And TARA-m, employing betting martingales for streaming detection with anytime valid type I error control that enables real time monitoring of quantum channels. We establish theoretical guarantees proving that under (context conditional) exchangeability, conformal p-values remain uniformly distributed even for strongly contextual quantum data, confirming that quantum contextuality does not break conformal prediction validity a result with implications beyond quantum certification to any application of distribution-free methods to nonclassical data. Extensive validation on both IBM Torino (superconducting, CHSH = 2.725) and IonQ Forte Enterprise (trapped ion, CHSH = 2.716) quantum processors demonstrates cross-platform robustness, achieving 36% security margins above the classical CHSH bound of 2. Critically, our framework reveals a methodological concern affecting quantum certification more broadly: same-distribution calibration can inflate detection performance by up to 44 percentage points compared to proper cross-distribution calibration, suggesting that prior quantum certification studies using standard train test splits may have systematically overestimated adversarial robustness.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "links": {
        "paper": "http://arxiv.org/abs/2512.04016v1",
        "pdf": "https://arxiv.org/pdf/2512.04016v1"
      },
      "arxiv_id": "2512.04016v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.04015v1",
      "title": "Learning Group Actions In Disentangled Latent Image Representations",
      "authors": [
        "Farhana Hossain Swarnali",
        "Miaomiao Zhang",
        "Tonmoy Hossain"
      ],
      "abstract": "Modeling group actions on latent representations enables controllable transformations of high-dimensional image data. Prior works applying group-theoretic priors or modeling transformations typically operate in the high-dimensional data space, where group actions apply uniformly across the entire input, making it difficult to disentangle the subspace that varies under transformations. While latent-space methods offer greater flexibility, they still require manual partitioning of latent variables into equivariant and invariant subspaces, limiting the ability to robustly learn and operate group actions within the representation space. To address this, we introduce a novel end-to-end framework that for the first time learns group actions on latent image manifolds, automatically discovering transformation-relevant structures without manual intervention. Our method uses learnable binary masks with straight-through estimation to dynamically partition latent representations into transformation-sensitive and invariant components. We formulate this within a unified optimization framework that jointly learns latent disentanglement and group transformation mappings. The framework can be seamlessly integrated with any standard encoder-decoder architecture. We validate our approach on five 2D/3D image datasets, demonstrating its ability to automatically learn disentangled latent factors for group actions in diverse data, while downstream classification tasks confirm the effectiveness of the learned representations. Our code is publicly available at https://github.com/farhanaswarnali/Learning-Group-Actions-In-Disentangled-Latent-Image-Representations .",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.04015v1",
        "pdf": "https://arxiv.org/pdf/2512.04015v1"
      },
      "arxiv_id": "2512.04015v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.04012v1",
      "title": "Emergent Outlier View Rejection in Visual Geometry Grounded Transformers",
      "authors": [
        "Jisang Han",
        "Sunghwan Hong",
        "Jaewoo Jung",
        "Wooseok Jang",
        "Honggyu An",
        "Qianqian Wang",
        "Seungryong Kim",
        "Chen Feng"
      ],
      "abstract": "Reliable 3D reconstruction from in-the-wild image collections is often hindered by \"noisy\" images-irrelevant inputs with little or no view overlap with others. While traditional Structure-from-Motion pipelines handle such cases through geometric verification and outlier rejection, feed-forward 3D reconstruction models lack these explicit mechanisms, leading to degraded performance under in-the-wild conditions. In this paper, we discover that the existing feed-forward reconstruction model, e.g., VGGT, despite lacking explicit outlier-rejection mechanisms or noise-aware training, can inherently distinguish distractor images. Through an in-depth analysis under varying proportions of synthetic distractors, we identify a specific layer that naturally exhibits outlier-suppressing behavior. Further probing reveals that this layer encodes discriminative internal representations that enable an effective noise-filtering capability, which we simply leverage to perform outlier-view rejection in feed-forward 3D reconstruction without any additional fine-tuning or supervision. Extensive experiments on both controlled and in-the-wild datasets demonstrate that this implicit filtering mechanism is consistent and generalizes well across diverse scenarios.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.04012v1",
        "pdf": "https://arxiv.org/pdf/2512.04012v1"
      },
      "arxiv_id": "2512.04012v1",
      "comment": "Project page: https://cvlab-kaist.github.io/RobustVGGT/",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2512.04008v1",
      "title": "Efficient Public Verification of Private ML via Regularization",
      "authors": [
        "ZoÃ« Ruha Bell",
        "Anvith Thudi",
        "Olive Franzese-McLaughlin",
        "Nicolas Papernot",
        "Shafi Goldwasser"
      ],
      "abstract": "Training with differential privacy (DP) provides a guarantee to members in a dataset that they cannot be identified by users of the released model. However, those data providers, and, in general, the public, lack methods to efficiently verify that models trained on their data satisfy DP guarantees. The amount of compute needed to verify DP guarantees for current algorithms scales with the amount of compute required to train the model. In this paper we design the first DP algorithm with near optimal privacy-utility trade-offs but whose DP guarantees can be verified cheaper than training. We focus on DP stochastic convex optimization (DP-SCO), where optimal privacy-utility trade-offs are known. Here we show we can obtain tight privacy-utility trade-offs by privately minimizing a series of regularized objectives and only using the standard DP composition bound. Crucially, this method can be verified with much less compute than training. This leads to the first known DP-SCO algorithm with near optimal privacy-utility whose DP verification scales better than training cost, significantly reducing verification costs on large datasets.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.LG",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.04008v1",
        "pdf": "https://arxiv.org/pdf/2512.04008v1"
      },
      "arxiv_id": "2512.04008v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.04007v1",
      "title": "On the Temporality for Sketch Representation Learning",
      "authors": [
        "Marcelo Isaias de Moraes Junior",
        "Moacir Antonelli Ponti"
      ],
      "abstract": "Sketches are simple human hand-drawn abstractions of complex scenes and real-world objects. Although the field of sketch representation learning has advanced significantly, there is still a gap in understanding the true relevance of the temporal aspect to the quality of these representations. This work investigates whether it is indeed justifiable to treat sketches as sequences, as well as which internal orders play a more relevant role. The results indicate that, although the use of traditional positional encodings is valid for modeling sketches as sequences, absolute coordinates consistently outperform relative ones. Furthermore, non-autoregressive decoders outperform their autoregressive counterparts. Finally, the importance of temporality was shown to depend on both the order considered and the task evaluated.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.04007v1",
        "pdf": "https://arxiv.org/pdf/2512.04007v1"
      },
      "arxiv_id": "2512.04007v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.04006v1",
      "title": "Diagonalizing the Softmax: Hadamard Initialization for Tractable Cross-Entropy Dynamics",
      "authors": [
        "Connall Garrod",
        "Jonathan P. Keating",
        "Christos Thrampoulidis"
      ],
      "abstract": "Cross-entropy (CE) training loss dominates deep learning practice, yet existing theory often relies on simplifications, either replacing it with squared loss or restricting to convex models, that miss essential behavior. CE and squared loss generate fundamentally different dynamics, and convex linear models cannot capture the complexities of non-convex optimization. We provide an in-depth characterization of multi-class CE optimization dynamics beyond the convex regime by analyzing a canonical two-layer linear neural network with standard-basis vectors as inputs: the simplest non-convex extension for which the implicit bias remained unknown. This model coincides with the unconstrained features model used to study neural collapse, making our work the first to prove that gradient flow on CE converges to the neural collapse geometry. We construct an explicit Lyapunov function that establishes global convergence, despite the presence of spurious critical points in the non-convex landscape. A key insight underlying our analysis is an inconspicuous finding: Hadamard Initialization diagonalizes the softmax operator, freezing the singular vectors of the weight matrices and reducing the dynamics entirely to their singular values. This technique opens a pathway for analyzing CE training dynamics well beyond our specific setting considered here.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.LG",
        "math.OC",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.04006v1",
        "pdf": "https://arxiv.org/pdf/2512.04006v1"
      },
      "arxiv_id": "2512.04006v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.04004v1",
      "title": "Physics-Embedded Gaussian Process for Traffic State Estimation",
      "authors": [
        "Yanlin Chen",
        "Kehua Chen",
        "Yinhai Wang"
      ],
      "abstract": "Traffic state estimation (TSE) becomes challenging when probe-vehicle penetration is low and observations are spatially sparse. Pure data-driven methods lack physical explanations and have poor generalization when observed data is sparse. In contrast, physical models have difficulty integrating uncertainties and capturing the real complexity of traffic. To bridge this gap, recent studies have explored combining them by embedding physical structure into Gaussian process. These approaches typically introduce the governing equations as soft constraints through pseudo-observations, enabling the integration of model structure within a variational framework. However, these methods rely heavily on penalty tuning and lack principled uncertainty calibration, which makes them sensitive to model mis-specification. In this work, we address these limitations by presenting a novel Physics-Embedded Gaussian Process (PEGP), designed to integrate domain knowledge with data-driven methods in traffic state estimation. Specifically, we design two multi-output kernels informed by classic traffic flow models, constructed via the explicit application of the linearized differential operator. Experiments on HighD, NGSIM show consistent improvements over non-physics baselines. PEGP-ARZ proves more reliable under sparse observation, while PEGP-LWR achieves lower errors with denser observation. Ablation study further reveals that PEGP-ARZ residuals align closely with physics and yield calibrated, interpretable uncertainty, whereas PEGP-LWR residuals are more orthogonal and produce nearly constant variance fields. This PEGP framework combines physical priors, uncertainty quantification, which can provide reliable support for TSE.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.04004v1",
        "pdf": "https://arxiv.org/pdf/2512.04004v1"
      },
      "arxiv_id": "2512.04004v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.04000v1",
      "title": "Divide, then Ground: Adapting Frame Selection to Query Types for Long-Form Video Understanding",
      "authors": [
        "Jialuo Li",
        "Bin Li",
        "Jiahao Li",
        "Yan Lu"
      ],
      "abstract": "The application of Large Multimodal Models (LMMs) to long-form video understanding is constrained by limited context lengths and the computationally prohibitive cost of processing dense video tokens. Consequently, recent research has focused on query-aware frame selection, methods that often incur significant computational overhead. This paper challenges the assumption that such complex search mechanisms are universally necessary. We first identify and validate a query typology distinguishing between global query and localized query. We demonstrate that while uniform sampling is both effective and efficient for global queries, localized queries indeed necessitate query-aware selection for optimal performance. Building on this insight, we propose DIG, a training-free frame selection framework that adapts its strategy based on the query type. Specifically,DIG employs efficient uniform sampling for global queries while activating a specialized pipeline to extract query-relevant frames for localized queries. Experiments on three long-form video understanding benchmarks demonstrate that DIG consistently outperforms existing baselines and robustly improves LMM performance, even when scaling the input frame count to 256.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.04000v1",
        "pdf": "https://arxiv.org/pdf/2512.04000v1"
      },
      "arxiv_id": "2512.04000v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03996v1",
      "title": "Highly Efficient Test-Time Scaling for T2I Diffusion Models with Text Embedding Perturbation",
      "authors": [
        "Hang Xu",
        "Linjiang Huang",
        "Feng Zhao"
      ],
      "abstract": "Test-time scaling (TTS) aims to achieve better results by increasing random sampling and evaluating samples based on rules and metrics. However, in text-to-image(T2I) diffusion models, most related works focus on search strategies and reward models, yet the impact of the stochastic characteristic of noise in T2I diffusion models on the method's performance remains unexplored. In this work, we analyze the effects of randomness in T2I diffusion models and explore a new format of randomness for TTS: text embedding perturbation, which couples with existing randomness like SDE-injected noise to enhance generative diversity and quality. We start with a frequency-domain analysis of these formats of randomness and their impact on generation, and find that these two randomness exhibit complementary behavior in the frequency domain: spatial noise favors low-frequency components (early steps), while text embedding perturbation enhances high-frequency details (later steps), thereby compensating for the potential limitations of spatial noise randomness in high-frequency manipulation. Concurrently, text embedding demonstrates varying levels of tolerance to perturbation across different dimensions of the generation process. Specifically, our method consists of two key designs: (1) Introducing step-based text embedding perturbation, combining frequency-guided noise schedules with spatial noise perturbation. (2) Adapting the perturbation intensity selectively based on their frequency-specific contributions to generation and tolerance to perturbation. Our approach can be seamlessly integrated into existing TTS methods and demonstrates significant improvements on multiple benchmarks with almost no additional computation. Code is available at \\href{https://github.com/xuhang07/TEP-Diffusion}{https://github.com/xuhang07/TEP-Diffusion}.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03996v1",
        "pdf": "https://arxiv.org/pdf/2512.03996v1"
      },
      "arxiv_id": "2512.03996v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03995v1",
      "title": "Artificial Microsaccade Compensation: Stable Vision for an Ornithopter",
      "authors": [
        "Levi Burner",
        "Guido de Croon",
        "Yiannis Aloimonos"
      ],
      "abstract": "Animals with foveated vision, including humans, experience microsaccades, small, rapid eye movements that they are not aware of. Inspired by this phenomenon, we develop a method for \"Artificial Microsaccade Compensation\". It can stabilize video captured by a tailless ornithopter that has resisted attempts to use camera-based sensing because it shakes at 12-20 Hz. Our approach minimizes changes in image intensity by optimizing over 3D rotation represented in SO(3). This results in a stabilized video, computed in real time, suitable for human viewing, and free from distortion. When adapted to hold a fixed viewing orientation, up to occasional saccades, it can dramatically reduce inter-frame motion while also benefiting from an efficient recursive update. When compared to Adobe Premier Pro's warp stabilizer, which is widely regarded as the best commercial video stabilization software available, our method achieves higher quality results while also running in real time.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.RO",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03995v1",
        "pdf": "https://arxiv.org/pdf/2512.03995v1"
      },
      "arxiv_id": "2512.03995v1",
      "comment": "29 pages, 5 figures, 2 tables, under review",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03994v1",
      "title": "Training-Free Policy Violation Detection via Activation-Space Whitening in LLMs",
      "authors": [
        "Oren Rachmil",
        "Roy Betser",
        "Itay Gershon",
        "Omer Hofman",
        "Nitay Yakoby",
        "Yuval Meron",
        "Idan Yankelev",
        "Asaf Shabtai",
        "Yuval Elovici",
        "Roman Vainshtein"
      ],
      "abstract": "Aligning proprietary large language models (LLMs) with internal organizational policies has become an urgent priority as organizations increasingly deploy LLMs in sensitive domains such as legal support, finance, and medical services. Beyond generic safety filters, enterprises require reliable mechanisms to detect policy violations within their regulatory and operational frameworks, where breaches can trigger legal and reputational risks. Existing content moderation frameworks, such as guardrails, remain largely confined to the safety domain and lack the robustness to capture nuanced organizational policies. LLM-as-a-judge and fine-tuning approaches, though flexible, introduce significant latency and lack interpretability. To address these limitations, we propose a training-free and efficient method that treats policy violation detection as an out-of-distribution (OOD) detection problem. Inspired by whitening techniques, we apply a linear transformation to decorrelate the model's hidden activations and standardize them to zero mean and unit variance, yielding near-identity covariance matrix. In this transformed space, we use the Euclidean norm as a compliance score to detect policy violations. The method requires only the policy text and a small number of illustrative samples, which makes it light-weight and easily deployable. On a challenging policy benchmark, our approach achieves state-of-the-art results, surpassing both existing guardrails and fine-tuned reasoning models. This work provides organizations with a practical and statistically grounded framework for policy-aware oversight of LLMs, advancing the broader goal of deployable AI governance. Code is available at: https://tinyurl.com/policy-violation-detection",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03994v1",
        "pdf": "https://arxiv.org/pdf/2512.03994v1"
      },
      "arxiv_id": "2512.03994v1",
      "comment": "Accepted to the AAAI 2026 Deployable AI (DAI) Workshop",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03992v1",
      "title": "DIQ-H: Evaluating Hallucination Persistence in VLMs Under Temporal Visual Degradation",
      "authors": [
        "Zexin Lin",
        "Hawen Wan",
        "Yebin Zhong",
        "Xiaoqiang"
      ],
      "abstract": "Vision-Language Models (VLMs) deployed in safety-critical applications such as autonomous driving must handle continuous visual streams under imperfect conditions. However, existing benchmarks focus on static, high-quality images and ignore temporal degradation and error propagation, which are critical failure modes where transient visual corruption induces hallucinations that persist across subsequent frames. We introduce DIQ-H, the first benchmark for evaluating VLM robustness under dynamic visual degradation in temporal sequences. DIQ-H applies physics-based corruptions including motion blur, sensor noise, and compression artifacts, and measures hallucination persistence, error recovery, and temporal consistency through multi-turn question-answering tasks. To enable scalable annotation, we propose Uncertainty-Guided Iterative Refinement (UIR), which generates reliable pseudo-ground-truth using lightweight VLMs with uncertainty filtering, achieving a 15.3 percent accuracy improvement. Experiments on 16 state-of-the-art VLMs reveal substantial robustness gaps: even advanced models such as GPT-4o achieve only a 78.5 percent recovery rate, while open-source models struggle with temporal consistency at less than 60 percent. DIQ-H provides a comprehensive platform for evaluating VLM reliability in real-world deployments.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03992v1",
        "pdf": "https://arxiv.org/pdf/2512.03992v1"
      },
      "arxiv_id": "2512.03992v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03981v1",
      "title": "DirectDrag: High-Fidelity, Mask-Free, Prompt-Free Drag-based Image Editing via Readout-Guided Feature Alignment",
      "authors": [
        "Sheng-Hao Liao",
        "Shang-Fu Chen",
        "Tai-Ming Huang",
        "Wen-Huang Cheng",
        "Kai-Lung Hua"
      ],
      "abstract": "Drag-based image editing using generative models provides intuitive control over image structures. However, existing methods rely heavily on manually provided masks and textual prompts to preserve semantic fidelity and motion precision. Removing these constraints creates a fundamental trade-off: visual artifacts without masks and poor spatial control without prompts. To address these limitations, we propose DirectDrag, a novel mask- and prompt-free editing framework. DirectDrag enables precise and efficient manipulation with minimal user input while maintaining high image fidelity and accurate point alignment. DirectDrag introduces two key innovations. First, we design an Auto Soft Mask Generation module that intelligently infers editable regions from point displacement, automatically localizing deformation along movement paths while preserving contextual integrity through the generative model's inherent capacity. Second, we develop a Readout-Guided Feature Alignment mechanism that leverages intermediate diffusion activations to maintain structural consistency during point-based edits, substantially improving visual fidelity. Despite operating without manual mask or prompt, DirectDrag achieves superior image quality compared to existing methods while maintaining competitive drag accuracy. Extensive experiments on DragBench and real-world scenarios demonstrate the effectiveness and practicality of DirectDrag for high-quality, interactive image manipulation. Project Page: https://frakw.github.io/DirectDrag/. Code is available at: https://github.com/frakw/DirectDrag.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03981v1",
        "pdf": "https://arxiv.org/pdf/2512.03981v1"
      },
      "arxiv_id": "2512.03981v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03979v1",
      "title": "BlurDM: A Blur Diffusion Model for Image Deblurring",
      "authors": [
        "Jin-Ting He",
        "Fu-Jen Tsai",
        "Yan-Tsung Peng",
        "Min-Hung Chen",
        "Chia-Wen Lin",
        "Yen-Yu Lin"
      ],
      "abstract": "Diffusion models show promise for dynamic scene deblurring; however, existing studies often fail to leverage the intrinsic nature of the blurring process within diffusion models, limiting their full potential. To address it, we present a Blur Diffusion Model (BlurDM), which seamlessly integrates the blur formation process into diffusion for image deblurring. Observing that motion blur stems from continuous exposure, BlurDM implicitly models the blur formation process through a dual-diffusion forward scheme, diffusing both noise and blur onto a sharp image. During the reverse generation process, we derive a dual denoising and deblurring formulation, enabling BlurDM to recover the sharp image by simultaneously denoising and deblurring, given pure Gaussian noise conditioned on the blurred image as input. Additionally, to efficiently integrate BlurDM into deblurring networks, we perform BlurDM in the latent space, forming a flexible prior generation network for deblurring. Extensive experiments demonstrate that BlurDM significantly and consistently enhances existing deblurring methods on four benchmark datasets. The source code is available at https://github.com/Jin-Ting-He/BlurDM.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03979v1",
        "pdf": "https://arxiv.org/pdf/2512.03979v1"
      },
      "arxiv_id": "2512.03979v1",
      "comment": "NeurIPS 2025",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03975v1",
      "title": "Sponsored Questions and How to Auction Them",
      "authors": [
        "Kshipra Bhawalkar",
        "Alexandros Psomas",
        "Di Wang"
      ],
      "abstract": "Online platforms connect users with relevant products and services using ads. A key challenge is that a user's search query often leaves their true intent ambiguous. Typically, platforms passively predict relevance based on available signals and in some cases offer query refinements. The shift from traditional search to conversational AI provides a new approach. When a user's query is ambiguous, a Large Language Model (LLM) can proactively offer several clarifying follow-up prompts. In this paper we consider the following: what if some of these follow-up prompts can be ``sponsored,'' i.e., selected for their advertising potential. How should these ``suggestion slots'' be allocated? And, how does this new mechanism interact with the traditional ad auction that might follow?\n  This paper introduces a formal model for designing and analyzing these interactive platforms. We use this model to investigate a critical engineering choice: whether it is better to build an end-to-end pipeline that jointly optimizes the user interaction and the final ad auction, or to decouple them into separate mechanisms for the suggestion slots and another for the subsequent ad slot. We show that the VCG mechanism can be adopted to jointly optimize the sponsored suggestion and the ads that follow; while this mechanism is more complex, it achieves outcomes that are efficient and truthful. On the other hand, we prove that the simple-to-implement modular approach suffers from strategic inefficiency: its Price of Anarchy is unbounded.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03975v1",
        "pdf": "https://arxiv.org/pdf/2512.03975v1"
      },
      "arxiv_id": "2512.03975v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03974v1",
      "title": "Refining Machine Learning Potentials through Thermodynamic Theory of Phase Transitions",
      "authors": [
        "Paul Fuchs",
        "Julija Zavadlav"
      ],
      "abstract": "Foundational Machine Learning Potentials can resolve the accuracy and transferability limitations of classical force fields. They enable microscopic insights into material behavior through Molecular Dynamics simulations, which can crucially expedite material design and discovery. However, insufficiently broad and systematically biased reference data affect the predictive quality of the learned models. Often, these models exhibit significant deviations from experimentally observed phase transition temperatures, in the order of several hundred kelvins. Thus, fine-tuning is necessary to achieve adequate accuracy in many practical problems. This work proposes a fine-tuning strategy via top-down learning, directly correcting the wrongly predicted transition temperatures to match the experimental reference data. Our approach leverages the Differentiable Trajectory Reweighting algorithm to minimize the free energy differences between phases at the experimental target pressures and temperatures. We demonstrate that our approach can accurately correct the phase diagram of pure Titanium in a pressure range of up to 5 GPa, matching the experimental reference within tenths of kelvins and improving the liquid-state diffusion constant. Our approach is model-agnostic, applicable to multi-component systems with solid-solid and solid-liquid transitions, and compliant with top-down training on other experimental properties. Therefore, our approach can serve as an essential step towards highly accurate application-specific and foundational machine learning potentials.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "physics.comp-ph",
        "cs.LG"
      ],
      "primary_category": "physics.comp-ph",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03974v1",
        "pdf": "https://arxiv.org/pdf/2512.03974v1"
      },
      "arxiv_id": "2512.03974v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03973v1",
      "title": "Guided Flow Policy: Learning from High-Value Actions in Offline Reinforcement Learning",
      "authors": [
        "Franki Nguimatsia Tiofack",
        "ThÃ©otime Le Hellard",
        "Fabian Schramm",
        "Nicolas Perrin-Gilbert",
        "Justin Carpentier"
      ],
      "abstract": "Offline reinforcement learning often relies on behavior regularization that enforces policies to remain close to the dataset distribution. However, such approaches fail to distinguish between high-value and low-value actions in their regularization components. We introduce Guided Flow Policy (GFP), which couples a multi-step flow-matching policy with a distilled one-step actor. The actor directs the flow policy through weighted behavior cloning to focus on cloning high-value actions from the dataset rather than indiscriminately imitating all state-action pairs. In turn, the flow policy constrains the actor to remain aligned with the dataset's best transitions while maximizing the critic. This mutual guidance enables GFP to achieve state-of-the-art performance across 144 state and pixel-based tasks from the OGBench, Minari, and D4RL benchmarks, with substantial gains on suboptimal datasets and challenging tasks. Webpage: https://simple-robotics.github.io/publications/guided-flow-policy/",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03973v1",
        "pdf": "https://arxiv.org/pdf/2512.03973v1"
      },
      "arxiv_id": "2512.03973v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03967v1",
      "title": "Technical Report on Text Dataset Distillation",
      "authors": [
        "Keith Ando Ogawa",
        "Bruno Lopes Yamamoto",
        "Lucas Lauton de Alcantara",
        "Victor Zacarias",
        "Edson Bollis",
        "Lucas Pellicer",
        "Rosimeire Pereira Costa",
        "Anna Helena Reali Costa",
        "Artur Jordao"
      ],
      "abstract": "In the vision domain, dataset distillation arises as a technique to condense a large dataset into a smaller synthetic one that exhibits a similar result in the training process. While image data presents an extensive literature of distillation methods, text dataset distillation has fewer works in comparison. Text dataset distillation initially grew as an adaptation of efforts from the vision universe, as the particularities of the modality became clear obstacles, it rose into a separate branch of research. Several milestones mark the development of this area, such as the introduction of methods that use transformer models, the generation of discrete synthetic text, and the scaling to decoder-only models with over 1B parameters. Despite major advances in modern approaches, the field remains in a maturing phase, with room for improvement on benchmarking standardization, approaches to overcome the discrete nature of text, handling complex tasks, and providing explicit examples of real-world applications. In this report, we review past and recent advances in dataset distillation for text, highlighting different distillation strategies, key contributions, and general challenges.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03967v1",
        "pdf": "https://arxiv.org/pdf/2512.03967v1"
      },
      "arxiv_id": "2512.03967v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03964v1",
      "title": "Training for Identity, Inference for Controllability: A Unified Approach to Tuning-Free Face Personalization",
      "authors": [
        "Lianyu Pang",
        "Ji Zhou",
        "Qiping Wang",
        "Baoquan Zhao",
        "Zhenguo Yang",
        "Qing Li",
        "Xudong Mao"
      ],
      "abstract": "Tuning-free face personalization methods have developed along two distinct paradigms: text embedding approaches that map facial features into the text embedding space, and adapter-based methods that inject features through auxiliary cross-attention layers. While both paradigms have shown promise, existing methods struggle to simultaneously achieve high identity fidelity and flexible text controllability. We introduce UniID, a unified tuning-free framework that synergistically integrates both paradigms. Our key insight is that when merging these approaches, they should mutually reinforce only identity-relevant information while preserving the original diffusion prior for non-identity attributes. We realize this through a principled training-inference strategy: during training, we employ an identity-focused learning scheme that guides both branches to capture identity features exclusively; at inference, we introduce a normalized rescaling mechanism that recovers the text controllability of the base diffusion model while enabling complementary identity signals to enhance each other. This principled design enables UniID to achieve high-fidelity face personalization with flexible text controllability. Extensive experiments against six state-of-the-art methods demonstrate that UniID achieves superior performance in both identity preservation and text controllability. Code will be available at https://github.com/lyuPang/UniID",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03964v1",
        "pdf": "https://arxiv.org/pdf/2512.03964v1"
      },
      "arxiv_id": "2512.03964v1",
      "comment": "17 pages, 13 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03963v1",
      "title": "TempR1: Improving Temporal Understanding of MLLMs via Temporal-Aware Multi-Task Reinforcement Learning",
      "authors": [
        "Tao Wu",
        "Li Yang",
        "Gen Zhan",
        "Yiting Liao",
        "Junlin Li",
        "Deliang Fu",
        "Li Zhang",
        "Limin Wang"
      ],
      "abstract": "Enhancing the temporal understanding of Multimodal Large Language Models (MLLMs) is essential for advancing long-form video analysis, enabling tasks such as temporal localization, action detection, and time-sensitive question answering. While reinforcement learning (RL) has recently been explored for improving temporal reasoning, existing approaches are often confined to limited task types and data, restricting their generalization across diverse temporal understanding scenarios. To address this challenge, we present TempR1, a temporal-aware multi-task reinforcement learning framework that systematically strengthens MLLMs' temporal comprehension. We curate a multi-task corpus that exposes the model to diverse temporal structures and semantics, and build upon the Group Relative Policy Optimization (GRPO) algorithm to achieve stable and effective cross-task optimization. Specifically, we categorize temporal tasks into three correspondence types between predicted intervals and ground-truth instances, and design tailored localization rewards for each, enabling TempR1 to capture fine-grained temporal dependencies and adapt to different temporal patterns. Extensive experiments demonstrate that TempR1 attains state-of-the-art performance across multiple benchmarks. Moreover, its joint optimization over complementary tasks yields a strong synergistic effect, enhancing both generalization and single-task performance, establishing a scalable and principled paradigm for temporal reasoning in MLLMs.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03963v1",
        "pdf": "https://arxiv.org/pdf/2512.03963v1"
      },
      "arxiv_id": "2512.03963v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03962v1",
      "title": "Tada-DIP: Input-adaptive Deep Image Prior for One-shot 3D Image Reconstruction",
      "authors": [
        "Evan Bell",
        "Shijun Liang",
        "Ismail Alkhouri",
        "Saiprasad Ravishankar"
      ],
      "abstract": "Deep Image Prior (DIP) has recently emerged as a promising one-shot neural-network based image reconstruction method. However, DIP has seen limited application to 3D image reconstruction problems. In this work, we introduce Tada-DIP, a highly effective and fully 3D DIP method for solving 3D inverse problems. By combining input-adaptation and denoising regularization, Tada-DIP produces high-quality 3D reconstructions while avoiding the overfitting phenomenon that is common in DIP. Experiments on sparse-view X-ray computed tomography reconstruction validate the effectiveness of the proposed method, demonstrating that Tada-DIP produces much better reconstructions than training-data-free baselines and achieves reconstruction performance on par with a supervised network trained using a large dataset with fully-sampled volumes.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "eess.IV",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03962v1",
        "pdf": "https://arxiv.org/pdf/2512.03962v1"
      },
      "arxiv_id": "2512.03962v1",
      "comment": "6 pages, 8 figures, 2025 Asilomar Conference on Signals, Systems, and Computers. Code is available at github.com/evanbell02/Tada-DIP/",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2512.03955v1",
      "title": "Benchmark for Planning and Control with Large Language Model Agents: Blocksworld with Model Context Protocol",
      "authors": [
        "Niklas Jobs",
        "Luis Miguel Vieira da Silva",
        "Jayanth Somashekaraiah",
        "Maximilian Weigand",
        "David Kube",
        "Felix Gehlhoff"
      ],
      "abstract": "Industrial automation increasingly requires flexible control strategies that can adapt to changing tasks and environments. Agents based on Large Language Models (LLMs) offer potential for such adaptive planning and execution but lack standardized benchmarks for systematic comparison. We introduce a benchmark with an executable simulation environment representing the Blocksworld problem providing five complexity categories. By integrating the Model Context Protocol (MCP) as a standardized tool interface, diverse agent architectures can be connected to and evaluated against the benchmark without implementation-specific modifications. A single-agent implementation demonstrates the benchmark's applicability, establishing quantitative metrics for comparison of LLM-based planning and execution approaches.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03955v1",
        "pdf": "https://arxiv.org/pdf/2512.03955v1"
      },
      "arxiv_id": "2512.03955v1",
      "comment": "This work has been submitted to IFAC for possible publication",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03939v1",
      "title": "MUT3R: Motion-aware Updating Transformer for Dynamic 3D Reconstruction",
      "authors": [
        "Guole Shen",
        "Tianchen Deng",
        "Xingrui Qin",
        "Nailin Wang",
        "Jianyu Wang",
        "Yanbo Wang",
        "Yongtao Chen",
        "Hesheng Wang",
        "Jingchuan Wang"
      ],
      "abstract": "Recent stateful recurrent neural networks have achieved remarkable progress on static 3D reconstruction but remain vulnerable to motion-induced artifacts, where non-rigid regions corrupt attention propagation between the spatial memory and image feature. By analyzing the internal behaviors of the state and image token updating mechanism, we find that aggregating self-attention maps across layers reveals a consistent pattern: dynamic regions are naturally down-weighted, exposing an implicit motion cue that the pretrained transformer already encodes but never explicitly uses. Motivated by this observation, we introduce MUT3R, a training-free framework that applies the attention-derived motion cue to suppress dynamic content in the early layers of the transformer during inference. Our attention-level gating module suppresses the influence of dynamic regions before their artifacts propagate through the feature hierarchy. Notably, we do not retrain or fine-tune the model; we let the pretrained transformer diagnose its own motion cues and correct itself. This early regulation stabilizes geometric reasoning in streaming scenarios and leads to improvements in temporal consistency and camera pose robustness across multiple dynamic benchmarks, offering a simple and training-free pathway toward motion-aware streaming reconstruction.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03939v1",
        "pdf": "https://arxiv.org/pdf/2512.03939v1"
      },
      "arxiv_id": "2512.03939v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03932v1",
      "title": "Beyond the Ground Truth: Enhanced Supervision for Image Restoration",
      "authors": [
        "Donghun Ryou",
        "Inju Ha",
        "Sanghyeok Chu",
        "Bohyung Han"
      ],
      "abstract": "Deep learning-based image restoration has achieved significant success. However, when addressing real-world degradations, model performance is limited by the quality of ground-truth images in datasets due to practical constraints in data acquisition. To address this limitation, we propose a novel framework that enhances existing ground truth images to provide higher-quality supervision for real-world restoration. Our framework generates perceptually enhanced ground truth images using super-resolution by incorporating adaptive frequency masks, which are learned by a conditional frequency mask generator. These masks guide the optimal fusion of frequency components from the original ground truth and its super-resolved variants, yielding enhanced ground truth images. This frequency-domain mixup preserves the semantic consistency of the original content while selectively enriching perceptual details, preventing hallucinated artifacts that could compromise fidelity. The enhanced ground truth images are used to train a lightweight output refinement network that can be seamlessly integrated with existing restoration models. Extensive experiments demonstrate that our approach consistently improves the quality of restored images. We further validate the effectiveness of both supervision enhancement and output refinement through user studies. Code is available at https://github.com/dhryougit/Beyond-the-Ground-Truth.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03932v1",
        "pdf": "https://arxiv.org/pdf/2512.03932v1"
      },
      "arxiv_id": "2512.03932v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03931v1",
      "title": "Autonomous Agents and Policy Compliance: A Framework for Reasoning About Penalties",
      "authors": [
        "Vineel Tummala",
        "Daniela Inclezan"
      ],
      "abstract": "This paper presents a logic programming-based framework for policy-aware autonomous agents that can reason about potential penalties for non-compliance and act accordingly. While prior work has primarily focused on ensuring compliance, our approach considers scenarios where deviating from policies may be necessary to achieve high-stakes goals. Additionally, modeling non-compliant behavior can assist policymakers by simulating realistic human decision-making. Our framework extends Gelfond and Lobo's Authorization and Obligation Policy Language (AOPL) to incorporate penalties and integrates Answer Set Programming (ASP) for reasoning. Compared to previous approaches, our method ensures well-formed policies, accounts for policy priorities, and enhances explainability by explicitly identifying rule violations and their consequences. Building on the work of Harders and Inclezan, we introduce penalty-based reasoning to distinguish between non-compliant plans, prioritizing those with minimal repercussions. To support this, we develop an automated translation from the extended AOPL into ASP and refine ASP-based planning algorithms to account for incurred penalties. Experiments in two domains demonstrate that our framework generates higher-quality plans that avoid harmful actions while, in some cases, also improving computational efficiency. These findings underscore its potential for enhancing autonomous decision-making and informing policy refinement. Under consideration in Theory and Practice of Logic Programming (TPLP).",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03931v1",
        "pdf": "https://arxiv.org/pdf/2512.03931v1"
      },
      "arxiv_id": "2512.03931v1",
      "comment": "27 pages, 5 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03928v1",
      "title": "Density-Informed VAE (DiVAE): Reliable Log-Prior Probability via Density Alignment Regularization",
      "authors": [
        "Michele Alessi",
        "Alessio Ansuini",
        "Alex Rodriguez"
      ],
      "abstract": "We introduce Density-Informed VAE (DiVAE), a lightweight, data-driven regularizer that aligns the VAE log-prior probability $\\log p_Z(z)$ with a log-density estimated from data. Standard VAEs match latents to a simple prior, overlooking density structure in the data-space. DiVAE encourages the encoder to allocate posterior mass in proportion to data-space density and, when the prior is learnable, nudges the prior toward high-density regions. This is realized by adding a robust, precision-weighted penalty to the ELBO, incurring negligible computational overhead. On synthetic datasets, DiVAE (i) improves distributional alignment of latent log-densities to its ground truth counterpart, (ii) improves prior coverage, and (iii) yields better OOD uncertainty calibration. On MNIST, DiVAE improves alignment of the prior with external estimates of the density, providing better interpretability, and improves OOD detection for learnable priors.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03928v1",
        "pdf": "https://arxiv.org/pdf/2512.03928v1"
      },
      "arxiv_id": "2512.03928v1",
      "comment": "PriGM Workshop EurIPS 2025",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03923v1",
      "title": "Quantum-Classical Physics-Informed Neural Networks for Solving Reservoir Seepage Equations",
      "authors": [
        "Xiang Rao",
        "Yina Liu",
        "Yuxuan Shen"
      ],
      "abstract": "Solving partial differential equations (PDEs) for reservoir seepage is critical for optimizing oil and gas field development and predicting production performance. Traditional numerical methods suffer from mesh-dependent errors and high computational costs, while classical Physics-Informed Neural Networks (PINNs) face bottlenecks in parameter efficiency, high-dimensional expression, and strong nonlinear fitting. To address these limitations, we propose a Discrete Variable (DV)-Circuit Quantum-Classical Physics-Informed Neural Network (QCPINN) and apply it to three typical reservoir seepage models for the first time: the pressure diffusion equation for heterogeneous single-phase flow, the nonlinear Buckley-Leverett (BL) equation for two-phase waterflooding, and the convection-diffusion equation for compositional flow considering adsorption. The QCPINN integrates classical preprocessing/postprocessing networks with a DV quantum core, leveraging quantum superposition and entanglement to enhance high-dimensional feature mapping while embedding physical constraints to ensure solution consistency. We test three quantum circuit topologies (Cascade, Cross-mesh, Alternate) and demonstrate through numerical experiments that QCPINNs achieve high prediction accuracy with fewer parameters than classical PINNs. Specifically, the Alternate topology outperforms others in heterogeneous single-phase flow and two-phase BL equation simulations, while the Cascade topology excels in compositional flow with convection-dispersion-adsorption coupling. Our work verifies the feasibility of QCPINN for reservoir engineering applications, bridging the gap between quantum computing research and industrial practice in oil and gas engineering.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.LG",
        "math.NA",
        "physics.comp-ph"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03923v1",
        "pdf": "https://arxiv.org/pdf/2512.03923v1"
      },
      "arxiv_id": "2512.03923v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03918v1",
      "title": "UniMo: Unifying 2D Video and 3D Human Motion with an Autoregressive Framework",
      "authors": [
        "Youxin Pang",
        "Yong Zhang",
        "Ruizhi Shao",
        "Xiang Deng",
        "Feng Gao",
        "Xu Xiaoming",
        "Xiaoming Wei",
        "Yebin Liu"
      ],
      "abstract": "We propose UniMo, an innovative autoregressive model for joint modeling of 2D human videos and 3D human motions within a unified framework, enabling simultaneous generation and understanding of these two modalities for the first time. Current methods predominantly focus on generating one modality given another as the condition or integrating either of them with other modalities such as text and audio. Unifying 2D videos and 3D motions for simultaneous optimization and generation remains largely unexplored, presenting significant challenges due to their substantial structural and distributional differences. Inspired by the LLM's ability to unify different modalities, our method models videos and 3D motions as a unified tokens sequence, utilizing separate embedding layers to mitigate distribution gaps. Additionally, we devise a sequence modeling strategy that integrates two distinct tasks within a single framework, proving the effectiveness of unified modeling. Moreover, to efficiently align with visual tokens and preserve 3D spatial information, we design a novel 3D motion tokenizer with a temporal expansion strategy, using a single VQ-VAE to produce quantized motion tokens. It features multiple expert decoders that handle body shapes, translation, global orientation, and body poses for reliable 3D motion reconstruction. Extensive experiments demonstrate that our method simultaneously generates corresponding videos and motions while performing accurate motion capture. This work taps into the capacity of LLMs to fuse diverse data types, paving the way for integrating human-centric information into existing models and potentially enabling multimodal, controllable joint modeling of humans, objects, and scenes.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03918v1",
        "pdf": "https://arxiv.org/pdf/2512.03918v1"
      },
      "arxiv_id": "2512.03918v1",
      "comment": "https://carlyx.github.io/UniMo/",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2512.03915v1",
      "title": "A Theoretical Framework for Auxiliary-Loss-Free Load Balancing of Sparse Mixture-of-Experts in Large-Scale AI Models",
      "authors": [
        "X. Y. Han",
        "Yuan Zhong"
      ],
      "abstract": "In large-scale AI training, Sparse Mixture-of-Experts (s-MoE) layers enable scaling by activating only a small subset of experts per token. An operational challenge in this design is load balancing: routing tokens to minimize the number of idle experts, which is important for the efficient utilization of (costly) GPUs. We provide a theoretical framework for analyzing the Auxiliary-Loss-Free Load Balancing (ALF-LB) procedure -- proposed by DeepSeek's Wang et al. (2024) -- by casting it as a one-step-per-iteration primal-dual method for an assignment problem. First, in a stylized deterministic setting, our framework yields several insightful structural properties: (i) a monotonic improvement of a Lagrangian objective, (ii) a preference rule that moves tokens from overloaded to underloaded experts, and (iii) an approximate-balancing guarantee. Then, we incorporate the stochastic and dynamic nature of AI training using a generalized online optimization formulation. In the online setting, we derive a strong convexity property of the objective that leads to a logarithmic expected regret bound under certain step-size choices. Additionally, we present real experiments on 1B-parameter DeepSeekMoE models to complement our theoretical findings. Together, these results build a principled framework for analyzing the Auxiliary-Loss-Free Load Balancing of s-MoE in AI models.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "math.OC",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03915v1",
        "pdf": "https://arxiv.org/pdf/2512.03915v1"
      },
      "arxiv_id": "2512.03915v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03913v1",
      "title": "Hierarchical Vision Language Action Model Using Success and Failure Demonstrations",
      "authors": [
        "Jeongeun Park",
        "Jihwan Yoon",
        "Byungwoo Jeon",
        "Juhan Park",
        "Jinwoo Shin",
        "Namhoon Cho",
        "Kyungjae Lee",
        "Sangdoo Yun",
        "Sungjoon Choi"
      ],
      "abstract": "Prior Vision-Language-Action (VLA) models are typically trained on teleoperated successful demonstrations, while discarding numerous failed attempts that occur naturally during data collection. However, these failures encode where and how policies can be fragile, information that can be exploited to improve robustness. We address this problem by leveraging mixed-quality datasets to learn failure-aware reasoning at planning time. We introduce VINE, a hierarchical vision-language-action model that separates high-level reasoning (System 2) from low-level control (System 1) under a hierarchical reinforcement learning formalism, making failures usable as a structured learning signal rather than noisy supervision. System 2 performs feasibility-guided tree search over a 2D scene-graph abstraction: it proposes subgoal transitions, predicts success probabilities from both successes and failures, and prunes brittle branches before execution, effectively casting plan evaluation as feasibility scoring. The selected subgoal sequence is then passed to System 1, which executes low-level actions without modifying the agent's core skills. Trained entirely from offline teleoperation data, VINE integrates negative experience directly into the decision loop. Across challenging manipulation tasks, this approach consistently improves success rates and robustness, demonstrating that failure data is an essential resource for converting the broad competence of VLAs into robust execution.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03913v1",
        "pdf": "https://arxiv.org/pdf/2512.03913v1"
      },
      "arxiv_id": "2512.03913v1",
      "comment": "https://vine-vla.github.io/",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2512.03911v1",
      "title": "Autonomous Reinforcement Learning Robot Control with Intel's Loihi 2 Neuromorphic Hardware",
      "authors": [
        "Kenneth Stewart",
        "Roxana Leontie",
        "Samantha Chapin",
        "Joe Hays",
        "Sumit Bam Shrestha",
        "Carl Glen Henshaw"
      ],
      "abstract": "We present an end-to-end pipeline for deploying reinforcement learning (RL) trained Artificial Neural Networks (ANNs) on neuromorphic hardware by converting them into spiking Sigma-Delta Neural Networks (SDNNs). We demonstrate that an ANN policy trained entirely in simulation can be transformed into an SDNN compatible with Intel's Loihi 2 architecture, enabling low-latency and energy-efficient inference. As a test case, we use an RL policy for controlling the Astrobee free-flying robot, similar to a previously hardware in space-validated controller. The policy, trained with Rectified Linear Units (ReLUs), is converted to an SDNN and deployed on Intel's Loihi 2, then evaluated in NVIDIA's Omniverse Isaac Lab simulation environment for closed-loop control of Astrobee's motion. We compare execution performance between GPU and Loihi 2. The results highlight the feasibility of using neuromorphic platforms for robotic control and establish a pathway toward energy-efficient, real-time neuromorphic computation in future space and terrestrial robotics applications.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03911v1",
        "pdf": "https://arxiv.org/pdf/2512.03911v1"
      },
      "arxiv_id": "2512.03911v1",
      "comment": "Submitted for review at NICE 2026 (Neuro-Inspired Computational Elements) conference",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03905v1",
      "title": "Zero-Shot Video Translation and Editing with Frame Spatial-Temporal Correspondence",
      "authors": [
        "Shuai Yang",
        "Junxin Lin",
        "Yifan Zhou",
        "Ziwei Liu",
        "Chen Change Loy"
      ],
      "abstract": "The remarkable success in text-to-image diffusion models has motivated extensive investigation of their potential for video applications. Zero-shot techniques aim to adapt image diffusion models for videos without requiring further model training. Recent methods largely emphasize integrating inter-frame correspondence into attention mechanisms. However, the soft constraint applied to identify the valid features to attend is insufficient, which could lead to temporal inconsistency. In this paper, we present FRESCO, which integrates intra-frame correspondence with inter-frame correspondence to formulate a more robust spatial-temporal constraint. This enhancement ensures a consistent transformation of semantically similar content between frames. Our method goes beyond attention guidance to explicitly optimize features, achieving high spatial-temporal consistency with the input video, significantly enhancing the visual coherence of manipulated videos. We verify FRESCO adaptations on two zero-shot tasks of video-to-video translation and text-guided video editing. Comprehensive experiments demonstrate the effectiveness of our framework in generating high-quality, coherent videos, highlighting a significant advance over current zero-shot methods.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03905v1",
        "pdf": "https://arxiv.org/pdf/2512.03905v1"
      },
      "arxiv_id": "2512.03905v1",
      "comment": "Code: https://github.com/Sunnycookies/FRESCO-v2, Project: https://williamyang1991.github.io/projects/FRESCOv2/",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2512.03903v1",
      "title": "BERnaT: Basque Encoders for Representing Natural Textual Diversity",
      "authors": [
        "Ekhi Azurmendi",
        "Joseba Fernandez de Landa",
        "Jaione Bengoetxea",
        "Maite Heredia",
        "Julen Etxaniz",
        "Mikel Zubillaga",
        "Ander Soraluze",
        "Aitor Soroa"
      ],
      "abstract": "Language models depend on massive text corpora that are often filtered for quality, a process that can unintentionally exclude non-standard linguistic varieties, reduce model robustness and reinforce representational biases. In this paper, we argue that language models should aim to capture the full spectrum of language variation (dialectal, historical, informal, etc.) rather than relying solely on standardized text. Focusing on Basque, a morphologically rich and low-resource language, we construct new corpora combining standard, social media, and historical sources, and pre-train the BERnaT family of encoder-only models in three configurations: standard, diverse, and combined. We further propose an evaluation framework that separates Natural Language Understanding (NLU) tasks into standard and diverse subsets to assess linguistic generalization. Results show that models trained on both standard and diverse data consistently outperform those trained on standard corpora, improving performance across all task types without compromising standard benchmark accuracy. These findings highlight the importance of linguistic diversity in building inclusive, generalizable language models.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03903v1",
        "pdf": "https://arxiv.org/pdf/2512.03903v1"
      },
      "arxiv_id": "2512.03903v1",
      "comment": "Submitted to LREC 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03899v1",
      "title": "Probabilistic Foundations of Fuzzy Simplicial Sets for Nonlinear Dimensionality Reduction",
      "authors": [
        "Janis Keck",
        "Lukas Silvester Barth",
        "Fatemeh",
        "Fahimi",
        "Parvaneh Joharinad",
        "JÃ¼rgen Jost"
      ],
      "abstract": "Fuzzy simplicial sets have become an object of interest in dimensionality reduction and manifold learning, most prominently through their role in UMAP. However, their definition through tools from algebraic topology without a clear probabilistic interpretation detaches them from commonly used theoretical frameworks in those areas. In this work we introduce a framework that explains fuzzy simplicial sets as marginals of probability measures on simplicial sets. In particular, this perspective shows that the fuzzy weights of UMAP arise from a generative model that samples Vietoris-Rips filtrations at random scales, yielding cumulative distribution functions of pairwise distances. More generally, the framework connects fuzzy simplicial sets to probabilistic models on the face poset, clarifies the relation between Kullback-Leibler divergence and fuzzy cross-entropy in this setting, and recovers standard t-norms and t-conorms via Boolean operations on the underlying simplicial sets. We then show how new embedding methods may be derived from this framework and illustrate this on an example where we generalize UMAP using Äech filtrations with triplet sampling. In summary, this probabilistic viewpoint provides a unified probabilistic theoretical foundation for fuzzy simplicial sets, clarifies the role of UMAP within this framework, and enables the systematic derivation of new dimensionality reduction methods.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.LG",
        "math.AT",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03899v1",
        "pdf": "https://arxiv.org/pdf/2512.03899v1"
      },
      "arxiv_id": "2512.03899v1",
      "comment": "47 pages (including appendix), 11 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03891v1",
      "title": "Digital Twin-based Control Co-Design of Full Vehicle Active Suspensions via Deep Reinforcement Learning",
      "authors": [
        "Ying-Kuan Tsai",
        "Yi-Ping Chen",
        "Vispi Karkaria",
        "Wei Chen"
      ],
      "abstract": "Active suspension systems are critical for enhancing vehicle comfort, safety, and stability, yet their performance is often limited by fixed hardware designs and control strategies that cannot adapt to uncertain and dynamic operating conditions. Recent advances in digital twins (DTs) and deep reinforcement learning (DRL) offer new opportunities for real-time, data-driven optimization across a vehicle's lifecycle. However, integrating these technologies into a unified framework remains an open challenge. This work presents a DT-based control co-design (CCD) framework for full-vehicle active suspensions using multi-generation design concepts. By integrating automatic differentiation into DRL, we jointly optimize physical suspension components and control policies under varying driver behaviors and environmental uncertainties. DRL also addresses the challenge of partial observability, where only limited states can be sensed and fed back to the controller, by learning optimal control actions directly from available sensor information. The framework incorporates model updating with quantile learning to capture data uncertainty, enabling real-time decision-making and adaptive learning from digital-physical interactions. The approach demonstrates personalized optimization of suspension systems under two distinct driving settings (mild and aggressive). Results show that the optimized systems achieve smoother trajectories and reduce control efforts by approximately 43% and 52% for mild and aggressive, respectively, while maintaining ride comfort and stability. Contributions include: developing a DT-enabled CCD framework integrating DRL and uncertainty-aware model updating for full-vehicle active suspensions, introducing a multi-generation design strategy for self-improving systems, and demonstrating personalized optimization of active suspension systems for distinct driver types.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.RO",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03891v1",
        "pdf": "https://arxiv.org/pdf/2512.03891v1"
      },
      "arxiv_id": "2512.03891v1",
      "comment": "28 pages, 17 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03887v1",
      "title": "A Hierarchical Tree-based approach for creating Configurable and Static Deep Research Agent (Static-DRA)",
      "authors": [
        "Saurav Prateek"
      ],
      "abstract": "The advancement in Large Language Models has driven the creation of complex agentic systems, such as Deep Research Agents (DRAs), to overcome the limitations of static Retrieval Augmented Generation (RAG) pipelines in handling complex, multi-turn research tasks. This paper introduces the Static Deep Research Agent (Static-DRA), a novel solution built upon a configurable and hierarchical Tree-based static workflow.\n  The core contribution is the integration of two user-tunable parameters, Depth and Breadth, which provide granular control over the research intensity. This design allows end-users to consciously balance the desired quality and comprehensiveness of the research report against the associated computational cost of Large Language Model (LLM) interactions. The agent's architecture, comprising Supervisor, Independent, and Worker agents, facilitates effective multi-hop information retrieval and parallel sub-topic investigation.\n  We evaluate the Static-DRA against the established DeepResearch Bench using the RACE (Reference-based Adaptive Criteria-driven Evaluation) framework. Configured with a depth of 2 and a breadth of 5, and powered by the gemini-2.5-pro model, the agent achieved an overall score of 34.72. Our experiments validate that increasing the configured Depth and Breadth parameters results in a more in-depth research process and a correspondingly higher evaluation score. The Static-DRA offers a pragmatic and resource-aware solution, empowering users with transparent control over the deep research process. The entire source code, outputs and benchmark results are open-sourced at https://github.com/SauravP97/Static-Deep-Research/",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03887v1",
        "pdf": "https://arxiv.org/pdf/2512.03887v1"
      },
      "arxiv_id": "2512.03887v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03883v1",
      "title": "Dual Cross-Attention Siamese Transformer for Rectal Tumor Regrowth Assessment in Watch-and-Wait Endoscopy",
      "authors": [
        "Jorge Tapias Gomez",
        "Despoina Kanata",
        "Aneesh Rangnekar",
        "Christina Lee",
        "Julio Garcia-Aguilar",
        "Joshua Jesse Smith",
        "Harini Veeraraghavan"
      ],
      "abstract": "Increasing evidence supports watch-and-wait (WW) surveillance for patients with rectal cancer who show clinical complete response (cCR) at restaging following total neoadjuvant treatment (TNT). However, objectively accurate methods to early detect local regrowth (LR) from follow-up endoscopy images during WW are essential to manage care and prevent distant metastases. Hence, we developed a Siamese Swin Transformer with Dual Cross-Attention (SSDCA) to combine longitudinal endoscopic images at restaging and follow-up and distinguish cCR from LR. SSDCA leverages pretrained Swin transformers to extract domain agnostic features and enhance robustness to imaging variations. Dual cross attention is implemented to emphasize features from the two scans without requiring any spatial alignment of images to predict response. SSDCA as well as Swin-based baselines were trained using image pairs from 135 patients and evaluated on a held-out set of image pairs from 62 patients. SSDCA produced the best balanced accuracy (81.76\\% $\\pm$ 0.04), sensitivity (90.07\\% $\\pm$ 0.08), and specificity (72.86\\% $\\pm$ 0.05). Robustness analysis showed stable performance irrespective of artifacts including blood, stool, telangiectasia, and poor image quality. UMAP clustering of extracted features showed maximal inter-cluster separation (1.45 $\\pm$ 0.18) and minimal intra-cluster dispersion (1.07 $\\pm$ 0.19) with SSDCA, confirming discriminative representation learning.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03883v1",
        "pdf": "https://arxiv.org/pdf/2512.03883v1"
      },
      "arxiv_id": "2512.03883v1",
      "comment": "6 pages, 5 figures, 1 table, submitted to ISBI conference",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03882v1",
      "title": "Automatic Attack Discovery for Few-Shot Class-Incremental Learning via Large Language Models",
      "authors": [
        "Haidong Kang",
        "Wei Wu",
        "Hanling Wang"
      ],
      "abstract": "Few-shot class incremental learning (FSCIL) is a more realistic and challenging paradigm in continual learning to incrementally learn unseen classes and overcome catastrophic forgetting on base classes with only a few training examples. Previous efforts have primarily centered around studying more effective FSCIL approaches. By contrast, less attention was devoted to thinking the security issues in contributing to FSCIL. This paper aims to provide a holistic study of the impact of attacks on FSCIL. We first derive insights by systematically exploring how human expert-designed attack methods (i.e., PGD, FGSM) affect FSCIL. We find that those methods either fail to attack base classes, or suffer from huge labor costs due to relying on huge expert knowledge. This highlights the need to craft a specialized attack method for FSCIL. Grounded in these insights, in this paper, we propose a simple yet effective ACraft method to automatically steer and discover optimal attack methods targeted at FSCIL by leveraging Large Language Models (LLMs) without human experts. Moreover, to improve the reasoning between LLMs and FSCIL, we introduce a novel Proximal Policy Optimization (PPO) based reinforcement learning to optimize learning, making LLMs generate better attack methods in the next generation by establishing positive feedback. Experiments on mainstream benchmarks show that our ACraft significantly degrades the performance of state-of-the-art FSCIL methods and dramatically beyond human expert-designed attack methods while maintaining the lowest costs of attack.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03882v1",
        "pdf": "https://arxiv.org/pdf/2512.03882v1"
      },
      "arxiv_id": "2512.03882v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03874v1",
      "title": "OmniDexVLG: Learning Dexterous Grasp Generation from Vision Language Model-Guided Grasp Semantics, Taxonomy and Functional Affordance",
      "authors": [
        "Lei Zhang",
        "Diwen Zheng",
        "Kaixin Bai",
        "Zhenshan Bing",
        "Zoltan-Csaba Marton",
        "Zhaopeng Chen",
        "Alois Christian Knoll",
        "Jianwei Zhang"
      ],
      "abstract": "Dexterous grasp generation aims to produce grasp poses that align with task requirements and human interpretable grasp semantics. However, achieving semantically controllable dexterous grasp synthesis remains highly challenging due to the lack of unified modeling of multiple semantic dimensions, including grasp taxonomy, contact semantics, and functional affordance. To address these limitations, we present OmniDexVLG, a multimodal, semantics aware grasp generation framework capable of producing structurally diverse and semantically coherent dexterous grasps under joint language and visual guidance. Our approach begins with OmniDexDataGen, a semantic rich dexterous grasp dataset generation pipeline that integrates grasp taxonomy guided configuration sampling, functional affordance contact point sampling, taxonomy aware differential force closure grasp sampling, and physics based optimization and validation, enabling systematic coverage of diverse grasp types. We further introduce OmniDexReasoner, a multimodal grasp type semantic reasoning module that leverages multi agent collaboration, retrieval augmented generation, and chain of thought reasoning to infer grasp related semantics and generate high quality annotations that align language instructions with task specific grasp intent. Building upon these components, we develop a unified Vision Language Grasping generation model that explicitly incorporates grasp taxonomy, contact structure, and functional affordance semantics, enabling fine grained control over grasp synthesis from natural language instructions. Extensive experiments in simulation and real world object grasping and ablation studies demonstrate that our method substantially outperforms state of the art approaches in terms of grasp diversity, contact semantic diversity, functional affordance diversity, and semantic consistency.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.RO",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03874v1",
        "pdf": "https://arxiv.org/pdf/2512.03874v1"
      },
      "arxiv_id": "2512.03874v1",
      "comment": "Project Website: https://sites.google.com/view/omnidexvlg, 16 pages",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03869v1",
      "title": "An Automated Framework for Large-Scale Graph-Based Cerebrovascular Analysis",
      "authors": [
        "Daniele Falcetta",
        "Liane S. Canas",
        "Lorenzo Suppa",
        "Matteo Pentassuglia",
        "Jon Cleary",
        "Marc Modat",
        "SÃ©bastien Ourselin",
        "Maria A. Zuluaga"
      ],
      "abstract": "We present CaravelMetrics, a computational framework for automated cerebrovascular analysis that models vessel morphology through skeletonization-derived graph representations. The framework integrates atlas-based regional parcellation, centerline extraction, and graph construction to compute fifteen morphometric, topological, fractal, and geometric features. The features can be estimated globally from the complete vascular network or regionally within arterial territories, enabling multiscale characterization of cerebrovascular organization. Applied to 570 3D TOF-MRA scans from the IXI dataset (ages 20-86), CaravelMetrics yields reproducible vessel graphs capturing age- and sex-related variations and education-associated increases in vascular complexity, consistent with findings reported in the literature. The framework provides a scalable and fully automated approach for quantitative cerebrovascular feature extraction, supporting normative modeling and population-level studies of vascular health and aging.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CV",
        "cs.CY"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03869v1",
        "pdf": "https://arxiv.org/pdf/2512.03869v1"
      },
      "arxiv_id": "2512.03869v1",
      "comment": "Submitted to ISBI 2026. 6 pages, 6 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03864v1",
      "title": "Hyperdimensional Computing for Sustainable Manufacturing: An Initial Assessment",
      "authors": [
        "Danny Hoang",
        "Anandkumar Patel",
        "Ruimen Chen",
        "Rajiv Malhotra",
        "Farhad Imani"
      ],
      "abstract": "Smart manufacturing can significantly improve efficiency and reduce energy consumption, yet the energy demands of AI models may offset these gains. This study utilizes in-situ sensing-based prediction of geometric quality in smart machining to compare the energy consumption, accuracy, and speed of common AI models. HyperDimensional Computing (HDC) is introduced as an alternative, achieving accuracy comparable to conventional models while drastically reducing energy consumption, 200$\\times$ for training and 175 to 1000$\\times$ for inference. Furthermore, HDC reduces training times by 200$\\times$ and inference times by 300 to 600$\\times$, showcasing its potential for energy-efficient smart manufacturing.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.PF",
        "cs.SC"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03864v1",
        "pdf": "https://arxiv.org/pdf/2512.03864v1"
      },
      "arxiv_id": "2512.03864v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03862v1",
      "title": "Diminishing Returns in Self-Supervised Learning",
      "authors": [
        "Oli Bridge",
        "Huey Sun",
        "Botond Branyicskai-Nagy",
        "Charles D'Ornano",
        "Shomit Basu"
      ],
      "abstract": "While transformer-based architectures have taken computer vision and NLP by storm, they often require a vast amount of parameters and training data to attain strong performance. In this work, we experiment with three distinct pre-training, intermediate fine-tuning, and downstream datasets and training objectives to explore their marginal benefits on a small 5M-parameter vision transformer. We find that while pre-training and fine-tuning always help our model but have diminishing returns, intermediate fine-tuning can actually show harmful impact on downstream performance, potentially due to dissimilarity in task mechanics. Taken together, our results suggest that small-scale ViTs benefit most from targeted pre-training and careful data selection, while indiscriminate stacking of intermediate tasks can waste compute and even degrade performance.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03862v1",
        "pdf": "https://arxiv.org/pdf/2512.03862v1"
      },
      "arxiv_id": "2512.03862v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03861v1",
      "title": "Scalable Decision Focused Learning via Online Trainable Surrogates",
      "authors": [
        "Gaetano Signorelli",
        "Michele Lombardi"
      ],
      "abstract": "Decision support systems often rely on solving complex optimization problems that may require to estimate uncertain parameters beforehand. Recent studies have shown how using traditionally trained estimators for this task can lead to suboptimal solutions. Using the actual decision cost as a loss function (called Decision Focused Learning) can address this issue, but with a severe loss of scalability at training time. To address this issue, we propose an acceleration method based on replacing costly loss function evaluations with an efficient surrogate. Unlike previously defined surrogates, our approach relies on unbiased estimators reducing the risk of spurious local optima and can provide information on its local confidence allowing one to switch to a fallback method when needed. Furthermore, the surrogate is designed for a black-box setting, which enables compensating for simplifications in the optimization model and account- ing for recourse actions during cost computation. In our results, the method reduces costly inner solver calls, with a solution quality comparable to other state-of-the-art techniques.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03861v1",
        "pdf": "https://arxiv.org/pdf/2512.03861v1"
      },
      "arxiv_id": "2512.03861v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03854v1",
      "title": "Prostate biopsy whole slide image dataset from an underrepresented Middle Eastern population",
      "authors": [
        "Peshawa J. Muhammad Ali",
        "Navin Vincent",
        "Saman S. Abdulla",
        "Han N. Mohammed Fadhl",
        "Anders Blilie",
        "Kelvin Szolnoky",
        "Julia Anna Mielcarz",
        "Xiaoyi Ji",
        "Kimmo Kartasalo",
        "Abdulbasit K. Al-Talabani",
        "Nita Mulliqi"
      ],
      "abstract": "Artificial intelligence (AI) is increasingly used in digital pathology. Publicly available histopathology datasets remain scarce, and those that do exist predominantly represent Western populations. Consequently, the generalizability of AI models to populations from less digitized regions, such as the Middle East, is largely unknown. This motivates the public release of our dataset to support the development and validation of pathology AI models across globally diverse populations. We present 339 whole-slide images of prostate core needle biopsies from a consecutive series of 185 patients collected in Erbil, Iraq. The slides are associated with Gleason scores and International Society of Urological Pathology grades assigned independently by three pathologists. Scanning was performed using two high-throughput scanners (Leica and Hamamatsu) and one compact scanner (Grundium). All slides were de-identified and are provided in their native formats without further conversion. The dataset enables grading concordance analyses, color normalization, and cross-scanner robustness evaluations. Data will be deposited in the Bioimage Archive (BIA) under accession code: to be announced (TBA), and released under a CC BY 4.0 license.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03854v1",
        "pdf": "https://arxiv.org/pdf/2512.03854v1"
      },
      "arxiv_id": "2512.03854v1",
      "comment": "13 pages, 2 figures and 1 table",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03852v1",
      "title": "Traffic Image Restoration under Adverse Weather via Frequency-Aware Mamba",
      "authors": [
        "Liwen Pan",
        "Longguang Wang",
        "Guangwei Gao",
        "Jun Wang",
        "Jun Shi",
        "Juncheng Li"
      ],
      "abstract": "Traffic image restoration under adverse weather conditions remains a critical challenge for intelligent transportation systems. Existing methods primarily focus on spatial-domain modeling but neglect frequency-domain priors. Although the emerging Mamba architecture excels at long-range dependency modeling through patch-wise correlation analysis, its potential for frequency-domain feature extraction remains unexplored. To address this, we propose Frequency-Aware Mamba (FAMamba), a novel framework that integrates frequency guidance with sequence modeling for efficient image restoration. Our architecture consists of two key components: (1) a Dual-Branch Feature Extraction Block (DFEB) that enhances local-global interaction via bidirectional 2D frequency-adaptive scanning, dynamically adjusting traversal paths based on sub-band texture distributions; and (2) a Prior-Guided Block (PGB) that refines texture details through wavelet-based high-frequency residual learning, enabling high-quality image reconstruction with precise details. Meanwhile, we design a novel Adaptive Frequency Scanning Mechanism (AFSM) for the Mamba architecture, which enables the Mamba to achieve frequency-domain scanning across distinct subgraphs, thereby fully leveraging the texture distribution characteristics inherent in subgraph structures. Extensive experiments demonstrate the efficiency and effectiveness of FAMamba.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03852v1",
        "pdf": "https://arxiv.org/pdf/2512.03852v1"
      },
      "arxiv_id": "2512.03852v1",
      "comment": "12pages, 13 figures, 5tables",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03851v1",
      "title": "Comparison of neural network training strategies for the simulation of dynamical systems",
      "authors": [
        "Paul Strasser",
        "Andreas Pfeffer",
        "Jakob Weber",
        "Markus Gurtner",
        "Andreas KÃ¶rner"
      ],
      "abstract": "Neural networks have become a widely adopted tool for modeling nonlinear dynamical systems from data. However, the choice of training strategy remains a key design decision, particularly for simulation tasks. This paper compares two predominant strategies: parallel and series-parallel training. The conducted empirical analysis spans five neural network architectures and two examples: a pneumatic valve test bench and an industrial robot benchmark. The study reveals that, even though series-parallel training dominates current practice, parallel training consistently yields better long-term prediction accuracy. Additionally, this work clarifies the often inconsistent terminology in the literature and relate both strategies to concepts from system identification. The findings suggest that parallel training should be considered the default training strategy for neural network-based simulation of dynamical systems.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03851v1",
        "pdf": "https://arxiv.org/pdf/2512.03851v1"
      },
      "arxiv_id": "2512.03851v1",
      "comment": "submitted to ECC",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03848v1",
      "title": "PULSE: A Unified Multi-Task Architecture for Cardiac Segmentation, Diagnosis, and Few-Shot Cross-Modality Clinical Adaptation",
      "authors": [
        "Hania Ghouse",
        "Maryam Alsharqi",
        "Farhad R. Nezami",
        "Muzammil Behzad"
      ],
      "abstract": "Cardiac image analysis remains fragmented across tasks: anatomical segmentation, disease classification, and grounded clinical report generation are typically handled by separate networks trained under different data regimes. No existing framework unifies these objectives within a single architecture while retaining generalization across imaging modalities and datasets. We introduce PULSE, a multi-task vision-language framework built on self-supervised representations and optimized through a composite supervision strategy that balances region overlap learning, pixel wise classification fidelity, and boundary aware IoU refinement. A multi-scale token reconstruction decoder enables anatomical segmentation, while shared global representations support disease classification and clinically grounded text output allowing the model to transition from pixels to structures and finally clinical reasoning within one architecture. Unlike prior task-specific pipelines, PULSE learns task-invariant cardiac priors, generalizes robustly across datasets, and can be adapted to new imaging modalities with minimal supervision. This moves the field closer to a scalable, foundation style cardiac analysis framework.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03848v1",
        "pdf": "https://arxiv.org/pdf/2512.03848v1"
      },
      "arxiv_id": "2512.03848v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03847v1",
      "title": "DVPO: Distributional Value Modeling-based Policy Optimization for LLM Post-Training",
      "authors": [
        "Dingwei Zhu",
        "Zhiheng Xi",
        "Shihan Dou",
        "Yuhui Wang",
        "Sixian Li",
        "Junjie Ye",
        "Honglin Guo",
        "Shichun Liu",
        "Chenhao Huang",
        "Yajie Yang",
        "Junlin Shang",
        "Senjie Jin",
        "Ming Zhang",
        "Jiazheng Zhang",
        "Caishuang Huang",
        "Yunke Zhang",
        "Demei Yan",
        "Yuran Wang",
        "Tao Gui"
      ],
      "abstract": "Reinforcement learning (RL) has shown strong performance in LLM post-training, but real-world deployment often involves noisy or incomplete supervision. In such settings, complex and unreliable supervision signals can destabilize training and harm generalization. While existing approaches such as worst-case optimization (e.g., RFQI, CQL) and mean-based methods (e.g., PPO, GRPO) can improve stability, they often overlook generalization and may produce overly conservative policies, leading to uneven performance across diverse real scenarios. To this end, we introduce DVPO (Distributional Value Modeling with Risk-aware Policy Optimization), a new RL framework that combines conditional risk theory with distributional value modeling to better balance robustness and generalization. DVPO learns token-level value distributions to provide fine-grained supervision, and applies an asymmetric risk regularization to shape the distribution tails: it contracts the lower tail to dampen noisy negative deviations, while expanding the upper tail to preserve exploratory diversity. Across extensive experiments and analysis in multi-turn dialogue, math reasoning, and scientific QA, DVPO consistently outperforms PPO, GRPO, and robust Bellman-based PPO under noisy supervision, showing its potential for LLM post-training in the real-world.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03847v1",
        "pdf": "https://arxiv.org/pdf/2512.03847v1"
      },
      "arxiv_id": "2512.03847v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03844v1",
      "title": "CoDA: From Text-to-Image Diffusion Models to Training-Free Dataset Distillation",
      "authors": [
        "Letian Zhou",
        "Songhua Liu",
        "Xinchao Wang"
      ],
      "abstract": "Prevailing Dataset Distillation (DD) methods leveraging generative models confront two fundamental limitations. First, despite pioneering the use of diffusion models in DD and delivering impressive performance, the vast majority of approaches paradoxically require a diffusion model pre-trained on the full target dataset, undermining the very purpose of DD and incurring prohibitive training costs. Second, although some methods turn to general text-to-image models without relying on such target-specific training, they suffer from a significant distributional mismatch, as the web-scale priors encapsulated in these foundation models fail to faithfully capture the target-specific semantics, leading to suboptimal performance. To tackle these challenges, we propose Core Distribution Alignment (CoDA), a framework that enables effective DD using only an off-the-shelf text-to-image model. Our key idea is to first identify the \"intrinsic core distribution\" of the target dataset using a robust density-based discovery mechanism. We then steer the generative process to align the generated samples with this core distribution. By doing so, CoDA effectively bridges the gap between general-purpose generative priors and target semantics, yielding highly representative distilled datasets. Extensive experiments suggest that, without relying on a generative model specifically trained on the target dataset, CoDA achieves performance on par with or even superior to previous methods with such reliance across all benchmarks, including ImageNet-1K and its subsets. Notably, it establishes a new state-of-the-art accuracy of 60.4% at the 50-images-per-class (IPC) setup on ImageNet-1K. Our code is available on the project webpage: https://github.com/zzzlt422/CoDA",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03844v1",
        "pdf": "https://arxiv.org/pdf/2512.03844v1"
      },
      "arxiv_id": "2512.03844v1",
      "comment": "34 pages, 24 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03837v1",
      "title": "Heatmap Pooling Network for Action Recognition from RGB Videos",
      "authors": [
        "Mengyuan Liu",
        "Jinfu Liu",
        "Yongkang Jiang",
        "Bin He"
      ],
      "abstract": "Human action recognition (HAR) in videos has garnered widespread attention due to the rich information in RGB videos. Nevertheless, existing methods for extracting deep features from RGB videos face challenges such as information redundancy, susceptibility to noise and high storage costs. To address these issues and fully harness the useful information in videos, we propose a novel heatmap pooling network (HP-Net) for action recognition from videos, which extracts information-rich, robust and concise pooled features of the human body in videos through a feedback pooling module. The extracted pooled features demonstrate obvious performance advantages over the previously obtained pose data and heatmap features from videos. In addition, we design a spatial-motion co-learning module and a text refinement modulation module to integrate the extracted pooled features with other multimodal data, enabling more robust action recognition. Extensive experiments on several benchmarks namely NTU RGB+D 60, NTU RGB+D 120, Toyota-Smarthome and UAV-Human consistently verify the effectiveness of our HP-Net, which outperforms the existing human action recognition methods. Our code is publicly available at: https://github.com/liujf69/HPNet-Action.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03837v1",
        "pdf": "https://arxiv.org/pdf/2512.03837v1"
      },
      "arxiv_id": "2512.03837v1",
      "comment": "Final Version of IEEE Transactions on Pattern Analysis and Machine Intelligence",
      "journal_ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence (2025)",
      "has_code": false
    },
    {
      "id": "2512.03834v1",
      "title": "Lean Unet: A Compact Model for Image Segmentation",
      "authors": [
        "Ture Hassler",
        "Ida Ãkerholm",
        "Marcus NordstrÃ¶m",
        "Gabriele Balletti",
        "Orcun Goksel"
      ],
      "abstract": "Unet and its variations have been standard in semantic image segmentation, especially for computer assisted radiology. Current Unet architectures iteratively downsample spatial resolution while increasing channel dimensions to preserve information content. Such a structure demands a large memory footprint, limiting training batch sizes and increasing inference latency. Channel pruning compresses Unet architecture without accuracy loss, but requires lengthy optimization and may not generalize across tasks and datasets. By investigating Unet pruning, we hypothesize that the final structure is the crucial factor, not the channel selection strategy of pruning. Based on our observations, we propose a lean Unet architecture (LUnet) with a compact, flat hierarchy where channels are not doubled as resolution is halved. We evaluate on a public MRI dataset allowing comparable reporting, as well as on two internal CT datasets. We show that a state-of-the-art pruning solution (STAMP) mainly prunes from the layers with the highest number of channels. Comparatively, simply eliminating a random channel at the pruning-identified layer or at the largest layer achieves similar or better performance. Our proposed LUnet with fixed architectures and over 30 times fewer parameters achieves performance comparable to both conventional Unet counterparts and data-adaptively pruned networks. The proposed lean Unet with constant channel count across layers requires far fewer parameters while achieving performance superior to standard Unet for the same total number of parameters. Skip connections allow Unet bottleneck channels to be largely reduced, unlike standard encoder-decoder architectures requiring increased bottleneck channels for information propagation.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03834v1",
        "pdf": "https://arxiv.org/pdf/2512.03834v1"
      },
      "arxiv_id": "2512.03834v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03827v1",
      "title": "A Robust Camera-based Method for Breath Rate Measurement",
      "authors": [
        "Alexey Protopopov"
      ],
      "abstract": "Proliferation of cheap and accessible cameras makes it possible to measure a subject's breath rate from video footage alone. Recent works on this topic have proposed a variety of approaches for accurately measuring human breath rate, however they are either tested in near-ideal conditions, or produce results that are not sufficiently accurate. The present study proposes a more robust method to measure breath rate in humans with minimal hardware requirements using a combination of mathematical transforms with a relative deviation from the ground truth of less than 5%. The method was tested on videos taken from 14 volunteers with a total duration of over 2 hours 30 minutes. The obtained results were compared to reference data and the average mean absolute error was found to be at 0.57 respirations per minute, which is noticeably better than the results from previous works. The breath rate measurement method proposed in the present article is more resistant to distortions caused by subject movement and thus allows one to remotely measure the subject's breath rate without any significant limitations on the subject's behavior.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03827v1",
        "pdf": "https://arxiv.org/pdf/2512.03827v1"
      },
      "arxiv_id": "2512.03827v1",
      "comment": "9 pages, 4 figures, 2 tables",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03819v1",
      "title": "Transmit Weights, Not Features: Orthogonal-Basis Aided Wireless Point-Cloud Transmission",
      "authors": [
        "Junlin Chang",
        "Yubo Han",
        "Hnag Yue",
        "John S Thompson",
        "Rongke Liu"
      ],
      "abstract": "The widespread adoption of depth sensors has substantially lowered the barrier to point-cloud acquisition. This letter proposes a semantic wireless transmission framework for three dimension (3D) point clouds built on Deep Joint Source - Channel Coding (DeepJSCC). Instead of sending raw features, the transmitter predicts combination weights over a receiver-side semantic orthogonal feature pool, enabling compact representations and robust reconstruction. A folding-based decoder deforms a 2D grid into 3D, enforcing manifold continuity while preserving geometric fidelity. Trained with Chamfer Distance (CD) and an orthogonality regularizer, the system is evaluated on ModelNet40 across varying Signal-to-Noise Ratios (SNRs) and bandwidths. Results show performance on par with SEmantic Point cloud Transmission (SEPT) at high bandwidth and clear gains in bandwidth-constrained regimes, with consistent improvements in both Peak Signal-to-Noise Ratio (PSNR) and CD. Ablation experiments confirm the benefits of orthogonalization and the folding prior.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03819v1",
        "pdf": "https://arxiv.org/pdf/2512.03819v1"
      },
      "arxiv_id": "2512.03819v1",
      "comment": "5 pages, 5 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03817v1",
      "title": "HieroGlyphTranslator: Automatic Recognition and Translation of Egyptian Hieroglyphs to English",
      "authors": [
        "Ahmed Nasser",
        "Marwan Mohamed",
        "Alaa Sherif",
        "Basmala Mahmoud",
        "Shereen Yehia",
        "Asmaa Saad",
        "Mariam S. El-Rahmany",
        "Ensaf H. Mohamed"
      ],
      "abstract": "Egyptian hieroglyphs, the ancient Egyptian writing system, are composed entirely of drawings. Translating these glyphs into English poses various challenges, including the fact that a single glyph can have multiple meanings. Deep learning translation applications are evolving rapidly, producing remarkable results that significantly impact our lives. In this research, we propose a method for the automatic recognition and translation of ancient Egyptian hieroglyphs from images to English. This study utilized two datasets for classification and translation: the Morris Franken dataset and the EgyptianTranslation dataset. Our approach is divided into three stages: segmentation (using Contour and Detectron2), mapping symbols to Gardiner codes, and translation (using the CNN model). The model achieved a BLEU score of 42.2, a significant result compared to previous research.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03817v1",
        "pdf": "https://arxiv.org/pdf/2512.03817v1"
      },
      "arxiv_id": "2512.03817v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03816v1",
      "title": "Log Probability Tracking of LLM APIs",
      "authors": [
        "TimothÃ©e Chauvin",
        "Erwan Le Merrer",
        "FranÃ§ois TaÃ¯ani",
        "Gilles Tredan"
      ],
      "abstract": "When using an LLM through an API provider, users expect the served model to remain consistent over time, a property crucial for the reliability of downstream applications and the reproducibility of research. Existing audit methods are too costly to apply at regular time intervals to the wide range of available LLM APIs. This means that model updates are left largely unmonitored in practice. In this work, we show that while LLM log probabilities (logprobs) are usually non-deterministic, they can still be used as the basis for cost-effective continuous monitoring of LLM APIs. We apply a simple statistical test based on the average value of each token logprob, requesting only a single token of output. This is enough to detect changes as small as one step of fine-tuning, making this approach more sensitive than existing methods while being 1,000x cheaper. We introduce the TinyChange benchmark as a way to measure the sensitivity of audit methods in the context of small, realistic model changes.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.LG",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03816v1",
        "pdf": "https://arxiv.org/pdf/2512.03816v1"
      },
      "arxiv_id": "2512.03816v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03805v1",
      "title": "Deep Reinforcement Learning for Dynamic Algorithm Configuration: A Case Study on Optimizing OneMax with the (1+($Î»$,$Î»$))-GA",
      "authors": [
        "Tai Nguyen",
        "Phong Le",
        "AndrÃ© Biedenkapp",
        "Carola Doerr",
        "Nguyen Dang"
      ],
      "abstract": "Dynamic Algorithm Configuration (DAC) studies the efficient identification of control policies for parameterized optimization algorithms. Numerous studies have leveraged the robustness of decision-making in Reinforcement Learning (RL) to address the optimization challenges in algorithm configuration. However, applying RL to DAC is challenging and often requires extensive domain expertise. We conduct a comprehensive study of deep-RL algorithms in DAC through a systematic analysis of controlling the population size parameter of the (1+($Î»$,$Î»$))-GA on OneMax instances. Our investigation of DDQN and PPO reveals two fundamental challenges that limit their effectiveness in DAC: scalability degradation and learning instability. We trace these issues to two primary causes: under-exploration and planning horizon coverage, each of which can be effectively addressed through targeted solutions. To address under-exploration, we introduce an adaptive reward shifting mechanism that leverages reward distribution statistics to enhance DDQN agent exploration, eliminating the need for instance-specific hyperparameter tuning and ensuring consistent effectiveness across different problem scales. In dealing with the planning horizon coverage problem, we demonstrate that undiscounted learning effectively resolves it in DDQN, while PPO faces fundamental variance issues that necessitate alternative algorithmic designs. We further analyze the hyperparameter dependencies of PPO, showing that while hyperparameter optimization enhances learning stability, it consistently falls short in identifying effective policies across various configurations. Finally, we demonstrate that DDQN equipped with our adaptive reward shifting strategy achieves performance comparable to theoretically derived policies with vastly improved sample efficiency, outperforming prior DAC approaches by several orders of magnitude.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03805v1",
        "pdf": "https://arxiv.org/pdf/2512.03805v1"
      },
      "arxiv_id": "2512.03805v1",
      "comment": "arXiv admin note: text overlap with arXiv:2502.20265",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03804v1",
      "title": "EfficientECG: Cross-Attention with Feature Fusion for Efficient Electrocardiogram Classification",
      "authors": [
        "Hanhui Deng",
        "Xinglin Li",
        "Jie Luo",
        "Zhanpeng Jin",
        "Di Wu"
      ],
      "abstract": "Electrocardiogram is a useful diagnostic signal that can detect cardiac abnormalities by measuring the electrical activity generated by the heart. Due to its rapid, non-invasive, and richly informative characteristics, ECG has many emerging applications. In this paper, we study novel deep learning technologies to effectively manage and analyse ECG data, with the aim of building a diagnostic model, accurately and quickly, that can substantially reduce the burden on medical workers. Unlike the existing ECG models that exhibit a high misdiagnosis rate, our deep learning approaches can automatically extract the features of ECG data through end-to-end training. Specifically, we first devise EfficientECG, an accurate and lightweight classification model for ECG analysis based on the existing EfficientNet model, which can effectively handle high-frequency long-sequence ECG data with various leading types. On top of that, we next propose a cross-attention-based feature fusion model of EfficientECG for analysing multi-lead ECG data with multiple features (e.g., gender and age). Our evaluations on representative ECG datasets validate the superiority of our model against state-of-the-art works in terms of high precision, multi-feature fusion, and lightweights.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03804v1",
        "pdf": "https://arxiv.org/pdf/2512.03804v1"
      },
      "arxiv_id": "2512.03804v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03796v1",
      "title": "LSRS: Latent Scale Rejection Sampling for Visual Autoregressive Modeling",
      "authors": [
        "Hong-Kai Zheng",
        "Piji Li"
      ],
      "abstract": "Visual Autoregressive (VAR) modeling approach for image generation proposes autoregressive processing across hierarchical scales, decoding multiple tokens per scale in parallel. This method achieves high-quality generation while accelerating synthesis. However, parallel token sampling within a scale may lead to structural errors, resulting in suboptimal generated images. To mitigate this, we propose Latent Scale Rejection Sampling (LSRS), a method that progressively refines token maps in the latent scale during inference to enhance VAR models. Our method uses a lightweight scoring model to evaluate multiple candidate token maps sampled at each scale, selecting the high-quality map to guide subsequent scale generation. By prioritizing early scales critical for structural coherence, LSRS effectively mitigates autoregressive error accumulation while maintaining computational efficiency. Experiments demonstrate that LSRS significantly improves VAR's generation quality with minimal additional computational overhead. For the VAR-d30 model, LSRS increases the inference time by merely 1% while reducing its FID score from 1.95 to 1.78. When the inference time is increased by 15%, the FID score can be further reduced to 1.66. LSRS offers an efficient test-time scaling solution for enhancing VAR-based generation.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03796v1",
        "pdf": "https://arxiv.org/pdf/2512.03796v1"
      },
      "arxiv_id": "2512.03796v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03795v1",
      "title": "MPCFormer: A physics-informed data-driven approach for explainable socially-aware autonomous driving",
      "authors": [
        "Jia Hu",
        "Zhexi Lian",
        "Xuerun Yan",
        "Ruiang Bi",
        "Dou Shen",
        "Yu Ruan",
        "Haoran Wang"
      ],
      "abstract": "Autonomous Driving (AD) vehicles still struggle to exhibit human-like behavior in highly dynamic and interactive traffic scenarios. The key challenge lies in AD's limited ability to interact with surrounding vehicles, largely due to a lack of understanding the underlying mechanisms of social interaction. To address this issue, we introduce MPCFormer, an explainable socially-aware autonomous driving approach with physics-informed and data-driven coupled social interaction dynamics. In this model, the dynamics are formulated into a discrete space-state representation, which embeds physics priors to enhance modeling explainability. The dynamics coefficients are learned from naturalistic driving data via a Transformer-based encoder-decoder architecture. To the best of our knowledge, MPCFormer is the first approach to explicitly model the dynamics of multi-vehicle social interactions. The learned social interaction dynamics enable the planner to generate manifold, human-like behaviors when interacting with surrounding traffic. By leveraging the MPC framework, the approach mitigates the potential safety risks typically associated with purely learning-based methods. Open-looped evaluation on NGSIM dataset demonstrates that MPCFormer achieves superior social interaction awareness, yielding the lowest trajectory prediction errors compared with other state-of-the-art approach. The prediction achieves an ADE as low as 0.86 m over a long prediction horizon of 5 seconds. Close-looped experiments in highly intense interaction scenarios, where consecutive lane changes are required to exit an off-ramp, further validate the effectiveness of MPCFormer. Results show that MPCFormer achieves the highest planning success rate of 94.67%, improves driving efficiency by 15.75%, and reduces the collision rate from 21.25% to 0.5%, outperforming a frontier Reinforcement Learning (RL) based planner.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03795v1",
        "pdf": "https://arxiv.org/pdf/2512.03795v1"
      },
      "arxiv_id": "2512.03795v1",
      "comment": "17 pages, 18 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03794v1",
      "title": "AdaptVision: Efficient Vision-Language Models via Adaptive Visual Acquisition",
      "authors": [
        "Zichuan Lin",
        "Yicheng Liu",
        "Yang Yang",
        "Lvfang Tao",
        "Deheng Ye"
      ],
      "abstract": "Vision-Language Models (VLMs) have achieved remarkable success in visual question answering tasks, but their reliance on large numbers of visual tokens introduces significant computational overhead. While existing efficient VLM approaches reduce visual tokens through fixed-ratio compression, they operate passively and lack the ability to adapt to varying task requirements. This motivates a fundamental question: Can VLMs autonomously determine the minimum number of visual tokens required for each sample? Inspired by human active vision mechanisms, we introduce AdaptVision, an efficient VLM paradigm that enables adaptive visual token acquisition through a coarse-to-fine approach. Our model initially processes compressed visual tokens from low-resolution images and selectively acquires additional visual information by invoking a bounding box tool to crop key regions when necessary. We train AdaptVision using a reinforcement learning framework that carefully balances accuracy and efficiency. Central to our approach is Decoupled Turn Policy Optimization (DTPO), which decouples the learning objective into two components: (1) tool learning, which optimizes correct tool utilization, and (2) accuracy improvement, which refines the generated responses to improve answer correctness. Based on this formulation, we further decouple advantage estimation by computing separate advantages for tokens associated with each objective. This formulation enables more effective optimization for AdaptVision compared to vanilla GRPO. Comprehensive experiments across multiple VQA benchmarks demonstrate that AdaptVision achieves superior performance while consuming substantially fewer visual tokens than state-of-the-art efficient VLM methods.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03794v1",
        "pdf": "https://arxiv.org/pdf/2512.03794v1"
      },
      "arxiv_id": "2512.03794v1",
      "comment": "15 pages, 9 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03787v1",
      "title": "Adaptive Identification and Modeling of Clinical Pathways with Process Mining",
      "authors": [
        "Francesco Vitale",
        "Nicola Mazzocca"
      ],
      "abstract": "Clinical pathways are specialized healthcare plans that model patient treatment procedures. They are developed to provide criteria-based progression and standardize patient treatment, thereby improving care, reducing resource use, and accelerating patient recovery. However, manual modeling of these pathways based on clinical guidelines and domain expertise is difficult and may not reflect the actual best practices for different variations or combinations of diseases. We propose a two-phase modeling method using process mining, which extends the knowledge base of clinical pathways by leveraging conformance checking diagnostics. In the first phase, historical data of a given disease is collected to capture treatment in the form of a process model. In the second phase, new data is compared against the reference model to verify conformance. Based on the conformance checking results, the knowledge base can be expanded with more specific models tailored to new variants or disease combinations. We demonstrate our approach using Synthea, a benchmark dataset simulating patient treatments for SARS-CoV-2 infections with varying COVID-19 complications. The results show that our method enables expanding the knowledge base of clinical pathways with sufficient precision, peaking to 95.62% AUC while maintaining an arc-degree simplicity of 67.11%.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03787v1",
        "pdf": "https://arxiv.org/pdf/2512.03787v1"
      },
      "arxiv_id": "2512.03787v1",
      "comment": "Accepted to the 41st ACM/SIGAPP Symposium On Applied Computing (ACM SAC 2026)",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03786v1",
      "title": "Forensic Activity Classification Using Digital Traces from iPhones: A Machine Learning-based Approach",
      "authors": [
        "Conor McCarthy",
        "Jan Peter van Zandwijk",
        "Marcel Worring",
        "Zeno Geradts"
      ],
      "abstract": "Smartphones and smartwatches are ever-present in daily life, and provide a rich source of information on their users' behaviour. In particular, digital traces derived from the phone's embedded movement sensors present an opportunity for a forensic investigator to gain insight into a person's physical activities. In this work, we present a machine learning-based approach to translate digital traces into likelihood ratios (LRs) for different types of physical activities. Evaluating on a new dataset, NFI\\_FARED, which contains digital traces from four different types of iPhones labelled with 19 activities, it was found that our approach could produce useful LR systems to distinguish 167 out of a possible 171 activity pairings. The same approach was extended to analyse likelihoods for multiple activities (or groups of activities) simultaneously and create activity timelines to aid in both the early and latter stages of forensic investigations. The dataset and all code required to replicate the results have also been made public to encourage further research on this topic.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03786v1",
        "pdf": "https://arxiv.org/pdf/2512.03786v1"
      },
      "arxiv_id": "2512.03786v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03783v1",
      "title": "Omni-AutoThink: Adaptive Multimodal Reasoning via Reinforcement Learning",
      "authors": [
        "Dongchao Yang",
        "Songxiang Liu",
        "Disong Wang",
        "Yuanyuan Wang",
        "Guanglu Wan",
        "Helen Meng"
      ],
      "abstract": "Recent advances in Omni models have enabled unified multimodal perception and generation. However, most existing systems still exhibit rigid reasoning behaviors, either overthinking simple problems or failing to reason when necessary. To address this limitation, we propose Omni-AutoThink, a novel adaptive reasoning framework that dynamically adjusts the model's reasoning depth according to task difficulty. Our framework comprises two stages: (1) an Adaptive Supervised Fine-Tuning (Adaptive SFT) stage, which endows the Omni model with fundamental reasoning capability using large-scale reasoning-augmented data, and (2) an Adaptive Reinforcement Learning (Adaptive GRPO) stage, which optimizes reasoning behaviors based on task complexity and reward feedback. We further construct a comprehensive adaptive reasoning benchmark that spans text-only, text-audio, text-visual, and text-audio-visual modalities, providing both training and evaluation splits for multimodal reasoning assessment. Experimental results demonstrate that our proposed framework significantly improves adaptive reasoning performance compared to previous baselines. All benchmark data and code will be publicly released.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03783v1",
        "pdf": "https://arxiv.org/pdf/2512.03783v1"
      },
      "arxiv_id": "2512.03783v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03772v1",
      "title": "Bayesian Optimization for Automatic Tuning of Torque-Level Nonlinear Model Predictive Control",
      "authors": [
        "Gabriele Fadini",
        "Deepak Ingole",
        "Tong Duy Son",
        "Alisa Rupenyan"
      ],
      "abstract": "This paper presents an auto-tuning framework for torque-based Nonlinear Model Predictive Control (nMPC), where the MPC serves as a real-time controller for optimal joint torque commands. The MPC parameters, including cost function weights and low-level controller gains, are optimized using high-dimensional Bayesian Optimization (BO) techniques, specifically Sparse Axis-Aligned Subspace (SAASBO) with a digital twin (DT) to achieve precise end-effector trajectory real-time tracking on an UR10e robot arm. The simulation model allows efficient exploration of the high-dimensional parameter space, and it ensures safe transfer to hardware. Our simulation results demonstrate significant improvements in tracking performance (+41.9%) and reduction in solve times (-2.5%) compared to manually-tuned parameters. Moreover, experimental validation on the real robot follows the trend (with a +25.8% improvement), emphasizing the importance of digital twin-enabled automated parameter optimization for robotic operations.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.RO",
        "cs.AI",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03772v1",
        "pdf": "https://arxiv.org/pdf/2512.03772v1"
      },
      "arxiv_id": "2512.03772v1",
      "comment": "6 pages, 7 figures, 3 tables",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03771v1",
      "title": "In-Context Representation Hijacking",
      "authors": [
        "Itay Yona",
        "Amir Sarid",
        "Michael Karasik",
        "Yossi Gandelsman"
      ],
      "abstract": "We introduce \\textbf{Doublespeak}, a simple \\emph{in-context representation hijacking} attack against large language models (LLMs). The attack works by systematically replacing a harmful keyword (e.g., \\textit{bomb}) with a benign token (e.g., \\textit{carrot}) across multiple in-context examples, provided a prefix to a harmful request. We demonstrate that this substitution leads to the internal representation of the benign token converging toward that of the harmful one, effectively embedding the harmful semantics under a euphemism. As a result, superficially innocuous prompts (e.g., ``How to build a carrot?'') are internally interpreted as disallowed instructions (e.g., ``How to build a bomb?''), thereby bypassing the model's safety alignment. We use interpretability tools to show that this semantic overwrite emerges layer by layer, with benign meanings in early layers converging into harmful semantics in later ones. Doublespeak is optimization-free, broadly transferable across model families, and achieves strong success rates on closed-source and open-source systems, reaching 74\\% ASR on Llama-3.3-70B-Instruct with a single-sentence context override. Our findings highlight a new attack surface in the latent space of LLMs, revealing that current alignment strategies are insufficient and should instead operate at the representation level.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03771v1",
        "pdf": "https://arxiv.org/pdf/2512.03771v1"
      },
      "arxiv_id": "2512.03771v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03768v1",
      "title": "Deep Unfolding: Recent Developments, Theory, and Design Guidelines",
      "authors": [
        "Nir Shlezinger",
        "Santiago Segarra",
        "Yi Zhang",
        "Dvir Avrahami",
        "Zohar Davidov",
        "Tirza Routtenberg",
        "Yonina C. Eldar"
      ],
      "abstract": "Optimization methods play a central role in signal processing, serving as the mathematical foundation for inference, estimation, and control. While classical iterative optimization algorithms provide interpretability and theoretical guarantees, they often rely on surrogate objectives, require careful hyperparameter tuning, and exhibit substantial computational latency. Conversely, machine learning (ML ) offers powerful data-driven modeling capabilities but lacks the structure, transparency, and efficiency needed for optimization-driven inference. Deep unfolding has recently emerged as a compelling framework that bridges these two paradigms by systematically transforming iterative optimization algorithms into structured, trainable ML architectures. This article provides a tutorial-style overview of deep unfolding, presenting a unified perspective of methodologies for converting optimization solvers into ML models and highlighting their conceptual, theoretical, and practical implications. We review the foundations of optimization for inference and for learning, introduce four representative design paradigms for deep unfolding, and discuss the distinctive training schemes that arise from their iterative nature. Furthermore, we survey recent theoretical advances that establish convergence and generalization guarantees for unfolded optimizers, and provide comparative qualitative and empirical studies illustrating their relative trade-offs in complexity, interpretability, and robustness.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03768v1",
        "pdf": "https://arxiv.org/pdf/2512.03768v1"
      },
      "arxiv_id": "2512.03768v1",
      "comment": "under review for publication in the IEEE",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03762v1",
      "title": "RoCo: Role-Based LLMs Collaboration for Automatic Heuristic Design",
      "authors": [
        "Jiawei Xu",
        "Fengfeng Wei",
        "Weineng Chen"
      ],
      "abstract": "Automatic Heuristic Design (AHD) has gained traction as a promising solution for solving combinatorial optimization problems (COPs). Large Language Models (LLMs) have emerged and become a promising approach to achieving AHD, but current LLM-based AHD research often only considers a single role. This paper proposes RoCo, a novel Multi-Agent Role-Based System, to enhance the diversity and quality of AHD through multi-role collaboration. RoCo coordinates four specialized LLM-guided agents-explorer, exploiter, critic, and integrator-to collaboratively generate high-quality heuristics. The explorer promotes long-term potential through creative, diversity-driven thinking, while the exploiter focuses on short-term improvements via conservative, efficiency-oriented refinements. The critic evaluates the effectiveness of each evolution step and provides targeted feedback and reflection. The integrator synthesizes proposals from the explorer and exploiter, balancing innovation and exploitation to drive overall progress. These agents interact in a structured multi-round process involving feedback, refinement, and elite mutations guided by both short-term and accumulated long-term reflections. We evaluate RoCo on five different COPs under both white-box and black-box settings. Experimental results demonstrate that RoCo achieves superior performance, consistently generating competitive heuristics that outperform existing methods including ReEvo and HSEvo, both in white-box and black-box scenarios. This role-based collaborative paradigm establishes a new standard for robust and high-performing AHD.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03762v1",
        "pdf": "https://arxiv.org/pdf/2512.03762v1"
      },
      "arxiv_id": "2512.03762v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03759v1",
      "title": "Principled RL for Diffusion LLMs Emerges from a Sequence-Level Perspective",
      "authors": [
        "Jingyang Ou",
        "Jiaqi Han",
        "Minkai Xu",
        "Shaoxuan Xu",
        "Jianwen Xie",
        "Stefano Ermon",
        "Yi Wu",
        "Chongxuan Li"
      ],
      "abstract": "Reinforcement Learning (RL) has proven highly effective for autoregressive language models, but adapting these methods to diffusion large language models (dLLMs) presents fundamental challenges. The core difficulty lies in likelihood approximation: while autoregressive models naturally provide token-level conditional probabilities essential for token-level RL objectives (e.g., GRPO), dLLMs generate sequences through iterative non-autoregressive denoising steps that lack this factorization. To address this fundamental mismatch, we propose ELBO-based Sequence-level Policy Optimization (ESPO), a principled RL framework that treats entire sequence generation as a single action and uses the ELBO as a tractable sequence-level likelihood proxy. Our method incorporates per-token normalization of importance ratios and robust KL-divergence estimation to ensure stable large-scale training. Extensive experiments on mathematical reasoning, coding, and planning tasks demonstrate that ESPO significantly outperforms token-level baselines, achieving dramatic improvements of 20-40 points on the Countdown task, while maintaining consistent gains on math and coding benchmarks. Our approach establishes sequence-level optimization as a principled and empirically effective paradigm for RL in dLLMs. Our code is available at https://github.com/ML-GSAI/ESPO.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03759v1",
        "pdf": "https://arxiv.org/pdf/2512.03759v1"
      },
      "arxiv_id": "2512.03759v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03755v1",
      "title": "Origin-Conditional Trajectory Encoding: Measuring Urban Configurational Asymmetries through Neural Decomposition",
      "authors": [
        "Stephen Law",
        "Tao Yang",
        "Nanjiang Chen",
        "Xuhui Lin"
      ],
      "abstract": "Urban analytics increasingly relies on AI-driven trajectory analysis, yet current approaches suffer from methodological fragmentation: trajectory learning captures movement patterns but ignores spatial context, while spatial embedding methods encode street networks but miss temporal dynamics. Three gaps persist: (1) lack of joint training that integrates spatial and temporal representations, (2) origin-agnostic treatment that ignores directional asymmetries in navigation ($A \\to B \\ne B \\to A$), and (3) over-reliance on auxiliary data (POIs, imagery) rather than fundamental geometric properties of urban space. We introduce a conditional trajectory encoder that jointly learns spatial and movement representations while preserving origin-dependent asymmetries using geometric features. This framework decomposes urban navigation into shared cognitive patterns and origin-specific spatial narratives, enabling quantitative measurement of cognitive asymmetries across starting locations. Our bidirectional LSTM processes visibility ratio and curvature features conditioned on learnable origin embeddings, decomposing representations into shared urban patterns and origin-specific signatures through contrastive learning. Results from six synthetic cities and real-world validation on Beijing's Xicheng District demonstrate that urban morphology creates systematic cognitive inequalities. This provides urban planners quantitative tools for assessing experiential equity, offers architects insights into layout decisions' cognitive impacts, and enables origin-aware analytics for navigation systems.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03755v1",
        "pdf": "https://arxiv.org/pdf/2512.03755v1"
      },
      "arxiv_id": "2512.03755v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03752v1",
      "title": "A BTR-Based Approach for Detection of Infrared Small Targets",
      "authors": [
        "Ke-Xin Li"
      ],
      "abstract": "Infrared small target detection plays a crucial role in military reconnaissance and air defense systems. However,existing low-rank sparse based methods still face high computational complexity when dealing with low-contrast small targets and complex dynamic backgrounds mixed with target-like interference. To address this limitation, we reconstruct the data into a fourth-order tensor and propose a new infrared small target detection model based on bilateral tensor ring decomposition, called BTR-ISTD. The approach begins by constructing a four-dimensional infrared tensor from an image sequence, then utilizes BTR decomposition to effectively distinguish weak spatial correlations from strong temporal-patch correlations while simultaneously capturing interactions between these two components. This model is efficiently solved under the proximal alternating minimization (PAM) framework. Experimental results demonstrate that the proposed approach outperforms several state-of-the-art methods in terms of detection accuracy, background suppression capability, and computational speed.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "eess.IV"
      ],
      "primary_category": "eess.IV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03752v1",
        "pdf": "https://arxiv.org/pdf/2512.03752v1"
      },
      "arxiv_id": "2512.03752v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03751v1",
      "title": "Research on Brain Tumor Classification Method Based on Improved ResNet34 Network",
      "authors": [
        "Yufeng Li",
        "Wenchao Zhao",
        "Bo Dang",
        "Weimin Wang"
      ],
      "abstract": "Previously, image interpretation in radiology relied heavily on manual methods. However, manual classification of brain tumor medical images is time-consuming and labor-intensive. Even with shallow convolutional neural network models, the accuracy is not ideal. To improve the efficiency and accuracy of brain tumor image classification, this paper proposes a brain tumor classification model based on an improved ResNet34 network. This model uses the ResNet34 residual network as the backbone network and incorporates multi-scale feature extraction. It uses a multi-scale input module as the first layer of the ResNet34 network and an Inception v2 module as the residual downsampling layer. Furthermore, a channel attention mechanism module assigns different weights to different channels of the image from a channel domain perspective, obtaining more important feature information. The results after a five-fold crossover experiment show that the average classification accuracy of the improved network model is approximately 98.8%, which is not only 1% higher than ResNet34, but also only 80% of the number of parameters of the original model. Therefore, the improved network model not only improves accuracy but also reduces clutter, achieving a classification effect with fewer parameters and higher accuracy.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03751v1",
        "pdf": "https://arxiv.org/pdf/2512.03751v1"
      },
      "arxiv_id": "2512.03751v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03750v1",
      "title": "Universally Converging Representations of Matter Across Scientific Foundation Models",
      "authors": [
        "Sathya Edamadaka",
        "Soojung Yang",
        "Ju Li",
        "Rafael GÃ³mez-Bombarelli"
      ],
      "abstract": "Machine learning models of vastly different modalities and architectures are being trained to predict the behavior of molecules, materials, and proteins. However, it remains unclear whether they learn similar internal representations of matter. Understanding their latent structure is essential for building scientific foundation models that generalize reliably beyond their training domains. Although representational convergence has been observed in language and vision, its counterpart in the sciences has not been systematically explored. Here, we show that representations learned by nearly sixty scientific models, spanning string-, graph-, 3D atomistic, and protein-based modalities, are highly aligned across a wide range of chemical systems. Models trained on different datasets have highly similar representations of small molecules, and machine learning interatomic potentials converge in representation space as they improve in performance, suggesting that foundation models learn a common underlying representation of physical reality. We then show two distinct regimes of scientific models: on inputs similar to those seen during training, high-performing models align closely and weak models diverge into local sub-optima in representation space; on vastly different structures from those seen during training, nearly all models collapse onto a low-information representation, indicating that today's models remain limited by training data and inductive bias and do not yet encode truly universal structure. Our findings establish representational alignment as a quantitative benchmark for foundation-level generality in scientific models. More broadly, our work can track the emergence of universal representations of matter as models scale, and for selecting and distilling models whose learned representations transfer best across modalities, domains of matter, and scientific tasks.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.LG",
        "cond-mat.mtrl-sci"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03750v1",
        "pdf": "https://arxiv.org/pdf/2512.03750v1"
      },
      "arxiv_id": "2512.03750v1",
      "comment": "Oral spotlight at NeurIPS 2025 UniReps Workshop",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03749v1",
      "title": "Fully Unsupervised Self-debiasing of Text-to-Image Diffusion Models",
      "authors": [
        "Korada Sri Vardhana",
        "Shrikrishna Lolla",
        "Soma Biswas"
      ],
      "abstract": "Text-to-image (T2I) diffusion models have achieved widespread success due to their ability to generate high-resolution, photorealistic images. These models are trained on large-scale datasets, like LAION-5B, often scraped from the internet. However, since this data contains numerous biases, the models inherently learn and reproduce them, resulting in stereotypical outputs. We introduce SelfDebias, a fully unsupervised test-time debiasing method applicable to any diffusion model that uses a UNet as its noise predictor. SelfDebias identifies semantic clusters in an image encoder's embedding space and uses these clusters to guide the diffusion process during inference, minimizing the KL divergence between the output distribution and the uniform distribution. Unlike supervised approaches, SelfDebias does not require human-annotated datasets or external classifiers trained for each generated concept. Instead, it is designed to automatically identify semantic modes. Extensive experiments show that SelfDebias generalizes across prompts and diffusion model architectures, including both conditional and unconditional models. It not only effectively debiases images along key demographic dimensions while maintaining the visual fidelity of the generated images, but also more abstract concepts for which identifying biases is also challenging.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03749v1",
        "pdf": "https://arxiv.org/pdf/2512.03749v1"
      },
      "arxiv_id": "2512.03749v1",
      "comment": "Accepted at WACV 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03746v1",
      "title": "Thinking with Programming Vision: Towards a Unified View for Thinking with Images",
      "authors": [
        "Zirun Guo",
        "Minjie Hong",
        "Feng Zhang",
        "Kai Jia",
        "Tao Jin"
      ],
      "abstract": "Multimodal large language models (MLLMs) that think with images can interactively use tools to reason about visual inputs, but current approaches often rely on a narrow set of tools with limited real-world necessity and scalability. In this work, we first reveal a critical and previously overlooked weakness: even state-of-the-art MLLMs are surprisingly brittle, showing significant performance degradation on images with simple orientation changes or natural corruptions, underscoring the need for more robust tool-based reasoning. To address this, we propose CodeVision, a flexible and scalable code-as-tool framework where the model generates code as a universal interface to invoke any image operation, moving beyond fixed tool registries. We train our model using a two-stage methodology, beginning with Supervised Fine-Tuning (SFT) on a high-quality dataset curated for complex, multi-turn tool composition and error recovery, followed by Reinforcement Learning (RL) with a novel and dense process reward function to encourage strategic and efficient tool use. To facilitate this research, we construct new SFT and RL datasets and introduce a challenging new benchmark suite designed to rigorously evaluate robustness to orientation changes and multi-tool reasoning. Experiments on Qwen2.5-VL and Qwen3-VL series show that our approach significantly improves model performance and fosters emergent capabilities such as flexible tool composition, efficient chained execution, and robust error recovery from runtime feedback. Code is available at https://github.com/ByteDance-BandAI/CodeVision.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CV",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03746v1",
        "pdf": "https://arxiv.org/pdf/2512.03746v1"
      },
      "arxiv_id": "2512.03746v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03745v1",
      "title": "Dual-level Modality Debiasing Learning for Unsupervised Visible-Infrared Person Re-Identification",
      "authors": [
        "Jiaze Li",
        "Yan Lu",
        "Bin Liu",
        "Guojun Yin",
        "Mang Ye"
      ],
      "abstract": "Two-stage learning pipeline has achieved promising results in unsupervised visible-infrared person re-identification (USL-VI-ReID). It first performs single-modality learning and then operates cross-modality learning to tackle the modality discrepancy. Although promising, this pipeline inevitably introduces modality bias: modality-specific cues learned in the single-modality training naturally propagate into the following cross-modality learning, impairing identity discrimination and generalization. To address this issue, we propose a Dual-level Modality Debiasing Learning (DMDL) framework that implements debiasing at both the model and optimization levels. At the model level, we propose a Causality-inspired Adjustment Intervention (CAI) module that replaces likelihood-based modeling with causal modeling, preventing modality-induced spurious patterns from being introduced, leading to a low-biased model. At the optimization level, a Collaborative Bias-free Training (CBT) strategy is introduced to interrupt the propagation of modality bias across data, labels, and features by integrating modality-specific augmentation, label refinement, and feature alignment. Extensive experiments on benchmark datasets demonstrate that DMDL could enable modality-invariant feature learning and a more generalized model.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03745v1",
        "pdf": "https://arxiv.org/pdf/2512.03745v1"
      },
      "arxiv_id": "2512.03745v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03744v1",
      "title": "Unlocking the Invisible Urban Traffic Dynamics under Extreme Weather: A New Physics-Constrained Hamiltonian Learning Algorithm",
      "authors": [
        "Xuhui Lin",
        "Qiuchen Lu"
      ],
      "abstract": "Urban transportation systems face increasing resilience challenges from extreme weather events, but current assessment methods rely on surface-level recovery indicators that miss hidden structural damage. Existing approaches cannot distinguish between true recovery and \"false recovery,\" where traffic metrics normalize, but the underlying system dynamics permanently degrade. To address this, a new physics-constrained Hamiltonian learning algorithm combining \"structural irreversibility detection\" and \"energy landscape reconstruction\" has been developed. Our approach extracts low-dimensional state representations, identifies quasi-Hamiltonian structures through physics-constrained optimization, and quantifies structural changes via energy landscape comparison. Analysis of London's extreme rainfall in 2021 demonstrates that while surface indicators were fully recovered, our algorithm detected 64.8\\% structural damage missed by traditional monitoring. Our framework provides tools for proactive structural risk assessment, enabling infrastructure investments based on true system health rather than misleading surface metrics.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03744v1",
        "pdf": "https://arxiv.org/pdf/2512.03744v1"
      },
      "arxiv_id": "2512.03744v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03743v1",
      "title": "Cross-embodied Co-design for Dexterous Hands",
      "authors": [
        "Kehlani Fay",
        "Darin Anthony Djapri",
        "Anya Zorin",
        "James Clinton",
        "Ali El Lahib",
        "Hao Su",
        "Michael T. Tolley",
        "Sha Yi",
        "Xiaolong Wang"
      ],
      "abstract": "Dexterous manipulation is limited by both control and design, without consensus as to what makes manipulators best for performing dexterous tasks. This raises a fundamental challenge: how should we design and control robot manipulators that are optimized for dexterity? We present a co-design framework that learns task-specific hand morphology and complementary dexterous control policies. The framework supports 1) an expansive morphology search space including joint, finger, and palm generation, 2) scalable evaluation across the wide design space via morphology-conditioned cross-embodied control, and 3) real-world fabrication with accessible components. We evaluate the approach across multiple dexterous tasks, including in-hand rotation with simulation and real deployment. Our framework enables an end-to-end pipeline that can design, train, fabricate, and deploy a new robotic hand in under 24 hours. The full framework will be open-sourced and available on our website.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.RO",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03743v1",
        "pdf": "https://arxiv.org/pdf/2512.03743v1"
      },
      "arxiv_id": "2512.03743v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2512.03736v1",
      "title": "Crossing the Sim2Real Gap Between Simulation and Ground Testing to Space Deployment of Autonomous Free-flyer Control",
      "authors": [
        "Kenneth Stewart",
        "Samantha Chapin",
        "Roxana Leontie",
        "Carl Glen Henshaw"
      ],
      "abstract": "Reinforcement learning (RL) offers transformative potential for robotic control in space. We present the first on-orbit demonstration of RL-based autonomous control of a free-flying robot, the NASA Astrobee, aboard the International Space Station (ISS). Using NVIDIA's Omniverse physics simulator and curriculum learning, we trained a deep neural network to replace Astrobee's standard attitude and translation control, enabling it to navigate in microgravity. Our results validate a novel training pipeline that bridges the simulation-to-reality (Sim2Real) gap, utilizing a GPU-accelerated, scientific-grade simulation environment for efficient Monte Carlo RL training. This successful deployment demonstrates the feasibility of training RL policies terrestrially and transferring them to space-based applications. This paves the way for future work in In-Space Servicing, Assembly, and Manufacturing (ISAM), enabling rapid on-orbit adaptation to dynamic mission requirements.",
      "published": "2025-12-03",
      "updated": "2025-12-03",
      "categories": [
        "cs.RO",
        "cs.LG",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "links": {
        "paper": "http://arxiv.org/abs/2512.03736v1",
        "pdf": "https://arxiv.org/pdf/2512.03736v1"
      },
      "arxiv_id": "2512.03736v1",
      "comment": "published at iSpaRo 2025",
      "journal_ref": "",
      "has_code": false
    }
  ]
}