{
  "fetched_at": "2026-02-15T00:34:51.246010",
  "total_papers": 100,
  "papers": [
    {
      "id": "2602.12281v1",
      "title": "Scaling Verification Can Be More Effective than Scaling Policy Learning for Vision-Language-Action Alignment",
      "authors": [
        "Jacky Kwok",
        "Xilun Zhang",
        "Mengdi Xu",
        "Yuejiang Liu",
        "Azalia Mirhoseini",
        "Chelsea Finn",
        "Marco Pavone"
      ],
      "abstract": "The long-standing vision of general-purpose robots hinges on their ability to understand and act upon natural language instructions. Vision-Language-Action (VLA) models have made remarkable progress toward this goal, yet their generated actions can still misalign with the given instructions. In this paper, we investigate test-time verification as a means to shrink the \"intention-action gap.'' We first characterize the test-time scaling law for embodied instruction following and demonstrate that jointly scaling the number of rephrased instructions and generated actions greatly increases test-time sample diversity, often recovering correct actions more efficiently than scaling each dimension independently. To capitalize on these scaling laws, we present CoVer, a contrastive verifier for vision-language-action alignment, and show that our architecture scales gracefully with additional computational resources and data. We then introduce \"boot-time compute\" and a hierarchical verification inference pipeline for VLAs. At deployment, our framework precomputes a diverse set of rephrased instructions from a Vision-Language-Model (VLM), repeatedly generates action candidates for each instruction, and then uses a verifier to select the optimal high-level prompt and low-level action chunks. Compared to scaling policy pre-training on the same data, our verification approach yields 22% gains in-distribution and 13% out-of-distribution on the SIMPLER benchmark, with a further 45% improvement in real-world experiments. On the PolaRiS benchmark, CoVer achieves 14% gains in task progress and 9% in success rate.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.RO",
        "cs.AI",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12281v1",
        "pdf": "https://arxiv.org/pdf/2602.12281v1"
      },
      "arxiv_id": "2602.12281v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12280v1",
      "title": "Stroke of Surprise: Progressive Semantic Illusions in Vector Sketching",
      "authors": [
        "Huai-Hsun Cheng",
        "Siang-Ling Zhang",
        "Yu-Lun Liu"
      ],
      "abstract": "Visual illusions traditionally rely on spatial manipulations such as multi-view consistency. In this work, we introduce Progressive Semantic Illusions, a novel vector sketching task where a single sketch undergoes a dramatic semantic transformation through the sequential addition of strokes. We present Stroke of Surprise, a generative framework that optimizes vector strokes to satisfy distinct semantic interpretations at different drawing stages. The core challenge lies in the \"dual-constraint\": initial prefix strokes must form a coherent object (e.g., a duck) while simultaneously serving as the structural foundation for a second concept (e.g., a sheep) upon adding delta strokes. To address this, we propose a sequence-aware joint optimization framework driven by a dual-branch Score Distillation Sampling (SDS) mechanism. Unlike sequential approaches that freeze the initial state, our method dynamically adjusts prefix strokes to discover a \"common structural subspace\" valid for both targets. Furthermore, we introduce a novel Overlay Loss that enforces spatial complementarity, ensuring structural integration rather than occlusion. Extensive experiments demonstrate that our method significantly outperforms state-of-the-art baselines in recognizability and illusion strength, successfully expanding visual anagrams from the spatial to the temporal dimension. Project page: https://stroke-of-surprise.github.io/",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12280v1",
        "pdf": "https://arxiv.org/pdf/2602.12280v1"
      },
      "arxiv_id": "2602.12280v1",
      "comment": "Project page: https://stroke-of-surprise.github.io/ Code: https://github.com/stroke-of-surprise/Stroke-Of-Surprise",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2602.12279v1",
      "title": "UniT: Unified Multimodal Chain-of-Thought Test-time Scaling",
      "authors": [
        "Leon Liangyu Chen",
        "Haoyu Ma",
        "Zhipeng Fan",
        "Ziqi Huang",
        "Animesh Sinha",
        "Xiaoliang Dai",
        "Jialiang Wang",
        "Zecheng He",
        "Jianwei Yang",
        "Chunyuan Li",
        "Junzhe Sun",
        "Chu Wang",
        "Serena Yeung-Levy",
        "Felix Juefei-Xu"
      ],
      "abstract": "Unified models can handle both multimodal understanding and generation within a single architecture, yet they typically operate in a single pass without iteratively refining their outputs. Many multimodal tasks, especially those involving complex spatial compositions, multiple interacting objects, or evolving instructions, require decomposing instructions, verifying intermediate results, and making iterative corrections. While test-time scaling (TTS) has demonstrated that allocating additional inference compute for iterative reasoning substantially improves language model performance, extending this paradigm to unified multimodal models remains an open challenge. We introduce UniT, a framework for multimodal chain-of-thought test-time scaling that enables a single unified model to reason, verify, and refine across multiple rounds. UniT combines agentic data synthesis, unified model training, and flexible test-time inference to elicit cognitive behaviors including verification, subgoal decomposition, and content memory. Our key findings are: (1) unified models trained on short reasoning trajectories generalize to longer inference chains at test time; (2) sequential chain-of-thought reasoning provides a more scalable and compute-efficient TTS strategy than parallel sampling; (3) training on generation and editing trajectories improves out-of-distribution visual reasoning. These results establish multimodal test-time scaling as an effective paradigm for advancing both generation and understanding in unified models.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12279v1",
        "pdf": "https://arxiv.org/pdf/2602.12279v1"
      },
      "arxiv_id": "2602.12279v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12278v1",
      "title": "AttentionRetriever: Attention Layers are Secretly Long Document Retrievers",
      "authors": [
        "David Jiahao Fu",
        "Lam Thanh Do",
        "Jiayu Li",
        "Kevin Chen-Chuan Chang"
      ],
      "abstract": "Retrieval augmented generation (RAG) has been widely adopted to help Large Language Models (LLMs) to process tasks involving long documents. However, existing retrieval models are not designed for long document retrieval and fail to address several key challenges of long document retrieval, including context-awareness, causal dependence, and scope of retrieval. In this paper, we proposed AttentionRetriever, a novel long document retrieval model that leverages attention mechanism and entity-based retrieval to build context-aware embeddings for long document and determine the scope of retrieval. With extensive experiments, we found AttentionRetriever is able to outperform existing retrieval models on long document retrieval datasets by a large margin while remaining as efficient as dense retrieval models.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12278v1",
        "pdf": "https://arxiv.org/pdf/2602.12278v1"
      },
      "arxiv_id": "2602.12278v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12276v1",
      "title": "Agentic Test-Time Scaling for WebAgents",
      "authors": [
        "Nicholas Lee",
        "Lutfi Eren Erdogan",
        "Chris Joseph John",
        "Surya Krishnapillai",
        "Michael W. Mahoney",
        "Kurt Keutzer",
        "Amir Gholami"
      ],
      "abstract": "Test-time scaling has become a standard way to improve performance and boost reliability of neural network models. However, its behavior on agentic, multi-step tasks remains less well-understood: small per-step errors can compound over long horizons; and we find that naive policies that uniformly increase sampling show diminishing returns. In this work, we present CATTS, a simple technique for dynamically allocating compute for multi-step agents. We first conduct an empirical study of inference-time scaling for web agents. We find that uniformly increasing per-step compute quickly saturates in long-horizon environments. We then investigate stronger aggregation strategies, including an LLM-based Arbiter that can outperform naive voting, but that can overrule high-consensus decisions. We show that uncertainty statistics derived from the agent's own vote distribution (entropy and top-1/top-2 margin) correlate with downstream success and provide a practical signal for dynamic compute allocation. Based on these findings, we introduce Confidence-Aware Test-Time Scaling (CATTS), which uses vote-derived uncertainty to allocate compute only when decisions are genuinely contentious. CATTS improves performance on WebArena-Lite and GoBrowse by up to 9.1% over React while using up to 2.3x fewer tokens than uniform scaling, providing both efficiency gains and an interpretable decision rule.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12276v1",
        "pdf": "https://arxiv.org/pdf/2602.12276v1"
      },
      "arxiv_id": "2602.12276v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12274v1",
      "title": "Function-Space Decoupled Diffusion for Forward and Inverse Modeling in Carbon Capture and Storage",
      "authors": [
        "Xin Ju",
        "Jiachen Yao",
        "Anima Anandkumar",
        "Sally M. Benson",
        "Gege Wen"
      ],
      "abstract": "Accurate characterization of subsurface flow is critical for Carbon Capture and Storage (CCS) but remains challenged by the ill-posed nature of inverse problems with sparse observations. We present Fun-DDPS, a generative framework that combines function-space diffusion models with differentiable neural operator surrogates for both forward and inverse modeling. Our approach learns a prior distribution over geological parameters (geomodel) using a single-channel diffusion model, then leverages a Local Neural Operator (LNO) surrogate to provide physics-consistent guidance for cross-field conditioning on the dynamics field. This decoupling allows the diffusion prior to robustly recover missing information in parameter space, while the surrogate provides efficient gradient-based guidance for data assimilation. We demonstrate Fun-DDPS on synthetic CCS modeling datasets, achieving two key results: (1) For forward modeling with only 25% observations, Fun-DDPS achieves 7.7% relative error compared to 86.9% for standard surrogates (an 11x improvement), proving its capability to handle extreme data sparsity where deterministic methods fail. (2) We provide the first rigorous validation of diffusion-based inverse solvers against asymptotically exact Rejection Sampling (RS) posteriors. Both Fun-DDPS and the joint-state baseline (Fun-DPS) achieve Jensen-Shannon divergence less than 0.06 against the ground truth. Crucially, Fun-DDPS produces physically consistent realizations free from the high-frequency artifacts observed in joint-state baselines, achieving this with 4x improved sample efficiency compared to rejection sampling.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.LG",
        "physics.geo-ph"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12274v1",
        "pdf": "https://arxiv.org/pdf/2602.12274v1"
      },
      "arxiv_id": "2602.12274v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12273v1",
      "title": "Learning to Control: The iUzawa-Net for Nonsmooth Optimal Control of Linear PDEs",
      "authors": [
        "Yongcun Song",
        "Xiaoming Yuan",
        "Hangrui Yue",
        "Tianyou Zeng"
      ],
      "abstract": "We propose an optimization-informed deep neural network approach, named iUzawa-Net, aiming for the first solver that enables real-time solutions for a class of nonsmooth optimal control problems of linear partial differential equations (PDEs). The iUzawa-Net unrolls an inexact Uzawa method for saddle point problems, replacing classical preconditioners and PDE solvers with specifically designed learnable neural networks. We prove universal approximation properties and establish the asymptotic $\\varepsilon$-optimality for the iUzawa-Net, and validate its promising numerical efficiency through nonsmooth elliptic and parabolic optimal control problems. Our techniques offer a versatile framework for designing and analyzing various optimization-informed deep learning approaches to optimal control and other PDE-constrained optimization problems. The proposed learning-to-control approach synergizes model-based optimization algorithms and data-driven deep learning techniques, inheriting the merits of both methodologies.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "math.OC",
        "cs.LG",
        "math.NA"
      ],
      "primary_category": "math.OC",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12273v1",
        "pdf": "https://arxiv.org/pdf/2602.12273v1"
      },
      "arxiv_id": "2602.12273v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12271v1",
      "title": "MonarchRT: Efficient Attention for Real-Time Video Generation",
      "authors": [
        "Krish Agarwal",
        "Zhuoming Chen",
        "Cheng Luo",
        "Yongqi Chen",
        "Haizhong Zheng",
        "Xun Huang",
        "Atri Rudra",
        "Beidi Chen"
      ],
      "abstract": "Real-time video generation with Diffusion Transformers is bottlenecked by the quadratic cost of 3D self-attention, especially in real-time regimes that are both few-step and autoregressive, where errors compound across time and each denoising step must carry substantially more information. In this setting, we find that prior sparse-attention approximations break down, despite showing strong results for bidirectional, many-step diffusion. Specifically, we observe that video attention is not reliably sparse, but instead combines pronounced periodic structure driven by spatiotemporal position with dynamic, sparse semantic correspondences and dense mixing, exceeding the representational capacity of even oracle top-k attention. Building on this insight, we propose Monarch-RT, a structured attention parameterization for video diffusion models that factorizes attention using Monarch matrices. Through appropriately aligned block structure and our extended tiled Monarch parameterization, we achieve high expressivity while preserving computational efficiency. We further overcome the overhead of parameterization through finetuning, with custom Triton kernels. We first validate the high efficacy of Monarch-RT over existing sparse baselines designed only for bidirectional models. We further observe that Monarch-RT attains up to 95% attention sparsity with no loss in quality when applied to the state-of-the-art model Self-Forcing, making Monarch-RT a pioneering work on highly-capable sparse attention parameterization for real-time video generation. Our optimized implementation outperforms FlashAttention-2, FlashAttention-3, and FlashAttention-4 kernels on Nvidia RTX 5090, H100, and B200 GPUs respectively, providing kernel speedups in the range of 1.4-11.8X. This enables us, for the first time, to achieve true real-time video generation with Self-Forcing at 16 FPS on a single RTX 5090.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12271v1",
        "pdf": "https://arxiv.org/pdf/2602.12271v1"
      },
      "arxiv_id": "2602.12271v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12270v1",
      "title": "Creative Ownership in the Age of AI",
      "authors": [
        "Annie Liang",
        "Jay Lu"
      ],
      "abstract": "Copyright law focuses on whether a new work is \"substantially similar\" to an existing one, but generative AI can closely imitate style without copying content, a capability now central to ongoing litigation. We argue that existing definitions of infringement are ill-suited to this setting and propose a new criterion: a generative AI output infringes on an existing work if it could not have been generated without that work in its training corpus. To operationalize this definition, we model generative systems as closure operators mapping a corpus of existing works to an output of new works. AI generated outputs are \\emph{permissible} if they do not infringe on any existing work according to our criterion. Our results characterize structural properties of permissible generation and reveal a sharp asymptotic dichotomy: when the process of organic creations is light-tailed, dependence on individual works eventually vanishes, so that regulation imposes no limits on AI generation; with heavy-tailed creations, regulation can be persistently constraining.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "econ.TH",
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "econ.TH",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12270v1",
        "pdf": "https://arxiv.org/pdf/2602.12270v1"
      },
      "arxiv_id": "2602.12270v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12268v1",
      "title": "CM2: Reinforcement Learning with Checklist Rewards for Multi-Turn and Multi-Step Agentic Tool Use",
      "authors": [
        "Zhen Zhang",
        "Kaiqiang Song",
        "Xun Wang",
        "Yebowen Hu",
        "Weixiang Yan",
        "Chenyang Zhao",
        "Henry Peng Zou",
        "Haoyun Deng",
        "Sathish Reddy Indurthi",
        "Shujian Liu",
        "Simin Ma",
        "Xiaoyang Wang",
        "Xin Eric Wang",
        "Song Wang"
      ],
      "abstract": "AI agents are increasingly used to solve real-world tasks by reasoning over multi-turn user interactions and invoking external tools. However, applying reinforcement learning to such settings remains difficult: realistic objectives often lack verifiable rewards and instead emphasize open-ended behaviors; moreover, RL for multi-turn, multi-step agentic tool use is still underexplored; and building and maintaining executable tool environments is costly, limiting scale and coverage. We propose CM2, an RL framework that replaces verifiable outcome rewards with checklist rewards. CM2 decomposes each turn's intended behavior into fine-grained binary criteria with explicit evidence grounding and structured metadata, turning open-ended judging into more stable classification-style decisions. To balance stability and informativeness, our method adopts a strategy of sparse reward assignment but dense evaluation criteria. Training is performed in a scalable LLM-simulated tool environment, avoiding heavy engineering for large tool sets. Experiments show that CM2 consistently improves over supervised fine-tuning. Starting from an 8B Base model and training on an 8k-example RL dataset, CM2 improves over the SFT counterpart by 8 points on tau^-Bench, by 10 points on BFCL-V4, and by 12 points on ToolSandbox. The results match or even outperform similarly sized open-source baselines, including the judging model. CM2 thus provides a scalable recipe for optimizing multi-turn, multi-step tool-using agents without relying on verifiable rewards. Code provided by the open-source community: https://github.com/namezhenzhang/CM2-RLCR-Tool-Agent.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12268v1",
        "pdf": "https://arxiv.org/pdf/2602.12268v1"
      },
      "arxiv_id": "2602.12268v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12267v1",
      "title": "Self-Supervised Learning via Flow-Guided Neural Operator on Time-Series Data",
      "authors": [
        "Duy Nguyen",
        "Jiachen Yao",
        "Jiayun Wang",
        "Julius Berner",
        "Animashree Anandkumar"
      ],
      "abstract": "Self-supervised learning (SSL) is a powerful paradigm for learning from unlabeled time-series data. However, popular methods such as masked autoencoders (MAEs) rely on reconstructing inputs from a fixed, predetermined masking ratio. Instead of this static design, we propose treating the corruption level as a new degree of freedom for representation learning, enhancing flexibility and performance. To achieve this, we introduce the Flow-Guided Neural Operator (FGNO), a novel framework combining operator learning with flow matching for SSL training. FGNO learns mappings in functional spaces by using Short-Time Fourier Transform to unify different time resolutions. We extract a rich hierarchy of features by tapping into different network layers and flow times that apply varying strengths of noise to the input data. This enables the extraction of versatile representations, from low-level patterns to high-level global features, using a single model adaptable to specific tasks. Unlike prior generative SSL methods that use noisy inputs during inference, we propose using clean inputs for representation extraction while learning representations with noise; this eliminates randomness and boosts accuracy. We evaluate FGNO across three biomedical domains, where it consistently outperforms established baselines. Our method yields up to 35% AUROC gains in neural signal decoding (BrainTreeBank), 16% RMSE reductions in skin temperature prediction (DREAMT), and over 20% improvement in accuracy and macro-F1 on SleepEDF under low-data regimes. These results highlight FGNO's robustness to data scarcity and its superior capacity to learn expressive representations for diverse time series.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12267v1",
        "pdf": "https://arxiv.org/pdf/2602.12267v1"
      },
      "arxiv_id": "2602.12267v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12262v1",
      "title": "T3D: Few-Step Diffusion Language Models via Trajectory Self-Distillation with Direct Discriminative Optimization",
      "authors": [
        "Tunyu Zhang",
        "Xinxi Zhang",
        "Ligong Han",
        "Haizhou Shi",
        "Xiaoxiao He",
        "Zhuowei Li",
        "Hao Wang",
        "Kai Xu",
        "Akash Srivastava",
        "Hao Wang",
        "Vladimir Pavlovic",
        "Dimitris N. Metaxas"
      ],
      "abstract": "Diffusion large language models (DLLMs) have the potential to enable fast text generation by decoding multiple tokens in parallel. However, in practice, their inference efficiency is constrained by the need for many refinement steps, while aggressively reducing the number of steps leads to a substantial degradation in generation quality. To alleviate this, we propose a trajectory self-distillation framework that improves few-step decoding by distilling the model's own generative trajectories. We incorporate Direct Discriminative Optimization (DDO), a reverse-KL objective that promotes mode-seeking distillation and encourages the student to concentrate on high-probability teacher modes. Across benchmarks, our approach consistently outperforms strong few-step baselines and standard training under tight step budgets. Although full-step decoding remains superior, we substantially narrow the gap, establishing a strong foundation towards practical few-step DLLMs. The source code is available at https://github.com/Tyrion58/T3D.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12262v1",
        "pdf": "https://arxiv.org/pdf/2602.12262v1"
      },
      "arxiv_id": "2602.12262v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12259v1",
      "title": "Think like a Scientist: Physics-guided LLM Agent for Equation Discovery",
      "authors": [
        "Jianke Yang",
        "Ohm Venkatachalam",
        "Mohammad Kianezhad",
        "Sharvaree Vadgama",
        "Rose Yu"
      ],
      "abstract": "Explaining observed phenomena through symbolic, interpretable formulas is a fundamental goal of science. Recently, large language models (LLMs) have emerged as promising tools for symbolic equation discovery, owing to their broad domain knowledge and strong reasoning capabilities. However, most existing LLM-based systems try to guess equations directly from data, without modeling the multi-step reasoning process that scientists often follow: first inferring physical properties such as symmetries, then using these as priors to restrict the space of candidate equations. We introduce KeplerAgent, an agentic framework that explicitly follows this scientific reasoning process. The agent coordinates physics-based tools to extract intermediate structure and uses these results to configure symbolic regression engines such as PySINDy and PySR, including their function libraries and structural constraints. Across a suite of physical equation benchmarks, KeplerAgent achieves substantially higher symbolic accuracy and greater robustness to noisy data than both LLM and traditional baselines.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12259v1",
        "pdf": "https://arxiv.org/pdf/2602.12259v1"
      },
      "arxiv_id": "2602.12259v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12257v1",
      "title": "On the implicit regularization of Langevin dynamics with projected noise",
      "authors": [
        "Govind Menon",
        "Austin J. Stromme",
        "Adrien Vacher"
      ],
      "abstract": "We study Langevin dynamics with noise projected onto the directions orthogonal to an isometric group action. This mathematical model is introduced to shed new light on the effects of symmetry on stochastic gradient descent for over-parametrized models. Our main result identifies a novel form of implicit regularization: when the initial and target density are both invariant under the group action, Langevin dynamics with projected noise is equivalent in law to Langevin dynamics with isotropic diffusion but with an additional drift term proportional to the negative log volume of the group orbit. We prove this result by constructing a coupling of the two processes via a third process on the group itself, and identify the additional drift as the mean curvature of the orbits.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "math.PR",
        "cs.AI"
      ],
      "primary_category": "math.PR",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12257v1",
        "pdf": "https://arxiv.org/pdf/2602.12257v1"
      },
      "arxiv_id": "2602.12257v1",
      "comment": "30 pages, 1 figure",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12253v1",
      "title": "Is Online Linear Optimization Sufficient for Strategic Robustness?",
      "authors": [
        "Yang Cai",
        "Haipeng Luo",
        "Chen-Yu Wei",
        "Weiqiang Zheng"
      ],
      "abstract": "We consider bidding in repeated Bayesian first-price auctions. Bidding algorithms that achieve optimal regret have been extensively studied, but their strategic robustness to the seller's manipulation remains relatively underexplored. Bidding algorithms based on no-swap-regret algorithms achieve both desirable properties, but are suboptimal in terms of statistical and computational efficiency. In contrast, online gradient ascent is the only algorithm that achieves $O(\\sqrt{TK})$ regret and strategic robustness [KSS24], where $T$ denotes the number of auctions and $K$ the number of bids.\n  In this paper, we explore whether simple online linear optimization (OLO) algorithms suffice for bidding algorithms with both desirable properties. Our main result shows that sublinear linearized regret is sufficient for strategic robustness. Specifically, we construct simple black-box reductions that convert any OLO algorithm into a strategically robust no-regret bidding algorithm, in both known and unknown value distribution settings. For the known value distribution case, our reduction yields a bidding algorithm that achieves $O(\\sqrt{T \\log K})$ regret and strategic robustness (with exponential improvement on the $K$-dependence compared to [KSS24]). For the unknown value distribution case, our reduction gives a bidding algorithm with high-probability $O(\\sqrt{T (\\log K+\\log(T/δ)})$ regret and strategic robustness, while removing the bounded density assumption made in [KSS24].",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.GT",
        "cs.LG"
      ],
      "primary_category": "cs.GT",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12253v1",
        "pdf": "https://arxiv.org/pdf/2602.12253v1"
      },
      "arxiv_id": "2602.12253v1",
      "comment": "26 pages",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12251v1",
      "title": "A technical curriculum on language-oriented artificial intelligence in translation and specialised communication",
      "authors": [
        "Ralph Krüger"
      ],
      "abstract": "This paper presents a technical curriculum on language-oriented artificial intelligence (AI) in the language and translation (L&T) industry. The curriculum aims to foster domain-specific technical AI literacy among stakeholders in the fields of translation and specialised communication by exposing them to the conceptual and technical/algorithmic foundations of modern language-oriented AI in an accessible way. The core curriculum focuses on 1) vector embeddings, 2) the technical foundations of neural networks, 3) tokenization and 4) transformer neural networks. It is intended to help users develop computational thinking as well as algorithmic awareness and algorithmic agency, ultimately contributing to their digital resilience in AI-driven work environments. The didactic suitability of the curriculum was tested in an AI-focused MA course at the Institute of Translation and Multilingual Communication at TH Koeln. Results suggest the didactic effectiveness of the curriculum, but participant feedback indicates that it should be embedded into higher-level didactic scaffolding - e.g., in the form of lecturer support - in order to enable optimal learning conditions.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12251v1",
        "pdf": "https://arxiv.org/pdf/2602.12251v1"
      },
      "arxiv_id": "2602.12251v1",
      "comment": "10 pages, 1 figure, EAMT 2026, TAITT Workshop",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12250v1",
      "title": "Community Concealment from Unsupervised Graph Learning-Based Clustering",
      "authors": [
        "Dalyapraz Manatova",
        "Pablo Moriano",
        "L. Jean Camp"
      ],
      "abstract": "Graph neural networks (GNNs) are designed to use attributed graphs to learn representations. Such representations are beneficial in the unsupervised learning of clusters and community detection. Nonetheless, such inference may reveal sensitive groups, clustered systems, or collective behaviors, raising concerns regarding group-level privacy. Community attribution in social and critical infrastructure networks, for example, can expose coordinated asset groups, operational hierarchies, and system dependencies that could be used for profiling or intelligence gathering. We study a defensive setting in which a data publisher (defender) seeks to conceal a community of interest while making limited, utility-aware changes in the network. Our analysis indicates that community concealment is strongly influenced by two quantifiable factors: connectivity at the community boundary and feature similarity between the protected community and adjacent communities. Informed by these findings, we present a perturbation strategy that rewires a set of selected edges and modifies node features to reduce the distinctiveness leveraged by GNN message passing. The proposed method outperforms DICE in our experiments on synthetic benchmarks and real network graphs under identical perturbation budgets. Overall, it achieves median relative concealment improvements of approximately 20-45% across the evaluated settings. These findings demonstrate a mitigation strategy against GNN-based community learning and highlight group-level privacy risks intrinsic to graph learning.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.LG",
        "cs.CR",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12250v1",
        "pdf": "https://arxiv.org/pdf/2602.12250v1"
      },
      "arxiv_id": "2602.12250v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12249v1",
      "title": "\"Sorry, I Didn't Catch That\": How Speech Models Miss What Matters Most",
      "authors": [
        "Kaitlyn Zhou",
        "Martijn Bartelds",
        "Federico Bianchi",
        "James Zou"
      ],
      "abstract": "Despite speech recognition systems achieving low word error rates on standard benchmarks, they often fail on short, high-stakes utterances in real-world deployments. Here, we study this failure mode in a high-stakes task: the transcription of U.S. street names as spoken by U.S. participants. We evaluate 15 models from OpenAI, Deepgram, Google, and Microsoft on recordings from linguistically diverse U.S. speakers and find an average transcription error rate of 44%. We quantify the downstream impact of failed transcriptions by geographic locations and show that mis-transcriptions systematically cause errors for all speakers, but that routing distance errors are twice as large for non-English primary speakers compared to English primary speakers. To mitigate this harm, we introduce a synthetic data generation approach that produces diverse pronunciations of named entities using open-source text-to-speech models. Fine-tuning with less than 1,000 synthetic samples improves street name transcription accuracy by nearly 60% (relative to base models) for non-English primary speakers. Our results highlight a critical gap between benchmark performance and real-world reliability in speech systems and demonstrate a simple, scalable path to reducing high-stakes transcription errors.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12249v1",
        "pdf": "https://arxiv.org/pdf/2602.12249v1"
      },
      "arxiv_id": "2602.12249v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12247v1",
      "title": "ExtractBench: A Benchmark and Evaluation Methodology for Complex Structured Extraction",
      "authors": [
        "Nick Ferguson",
        "Josh Pennington",
        "Narek Beghian",
        "Aravind Mohan",
        "Douwe Kiela",
        "Sheshansh Agrawal",
        "Thien Hang Nguyen"
      ],
      "abstract": "Unstructured documents like PDFs contain valuable structured information, but downstream systems require this data in reliable, standardized formats. LLMs are increasingly deployed to automate this extraction, making accuracy and reliability paramount. However, progress is bottlenecked by two gaps. First, no end-to-end benchmark evaluates PDF-to-JSON extraction under enterprise-scale schema breadth. Second, no principled methodology captures the semantics of nested extraction, where fields demand different notions of correctness (exact match for identifiers, tolerance for quantities, semantic equivalence for names), arrays require alignment, and omission must be distinguished from hallucination. We address both gaps with ExtractBench, an open-source benchmark and evaluation framework for PDF-to-JSON structured extraction. The benchmark pairs 35 PDF documents with JSON Schemas and human-annotated gold labels across economically valuable domains, yielding 12,867 evaluatable fields spanning schema complexities from tens to hundreds of fields. The evaluation framework treats the schema as an executable specification: each field declares its scoring metric. Baseline evaluations reveal that frontier models (GPT-5/5.2, Gemini-3 Flash/Pro, Claude 4.5 Opus/Sonnet) remain unreliable on realistic schemas. Performance degrades sharply with schema breadth, culminating in 0% valid output on a 369-field financial reporting schema across all tested models. We release ExtractBench at https://github.com/ContextualAI/extract-bench.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12247v1",
        "pdf": "https://arxiv.org/pdf/2602.12247v1"
      },
      "arxiv_id": "2602.12247v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12245v1",
      "title": "Intrinsic-Energy Joint Embedding Predictive Architectures Induce Quasimetric Spaces",
      "authors": [
        "Anthony Kobanda",
        "Waris Radji"
      ],
      "abstract": "Joint-Embedding Predictive Architectures (JEPAs) aim to learn representations by predicting target embeddings from context embeddings, inducing a scalar compatibility energy in a latent space. In contrast, Quasimetric Reinforcement Learning (QRL) studies goal-conditioned control through directed distance values (cost-to-go) that support reaching goals under asymmetric dynamics. In this short article, we connect these viewpoints by restricting attention to a principled class of JEPA energy functions : intrinsic (least-action) energies, defined as infima of accumulated local effort over admissible trajectories between two states. Under mild closure and additivity assumptions, any intrinsic energy is a quasimetric. In goal-reaching control, optimal cost-to-go functions admit exactly this intrinsic form ; inversely, JEPAs trained to model intrinsic energies lie in the quasimetric value class targeted by QRL. Moreover, we observe why symmetric finite energies are structurally mismatched with one-way reachability, motivating asymmetric (quasimetric) energies when directionality matters.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12245v1",
        "pdf": "https://arxiv.org/pdf/2602.12245v1"
      },
      "arxiv_id": "2602.12245v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12241v1",
      "title": "Moonshine v2: Ergodic Streaming Encoder ASR for Latency-Critical Speech Applications",
      "authors": [
        "Manjunath Kudlur",
        "Evan King",
        "James Wang",
        "Pete Warden"
      ],
      "abstract": "Latency-critical speech applications (e.g., live transcription, voice commands, and real-time translation) demand low time-to-first-token (TTFT) and high transcription accuracy, particularly on resource-constrained edge devices. Full-attention Transformer encoders remain a strong accuracy baseline for automatic speech recognition (ASR) because every frame can directly attend to every other frame, which resolves otherwise locally ambiguous acoustics using distant lexical context. However, this global dependency incurs quadratic complexity in sequence length, inducing an inherent \"encode-the-whole-utterance\" latency profile. For streaming use cases, this causes TTFT to grow linearly with utterance length as the encoder must process the entire prefix before any decoder token can be emitted. To better meet the needs of on-device, streaming ASR use cases we introduce Moonshine v2, an ergodic streaming-encoder ASR model that employs sliding-window self-attention to achieve bounded, low-latency inference while preserving strong local context. Our models achieve state of the art word error rates across standard benchmarks, attaining accuracy on-par with models 6x their size while running significantly faster. These results demonstrate that carefully designed local attention is competitive with the accuracy of full attention at a fraction of the size and latency cost, opening new possibilities for interactive speech interfaces on edge devices.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.CL",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12241v1",
        "pdf": "https://arxiv.org/pdf/2602.12241v1"
      },
      "arxiv_id": "2602.12241v1",
      "comment": "7 pages, 5 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12237v1",
      "title": "Olmix: A Framework for Data Mixing Throughout LM Development",
      "authors": [
        "Mayee F. Chen",
        "Tyler Murray",
        "David Heineman",
        "Matt Jordan",
        "Hannaneh Hajishirzi",
        "Christopher Ré",
        "Luca Soldaini",
        "Kyle Lo"
      ],
      "abstract": "Data mixing -- determining the ratios of data from different domains -- is a first-order concern for training language models (LMs). While existing mixing methods show promise, they fall short when applied during real-world LM development. We present Olmix, a framework that addresses two such challenges. First, the configuration space for developing a mixing method is not well understood -- design choices across existing methods lack justification or consensus and overlook practical issues like data constraints. We conduct a comprehensive empirical study of this space, identifying which design choices lead to a strong mixing method. Second, in practice, the domain set evolves throughout LM development as datasets are added, removed, partitioned, and revised -- a problem setting largely unaddressed by existing works, which assume fixed domains. We study how to efficiently recompute the mixture after the domain set is updated, leveraging information from past mixtures. We introduce mixture reuse, a mechanism that reuses existing ratios and recomputes ratios only for domains affected by the update. Over a sequence of five domain-set updates mirroring real-world LM development, mixture reuse matches the performance of fully recomputing the mix after each update with 74% less compute and improves over training without mixing by 11.6% on downstream tasks.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12237v1",
        "pdf": "https://arxiv.org/pdf/2602.12237v1"
      },
      "arxiv_id": "2602.12237v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12236v1",
      "title": "Energy-Aware Spike Budgeting for Continual Learning in Spiking Neural Networks for Neuromorphic Vision",
      "authors": [
        "Anika Tabassum Meem",
        "Muntasir Hossain Nadid",
        "Md Zesun Ahmed Mia"
      ],
      "abstract": "Neuromorphic vision systems based on spiking neural networks (SNNs) offer ultra-low-power perception for event-based and frame-based cameras, yet catastrophic forgetting remains a critical barrier to deployment in continually evolving environments. Existing continual learning methods, developed primarily for artificial neural networks, seldom jointly optimize accuracy and energy efficiency, with particularly limited exploration on event-based datasets. We propose an energy-aware spike budgeting framework for continual SNN learning that integrates experience replay, learnable leaky integrate-and-fire neuron parameters, and an adaptive spike scheduler to enforce dataset-specific energy constraints during training. Our approach exhibits modality-dependent behavior: on frame-based datasets (MNIST, CIFAR-10), spike budgeting acts as a sparsity-inducing regularizer, improving accuracy while reducing spike rates by up to 47\\%; on event-based datasets (DVS-Gesture, N-MNIST, CIFAR-10-DVS), controlled budget relaxation enables accuracy gains up to 17.45 percentage points with minimal computational overhead. Across five benchmarks spanning both modalities, our method demonstrates consistent performance improvements while minimizing dynamic power consumption, advancing the practical viability of continual learning in neuromorphic vision systems.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.NE",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12236v1",
        "pdf": "https://arxiv.org/pdf/2602.12236v1"
      },
      "arxiv_id": "2602.12236v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12233v1",
      "title": "Categorical Flow Maps",
      "authors": [
        "Daan Roos",
        "Oscar Davis",
        "Floor Eijkelboom",
        "Michael Bronstein",
        "Max Welling",
        "İsmail İlkan Ceylan",
        "Luca Ambrogioni",
        "Jan-Willem van de Meent"
      ],
      "abstract": "We introduce Categorical Flow Maps, a flow-matching method for accelerated few-step generation of categorical data via self-distillation. Building on recent variational formulations of flow matching and the broader trend towards accelerated inference in diffusion and flow-based models, we define a flow map towards the simplex that transports probability mass toward a predicted endpoint, yielding a parametrisation that naturally constrains model predictions. Since our trajectories are continuous rather than discrete, Categorical Flow Maps can be trained with existing distillation techniques, as well as a new objective based on endpoint consistency. This continuous formulation also automatically unlocks test-time inference: we can directly reuse existing guidance and reweighting techniques in the categorical setting to steer sampling toward downstream objectives. Empirically, we achieve state-of-the-art few-step results on images, molecular graphs, and text, with strong performance even in single-step generation.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12233v1",
        "pdf": "https://arxiv.org/pdf/2602.12233v1"
      },
      "arxiv_id": "2602.12233v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12229v1",
      "title": "Diffusion Alignment Beyond KL: Variance Minimisation as Effective Policy Optimiser",
      "authors": [
        "Zijing Ou",
        "Jacob Si",
        "Junyi Zhu",
        "Ondrej Bohdal",
        "Mete Ozay",
        "Taha Ceritli",
        "Yingzhen Li"
      ],
      "abstract": "Diffusion alignment adapts pretrained diffusion models to sample from reward-tilted distributions along the denoising trajectory. This process naturally admits a Sequential Monte Carlo (SMC) interpretation, where the denoising model acts as a proposal and reward guidance induces importance weights. Motivated by this view, we introduce Variance Minimisation Policy Optimisation (VMPO), which formulates diffusion alignment as minimising the variance of log importance weights rather than directly optimising a Kullback-Leibler (KL) based objective. We prove that the variance objective is minimised by the reward-tilted target distribution and that, under on-policy sampling, its gradient coincides with that of standard KL-based alignment. This perspective offers a common lens for understanding diffusion alignment. Under different choices of potential functions and variance minimisation strategies, VMPO recovers various existing methods, while also suggesting new design directions beyond KL.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12229v1",
        "pdf": "https://arxiv.org/pdf/2602.12229v1"
      },
      "arxiv_id": "2602.12229v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12224v1",
      "title": "Bandit Learning in Matching Markets with Interviews",
      "authors": [
        "Amirmahdi Mirfakhar",
        "Xuchuang Wang",
        "Mengfan Xu",
        "Hedyeh Beyhaghi",
        "Mohammad Hajiesmaili"
      ],
      "abstract": "Two-sided matching markets rely on preferences from both sides, yet it is often impractical to evaluate preferences. Participants, therefore, conduct a limited number of interviews, which provide early, noisy impressions and shape final decisions. We study bandit learning in matching markets with interviews, modeling interviews as \\textit{low-cost hints} that reveal partial preference information to both sides. Our framework departs from existing work by allowing firm-side uncertainty: firms, like agents, may be unsure of their own preferences and can make early hiring mistakes by hiring less preferred agents. To handle this, we extend the firm's action space to allow \\emph{strategic deferral} (choosing not to hire in a round), enabling recovery from suboptimal hires and supporting decentralized learning without coordination. We design novel algorithms for (i) a centralized setting with an omniscient interview allocator and (ii) decentralized settings with two types of firm-side feedback. Across all settings, our algorithms achieve time-independent regret, a substantial improvement over the $O(\\log T)$ regret bounds known for learning stable matchings without interviews. Also, under mild structured markets, decentralized performance matches the centralized counterpart up to polynomial factors in the number of agents and firms.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.GT",
        "cs.AI",
        "econ.TH"
      ],
      "primary_category": "cs.GT",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12224v1",
        "pdf": "https://arxiv.org/pdf/2602.12224v1"
      },
      "arxiv_id": "2602.12224v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12222v1",
      "title": "Towards On-Policy SFT: Distribution Discriminant Theory and its Applications in LLM Training",
      "authors": [
        "Miaosen Zhang",
        "Yishan Liu",
        "Shuxia Lin",
        "Xu Yang",
        "Qi Dai",
        "Chong Luo",
        "Weihao Jiang",
        "Peng Hou",
        "Anxiang Zeng",
        "Xin Geng",
        "Baining Guo"
      ],
      "abstract": "Supervised fine-tuning (SFT) is computationally efficient but often yields inferior generalization compared to reinforcement learning (RL). This gap is primarily driven by RL's use of on-policy data. We propose a framework to bridge this chasm by enabling On-Policy SFT. We first present \\textbf{\\textit{Distribution Discriminant Theory (DDT)}}, which explains and quantifies the alignment between data and the model-induced distribution. Leveraging DDT, we introduce two complementary techniques: (i) \\textbf{\\textit{In-Distribution Finetuning (IDFT)}}, a loss-level method to enhance generalization ability of SFT, and (ii) \\textbf{\\textit{Hinted Decoding}}, a data-level technique that can re-align the training corpus to the model's distribution. Extensive experiments demonstrate that our framework achieves generalization performance on par with prominent offline RL algorithms, including DPO and SimPO, while maintaining the efficiency of an SFT pipeline. The proposed framework thus offers a practical alternative in domains where RL is infeasible. We open-source the code here: https://github.com/zhangmiaosen2000/Towards-On-Policy-SFT",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12222v1",
        "pdf": "https://arxiv.org/pdf/2602.12222v1"
      },
      "arxiv_id": "2602.12222v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12221v1",
      "title": "Best of Both Worlds: Multimodal Reasoning and Generation via Unified Discrete Flow Matching",
      "authors": [
        "Onkar Susladkar",
        "Tushar Prakash",
        "Gayatri Deshmukh",
        "Kiet A. Nguyen",
        "Jiaxun Zhang",
        "Adheesh Juvekar",
        "Tianshu Bao",
        "Lin Chai",
        "Sparsh Mittal",
        "Inderjit S Dhillon",
        "Ismini Lourentzou"
      ],
      "abstract": "We propose UniDFlow, a unified discrete flow-matching framework for multimodal understanding, generation, and editing. It decouples understanding and generation via task-specific low-rank adapters, avoiding objective interference and representation entanglement, while a novel reference-based multimodal preference alignment optimizes relative outcomes under identical conditioning, improving faithfulness and controllability without large-scale retraining. UniDFlpw achieves SOTA performance across eight benchmarks and exhibits strong zero-shot generalization to tasks including inpainting, in-context image generation, reference-based editing, and compositional generation, despite no explicit task-specific training.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12221v1",
        "pdf": "https://arxiv.org/pdf/2602.12221v1"
      },
      "arxiv_id": "2602.12221v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12218v1",
      "title": "The Observer Effect in World Models: Invasive Adaptation Corrupts Latent Physics",
      "authors": [
        "Christian Internò",
        "Jumpei Yamaguchi",
        "Loren Amdahl-Culleton",
        "Markus Olhofer",
        "David Klindt",
        "Barbara Hammer"
      ],
      "abstract": "Determining whether neural models internalize physical laws as world models, rather than exploiting statistical shortcuts, remains challenging, especially under out-of-distribution (OOD) shifts. Standard evaluations often test latent capability via downstream adaptation (e.g., fine-tuning or high-capacity probes), but such interventions can change the representations being measured and thus confound what was learned during self-supervised learning (SSL). We propose a non-invasive evaluation protocol, PhyIP. We test whether physical quantities are linearly decodable from frozen representations, motivated by the linear representation hypothesis. Across fluid dynamics and orbital mechanics, we find that when SSL achieves low error, latent structure becomes linearly accessible. PhyIP recovers internal energy and Newtonian inverse-square scaling on OOD tests (e.g., $ρ> 0.90$). In contrast, adaptation-based evaluations can collapse this structure ($ρ\\approx 0.05$). These findings suggest that adaptation-based evaluation can obscure latent structures and that low-capacity probes offer a more accurate evaluation of physical world models.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12218v1",
        "pdf": "https://arxiv.org/pdf/2602.12218v1"
      },
      "arxiv_id": "2602.12218v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12207v1",
      "title": "VIRENA: Virtual Arena for Research, Education, and Democratic Innovation",
      "authors": [
        "Emma Hoes",
        "K. Jonathan Klueser",
        "Fabrizio Gilardi"
      ],
      "abstract": "Digital platforms shape how people communicate, deliberate, and form opinions. Studying these dynamics has become increasingly difficult due to restricted data access, ethical constraints on real-world experiments, and limitations of existing research tools. VIRENA (Virtual Arena) is a platform that enables controlled experimentation in realistic social media environments. Multiple participants interact simultaneously in realistic replicas of feed-based platforms (Instagram, Facebook, Reddit) and messaging apps (WhatsApp, Messenger). Large language model-powered AI agents participate alongside humans with configurable personas and realistic behavior. Researchers can manipulate content moderation approaches, pre-schedule stimulus content, and run experiments across conditions through a visual interface requiring no programming skills. VIRENA makes possible research designs that were previously impractical: studying human--AI interaction in realistic social contexts, experimentally comparing moderation interventions, and observing group deliberation as it unfolds. Built on open-source technologies that ensure data remain under institutional control and comply with data protection requirements, VIRENA is currently in use at the University of Zurich and available for pilot collaborations. Designed for researchers, educators, and public organizations alike, VIRENA's no-code interface makes controlled social media simulation accessible across disciplines and sectors. This paper documents its design, architecture, and capabilities.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.HC",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12207v1",
        "pdf": "https://arxiv.org/pdf/2602.12207v1"
      },
      "arxiv_id": "2602.12207v1",
      "comment": "VIRENA is under active development and currently in use at the University of Zurich, supported by the DIZH Innovation Program: 2nd Founder-Call. This preprint will be updated as new features are released. For the latest version and to inquire about demos or pilot collaborations, contact the authors",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12205v1",
      "title": "DeepGen 1.0: A Lightweight Unified Multimodal Model for Advancing Image Generation and Editing",
      "authors": [
        "Dianyi Wang",
        "Ruihang Li",
        "Feng Han",
        "Chaofan Ma",
        "Wei Song",
        "Siyuan Wang",
        "Yibin Wang",
        "Yi Xin",
        "Hongjian Liu",
        "Zhixiong Zhang",
        "Shengyuan Ding",
        "Tianhang Wang",
        "Zhenglin Cheng",
        "Tao Lin",
        "Cheng Jin",
        "Kaicheng Yu",
        "Jingjing Chen",
        "Wenjie Wang",
        "Zhongyu Wei",
        "Jiaqi Wang"
      ],
      "abstract": "Current unified multimodal models for image generation and editing typically rely on massive parameter scales (e.g., >10B), entailing prohibitive training costs and deployment footprints. In this work, we present DeepGen 1.0, a lightweight 5B unified model that achieves comprehensive capabilities competitive with or surpassing much larger counterparts. To overcome the limitations of compact models in semantic understanding and fine-grained control, we introduce Stacked Channel Bridging (SCB), a deep alignment framework that extracts hierarchical features from multiple VLM layers and fuses them with learnable 'think tokens' to provide the generative backbone with structured, reasoning-rich guidance. We further design a data-centric training strategy spanning three progressive stages: (1) Alignment Pre-training on large-scale image-text pairs and editing triplets to synchronize VLM and DiT representations, (2) Joint Supervised Fine-tuning on a high-quality mixture of generation, editing, and reasoning tasks to foster omni-capabilities, and (3) Reinforcement Learning with MR-GRPO, which leverages a mixture of reward functions and supervision signals, resulting in substantial gains in generation quality and alignment with human preferences, while maintaining stable training progress and avoiding visual artifacts. Despite being trained on only ~50M samples, DeepGen 1.0 achieves leading performance across diverse benchmarks, surpassing the 80B HunyuanImage by 28% on WISE and the 27B Qwen-Image-Edit by 37% on UniREditBench. By open-sourcing our training code, weights, and datasets, we provide an efficient, high-performance alternative to democratize unified multimodal research.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12205v1",
        "pdf": "https://arxiv.org/pdf/2602.12205v1"
      },
      "arxiv_id": "2602.12205v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12204v1",
      "title": "Learning to Forget Attention: Memory Consolidation for Adaptive Compute Reduction",
      "authors": [
        "Ibne Farabi Shihab",
        "Sanjeda Akter",
        "Anuj Sharma"
      ],
      "abstract": "Hybrid architectures combining state-space models with attention have achieved strong efficiency-quality tradeoffs, yet existing approaches either apply attention uniformly or learn static sparse patterns. This misses a key opportunity: \\emph{attention demand should decrease over time as recurring patterns become familiar}. We present a surprising finding from analyzing GPT-2 models: \\textbf{88\\%} of attention operations retrieve information already predictable from the model's hidden state, and this redundancy does \\emph{not} decrease during training. Motivated by this observation, we introduce \\textbf{\\ours{}} (\\textbf{C}onsolidation-based \\textbf{R}outing for \\textbf{A}daptive \\textbf{M}emory), a biologically inspired memory consolidation mechanism that gradually distills episodic retrievals into parametric semantic memory. Unlike prior sparse attention methods, \\ours{} exhibits \\emph{decreasing attention utilization} over training, achieving a \\textbf{37.8$\\times$} reduction through a sharp phase transition at approximately 3K steps. We prove that this capability is \\emph{impossible} without consolidation: any static routing scheme requires $Ω(f \\cdot n)$ attention for tasks with recurring patterns of frequency $f$. On our proposed SRCD benchmark, \\ours{} achieves \\textbf{100\\% retrieval accuracy} at 1.6\\% attention compute (vs.\\ 68\\% for baselines), and consolidated patterns transfer to unseen tasks with \\textbf{48--52\\%} attention reduction without retraining. Remarkably, the learned consolidation dynamics quantitatively match human episodic-to-semantic memory transition curves from cognitive psychology ($γ= 0.43$ vs.\\ $γ_{\\text{human}} \\approx 0.4$--$0.5$). Code and benchmarks are available at [anonymized].",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12204v1",
        "pdf": "https://arxiv.org/pdf/2602.12204v1"
      },
      "arxiv_id": "2602.12204v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12196v1",
      "title": "Visual Reasoning Benchmark: Evaluating Multimodal LLMs on Classroom-Authentic Visual Problems from Primary Education",
      "authors": [
        "Mohamed Huti",
        "Alasdair Mackintosh",
        "Amy Waldock",
        "Dominic Andrews",
        "Maxime Lelièvre",
        "Moritz Boos",
        "Tobias Murray",
        "Paul Atherton",
        "Robin A. A. Ince",
        "Oliver G. B. Garrod"
      ],
      "abstract": "AI models have achieved state-of-the-art results in textual reasoning; however, their ability to reason over spatial and relational structures remains a critical bottleneck -- particularly in early-grade maths, which relies heavily on visuals. This paper introduces the visual reasoning benchmark (VRB), a novel dataset designed to evaluate Multimodal Large Language Models (MLLMs) on their ability to solve authentic visual problems from classrooms. This benchmark is built on a set of 701 questions sourced from primary school examinations in Zambia and India, which cover a range of tasks such as reasoning by analogy, pattern completion, and spatial matching. We outline the methodology and development of the benchmark which intentionally uses unedited, minimal-text images to test if models can meet realistic needs of primary education. Our findings reveal a ``jagged frontier'' of capability where models demonstrate better proficiency in static skills such as counting and scaling, but reach a distinct ``spatial ceiling'' when faced with dynamic operations like folding, reflection, and rotation. These weaknesses pose a risk for classroom use on visual reasoning problems, with the potential for incorrect marking, false scaffolding, and reinforcing student misconceptions. Consequently, education-focused benchmarks like the VRB are essential for determining the functional boundaries of multimodal tools used in classrooms.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12196v1",
        "pdf": "https://arxiv.org/pdf/2602.12196v1"
      },
      "arxiv_id": "2602.12196v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12189v1",
      "title": "WaveFormer: Wavelet Embedding Transformer for Biomedical Signals",
      "authors": [
        "Habib Irani",
        "Bikram De",
        "Vangelis Metsis"
      ],
      "abstract": "Biomedical signal classification presents unique challenges due to long sequences, complex temporal dynamics, and multi-scale frequency patterns that are poorly captured by standard transformer architectures. We propose WaveFormer, a transformer architecture that integrates wavelet decomposition at two critical stages: embedding construction, where multi-channel Discrete Wavelet Transform (DWT) extracts frequency features to create tokens containing both time-domain and frequency-domain information, and positional encoding, where Dynamic Wavelet Positional Encoding (DyWPE) adapts position embeddings to signal-specific temporal structure through mono-channel DWT analysis. We evaluate WaveFormer on eight diverse datasets spanning human activity recognition and brain signal analysis, with sequence lengths ranging from 50 to 3000 timesteps and channel counts from 1 to 144. Experimental results demonstrate that WaveFormer achieves competitive performance through comprehensive frequency-aware processing. Our approach provides a principled framework for incorporating frequency-domain knowledge into transformer-based time series classification.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12189v1",
        "pdf": "https://arxiv.org/pdf/2602.12189v1"
      },
      "arxiv_id": "2602.12189v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12187v1",
      "title": "SAGEO Arena: A Realistic Environment for Evaluating Search-Augmented Generative Engine Optimization",
      "authors": [
        "Sunghwan Kim",
        "Wooseok Jeong",
        "Serin Kim",
        "Sangam Lee",
        "Dongha Lee"
      ],
      "abstract": "Search-Augmented Generative Engines (SAGE) have emerged as a new paradigm for information access, bridging web-scale retrieval with generative capabilities to deliver synthesized answers. This shift has fundamentally reshaped how web content gains exposure online, giving rise to Search-Augmented Generative Engine Optimization (SAGEO), the practice of optimizing web documents to improve their visibility in AI-generated responses. Despite growing interest, no evaluation environment currently supports comprehensive investigation of SAGEO. Specifically, existing benchmarks lack end-to-end visibility evaluation of optimization strategies, operating on pre-determined candidate documents that abstract away retrieval and reranking preceding generation. Moreover, existing benchmarks discard structural information (e.g., schema markup) present in real web documents, overlooking the rich signals that search systems actively leverage in practice. Motivated by these gaps, we introduce SAGEO Arena, a realistic and reproducible environment for stage-level SAGEO analysis. Our objective is to jointly target search-oriented optimization (SEO) and generation-centric optimization (GEO). To achieve this, we integrate a full generative search pipeline over a large-scale corpus of web documents with rich structural information. Our findings reveal that existing approaches remain largely impractical under realistic conditions and often degrade performance in retrieval and reranking. We also find that structural information helps mitigate these limitations, and that effective SAGEO requires tailoring optimization to each pipeline stage. Overall, our benchmark paves the way for realistic SAGEO evaluation and optimization beyond simplified settings.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12187v1",
        "pdf": "https://arxiv.org/pdf/2602.12187v1"
      },
      "arxiv_id": "2602.12187v1",
      "comment": "Work in Progress",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12181v1",
      "title": "Convex Markov Games and Beyond: New Proof of Existence, Characterization and Learning Algorithms for Nash Equilibria",
      "authors": [
        "Anas Barakat",
        "Ioannis Panageas",
        "Antonios Varvitsiotis"
      ],
      "abstract": "Convex Markov Games (cMGs) were recently introduced as a broad class of multi-agent learning problems that generalize Markov games to settings where strategic agents optimize general utilities beyond additive rewards. While cMGs expand the modeling frontier, their theoretical foundations, particularly the structure of Nash equilibria (NE) and guarantees for learning algorithms, are not yet well understood. In this work, we address these gaps for an extension of cMGs, which we term General Utility Markov Games (GUMGs), capturing new applications requiring coupling between agents' occupancy measures. We prove that in GUMGs, Nash equilibria coincide with the fixed points of projected pseudo-gradient dynamics (i.e., first-order stationary points), enabled by a novel agent-wise gradient domination property. This insight also yields a simple proof of NE existence using Brouwer's fixed-point theorem. We further show the existence of Markov perfect equilibria. Building on this characterization, we establish a policy gradient theorem for GUMGs and design a model-free policy gradient algorithm. For potential GUMGs, we establish iteration complexity guarantees for computing approximate-NE under exact gradients and provide sample complexity bounds in both the generative model and on-policy settings. Our results extend beyond prior work restricted to zero-sum cMGs, providing the first theoretical analysis of common-interest cMGs.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.GT",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.GT",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12181v1",
        "pdf": "https://arxiv.org/pdf/2602.12181v1"
      },
      "arxiv_id": "2602.12181v1",
      "comment": "AISTATS 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12180v1",
      "title": "How Sampling Shapes LLM Alignment: From One-Shot Optima to Iterative Dynamics",
      "authors": [
        "Yurong Chen",
        "Yu He",
        "Michael I. Jordan",
        "Fan Yao"
      ],
      "abstract": "Standard methods for aligning large language models with human preferences learn from pairwise comparisons among sampled candidate responses and regularize toward a reference policy. Despite their effectiveness, the effects of sampling and reference choices are poorly understood theoretically. We investigate these effects through Identity Preference Optimization, a widely used preference alignment framework, and show that proper instance-dependent sampling can yield stronger ranking guarantees, while skewed on-policy sampling can induce excessive concentration under structured preferences. We then analyze iterative alignment dynamics in which the learned policy feeds back into future sampling and reference policies, reflecting a common practice of model-generated preference data. We prove that these dynamics can exhibit persistent oscillations or entropy collapse for certain parameter choices, and characterize regimes that guarantee stability. Our theoretical insights extend to Direct Preference Optimization, indicating the phenomena we captured are common to a broader class of preference-alignment methods. Experiments on real-world preference data validate our findings.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.LG",
        "cs.GT"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12180v1",
        "pdf": "https://arxiv.org/pdf/2602.12180v1"
      },
      "arxiv_id": "2602.12180v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12177v1",
      "title": "EO-VAE: Towards A Multi-sensor Tokenizer for Earth Observation Data",
      "authors": [
        "Nils Lehmann",
        "Yi Wang",
        "Zhitong Xiong",
        "Xiaoxiang Zhu"
      ],
      "abstract": "State-of-the-art generative image and video models rely heavily on tokenizers that compress high-dimensional inputs into more efficient latent representations. While this paradigm has revolutionized RGB generation, Earth observation (EO) data presents unique challenges due to diverse sensor specifications and variable spectral channels. We propose EO-VAE, a multi-sensor variational autoencoder designed to serve as a foundational tokenizer for the EO domain. Unlike prior approaches that train separate tokenizers for each modality, EO-VAE utilizes a single model to encode and reconstruct flexible channel combinations via dynamic hypernetworks. Our experiments on the TerraMesh dataset demonstrate that EO-VAE achieves superior reconstruction fidelity compared to the TerraMind tokenizers, establishing a robust baseline for latent generative modeling in remote sensing.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12177v1",
        "pdf": "https://arxiv.org/pdf/2602.12177v1"
      },
      "arxiv_id": "2602.12177v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12173v1",
      "title": "SAM3-LiteText: An Anatomical Study of the SAM3 Text Encoder for Efficient Vision-Language Segmentation",
      "authors": [
        "Chengxi Zeng",
        "Yuxuan Jiang",
        "Ge Gao",
        "Shuai Wang",
        "Duolikun Danier",
        "Bin Zhu",
        "Stevan Rudinac",
        "David Bull",
        "Fan Zhang"
      ],
      "abstract": "Vision-language segmentation models such as SAM3 enable flexible, prompt-driven visual grounding, but inherit large, general-purpose text encoders originally designed for open-ended language understanding. In practice, segmentation prompts are short, structured, and semantically constrained, leading to substantial over-provisioning in text encoder capacity and persistent computational and memory overhead. In this paper, we perform a large-scale anatomical analysis of text prompting in vision-language segmentation, covering 404,796 real prompts across multiple benchmarks. Our analysis reveals severe redundancy: most context windows are underutilized, vocabulary usage is highly sparse, and text embeddings lie on low-dimensional manifold despite high-dimensional representations. Motivated by these findings, we propose SAM3-LiteText, a lightweight text encoding framework that replaces the original SAM3 text encoder with a compact MobileCLIP student that is optimized by knowledge distillation. Extensive experiments on image and video segmentation benchmarks show that SAM3-LiteText reduces text encoder parameters by up to 88%, substantially reducing static memory footprint, while maintaining segmentation performance comparable to the original model. Code: https://github.com/SimonZeng7108/efficientsam3/tree/sam3_litetext.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12173v1",
        "pdf": "https://arxiv.org/pdf/2602.12173v1"
      },
      "arxiv_id": "2602.12173v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12172v1",
      "title": "Pedagogically-Inspired Data Synthesis for Language Model Knowledge Distillation",
      "authors": [
        "Bowei He",
        "Yankai Chen",
        "Xiaokun Zhang",
        "Linghe Kong",
        "Philip S. Yu",
        "Xue Liu",
        "Chen Ma"
      ],
      "abstract": "Knowledge distillation from Large Language Models (LLMs) to smaller models has emerged as a critical technique for deploying efficient AI systems. However, current methods for distillation via synthetic data lack pedagogical awareness, treating knowledge transfer as a one-off data synthesis and training task rather than a systematic learning process. In this paper, we propose a novel pedagogically-inspired framework for LLM knowledge distillation that draws from fundamental educational principles. Our approach introduces a three-stage pipeline -- Knowledge Identifier, Organizer, and Adapter (IOA) -- that systematically identifies knowledge deficiencies in student models, organizes knowledge delivery through progressive curricula, and adapts representations to match the cognitive capacity of student models. We integrate Bloom's Mastery Learning Principles and Vygotsky's Zone of Proximal Development to create a dynamic distillation process where student models approach teacher model's performance on prerequisite knowledge before advancing, and new knowledge is introduced with controlled, gradual difficulty increments. Extensive experiments using LLaMA-3.1/3.2 and Qwen2.5 as student models demonstrate that IOA achieves significant improvements over baseline distillation methods, with student models retaining 94.7% of teacher performance on DollyEval while using less than 1/10th of the parameters. Our framework particularly excels in complex reasoning tasks, showing 19.2% improvement on MATH and 22.3% on HumanEval compared with state-of-the-art baselines.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12172v1",
        "pdf": "https://arxiv.org/pdf/2602.12172v1"
      },
      "arxiv_id": "2602.12172v1",
      "comment": "Accepted by ICLR 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12170v1",
      "title": "Statistical Parsing for Logical Information Retrieval",
      "authors": [
        "Greg Coppola"
      ],
      "abstract": "In previous work (Coppola, 2024) we introduced the Quantified Boolean Bayesian Network (QBBN), a logical graphical model that implements the forward fragment of natural deduction (Prawitz, 1965) as a probabilistic factor graph. That work left two gaps: no negation/backward reasoning, and no parser for natural language.\n  This paper addresses both gaps across inference, semantics, and syntax. For inference, we extend the QBBN with NEG factors enforcing P(x) + P(neg x) = 1, enabling contrapositive reasoning (modus tollens) via backward lambda messages, completing Prawitz's simple elimination rules. The engine handles 44/44 test cases spanning 22 reasoning patterns. For semantics, we present a typed logical language with role-labeled predicates, modal quantifiers, and three tiers of expressiveness following Prawitz: first-order quantification, propositions as arguments, and predicate quantification via lambda abstraction. For syntax, we present a typed slot grammar that deterministically compiles sentences to logical form (33/33 correct, zero ambiguity). LLMs handle disambiguation (95% PP attachment accuracy) but cannot produce structured parses directly (12.4% UAS), confirming grammars are necessary. The architecture: LLM preprocesses, grammar parses, LLM reranks, QBBN infers.\n  We argue this reconciles formal semantics with Sutton's \"bitter lesson\" (2019): LLMs eliminate the annotation bottleneck that killed formal NLP, serving as annotator while the QBBN serves as verifier. Code: https://github.com/gregorycoppola/world",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12170v1",
        "pdf": "https://arxiv.org/pdf/2602.12170v1"
      },
      "arxiv_id": "2602.12170v1",
      "comment": "23 pages, 6 tables",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12164v1",
      "title": "Sci-CoE: Co-evolving Scientific Reasoning LLMs via Geometric Consensus with Sparse Supervision",
      "authors": [
        "Xiaohan He",
        "Shiyang Feng",
        "Songtao Huang",
        "Lei Bai",
        "Bin Wang",
        "Bo Zhang"
      ],
      "abstract": "Large language models (LLMs) have demonstrated exceptional reasoning capabilities, and co-evolving paradigms have shown promising results in domains such as code and math. However, in scientific reasoning tasks, these models remain fragile due to unreliable solution evaluation and limited diversity in verification strategies. In this work, we propose Sci-CoE, a two-stage scientific co-evolving framework that enables models to self-evolve as both solver and verifier through a transition from sparse supervision to unsupervised learning. In the first stage, the model uses a small set of annotated data to establish fundamental correctness judgment anchors for the Verifier. In the second stage, we introduce a geometric reward mechanism that jointly considers consensus, reliability, and diversity, driving large-scale self-iteration on unlabeled data. Experiments on several general scientific benchmarks demonstrate that Sci-CoE enhances complex reasoning capabilities and exhibits strong scalability, facilitating the construction of more robust and diverse evaluation systems. Codes are available at https://github.com/InternScience/Sci-CoE.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12164v1",
        "pdf": "https://arxiv.org/pdf/2602.12164v1"
      },
      "arxiv_id": "2602.12164v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12162v1",
      "title": "Amortized Molecular Optimization via Group Relative Policy Optimization",
      "authors": [
        "Muhammad bin Javaid",
        "Hasham Hussain",
        "Ashima Khanna",
        "Berke Kisin",
        "Jonathan Pirnay",
        "Alexander Mitsos",
        "Dominik G. Grimm",
        "Martin Grohe"
      ],
      "abstract": "Molecular design encompasses tasks ranging from de-novo design to structural alteration of given molecules or fragments. For the latter, state-of-the-art methods predominantly function as \"Instance Optimizers'', expending significant compute restarting the search for every input structure. While model-based approaches theoretically offer amortized efficiency by learning a policy transferable to unseen structures, existing methods struggle to generalize. We identify a key failure mode: the high variance arising from the heterogeneous difficulty of distinct starting structures. To address this, we introduce GRXForm, adapting a pre-trained Graph Transformer model that optimizes molecules via sequential atom-and-bond additions. We employ Group Relative Policy Optimization (GRPO) for goal-directed fine-tuning to mitigate variance by normalizing rewards relative to the starting structure. Empirically, GRXForm generalizes to out-of-distribution molecular scaffolds without inference-time oracle calls or refinement, achieving scores in multi-objective optimization competitive with leading instance optimizers.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12162v1",
        "pdf": "https://arxiv.org/pdf/2602.12162v1"
      },
      "arxiv_id": "2602.12162v1",
      "comment": "23 pages, 5 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12160v1",
      "title": "DreamID-Omni: Unified Framework for Controllable Human-Centric Audio-Video Generation",
      "authors": [
        "Xu Guo",
        "Fulong Ye",
        "Qichao Sun",
        "Liyang Chen",
        "Bingchuan Li",
        "Pengze Zhang",
        "Jiawei Liu",
        "Songtao Zhao",
        "Qian He",
        "Xiangwang Hou"
      ],
      "abstract": "Recent advancements in foundation models have revolutionized joint audio-video generation. However, existing approaches typically treat human-centric tasks including reference-based audio-video generation (R2AV), video editing (RV2AV) and audio-driven video animation (RA2V) as isolated objectives. Furthermore, achieving precise, disentangled control over multiple character identities and voice timbres within a single framework remains an open challenge. In this paper, we propose DreamID-Omni, a unified framework for controllable human-centric audio-video generation. Specifically, we design a Symmetric Conditional Diffusion Transformer that integrates heterogeneous conditioning signals via a symmetric conditional injection scheme. To resolve the pervasive identity-timbre binding failures and speaker confusion in multi-person scenarios, we introduce a Dual-Level Disentanglement strategy: Synchronized RoPE at the signal level to ensure rigid attention-space binding, and Structured Captions at the semantic level to establish explicit attribute-subject mappings. Furthermore, we devise a Multi-Task Progressive Training scheme that leverages weakly-constrained generative priors to regularize strongly-constrained tasks, preventing overfitting and harmonizing disparate objectives. Extensive experiments demonstrate that DreamID-Omni achieves comprehensive state-of-the-art performance across video, audio, and audio-visual consistency, even outperforming leading proprietary commercial models. We will release our code to bridge the gap between academic research and commercial-grade applications.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12160v1",
        "pdf": "https://arxiv.org/pdf/2602.12160v1"
      },
      "arxiv_id": "2602.12160v1",
      "comment": "Project: https://guoxu1233.github.io/DreamID-Omni/",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2602.12159v1",
      "title": "3DGSNav: Enhancing Vision-Language Model Reasoning for Object Navigation via Active 3D Gaussian Splatting",
      "authors": [
        "Wancai Zheng",
        "Hao Chen",
        "Xianlong Lu",
        "Linlin Ou",
        "Xinyi Yu"
      ],
      "abstract": "Object navigation is a core capability of embodied intelligence, enabling an agent to locate target objects in unknown environments. Recent advances in vision-language models (VLMs) have facilitated zero-shot object navigation (ZSON). However, existing methods often rely on scene abstractions that convert environments into semantic maps or textual representations, causing high-level decision making to be constrained by the accuracy of low-level perception. In this work, we present 3DGSNav, a novel ZSON framework that embeds 3D Gaussian Splatting (3DGS) as persistent memory for VLMs to enhance spatial reasoning. Through active perception, 3DGSNav incrementally constructs a 3DGS representation of the environment, enabling trajectory-guided free-viewpoint rendering of frontier-aware first-person views. Moreover, we design structured visual prompts and integrate them with Chain-of-Thought (CoT) prompting to further improve VLM reasoning. During navigation, a real-time object detector filters potential targets, while VLM-driven active viewpoint switching performs target re-verification, ensuring efficient and reliable recognition. Extensive evaluations across multiple benchmarks and real-world experiments on a quadruped robot demonstrate that our method achieves robust and competitive performance against state-of-the-art approaches.The Project Page:https://aczheng-cai.github.io/3dgsnav.github.io/",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12159v1",
        "pdf": "https://arxiv.org/pdf/2602.12159v1"
      },
      "arxiv_id": "2602.12159v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12158v1",
      "title": "SafeNeuron: Neuron-Level Safety Alignment for Large Language Models",
      "authors": [
        "Zhaoxin Wang",
        "Jiaming Liang",
        "Fengbin Zhu",
        "Weixiang Zhao",
        "Junfeng Fang",
        "Jiayi Ji",
        "Handing Wang",
        "Tat-Seng Chua"
      ],
      "abstract": "Large language models (LLMs) and multimodal LLMs are typically safety-aligned before release to prevent harmful content generation. However, recent studies show that safety behaviors are concentrated in a small subset of parameters, making alignment brittle and easily bypassed through neuron-level attacks. Moreover, most existing alignment methods operate at the behavioral level, offering limited control over the model's internal safety mechanisms. In this work, we propose SafeNeuron, a neuron-level safety alignment framework that improves robustness by redistributing safety representations across the network. SafeNeuron first identifies safety-related neurons, then freezes these neurons during preference optimization to prevent reliance on sparse safety pathways and force the model to construct redundant safety representations. Extensive experiments across models and modalities demonstrate that SafeNeuron significantly improves robustness against neuron pruning attacks, reduces the risk of open-source models being repurposed as red-team generators, and preserves general capabilities. Furthermore, our layer-wise analysis reveals that safety behaviors are governed by stable and shared internal representations. Overall, SafeNeuron provides an interpretable and robust perspective for model alignment.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12158v1",
        "pdf": "https://arxiv.org/pdf/2602.12158v1"
      },
      "arxiv_id": "2602.12158v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12157v1",
      "title": "TexSpot: 3D Texture Enhancement with Spatially-uniform Point Latent Representation",
      "authors": [
        "Ziteng Lu",
        "Yushuang Wu",
        "Chongjie Ye",
        "Yuda Qiu",
        "Jing Shao",
        "Xiaoyang Guo",
        "Jiaqing Zhou",
        "Tianlei Hu",
        "Kun Zhou",
        "Xiaoguang Han"
      ],
      "abstract": "High-quality 3D texture generation remains a fundamental challenge due to the view-inconsistency inherent in current mainstream multi-view diffusion pipelines. Existing representations either rely on UV maps, which suffer from distortion during unwrapping, or point-based methods, which tightly couple texture fidelity to geometric density that limits high-resolution texture generation. To address these limitations, we introduce TexSpot, a diffusion-based texture enhancement framework. At its core is Texlet, a novel 3D texture representation that merges the geometric expressiveness of point-based 3D textures with the compactness of UV-based representation. Each Texlet latent vector encodes a local texture patch via a 2D encoder and is further aggregated using a 3D encoder to incorporate global shape context. A cascaded 3D-to-2D decoder reconstructs high-quality texture patches, enabling the Texlet space learning. Leveraging this representation, we train a diffusion transformer conditioned on Texlets to refine and enhance textures produced by multi-view diffusion methods. Extensive experiments demonstrate that TexSpot significantly improves visual fidelity, geometric consistency, and robustness over existing state-of-the-art 3D texture generation and enhancement approaches. Project page: https://anonymous.4open.science/w/TexSpot-page-2D91.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.CV",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12157v1",
        "pdf": "https://arxiv.org/pdf/2602.12157v1"
      },
      "arxiv_id": "2602.12157v1",
      "comment": "Project page: https://anonymous.4open.science/w/TexSpot-page-2D91",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12155v1",
      "title": "FAIL: Flow Matching Adversarial Imitation Learning for Image Generation",
      "authors": [
        "Yeyao Ma",
        "Chen Li",
        "Xiaosong Zhang",
        "Han Hu",
        "Weidi Xie"
      ],
      "abstract": "Post-training of flow matching models-aligning the output distribution with a high-quality target-is mathematically equivalent to imitation learning. While Supervised Fine-Tuning mimics expert demonstrations effectively, it cannot correct policy drift in unseen states. Preference optimization methods address this but require costly preference pairs or reward modeling. We propose Flow Matching Adversarial Imitation Learning (FAIL), which minimizes policy-expert divergence through adversarial training without explicit rewards or pairwise comparisons. We derive two algorithms: FAIL-PD exploits differentiable ODE solvers for low-variance pathwise gradients, while FAIL-PG provides a black-box alternative for discrete or computationally constrained settings. Fine-tuning FLUX with only 13,000 demonstrations from Nano Banana pro, FAIL achieves competitive performance on prompt following and aesthetic benchmarks. Furthermore, the framework generalizes effectively to discrete image and video generation, and functions as a robust regularizer to mitigate reward hacking in reward-based optimization. Code and data are available at https://github.com/HansPolo113/FAIL.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12155v1",
        "pdf": "https://arxiv.org/pdf/2602.12155v1"
      },
      "arxiv_id": "2602.12155v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12153v1",
      "title": "dVoting: Fast Voting for dLLMs",
      "authors": [
        "Sicheng Feng",
        "Zigeng Chen",
        "Xinyin Ma",
        "Gongfan Fang",
        "Xinchao Wang"
      ],
      "abstract": "Diffusion Large Language Models (dLLMs) represent a new paradigm beyond autoregressive modeling, offering competitive performance while naturally enabling a flexible decoding process. Specifically, dLLMs can generate tokens at arbitrary positions in parallel, endowing them with significant potential for parallel test-time scaling, which was previously constrained by severe inefficiency in autoregressive modeling. In this work, we introduce dVoting, a fast voting technique that boosts reasoning capability without training, with only an acceptable extra computational overhead. dVoting is motivated by the observation that, across multiple samples for the same prompt, token predictions remain largely consistent, whereas performance is determined by a small subset of tokens exhibiting cross-sample variability. Leveraging the arbitrary-position generation capability of dLLMs, dVoting performs iterative refinement by sampling, identifying uncertain tokens via consistency analysis, regenerating them through voting, and repeating this process until convergence. Extensive evaluations demonstrate that dVoting consistently improves performance across various benchmarks. It achieves gains of 6.22%-7.66% on GSM8K, 4.40%-7.20% on MATH500, 3.16%-14.84% on ARC-C, and 4.83%-5.74% on MMLU. Our code is available at https://github.com/fscdc/dVoting",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12153v1",
        "pdf": "https://arxiv.org/pdf/2602.12153v1"
      },
      "arxiv_id": "2602.12153v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12150v1",
      "title": "GPT-4o Lacks Core Features of Theory of Mind",
      "authors": [
        "John Muchovej",
        "Amanda Royka",
        "Shane Lee",
        "Julian Jara-Ettinger"
      ],
      "abstract": "Do Large Language Models (LLMs) possess a Theory of Mind (ToM)? Research into this question has focused on evaluating LLMs against benchmarks and found success across a range of social tasks. However, these evaluations do not test for the actual representations posited by ToM: namely, a causal model of mental states and behavior. Here, we use a cognitively-grounded definition of ToM to develop and test a new evaluation framework. Specifically, our approach probes whether LLMs have a coherent, domain-general, and consistent model of how mental states cause behavior -- regardless of whether that model matches a human-like ToM. We find that even though LLMs succeed in approximating human judgments in a simple ToM paradigm, they fail at a logically equivalent task and exhibit low consistency between their action predictions and corresponding mental state inferences. As such, these findings suggest that the social proficiency exhibited by LLMs is not the result of an domain-general or consistent ToM.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12150v1",
        "pdf": "https://arxiv.org/pdf/2602.12150v1"
      },
      "arxiv_id": "2602.12150v1",
      "comment": "Submitted to CogSci 2025; see more at https://jmuchovej.com/projects/llm-tom. Note: \"abstractness\" is the second feature we test for, but due to arXiv's abstract requirements, the text has been altered",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12147v1",
      "title": "It's TIME: Towards the Next Generation of Time Series Forecasting Benchmarks",
      "authors": [
        "Zhongzheng Qiao",
        "Sheng Pan",
        "Anni Wang",
        "Viktoriya Zhukova",
        "Yong Liu",
        "Xudong Jiang",
        "Qingsong Wen",
        "Mingsheng Long",
        "Ming Jin",
        "Chenghao Liu"
      ],
      "abstract": "Time series foundation models (TSFMs) are revolutionizing the forecasting landscape from specific dataset modeling to generalizable task evaluation. However, we contend that existing benchmarks exhibit common limitations in four dimensions: constrained data composition dominated by reused legacy sources, compromised data integrity lacking rigorous quality assurance, misaligned task formulations detached from real-world contexts, and rigid analysis perspectives that obscure generalizable insights. To bridge these gaps, we introduce TIME, a next-generation task-centric benchmark comprising 50 fresh datasets and 98 forecasting tasks, tailored for strict zero-shot TSFM evaluation free from data leakage. Integrating large language models and human expertise, we establish a rigorous human-in-the-loop benchmark construction pipeline to ensure high data integrity and redefine task formulation by aligning forecasting configurations with real-world operational requirements and variate predictability. Furthermore, we propose a novel pattern-level evaluation perspective that moves beyond traditional dataset-level evaluations based on static meta labels. By leveraging structural time series features to characterize intrinsic temporal properties, this approach offers generalizable insights into model capabilities across diverse patterns. We evaluate 12 representative TSFMs and establish a multi-granular leaderboard to facilitate in-depth analysis and visualized inspection. The leaderboard is available at https://huggingface.co/spaces/Real-TSF/TIME-leaderboard.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12147v1",
        "pdf": "https://arxiv.org/pdf/2602.12147v1"
      },
      "arxiv_id": "2602.12147v1",
      "comment": "The source code will be released on GitHub shortly",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2602.12146v1",
      "title": "Seq2Seq2Seq: Lossless Data Compression via Discrete Latent Transformers and Reinforcement Learning",
      "authors": [
        "Mahdi Khodabandeh",
        "Ghazal Shabani",
        "Arash Yousefi Jordehi",
        "Seyed Abolghasem Mirroshandel"
      ],
      "abstract": "Efficient lossless compression is essential for minimizing storage costs and transmission overhead while preserving data integrity. Traditional compression techniques, such as dictionary-based and statistical methods, often struggle to optimally exploit the structure and redundancy in complex data formats. Recent advancements in deep learning have opened new avenues for compression; however, many existing approaches depend on dense vector representations that obscure the underlying token structure. To address these limitations, we propose a novel lossless compression method that leverages Reinforcement Learning applied to a T5 language model architecture. This approach enables the compression of data into sequences of tokens rather than traditional vector representations. Unlike auto-encoders, which typically encode information into continuous latent spaces, our method preserves the token-based structure, aligning more closely with the original data format. This preservation allows for higher compression ratios while maintaining semantic integrity. By training the model using an off-policy Reinforcement Learning algorithm, we optimize sequence length to minimize redundancy and enhance compression efficiency. Our method introduces an efficient and adaptive data compression system built upon advanced Reinforcement Learning techniques, functioning independently of external grammatical or world knowledge. This approach shows significant improvements in compression ratios compared to conventional methods. By leveraging the latent information within language models, our system effectively compresses data without requiring explicit content understanding, paving the way for more robust and practical compression solutions across various applications.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IT"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12146v1",
        "pdf": "https://arxiv.org/pdf/2602.12146v1"
      },
      "arxiv_id": "2602.12146v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12144v1",
      "title": "On the Adoption of AI Coding Agents in Open-source Android and iOS Development",
      "authors": [
        "Muhammad Ahmad Khan",
        "Hasnain Ali",
        "Muneeb Rana",
        "Muhammad Saqib Ilyas",
        "Abdul Ali Bangash"
      ],
      "abstract": "AI coding agents are increasingly contributing to software development, yet their impact on mobile development has received little empirical attention. In this paper, we present the first category-level empirical study of agent-generated code in open-source mobile app projects. We analyzed PR acceptance behaviors across mobile platforms, agents, and task categories using 2,901 AI-authored pull requests (PRs) in 193 verified Android and iOS open-source GitHub repositories in the AIDev dataset. We find that Android projects have received 2x more AI-authored PRs and have achieved higher PR acceptance rate (71%) than iOS (63%), with significant agent-level variation on Android. Across task categories, PRs with routine tasks (feature, fix, and ui) achieve the highest acceptance, while structural changes like refactor and build achieve lower success and longer resolution times. Furthermore, our evolution analysis shows improvement in PR resolution time on Android through mid-2025 before it declined again. Our findings offer the first evidence-based characterization of AI agents effects on OSS mobile projects and establish empirical baselines for evaluating agent-generated contributions to design platform aware agentic systems.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12144v1",
        "pdf": "https://arxiv.org/pdf/2602.12144v1"
      },
      "arxiv_id": "2602.12144v1",
      "comment": "Accepted at MSR 2026 Mining Challenge track",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12143v1",
      "title": "STAR : Bridging Statistical and Agentic Reasoning for Large Model Performance Prediction",
      "authors": [
        "Xiaoxiao Wang",
        "Chunxiao Li",
        "Junying Wang",
        "Yijin Guo",
        "Zijian Chen",
        "Chunyi Li",
        "Xiaohong Liu",
        "Zicheng Zhang",
        "Guangtao Zhai"
      ],
      "abstract": "As comprehensive large model evaluation becomes prohibitively expensive, predicting model performance from limited observations has become essential. However, existing statistical methods struggle with pattern shifts, data sparsity, and lack of explanation, while pure LLM methods remain unreliable. We propose STAR, a framework that bridges data-driven STatistical expectations with knowledge-driven Agentic Reasoning. STAR leverages specialized retrievers to gather external knowledge and embeds semantic features into Constrained Probabilistic Matrix Factorization (CPMF) to generate statistical expectations with uncertainty. A reasoning module guided by Expectation Violation Theory (EVT) then refines predictions through intra-family analysis, cross-model comparison, and credibility-aware aggregation, producing adjustments with traceable explanations. Extensive experiments show that STAR consistently outperforms all baselines on both score-based and rank-based metrics, delivering a 14.46% gain in total score over the strongest statistical method under extreme sparsity, with only 1--2 observed scores per test model.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12143v1",
        "pdf": "https://arxiv.org/pdf/2602.12143v1"
      },
      "arxiv_id": "2602.12143v1",
      "comment": "10 pages, 8 figures, 17 tables. Code available at https://github.com/xiaoxiaostudy/star",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2602.12139v1",
      "title": "Oscillators Are All You Need: Irregular Time Series Modelling via Damped Harmonic Oscillators with Closed-Form Solutions",
      "authors": [
        "Yashas Shende",
        "Aritra Das",
        "Reva Laxmi Chauhan",
        "Arghya Pathak",
        "Debayan Gupta"
      ],
      "abstract": "Transformers excel at time series modelling through attention mechanisms that capture long-term temporal patterns. However, they assume uniform time intervals and therefore struggle with irregular time series. Neural Ordinary Differential Equations (NODEs) effectively handle irregular time series by modelling hidden states as continuously evolving trajectories. ContiFormers arxiv:2402.10635 combine NODEs with Transformers, but inherit the computational bottleneck of the former by using heavy numerical solvers. This bottleneck can be removed by using a closed-form solution for the given dynamical system - but this is known to be intractable in general! We obviate this by replacing NODEs with a novel linear damped harmonic oscillator analogy - which has a known closed-form solution. We model keys and values as damped, driven oscillators and expand the query in a sinusoidal basis up to a suitable number of modes. This analogy naturally captures the query-key coupling that is fundamental to any transformer architecture by modelling attention as a resonance phenomenon. Our closed-form solution eliminates the computational overhead of numerical ODE solvers while preserving expressivity. We prove that this oscillator-based parameterisation maintains the universal approximation property of continuous-time attention; specifically, any discrete attention matrix realisable by ContiFormer's continuous keys can be approximated arbitrarily well by our fixed oscillator modes. Our approach delivers both theoretical guarantees and scalability, achieving state-of-the-art performance on irregular time series benchmarks while being orders of magnitude faster.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12139v1",
        "pdf": "https://arxiv.org/pdf/2602.12139v1"
      },
      "arxiv_id": "2602.12139v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12134v1",
      "title": "Value Alignment Tax: Measuring Value Trade-offs in LLM Alignment",
      "authors": [
        "Jiajun Chen",
        "Hua Shen"
      ],
      "abstract": "Existing work on value alignment typically characterizes value relations statically, ignoring how interventions - such as prompting, fine-tuning, or preference optimization - reshape the broader value system. We introduce the Value Alignment Tax (VAT), a framework that measures how alignment-induced changes propagate across interconnected values relative to achieved on-target gain. VAT captures the dynamics of value expression under alignment pressure. Using a controlled scenario-action dataset grounded in Schwartz value theory, we collect paired pre-post normative judgments and analyze alignment effects across models, values, and alignment strategies. Our results show that alignment often produces uneven, structured co-movement among values. These effects are invisible under conventional target-only evaluation, revealing systemic, process-level alignment risks and offering new insights into the dynamics of value alignment in LLMs.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12134v1",
        "pdf": "https://arxiv.org/pdf/2602.12134v1"
      },
      "arxiv_id": "2602.12134v1",
      "comment": "Preprint. Under review. 20 pages, 13 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12133v1",
      "title": "Neutral Prompts, Non-Neutral People: Quantifying Gender and Skin-Tone Bias in Gemini Flash 2.5 Image and GPT Image 1.5",
      "authors": [
        "Roberto Balestri"
      ],
      "abstract": "This study quantifies gender and skin-tone bias in two widely deployed commercial image generators - Gemini Flash 2.5 Image (NanoBanana) and GPT Image 1.5 - to test the assumption that neutral prompts yield demographically neutral outputs. We generated 3,200 photorealistic images using four semantically neutral prompts. The analysis employed a rigorous pipeline combining hybrid color normalization, facial landmark masking, and perceptually uniform skin tone quantification using the Monk (MST), PERLA, and Fitzpatrick scales. Neutral prompts produced highly polarized defaults. Both models exhibited a strong \"default white\" bias (>96% of outputs). However, they diverged sharply on gender: Gemini favored female-presenting subjects, while GPT favored male-presenting subjects with lighter skin tones. This research provides a large-scale, comparative audit of state-of-the-art models using an illumination-aware colorimetric methodology, distinguishing aesthetic rendering from underlying pigmentation in synthetic imagery. The study demonstrates that neutral prompts function as diagnostic probes rather than neutral instructions. It offers a robust framework for auditing algorithmic visual culture and challenges the sociolinguistic assumption that unmarked language results in inclusive representation.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12133v1",
        "pdf": "https://arxiv.org/pdf/2602.12133v1"
      },
      "arxiv_id": "2602.12133v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12129v1",
      "title": "Towards Personalized Bangla Book Recommendation: A Large-Scale Multi-Entity Book Graph Dataset",
      "authors": [
        "Rahin Arefin Ahmed",
        "Md. Anik Chowdhury",
        "Sakil Ahmed Sheikh Reza",
        "Devnil Bhattacharjee",
        "Muhammad Abdullah Adnan",
        "Nafis Sadeq"
      ],
      "abstract": "Personalized book recommendation in Bangla literature has been constrained by the lack of structured, large-scale, and publicly available datasets. This work introduces RokomariBG, a large-scale, multi-entity heterogeneous book graph dataset designed to support research on personalized recommendation in a low-resource language setting. The dataset comprises 127,302 books, 63,723 users, 16,601 authors, 1,515 categories, 2,757 publishers, and 209,602 reviews, connected through eight relation types and organized as a comprehensive knowledge graph.\n  To demonstrate the utility of the dataset, we provide a systematic benchmarking study on the Top-N recommendation task, evaluating a diverse set of representative recommendation models, including classical collaborative filtering methods, matrix factorization models, content-based approaches, graph neural networks, a hybrid matrix factorization model with side information, and a neural two-tower retrieval architecture. The benchmarking results highlight the importance of leveraging multi-relational structure and textual side information, with neural retrieval models achieving the strongest performance (NDCG@10 = 0.204). Overall, this work establishes a foundational benchmark and a publicly available resource for Bangla book recommendation research, enabling reproducible evaluation and future studies on recommendation in low-resource cultural domains. The dataset and code are publicly available at https://github.com/backlashblitz/Bangla-Book-Recommendation-Dataset",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12129v1",
        "pdf": "https://arxiv.org/pdf/2602.12129v1"
      },
      "arxiv_id": "2602.12129v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12128v1",
      "title": "HLA: Hadamard Linear Attention",
      "authors": [
        "Hanno Ackermann",
        "Hong Cai",
        "Mohsen Ghafoorian",
        "Amirhossein Habibian"
      ],
      "abstract": "The attention mechanism is an important reason for the success of transformers. It relies on computing pairwise relations between tokens. To reduce the high computational cost of standard quadratic attention, linear attention has been proposed as an efficient approximation. It employs kernel functions that are applied independently to the inputs before the pairwise similarities are calculated. That allows for an efficient computational procedure which, however, amounts to a low-degree rational function approximating softmax.\n  We propose Hadamard Linear Attention (HLA). Unlike previous works on linear attention, the nonlinearity in HLA is not applied separately to queries and keys, but, analogously to standard softmax attention, after the pairwise similarities have been computed. It will be shown that the proposed nonlinearity amounts to a higher-degree rational function to approximate softmax. An efficient computational scheme for the proposed method is derived that is similar to that of standard linear attention. In contrast to other approaches, no time-consuming tensor reshaping is necessary to apply the proposed algorithm. The effectiveness of the approach is demonstrated by applying it to a large diffusion transformer model for video generation, an application that involves very large amounts of tokens.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12128v1",
        "pdf": "https://arxiv.org/pdf/2602.12128v1"
      },
      "arxiv_id": "2602.12128v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12127v1",
      "title": "PosterOmni: Generalized Artistic Poster Creation via Task Distillation and Unified Reward Feedback",
      "authors": [
        "Sixiang Chen",
        "Jianyu Lai",
        "Jialin Gao",
        "Hengyu Shi",
        "Zhongying Liu",
        "Tian Ye",
        "Junfeng Luo",
        "Xiaoming Wei",
        "Lei Zhu"
      ],
      "abstract": "Image-to-poster generation is a high-demand task requiring not only local adjustments but also high-level design understanding. Models must generate text, layout, style, and visual elements while preserving semantic fidelity and aesthetic coherence. The process spans two regimes: local editing, where ID-driven generation, rescaling, filling, and extending must preserve concrete visual entities; and global creation, where layout- and style-driven tasks rely on understanding abstract design concepts. These intertwined demands make image-to-poster a multi-dimensional process coupling entity-preserving editing with concept-driven creation under image-prompt control. To address these challenges, we propose PosterOmni, a generalized artistic poster creation framework that unlocks the potential of a base edit model for multi-task image-to-poster generation. PosterOmni integrates the two regimes, namely local editing and global creation, within a single system through an efficient data-distillation-reward pipeline: (i) constructing multi-scenario image-to-poster datasets covering six task types across entity-based and concept-based creation; (ii) distilling knowledge between local and global experts for supervised fine-tuning; and (iii) applying unified PosterOmni Reward Feedback to jointly align visual entity-preserving and aesthetic preference across all tasks. Additionally, we establish PosterOmni-Bench, a unified benchmark for evaluating both local editing and global creation. Extensive experiments show that PosterOmni significantly enhances reference adherence, global composition quality, and aesthetic harmony, outperforming all open-source baselines and even surpassing several proprietary systems.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12127v1",
        "pdf": "https://arxiv.org/pdf/2602.12127v1"
      },
      "arxiv_id": "2602.12127v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12125v1",
      "title": "Learning beyond Teacher: Generalized On-Policy Distillation with Reward Extrapolation",
      "authors": [
        "Wenkai Yang",
        "Weijie Liu",
        "Ruobing Xie",
        "Kai Yang",
        "Saiyong Yang",
        "Yankai Lin"
      ],
      "abstract": "On-policy distillation (OPD), which aligns the student with the teacher's logit distribution on student-generated trajectories, has demonstrated strong empirical gains in improving student performance and often outperforms off-policy distillation and reinforcement learning (RL) paradigms. In this work, we first theoretically show that OPD is a special case of dense KL-constrained RL where the reward function and the KL regularization are always weighted equally and the reference model can by any model. Then, we propose the Generalized On-Policy Distillation (G-OPD) framework, which extends the standard OPD objective by introducing a flexible reference model and a reward scaling factor that controls the relative weight of the reward term against the KL regularization. Through comprehensive experiments on math reasoning and code generation tasks, we derive two novel insights: (1) Setting the reward scaling factor to be greater than 1 (i.e., reward extrapolation), which we term ExOPD, consistently improves over standard OPD across a range of teacher-student size pairings. In particular, in the setting where we merge the knowledge from different domain experts, obtained by applying domain-specific RL to the same student model, back into the original student, ExOPD enables the student to even surpass the teacher's performance boundary and outperform the domain teachers. (2) Building on ExOPD, we further find that in the strong-to-weak distillation setting (i.e., distilling a smaller student from a larger teacher), performing reward correction by choosing the reference model as the teacher's base model before RL yields a more accurate reward signal and further improves distillation performance. However, this choice assumes access to the teacher's pre-RL variant and incurs more computational overhead. We hope our work offers new insights for future research on OPD.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12125v1",
        "pdf": "https://arxiv.org/pdf/2602.12125v1"
      },
      "arxiv_id": "2602.12125v1",
      "comment": "Work in progress. Github repo: https://github.com/RUCBM/G-OPD",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2602.12124v1",
      "title": "Capability-Oriented Training Induced Alignment Risk",
      "authors": [
        "Yujun Zhou",
        "Yue Huang",
        "Han Bao",
        "Kehan Guo",
        "Zhenwen Liang",
        "Pin-Yu Chen",
        "Tian Gao",
        "Werner Geyer",
        "Nuno Moniz",
        "Nitesh V Chawla",
        "Xiangliang Zhang"
      ],
      "abstract": "While most AI alignment research focuses on preventing models from generating explicitly harmful content, a more subtle risk is emerging: capability-oriented training induced exploitation. We investigate whether language models, when trained with reinforcement learning (RL) in environments with implicit loopholes, will spontaneously learn to exploit these flaws to maximize their reward, even without any malicious intent in their training. To test this, we design a suite of four diverse \"vulnerability games\", each presenting a unique, exploitable flaw related to context-conditional compliance, proxy metrics, reward tampering, and self-evaluation. Our experiments show that models consistently learn to exploit these vulnerabilities, discovering opportunistic strategies that significantly increase their reward at the expense of task correctness or safety. More critically, we find that these exploitative strategies are not narrow \"tricks\" but generalizable skills; they can be transferred to new tasks and even \"distilled\" from a capable teacher model to other student models through data alone. Our findings reveal that capability-oriented training induced risks pose a fundamental challenge to current alignment approaches, suggesting that future AI safety work must extend beyond content moderation to rigorously auditing and securing the training environments and reward mechanisms themselves. Code is available at https://github.com/YujunZhou/Capability_Oriented_Alignment_Risk.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12124v1",
        "pdf": "https://arxiv.org/pdf/2602.12124v1"
      },
      "arxiv_id": "2602.12124v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12123v1",
      "title": "Meta-Sel: Efficient Demonstration Selection for In-Context Learning via Supervised Meta-Learning",
      "authors": [
        "Xubin Wang",
        "Weijia Jia"
      ],
      "abstract": "Demonstration selection is a practical bottleneck in in-context learning (ICL): under a tight prompt budget, accuracy can change substantially depending on which few-shot examples are included, yet selection must remain cheap enough to run per query over large candidate pools. We propose Meta-Sel, a lightweight supervised meta-learning approach for intent classification that learns a fast, interpretable scoring function for (candidate, query) pairs from labeled training data.\n  Meta-Sel constructs a meta-dataset by sampling pairs from the training split and using class agreement as supervision, then trains a calibrated logistic regressor on two inexpensive meta-features: TF--IDF cosine similarity and a length-compatibility ratio. At inference time, the selector performs a single vectorized scoring pass over the full candidate pool and returns the top-k demonstrations, requiring no model fine-tuning, no online exploration, and no additional LLM calls. This yields deterministic rankings and makes the selection mechanism straightforward to audit via interpretable feature weights.\n  Beyond proposing Meta-Sel, we provide a broad empirical study of demonstration selection, benchmarking 12 methods -- spanning prompt engineering baselines, heuristic selection, reinforcement learning, and influence-based approaches -- across four intent datasets and five open-source LLMs. Across this benchmark, Meta-Sel consistently ranks among the top-performing methods, is particularly effective for smaller models where selection quality can partially compensate for limited model capacity, and maintains competitive selection-time overhead.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12123v1",
        "pdf": "https://arxiv.org/pdf/2602.12123v1"
      },
      "arxiv_id": "2602.12123v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12120v1",
      "title": "Commencing-Student Enrolment Forecasting Under Data Sparsity with Time Series Foundation Models",
      "authors": [
        "Jittarin Jetwiriyanon",
        "Teo Susnjak",
        "Surangika Ranathunga"
      ],
      "abstract": "Many universities face increasing financial pressure and rely on accurate forecasts of commencing enrolments. However, enrolment forecasting in higher education is often data-sparse; annual series are short and affected by reporting changes and regime shifts. Popular classical approaches can be unreliable, as parameter estimation and model selection are unstable with short samples, and structural breaks degrade extrapolation. Recently, TSFMs have provided zero-shot priors, delivering strong gains in annual, data-sparse institutional forecasting under leakage-disciplined covariate construction. We benchmark multiple TSFM families in a zero-shot setting and test a compact, leakage-safe covariate set and introduce the Institutional Operating Conditions Index (IOCI), a transferable 0-100 regime covariate derived from time-stamped documentary evidence available at each forecast origin, alongside Google Trends demand proxies with stabilising feature engineering. Using an expanding-window backtest with strict vintage alignment, covariate-conditioned TSFMs perform on par with classical benchmarks without institution-specific training, with performance differences varying by cohort and model.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12120v1",
        "pdf": "https://arxiv.org/pdf/2602.12120v1"
      },
      "arxiv_id": "2602.12120v1",
      "comment": "31 pages, 5 figures, 3 tables",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12117v1",
      "title": "KAN-FIF: Spline-Parameterized Lightweight Physics-based Tropical Cyclone Estimation on Meteorological Satellite",
      "authors": [
        "Jiakang Shen",
        "Qinghui Chen",
        "Runtong Wang",
        "Chenrui Xu",
        "Jinglin Zhang",
        "Cong Bai",
        "Feng Zhang"
      ],
      "abstract": "Tropical cyclones (TC) are among the most destructive natural disasters, causing catastrophic damage to coastal regions through extreme winds, heavy rainfall, and storm surges. Timely monitoring of tropical cyclones is crucial for reducing loss of life and property, yet it is hindered by the computational inefficiency and high parameter counts of existing methods on resource-constrained edge devices. Current physics-guided models suffer from linear feature interactions that fail to capture high-order polynomial relationships between TC attributes, leading to inflated model sizes and hardware incompatibility. To overcome these challenges, this study introduces the Kolmogorov-Arnold Network-based Feature Interaction Framework (KAN-FIF), a lightweight multimodal architecture that integrates MLP and CNN layers with spline-parameterized KAN layers. For Maximum Sustained Wind (MSW) prediction, experiments demonstrate that the KAN-FIF framework achieves a $94.8\\%$ reduction in parameters (0.99MB vs 19MB) and $68.7\\%$ faster inference per sample (2.3ms vs 7.35ms) compared to baseline model Phy-CoCo, while maintaining superior accuracy with $32.5\\%$ lower MAE. The offline deployment experiment of the FY-4 series meteorological satellite processor on the Qingyun-1000 development board achieved a 14.41ms per-sample inference latency with the KAN-FIF framework, demonstrating promising feasibility for operational TC monitoring and extending deployability to edge-device AI applications. The code is released at https://github.com/Jinglin-Zhang/KAN-FIF.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12117v1",
        "pdf": "https://arxiv.org/pdf/2602.12117v1"
      },
      "arxiv_id": "2602.12117v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12113v1",
      "title": "Stop Unnecessary Reflection: Training LRMs for Efficient Reasoning with Adaptive Reflection and Length Coordinated Penalty",
      "authors": [
        "Zewei Yu",
        "Lirong Gao",
        "Yuke Zhu",
        "Bo Zheng",
        "Sheng Guo",
        "Haobo Wang",
        "Junbo Zhao"
      ],
      "abstract": "Large Reasoning Models (LRMs) have demonstrated remarkable performance on complex reasoning tasks by employing test-time scaling. However, they often generate over-long chains-of-thought that, driven by substantial reflections such as repetitive self-questioning and circular reasoning, lead to high token consumption, substantial computational overhead, and increased latency without improving accuracy, particularly in smaller models. Our observation reveals that increasing problem complexity induces more excessive and unnecessary reflection, which in turn reduces accuracy and increases token overhead. To address this challenge, we propose Adaptive Reflection and Length Coordinated Penalty (ARLCP), a novel reinforcement learning framework designed to dynamically balance reasoning efficiency and solution accuracy. ARLCP introduces two key innovations: (1) a reflection penalty that adaptively curtails unnecessary reflective steps while preserving essential reasoning, and (2) a length penalty calibrated to the estimated complexity of the problem. By coordinating these penalties, ARLCP encourages the model to generate more concise and effective reasoning paths. We evaluate our method on five mathematical reasoning benchmarks using DeepSeek-R1-Distill-Qwen-1.5B and DeepSeek-R1-Distill-Qwen-7B models. Experimental results show that ARLCP achieves a superior efficiency-accuracy trade-off compared to existing approaches. For the 1.5B model, it reduces the average response length by 53.1% while simultaneously improving accuracy by 5.8%. For the 7B model, it achieves a 35.0% reduction in length with a 2.7% accuracy gain. The code is released at https://github.com/ZeweiYu1/ARLCP .",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12113v1",
        "pdf": "https://arxiv.org/pdf/2602.12113v1"
      },
      "arxiv_id": "2602.12113v1",
      "comment": "Accepted to ICLR 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12112v1",
      "title": "Few-Shot Design Optimization by Exploiting Auxiliary Information",
      "authors": [
        "Arjun Mani",
        "Carl Vondrick",
        "Richard Zemel"
      ],
      "abstract": "Many real-world design problems involve optimizing an expensive black-box function $f(x)$, such as hardware design or drug discovery. Bayesian Optimization has emerged as a sample-efficient framework for this problem. However, the basic setting considered by these methods is simplified compared to real-world experimental setups, where experiments often generate a wealth of useful information. We introduce a new setting where an experiment generates high-dimensional auxiliary information $h(x)$ along with the performance measure $f(x)$; moreover, a history of previously solved tasks from the same task family is available for accelerating optimization. A key challenge of our setting is learning how to represent and utilize $h(x)$ for efficiently solving new optimization tasks beyond the task history. We develop a novel approach for this setting based on a neural model which predicts $f(x)$ for unseen designs given a few-shot context containing observations of $h(x)$. We evaluate our method on two challenging domains, robotic hardware design and neural network hyperparameter tuning, and introduce a novel design problem and large-scale benchmark for the former. On both domains, our method utilizes auxiliary feedback effectively to achieve more accurate few-shot prediction and faster optimization of design tasks, significantly outperforming several methods for multi-task optimization.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12112v1",
        "pdf": "https://arxiv.org/pdf/2602.12112v1"
      },
      "arxiv_id": "2602.12112v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12108v1",
      "title": "The Pensieve Paradigm: Stateful Language Models Mastering Their Own Context",
      "authors": [
        "Xiaoyuan Liu",
        "Tian Liang",
        "Dongyang Ma",
        "Deyu Zhou",
        "Haitao Mi",
        "Pinjia He",
        "Yan Wang"
      ],
      "abstract": "In the world of Harry Potter, when Dumbledore's mind is overburdened, he extracts memories into a Pensieve to be revisited later. In the world of AI, while we possess the Pensieve-mature databases and retrieval systems, our models inexplicably lack the \"wand\" to operate it. They remain like a Dumbledore without agency, passively accepting a manually engineered context as their entire memory. This work finally places the wand in the model's hand. We introduce StateLM, a new class of foundation models endowed with an internal reasoning loop to manage their own state. We equip our model with a suite of memory tools, such as context pruning, document indexing, and note-taking, and train it to actively manage these tools. By learning to dynamically engineering its own context, our model breaks free from the architectural prison of a fixed window. Experiments across various model sizes demonstrate StateLM's effectiveness across diverse scenarios. On long-document QA tasks, StateLMs consistently outperform standard LLMs across all model scales; on the chat memory task, they achieve absolute accuracy improvements of 10% to 20% over standard LLMs. On the deep research task BrowseComp-Plus, the performance gap becomes even more pronounced: StateLM achieves up to 52% accuracy, whereas standard LLM counterparts struggle around 5%. Ultimately, our approach shifts LLMs from passive predictors to state-aware agents where reasoning becomes a stateful and manageable process.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12108v1",
        "pdf": "https://arxiv.org/pdf/2602.12108v1"
      },
      "arxiv_id": "2602.12108v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12107v1",
      "title": "On the Complexity of Offline Reinforcement Learning with $Q^\\star$-Approximation and Partial Coverage",
      "authors": [
        "Haolin Liu",
        "Braham Snyder",
        "Chen-Yu Wei"
      ],
      "abstract": "We study offline reinforcement learning under $Q^\\star$-approximation and partial coverage, a setting that motivates practical algorithms such as Conservative $Q$-Learning (CQL; Kumar et al., 2020) but has received limited theoretical attention. Our work is inspired by the following open question: \"Are $Q^\\star$-realizability and Bellman completeness sufficient for sample-efficient offline RL under partial coverage?\"\n  We answer in the negative by establishing an information-theoretic lower bound. Going substantially beyond this, we introduce a general framework that characterizes the intrinsic complexity of a given $Q^\\star$ function class, inspired by model-free decision-estimation coefficients (DEC) for online RL (Foster et al., 2023b; Liu et al., 2025b). This complexity recovers and improves the quantities underlying the guarantees of Chen and Jiang (2022) and Uehara et al. (2023), and extends to broader settings. Our decision-estimation decomposition can be combined with a wide range of $Q^\\star$ estimation procedures, modularizing and generalizing existing approaches.\n  Beyond the general framework, we make further contributions: By developing a novel second-order performance difference lemma, we obtain the first $ε^{-2}$ sample complexity under partial coverage for soft $Q$-learning, improving the $ε^{-4}$ bound of Uehara et al. (2023). We remove Chen and Jiang's (2022) need for additional online interaction when the value gap of $Q^\\star$ is unknown. We also give the first characterization of offline learnability for general low-Bellman-rank MDPs without Bellman completeness (Jiang et al., 2017; Du et al., 2021; Jin et al., 2021), a canonical setting in online RL that remains unexplored in offline RL except for special cases. Finally, we provide the first analysis for CQL under $Q^\\star$-realizability and Bellman completeness beyond the tabular case.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12107v1",
        "pdf": "https://arxiv.org/pdf/2602.12107v1"
      },
      "arxiv_id": "2602.12107v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12105v1",
      "title": "Iskra: A System for Inverse Geometry Processing",
      "authors": [
        "Ana Dodik",
        "Ahmed H. Mahmoud",
        "Justin Solomon"
      ],
      "abstract": "We propose a system for differentiating through solutions to geometry processing problems. Our system differentiates a broad class of geometric algorithms, exploiting existing fast problem-specific schemes common to geometry processing, including local-global and ADMM solvers. It is compatible with machine learning frameworks, opening doors to new classes of inverse geometry processing applications. We marry the scatter-gather approach to mesh processing with tensor-based workflows and rely on the adjoint method applied to user-specified imperative code to generate an efficient backward pass behind the scenes. We demonstrate our approach by differentiating through mean curvature flow, spectral conformal parameterization, geodesic distance computation, and as-rigid-as-possible deformation, examining usability and performance on these applications. Our system allows practitioners to differentiate through existing geometry processing algorithms without needing to reformulate them, resulting in low implementation effort, fast runtimes, and lower memory requirements than differentiable optimization tools not tailored to geometry processing.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.GR",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.GR",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12105v1",
        "pdf": "https://arxiv.org/pdf/2602.12105v1"
      },
      "arxiv_id": "2602.12105v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12100v1",
      "title": "AssetFormer: Modular 3D Assets Generation with Autoregressive Transformer",
      "authors": [
        "Lingting Zhu",
        "Shengju Qian",
        "Haidi Fan",
        "Jiayu Dong",
        "Zhenchao Jin",
        "Siwei Zhou",
        "Gen Dong",
        "Xin Wang",
        "Lequan Yu"
      ],
      "abstract": "The digital industry demands high-quality, diverse modular 3D assets, especially for user-generated content~(UGC). In this work, we introduce AssetFormer, an autoregressive Transformer-based model designed to generate modular 3D assets from textual descriptions. Our pilot study leverages real-world modular assets collected from online platforms. AssetFormer tackles the challenge of creating assets composed of primitives that adhere to constrained design parameters for various applications. By innovatively adapting module sequencing and decoding techniques inspired by language models, our approach enhances asset generation quality through autoregressive modeling. Initial results indicate the effectiveness of AssetFormer in streamlining asset creation for professional development and UGC scenarios. This work presents a flexible framework extendable to various types of modular 3D assets, contributing to the broader field of 3D content generation. The code is available at https://github.com/Advocate99/AssetFormer.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12100v1",
        "pdf": "https://arxiv.org/pdf/2602.12100v1"
      },
      "arxiv_id": "2602.12100v1",
      "comment": "Accepted by ICLR 2026. 23 pages, 14 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12099v1",
      "title": "GigaBrain-0.5M*: a VLA That Learns From World Model-Based Reinforcement Learning",
      "authors": [
        "GigaBrain Team",
        "Boyuan Wang",
        "Chaojun Ni",
        "Guan Huang",
        "Guosheng Zhao",
        "Hao Li",
        "Jie Li",
        "Jindi Lv",
        "Jingyu Liu",
        "Lv Feng",
        "Mingming Yu",
        "Peng Li",
        "Qiuping Deng",
        "Tianze Liu",
        "Xinyu Zhou",
        "Xinze Chen",
        "Xiaofeng Wang",
        "Yang Wang",
        "Yifan Li",
        "Yifei Nie",
        "Yilong Li",
        "Yukun Zhou",
        "Yun Ye",
        "Zhichao Liu",
        "Zheng Zhu"
      ],
      "abstract": "Vision-language-action (VLA) models that directly predict multi-step action chunks from current observations face inherent limitations due to constrained scene understanding and weak future anticipation capabilities. In contrast, video world models pre-trained on web-scale video corpora exhibit robust spatiotemporal reasoning and accurate future prediction, making them a natural foundation for enhancing VLA learning. Therefore, we propose \\textit{GigaBrain-0.5M*}, a VLA model trained via world model-based reinforcement learning. Built upon \\textit{GigaBrain-0.5}, which is pre-trained on over 10,000 hours of robotic manipulation data, whose intermediate version currently ranks first on the international RoboChallenge benchmark. \\textit{GigaBrain-0.5M*} further integrates world model-based reinforcement learning via \\textit{RAMP} (Reinforcement leArning via world Model-conditioned Policy) to enable robust cross-task adaptation. Empirical results demonstrate that \\textit{RAMP} achieves substantial performance gains over the RECAP baseline, yielding improvements of approximately 30\\% on challenging tasks including \\texttt{Laundry Folding}, \\texttt{Box Packing}, and \\texttt{Espresso Preparation}. Critically, \\textit{GigaBrain-0.5M$^*$} exhibits reliable long-horizon execution, consistently accomplishing complex manipulation tasks without failure as validated by real-world deployment videos on our \\href{https://gigabrain05m.github.io}{project page}.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12099v1",
        "pdf": "https://arxiv.org/pdf/2602.12099v1"
      },
      "arxiv_id": "2602.12099v1",
      "comment": "https://gigabrain05m.github.io/",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2602.12096v1",
      "title": "Multi Graph Search for High-Dimensional Robot Motion Planning",
      "authors": [
        "Itamar Mishani",
        "Maxim Likhachev"
      ],
      "abstract": "Efficient motion planning for high-dimensional robotic systems, such as manipulators and mobile manipulators, is critical for real-time operation and reliable deployment. Although advances in planning algorithms have enhanced scalability to high-dimensional state spaces, these improvements often come at the cost of generating unpredictable, inconsistent motions or requiring excessive computational resources and memory. In this work, we introduce Multi-Graph Search (MGS), a search-based motion planning algorithm that generalizes classical unidirectional and bidirectional search to a multi-graph setting. MGS maintains and incrementally expands multiple implicit graphs over the state space, focusing exploration on high-potential regions while allowing initially disconnected subgraphs to be merged through feasible transitions as the search progresses. We prove that MGS is complete and bounded-suboptimal, and empirically demonstrate its effectiveness on a range of manipulation and mobile manipulation tasks. Demonstrations, benchmarks and code are available at https://multi-graph-search.github.io/.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12096v1",
        "pdf": "https://arxiv.org/pdf/2602.12096v1"
      },
      "arxiv_id": "2602.12096v1",
      "comment": "Submitted for Publication",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12092v1",
      "title": "DeepSight: An All-in-One LM Safety Toolkit",
      "authors": [
        "Bo Zhang",
        "Jiaxuan Guo",
        "Lijun Li",
        "Dongrui Liu",
        "Sujin Chen",
        "Guanxu Chen",
        "Zhijie Zheng",
        "Qihao Lin",
        "Lewen Yan",
        "Chen Qian",
        "Yijin Zhou",
        "Yuyao Wu",
        "Shaoxiong Guo",
        "Tianyi Du",
        "Jingyi Yang",
        "Xuhao Hu",
        "Ziqi Miao",
        "Xiaoya Lu",
        "Jing Shao",
        "Xia Hu"
      ],
      "abstract": "As the development of Large Models (LMs) progresses rapidly, their safety is also a priority. In current Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) safety workflow, evaluation, diagnosis, and alignment are often handled by separate tools. Specifically, safety evaluation can only locate external behavioral risks but cannot figure out internal root causes. Meanwhile, safety diagnosis often drifts from concrete risk scenarios and remains at the explainable level. In this way, safety alignment lack dedicated explanations of changes in internal mechanisms, potentially degrading general capabilities. To systematically address these issues, we propose an open-source project, namely DeepSight, to practice a new safety evaluation-diagnosis integrated paradigm. DeepSight is low-cost, reproducible, efficient, and highly scalable large-scale model safety evaluation project consisting of a evaluation toolkit DeepSafe and a diagnosis toolkit DeepScan. By unifying task and data protocols, we build a connection between the two stages and transform safety evaluation from black-box to white-box insight. Besides, DeepSight is the first open source toolkit that support the frontier AI risk evaluation and joint safety evaluation and diagnosis.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12092v1",
        "pdf": "https://arxiv.org/pdf/2602.12092v1"
      },
      "arxiv_id": "2602.12092v1",
      "comment": "Technical report, 29 pages, 24 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12089v1",
      "title": "Choose Your Agent: Tradeoffs in Adopting AI Advisors, Coaches, and Delegates in Multi-Party Negotiation",
      "authors": [
        "Kehang Zhu",
        "Lithium Thain",
        "Vivian Tsai",
        "James Wexler",
        "Crystal Qian"
      ],
      "abstract": "As AI usage becomes more prevalent in social contexts, understanding agent-user interaction is critical to designing systems that improve both individual and group outcomes. We present an online behavioral experiment (N = 243) in which participants play three multi-turn bargaining games in groups of three. Each game, presented in randomized order, grants \\textit{access to} a single LLM assistance modality: proactive recommendations from an \\textit{Advisor}, reactive feedback from a \\textit{Coach}, or autonomous execution by a \\textit{Delegate}; all modalities are powered by an underlying LLM that achieves superhuman performance in an all-agent environment. On each turn, participants privately decide whether to act manually or use the AI modality available in that game. Despite preferring the \\textit{Advisor} modality, participants achieve the highest mean individual gains with the \\textit{Delegate}, demonstrating a preference-performance misalignment. Moreover, delegation generates positive externalities; even non-adopting users in \\textit{access-to-delegate} treatment groups benefit by receiving higher-quality offers. Mechanism analysis reveals that the \\textit{Delegate} agent acts as a market maker, injecting rational, Pareto-improving proposals that restructure the trading environment. Our research reveals a gap between agent capabilities and realized group welfare. While autonomous agents can exhibit super-human strategic performance, their impact on realized welfare gains can be constrained by interfaces, user perceptions, and adoption barriers. Assistance modalities should be designed as mechanisms with endogenous participation; adoption-compatible interaction rules are a prerequisite to improving human welfare with automated assistance.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.GT",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12089v1",
        "pdf": "https://arxiv.org/pdf/2602.12089v1"
      },
      "arxiv_id": "2602.12089v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12087v1",
      "title": "Geometry of Uncertainty: Learning Metric Spaces for Multimodal State Estimation in RL",
      "authors": [
        "Alfredo Reichlin",
        "Adriano Pacciarelli",
        "Danica Kragic",
        "Miguel Vasco"
      ],
      "abstract": "Estimating the state of an environment from high-dimensional, multimodal, and noisy observations is a fundamental challenge in reinforcement learning (RL). Traditional approaches rely on probabilistic models to account for the uncertainty, but often require explicit noise assumptions, in turn limiting generalization. In this work, we contribute a novel method to learn a structured latent representation, in which distances between states directly correlate with the minimum number of actions required to transition between them. The proposed metric space formulation provides a geometric interpretation of uncertainty without the need for explicit probabilistic modeling. To achieve this, we introduce a multimodal latent transition model and a sensor fusion mechanism based on inverse distance weighting, allowing for the adaptive integration of multiple sensor modalities without prior knowledge of noise distributions. We empirically validate the approach on a range of multimodal RL tasks, demonstrating improved robustness to sensor noise and superior state estimation compared to baseline methods. Our experiments show enhanced performance of an RL agent via the learned representation, eliminating the need of explicit noise augmentation. The presented results suggest that leveraging transition-aware metric spaces provides a principled and scalable solution for robust state estimation in sequential decision-making.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12087v1",
        "pdf": "https://arxiv.org/pdf/2602.12087v1"
      },
      "arxiv_id": "2602.12087v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12083v1",
      "title": "Differentiable Modal Logic for Multi-Agent Diagnosis, Orchestration and Communication",
      "authors": [
        "Antonin Sulc"
      ],
      "abstract": "As multi-agent AI systems evolve from simple chatbots to autonomous swarms, debugging semantic failures requires reasoning about knowledge, belief, causality, and obligation, precisely what modal logic was designed to formalize. However, traditional modal logic requires manual specification of relationship structures that are unknown or dynamic in real systems. This tutorial demonstrates differentiable modal logic (DML), implemented via Modal Logical Neural Networks (MLNNs), enabling systems to learn trust networks, causal chains, and regulatory boundaries from behavioral data alone.\n  We present a unified neurosymbolic debugging framework through four modalities: epistemic (who to trust), temporal (when events cause failures), deontic (what actions are permitted), and doxastic (how to interpret agent confidence). Each modality is demonstrated on concrete multi-agent scenarios, from discovering deceptive alliances in diplomacy games to detecting LLM hallucinations, with complete implementations showing how logical contradictions become learnable optimization objectives. Key contributions for the neurosymbolic community: (1) interpretable learned structures where trust and causality are explicit parameters, not opaque embeddings; (2) knowledge injection via differentiable axioms that guide learning with sparse data (3) compositional multi-modal reasoning that combines epistemic, temporal, and deontic constraints; and (4) practical deployment patterns for monitoring, active control and communication of multi-agent systems. All code provided as executable Jupyter notebooks.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12083v1",
        "pdf": "https://arxiv.org/pdf/2602.12083v1"
      },
      "arxiv_id": "2602.12083v1",
      "comment": "29 pages, 8 figures, 8 tables, Tutorial at 3rd International Conference on Neuro-Symbolic Systems (NeuS)",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12082v1",
      "title": "Empirical Gaussian Processes",
      "authors": [
        "Jihao Andreas Lin",
        "Sebastian Ament",
        "Louis C. Tiao",
        "David Eriksson",
        "Maximilian Balandat",
        "Eytan Bakshy"
      ],
      "abstract": "Gaussian processes (GPs) are powerful and widely used probabilistic regression models, but their effectiveness in practice is often limited by the choice of kernel function. This kernel function is typically handcrafted from a small set of standard functions, a process that requires expert knowledge, results in limited adaptivity to data, and imposes strong assumptions on the hypothesis space. We study Empirical GPs, a principled framework for constructing flexible, data-driven GP priors that overcome these limitations. Rather than relying on standard parametric kernels, we estimate the mean and covariance functions empirically from a corpus of historical observations, enabling the prior to reflect rich, non-trivial covariance structures present in the data. Theoretically, we show that the resulting model converges to the GP that is closest (in KL-divergence sense) to the real data generating process. Practically, we formulate the problem of learning the GP prior from independent datasets as likelihood estimation and derive an Expectation-Maximization algorithm with closed-form updates, allowing the model handle heterogeneous observation locations across datasets. We demonstrate that Empirical GPs achieve competitive performance on learning curve extrapolation and time series forecasting benchmarks.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12082v1",
        "pdf": "https://arxiv.org/pdf/2602.12082v1"
      },
      "arxiv_id": "2602.12082v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12080v1",
      "title": "PathCRF: Ball-Free Soccer Event Detection via Possession Path Inference from Player Trajectories",
      "authors": [
        "Hyunsung Kim",
        "Kunhee Lee",
        "Sangwoo Seo",
        "Sang-Ki Ko",
        "Jinsung Yoon",
        "Chanyoung Park"
      ],
      "abstract": "Despite recent advances in AI, event data collection in soccer still relies heavily on labor-intensive manual annotation. Although prior work has explored automatic event detection using player and ball trajectories, ball tracking also remains difficult to scale due to high infrastructural and operational costs. As a result, comprehensive data collection in soccer is largely confined to top-tier competitions, limiting the broader adoption of data-driven analysis in this domain. To address this challenge, this paper proposes PathCRF, a framework for detecting on-ball soccer events using only player tracking data. We model player trajectories as a fully connected dynamic graph and formulate event detection as the problem of selecting exactly one edge corresponding to the current possession state at each time step. To ensure logical consistency of the resulting edge sequence, we employ a Conditional Random Field (CRF) that forbids impossible transitions between consecutive edges. Both emission and transition scores dynamically computed from edge embeddings produced by a Set Attention-based backbone architecture. During inference, the most probable edge sequence is obtained via Viterbi decoding, and events such as ball controls or passes are detected whenever the selected edge changes between adjacent time steps. Experiments show that PathCRF produces accurate, logically consistent possession paths, enabling reliable downstream analyses while substantially reducing the need for manual event annotation. The source code is available at https://github.com/hyunsungkim-ds/pathcrf.git.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12080v1",
        "pdf": "https://arxiv.org/pdf/2602.12080v1"
      },
      "arxiv_id": "2602.12080v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12078v1",
      "title": "Tiny Recursive Reasoning with Mamba-2 Attention Hybrid",
      "authors": [
        "Wenlong Wang",
        "Fergal Reid"
      ],
      "abstract": "Recent work on recursive reasoning models like TRM demonstrates that tiny networks (7M parameters) can achieve strong performance on abstract reasoning tasks through latent recursion -- iterative refinement in hidden representation space without emitting intermediate tokens. This raises a natural question about operator choice: Mamba-2's state space recurrence is itself a form of iterative refinement, making it a natural candidate for recursive reasoning -- but does introducing Mamba-2 into the recursive scaffold preserve reasoning capability? We investigate this by replacing the Transformer blocks in TRM with Mamba-2 hybrid operators while maintaining parameter parity (6.83M vs 6.86M parameters). On ARC-AGI-1, we find that the hybrid improves pass@2 (the official metric) by +2.0\\% (45.88\\% vs 43.88\\%) and consistently outperforms at higher K values (+4.75\\% at pass@100), whilst maintaining pass@1 parity. This suggests improved candidate coverage -- the model generates correct solutions more reliably -- with similar top-1 selection. Our results validate that Mamba-2 hybrid operators preserve reasoning capability within the recursive scaffold, establishing SSM-based operators as viable candidates in the recursive operator design space and taking a first step towards understanding the best mixing strategies for recursive reasoning.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12078v1",
        "pdf": "https://arxiv.org/pdf/2602.12078v1"
      },
      "arxiv_id": "2602.12078v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12058v1",
      "title": "ModelWisdom: An Integrated Toolkit for TLA+ Model Visualization, Digest and Repair",
      "authors": [
        "Zhiyong Chen",
        "Jialun Cao",
        "Chang Xu",
        "Shing-Chi Cheung"
      ],
      "abstract": "Model checking in TLA+ provides strong correctness guarantees, yet practitioners continue to face significant challenges in interpreting counterexamples, understanding large state-transition graphs, and repairing faulty models. These difficulties stem from the limited explainability of raw model-checker output and the substantial manual effort required to trace violations back to source specifications. Although the TLA+ Toolbox includes a state diagram viewer, it offers only a static, fully expanded graph without folding, color highlighting, or semantic explanations, which limits its scalability and interpretability. We present ModelWisdom, an interactive environment that uses visualization and large language models to make TLA+ model checking more interpretable and actionable. ModelWisdom offers: (i) Model Visualization, with colorized violation highlighting, click-through links from transitions to TLA+ code, and mapping between violating states and broken properties; (ii) Graph Optimization, including tree-based structuring and node/edge folding to manage large models; (iii) Model Digest, which summarizes and explains subgraphs via large language models (LLMs) and performs preprocessing and partial explanations; and (iv) Model Repair, which extracts error information and supports iterative debugging. Together, these capabilities turn raw model-checker output into an interactive, explainable workflow, improving understanding and reducing debugging effort for nontrivial TLA+ specifications. The website to ModelWisdom is available: https://model-wisdom.pages.dev. A demonstrative video can be found at https://www.youtube.com/watch?v=plyZo30VShA.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.FL"
      ],
      "primary_category": "cs.SE",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12058v1",
        "pdf": "https://arxiv.org/pdf/2602.12058v1"
      },
      "arxiv_id": "2602.12058v1",
      "comment": "Accepted by FM 2026 Research Track (Tool)",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12056v1",
      "title": "LawThinker: A Deep Research Legal Agent in Dynamic Environments",
      "authors": [
        "Xinyu Yang",
        "Chenlong Deng",
        "Tongyu Wen",
        "Binyu Xie",
        "Zhicheng Dou"
      ],
      "abstract": "Legal reasoning requires not only correct outcomes but also procedurally compliant reasoning processes. However, existing methods lack mechanisms to verify intermediate reasoning steps, allowing errors such as inapplicable statute citations to propagate undetected through the reasoning chain. To address this, we propose LawThinker, an autonomous legal research agent that adopts an Explore-Verify-Memorize strategy for dynamic judicial environments. The core idea is to enforce verification as an atomic operation after every knowledge exploration step. A DeepVerifier module examines each retrieval result along three dimensions of knowledge accuracy, fact-law relevance, and procedural compliance, with a memory module for cross-round knowledge reuse in long-horizon tasks. Experiments on the dynamic benchmark J1-EVAL show that LawThinker achieves a 24% improvement over direct reasoning and an 11% gain over workflow-based methods, with particularly strong improvements on process-oriented metrics. Evaluations on three static benchmarks further confirm its generalization capability. The code is available at https://github.com/yxy-919/LawThinker-agent .",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12056v1",
        "pdf": "https://arxiv.org/pdf/2602.12056v1"
      },
      "arxiv_id": "2602.12056v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12055v1",
      "title": "Multi UAVs Preflight Planning in a Shared and Dynamic Airspace",
      "authors": [
        "Amath Sow",
        "Mauricio Rodriguez Cesen",
        "Fabiola Martins Campos de Oliveira",
        "Mariusz Wzorek",
        "Daniel de Leng",
        "Mattias Tiger",
        "Fredrik Heintz",
        "Christian Esteve Rothenberg"
      ],
      "abstract": "Preflight planning for large-scale Unmanned Aerial Vehicle (UAV) fleets in dynamic, shared airspace presents significant challenges, including temporal No-Fly Zones (NFZs), heterogeneous vehicle profiles, and strict delivery deadlines. While Multi-Agent Path Finding (MAPF) provides a formal framework, existing methods often lack the scalability and flexibility required for real-world Unmanned Traffic Management (UTM). We propose DTAPP-IICR: a Delivery-Time Aware Prioritized Planning method with Incremental and Iterative Conflict Resolution. Our framework first generates an initial solution by prioritizing missions based on urgency. Secondly, it computes roundtrip trajectories using SFIPP-ST, a novel 4D single-agent planner (Safe Flight Interval Path Planning with Soft and Temporal Constraints). SFIPP-ST handles heterogeneous UAVs, strictly enforces temporal NFZs, and models inter-agent conflicts as soft constraints. Subsequently, an iterative Large Neighborhood Search, guided by a geometric conflict graph, efficiently resolves any residual conflicts. A completeness-preserving directional pruning technique further accelerates the 3D search. On benchmarks with temporal NFZs, DTAPP-IICR achieves near-100% success with fleets of up to 1,000 UAVs and gains up to 50% runtime reduction from pruning, outperforming batch Enhanced Conflict-Based Search in the UTM context. Scaling successfully in realistic city-scale operations where other priority-based methods fail even at moderate deployments, DTAPP-IICR is positioned as a practical and scalable solution for preflight planning in dense, dynamic urban airspace.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.AI",
        "cs.MA",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12055v1",
        "pdf": "https://arxiv.org/pdf/2602.12055v1"
      },
      "arxiv_id": "2602.12055v1",
      "comment": "AAMAS 2026 accepted paper",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12049v1",
      "title": "Improving HPC Code Generation Capability of LLMs via Online Reinforcement Learning with Real-Machine Benchmark Rewards",
      "authors": [
        "Ryo Mikasa",
        "Shun-ichiro Hayashi",
        "Daichi Mukunoki",
        "Tetsuya Hoshino",
        "Takahiro Katagiri"
      ],
      "abstract": "Large language models (LLMs) have demonstrated strong code generation capabilities, yet the runtime performance of generated code is not guaranteed, and there have been few attempts to train LLMs using runtime performance as a reward in the HPC domain. We propose an online reinforcement learning approach that executes LLM-generated code on a supercomputer and directly feeds back the measured runtime performance (GFLOPS) as a reward. We further introduce a Staged Quality-Diversity (SQD) algorithm that progressively varies the permitted optimization techniques on a per-problem basis, enabling the model to learn code optimization from diverse perspectives. We build a distributed system connecting a GPU training cluster with a CPU benchmarking cluster, and train Qwen2.5 Coder 14B on a double-precision matrix multiplication task using Group Relative Policy Optimization (GRPO). Through two experiments, we show that reinforcement learning combining runtime performance feedback with staged optimization can improve the HPC code generation capability of LLMs.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12049v1",
        "pdf": "https://arxiv.org/pdf/2602.12049v1"
      },
      "arxiv_id": "2602.12049v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12047v1",
      "title": "Safety Beyond the Training Data: Robust Out-of-Distribution MPC via Conformalized System Level Synthesis",
      "authors": [
        "Anutam Srinivasan",
        "Antoine Leeman",
        "Glen Chou"
      ],
      "abstract": "We present a novel framework for robust out-of-distribution planning and control using conformal prediction (CP) and system level synthesis (SLS), addressing the challenge of ensuring safety and robustness when using learned dynamics models beyond the training data distribution. We first derive high-confidence model error bounds using weighted CP with a learned, state-control-dependent covariance model. These bounds are integrated into an SLS-based robust nonlinear model predictive control (MPC) formulation, which performs constraint tightening over the prediction horizon via volume-optimized forward reachable sets. We provide theoretical guarantees on coverage and robustness under distributional drift, and analyze the impact of data density and trajectory tube size on prediction coverage. Empirically, we demonstrate our method on nonlinear systems of increasing complexity, including a 4D car and a {12D} quadcopter, improving safety and robustness compared to fixed-bound and non-robust baselines, especially outside of the data distribution.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.RO",
        "cs.LG",
        "eess.SY",
        "math.OC"
      ],
      "primary_category": "cs.RO",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12047v1",
        "pdf": "https://arxiv.org/pdf/2602.12047v1"
      },
      "arxiv_id": "2602.12047v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12045v1",
      "title": "Fourier Transformers for Latent Crystallographic Diffusion and Generative Modeling",
      "authors": [
        "Jed A. Duersch",
        "Elohan Veillon",
        "Astrid Klipfel",
        "Adlane Sayede",
        "Zied Bouraoui"
      ],
      "abstract": "The discovery of new crystalline materials calls for generative models that handle periodic boundary conditions, crystallographic symmetries, and physical constraints, while scaling to large and structurally diverse unit cells. We propose a reciprocal-space generative pipeline that represents crystals through a truncated Fourier transform of the species-resolved unit-cell density, rather than modeling atomic coordinates directly. This representation is periodicity-native, admits simple algebraic actions of space-group symmetries, and naturally supports variable atomic multiplicities during generation, addressing a common limitation of particle-based approaches. Using only nine Fourier basis functions per spatial dimension, our approach reconstructs unit cells containing up to 108 atoms per chemical species. We instantiate this pipeline with a transformer variational autoencoder over complex-valued Fourier coefficients, and a latent diffusion model that generates in the compressed latent space. We evaluate reconstruction and latent diffusion on the LeMaterial benchmark and compare unconditional generation against coordinate-based baselines in the small-cell regime ($\\leq 16$ atoms per unit cell).",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12045v1",
        "pdf": "https://arxiv.org/pdf/2602.12045v1"
      },
      "arxiv_id": "2602.12045v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12044v1",
      "title": "A DMD-Based Adaptive Modulation Method for High Dynamic Range Imaging in High-Glare Environments",
      "authors": [
        "Banglei Guan",
        "Jing Tao",
        "Liang Xu",
        "Dongcai Tan",
        "Pengju Sun",
        "Jianbing Liu",
        "Yang Shang",
        "Qifeng Yu"
      ],
      "abstract": "Background The accuracy of photomechanics measurements critically relies on image quality,particularly under extreme illumination conditions such as welding arc monitoring and polished metallic surface analysis. High dynamic range (HDR) imaging above 120 dB is essential in these contexts. Conventional CCD/CMOS sensors, with dynamic ranges typically below 70 dB, are highly susceptible to saturation under glare, resulting in irreversible loss of detail and significant errors in digital image correlation (DIC). Methods This paper presents an HDR imaging system that leverages the spatial modulation capability of a digital micromirror device (DMD). The system architecture enables autonomous regional segmentation and adaptive exposure control for high-dynamic-range scenes through an integrated framework comprising two synergistic subsystems: a DMD-based optical modulation unit and an adaptive computational imaging pipeline. Results The system achieves a measurable dynamic range of 127 dB, effectively eliminating satu ration artifacts under high glare. Experimental results demonstrate a 78% reduction in strain error and improved DIC positioning accuracy, confirming reliable performance across extreme intensity variations. Conclusion The DMD-based system provides high fidelity adaptive HDR imaging, overcoming key limitations of conventional sensors. It exhibits strong potential for optical metrology and stress analysis in high-glare environments where traditional methods are inadequate.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12044v1",
        "pdf": "https://arxiv.org/pdf/2602.12044v1"
      },
      "arxiv_id": "2602.12044v1",
      "comment": "This paper has been accepted by Experimental Mechanics",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12039v1",
      "title": "The Implicit Bias of Logit Regularization",
      "authors": [
        "Alon Beck",
        "Yohai Bar Sinai",
        "Noam Levi"
      ],
      "abstract": "Logit regularization, the addition a convex penalty directly in logit space, is widely used in modern classifiers, with label smoothing as a prominent example. While such methods often improve calibration and generalization, their mechanism remains under-explored. In this work, we analyze a general class of such logit regularizers in the context of linear classification, and demonstrate that they induce an implicit bias of logit clustering around finite per-sample targets. For Gaussian data, or whenever logits are sufficiently clustered, we prove that logit clustering drives the weight vector to align exactly with Fisher's Linear Discriminant. To demonstrate the consequences, we study a simple signal-plus-noise model in which this transition has dramatic effects: Logit regularization halves the critical sample complexity and induces grokking in the small-noise limit, while making generalization robust to noise. Our results extend the theoretical understanding of label smoothing and highlight the efficacy of a broader class of logit-regularization methods.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12039v1",
        "pdf": "https://arxiv.org/pdf/2602.12039v1"
      },
      "arxiv_id": "2602.12039v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12038v1",
      "title": "An Empirical Study of the Imbalance Issue in Software Vulnerability Detection",
      "authors": [
        "Yuejun Guo",
        "Qiang Hu",
        "Qiang Tang",
        "Yves Le Traon"
      ],
      "abstract": "Vulnerability detection is crucial to protect software security. Nowadays, deep learning (DL) is the most promising technique to automate this detection task, leveraging its superior ability to extract patterns and representations within extensive code volumes. Despite its promise, DL-based vulnerability detection remains in its early stages, with model performance exhibiting variability across datasets. Drawing insights from other well-explored application areas like computer vision, we conjecture that the imbalance issue (the number of vulnerable code is extremely small) is at the core of the phenomenon. To validate this, we conduct a comprehensive empirical study involving nine open-source datasets and two state-of-the-art DL models. The results confirm our conjecture. We also obtain insightful findings on how existing imbalance solutions perform in vulnerability detection. It turns out that these solutions perform differently as well across datasets and evaluation metrics. Specifically: 1) Focal loss is more suitable to improve the precision, 2) mean false error and class-balanced loss encourages the recall, and 3) random over-sampling facilitates the F1-measure. However, none of them excels across all metrics. To delve deeper, we explore external influences on these solutions and offer insights for developing new solutions.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12038v1",
        "pdf": "https://arxiv.org/pdf/2602.12038v1"
      },
      "arxiv_id": "2602.12038v1",
      "comment": "This paper was accepted by the 28th European Symposium on Research in Computer Security (ESORICS), 2023",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12029v1",
      "title": "PrefillShare: A Shared Prefill Module for KV Reuse in Multi-LLM Disaggregated Serving",
      "authors": [
        "Sunghyeon Woo",
        "Hoseung Kim",
        "Sunghwan Shim",
        "Minjung Jo",
        "Hyunjoon Jeong",
        "Jeongtae Lee",
        "Joonghoon Kim",
        "Sungjae Lee",
        "Baeseong Park",
        "Se Jung Kwon",
        "Dongsoo Lee"
      ],
      "abstract": "Multi-agent systems increasingly orchestrate multiple specialized language models to solve complex real-world problems, often invoking them over a shared context. This execution pattern repeatedly processes the same prompt prefix across models. Consequently, each model redundantly executes the prefill stage and maintains its own key-value (KV) cache, increasing aggregate prefill load and worsening tail latency by intensifying prefill-decode interference in existing LLM serving stacks. Disaggregated serving reduces such interference by placing prefill and decode on separate GPUs, but disaggregation does not fundamentally eliminate inter-model redundancy in computation and KV storage for the same prompt. To address this issue, we propose PrefillShare, a novel algorithm that enables sharing the prefill stage across multiple models in a disaggregated setting. PrefillShare factorizes the model into prefill and decode modules, freezes the prefill module, and fine-tunes only the decode module. This design allows multiple task-specific models to share a prefill module and the KV cache generated for the same prompt. We further introduce a routing mechanism that enables effective prefill sharing across heterogeneous models in a vLLM-based disaggregated system. PrefillShare not only matches full fine-tuning accuracy on a broad range of tasks and models, but also delivers 4.5x lower p95 latency and 3.9x higher throughput in multi-model agent workloads.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.LG",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12029v1",
        "pdf": "https://arxiv.org/pdf/2602.12029v1"
      },
      "arxiv_id": "2602.12029v1",
      "comment": "Preprint. 13 pages, 6 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12026v1",
      "title": "Protein Circuit Tracing via Cross-layer Transcoders",
      "authors": [
        "Darin Tsui",
        "Kunal Talreja",
        "Daniel Saeedi",
        "Amirali Aghazadeh"
      ],
      "abstract": "Protein language models (pLMs) have emerged as powerful predictors of protein structure and function. However, the computational circuits underlying their predictions remain poorly understood. Recent mechanistic interpretability methods decompose pLM representations into interpretable features, but they treat each layer independently and thus fail to capture cross-layer computation, limiting their ability to approximate the full model. We introduce ProtoMech, a framework for discovering computational circuits in pLMs using cross-layer transcoders that learn sparse latent representations jointly across layers to capture the model's full computational circuitry. Applied to the pLM ESM2, ProtoMech recovers 82-89% of the original performance on protein family classification and function prediction tasks. ProtoMech then identifies compressed circuits that use <1% of the latent space while retaining up to 79% of model accuracy, revealing correspondence with structural and functional motifs, including binding, signaling, and stability. Steering along these circuits enables high-fitness protein design, surpassing baseline methods in more than 70% of cases. These results establish ProtoMech as a principled framework for protein circuit tracing.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.LG",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12026v1",
        "pdf": "https://arxiv.org/pdf/2602.12026v1"
      },
      "arxiv_id": "2602.12026v1",
      "comment": "29 pages, 15 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12021v1",
      "title": "Improved state mixing in higher-order and block diagonal linear recurrent networks",
      "authors": [
        "Igor Dubinin",
        "Antonio Orvieto",
        "Felix Effenberger"
      ],
      "abstract": "Linear recurrent networks (LRNNs) and linear state space models (SSMs) promise computational and memory efficiency on long-sequence modeling tasks, yet their diagonal state transitions limit expressivity. Dense and nonlinear architectures (e.g., LSTMs) on the other hand are provably more expressive, but computationally costly. Here, we explore how expressivity in LRNNs can be increased via richer state mixing across time and channels while maintaining competitive efficiency. Specifically, we introduce two structured LRNN architectures: (i) Higher-order Linear Recurrent Units (H-LRU), which generalize first-order recurrence to higher order, mixing multiple past states, and (ii) Block-Diagonal LRUs (BD-LRU), which enable dense intra-block channel mixing. Per-channel (H-LRU) or per-row (BD-LRU) L1-normalization of selective gates stabilizes training and allows for scaling window/block sizes. A parallel-scan implementation of the proposed architectures keeps the throughput competitive with diagonal LRNNs for moderate orders (H-LRU) and block sizes (BD-LRU). In synthetic sequence modeling tasks, the performance of BD-LRU matches or exceeds those of linear SSMs (Mamba), low-rank LRNNs (DeltaNet) and LSTM baselines, while H-LRU is found to be the most parameter-efficient in compression task. In both synthetic sequence modeling and language modeling, our results indicate that the structure of state mixing rather than width alone shapes expressivity of LRNNs, offering a practical route to closing the efficiency-expressivity gap in linear sequence models.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12021v1",
        "pdf": "https://arxiv.org/pdf/2602.12021v1"
      },
      "arxiv_id": "2602.12021v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12014v1",
      "title": "FedGRPO: Privately Optimizing Foundation Models with Group-Relative Rewards from Domain Client",
      "authors": [
        "Gongxi Zhu",
        "Hanlin Gu",
        "Lixin Fan",
        "Qiang Yang",
        "Yuxing Han"
      ],
      "abstract": "One important direction of Federated Foundation Models (FedFMs) is leveraging data from small client models to enhance the performance of a large server-side foundation model. Existing methods based on model level or representation level knowledge transfer either require expensive local training or incur high communication costs and introduce unavoidable privacy risks. We reformulate this problem as a reinforcement learning style evaluation process and propose FedGRPO, a privacy preserving framework comprising two modules. The first module performs competence-based expert selection by building a lightweight confidence graph from auxiliary data to identify the most suitable clients for each question. The second module leverages the \"Group Relative\" concept from the Group Relative Policy Optimization (GRPO) framework by packaging each question together with its solution rationale into candidate policies, dispatching these policies to a selected subset of expert clients, and aggregating solely the resulting scalar reward signals via a federated group-relative loss function. By exchanging reward values instead of data or model updates, FedGRPO reduces privacy risk and communication overhead while enabling parallel evaluation across heterogeneous devices. Empirical results on diverse domain tasks demonstrate that FedGRPO achieves superior downstream accuracy and communication efficiency compared to conventional FedFMs baselines.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12014v1",
        "pdf": "https://arxiv.org/pdf/2602.12014v1"
      },
      "arxiv_id": "2602.12014v1",
      "comment": "Accepted by AAAI 2026 as Oral",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12013v1",
      "title": "InjectRBP: Steering Large Language Model Reasoning Behavior via Pattern Injection",
      "authors": [
        "Xiuping Wu",
        "Zhao Yu",
        "Yuxin Cheng",
        "Ngai Wong",
        "Liangjun Ke",
        "Tapas Mishra",
        "Konstantinos V. Katsikopoulos"
      ],
      "abstract": "Reasoning can significantly enhance the performance of Large Language Models. While recent studies have exploited behavior-related prompts adjustment to enhance reasoning, these designs remain largely intuitive and lack a systematic analysis of the underlying behavioral patterns. Motivated by this, we investigate how models' reasoning behaviors shape reasoning from the perspective of behavioral patterns. We observe that models exhibit adaptive distributions of reasoning behaviors when responding to specific types of questions, and that structurally injecting these patterns can substantially influence the quality of the models' reasoning processes and outcomes. Building on these findings, we propose two optimization methods that require no parameter updates: InjectCorrect and InjectRLOpt. InjectCorrect guides the model by imitating behavioral patterns derived from its own past correct answers. InjectRLOpt learns a value function from historical behavior-pattern data and, via our proposed Reliability-Aware Softmax Policy, generates behavioral injectant during inference to steer the reasoning process. Our experiments demonstrate that both methods can improve model performance across various reasoning tasks without requiring any modifications to model parameters, achieving gains of up to 5.34% and 8.67%, respectively.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12013v1",
        "pdf": "https://arxiv.org/pdf/2602.12013v1"
      },
      "arxiv_id": "2602.12013v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12009v1",
      "title": "On the Sensitivity of Firing Rate-Based Federated Spiking Neural Networks to Differential Privacy",
      "authors": [
        "Luiz Pereira",
        "Mirko Perkusich",
        "Dalton Valadares",
        "Kyller Gorgônio"
      ],
      "abstract": "Federated Neuromorphic Learning (FNL) enables energy-efficient and privacy-preserving learning on devices without centralizing data. However, real-world deployments require additional privacy mechanisms that can significantly alter training signals. This paper analyzes how Differential Privacy (DP) mechanisms, specifically gradient clipping and noise injection, perturb firing-rate statistics in Spiking Neural Networks (SNNs) and how these perturbations are propagated to rate-based FNL coordination. On a speech recognition task under non-IID settings, ablations across privacy budgets and clipping bounds reveal systematic rate shifts, attenuated aggregation, and ranking instability during client selection. Moreover, we relate these shifts to sparsity and memory indicators. Our findings provide actionable guidance for privacy-preserving FNL, specifically regarding the balance between privacy strength and rate-dependent coordination.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12009v1",
        "pdf": "https://arxiv.org/pdf/2602.12009v1"
      },
      "arxiv_id": "2602.12009v1",
      "comment": "To be published in 2026 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12004v1",
      "title": "CSEval: A Framework for Evaluating Clinical Semantics in Text-to-Image Generation",
      "authors": [
        "Robert Cronshaw",
        "Konstantinos Vilouras",
        "Junyu Yan",
        "Yuning Du",
        "Feng Chen",
        "Steven McDonagh",
        "Sotirios A. Tsaftaris"
      ],
      "abstract": "Text-to-image generation has been increasingly applied in medical domains for various purposes such as data augmentation and education. Evaluating the quality and clinical reliability of these generated images is essential. However, existing methods mainly assess image realism or diversity, while failing to capture whether the generated images reflect the intended clinical semantics, such as anatomical location and pathology. In this study, we propose the Clinical Semantics Evaluator (CSEval), a framework that leverages language models to assess clinical semantic alignment between the generated images and their conditioning prompts. Our experiments show that CSEval identifies semantic inconsistencies overlooked by other metrics and correlates with expert judgment. CSEval provides a scalable and clinically meaningful complement to existing evaluation methods, supporting the safe adoption of generative models in healthcare.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12004v1",
        "pdf": "https://arxiv.org/pdf/2602.12004v1"
      },
      "arxiv_id": "2602.12004v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12003v1",
      "title": "Projected Representation Conditioning for High-fidelity Novel View Synthesis",
      "authors": [
        "Min-Seop Kwak",
        "Minkyung Kwon",
        "Jinhyeok Choi",
        "Jiho Park",
        "Seungryong Kim"
      ],
      "abstract": "We propose a novel framework for diffusion-based novel view synthesis in which we leverage external representations as conditions, harnessing their geometric and semantic correspondence properties for enhanced geometric consistency in generated novel viewpoints. First, we provide a detailed analysis exploring the correspondence capabilities emergent in the spatial attention of external visual representations. Building from these insights, we propose a representation-guided novel view synthesis through dedicated representation projection modules that inject external representations into the diffusion process, a methodology named ReNoV, short for representation-guided novel view synthesis. Our experiments show that this design yields marked improvements in both reconstruction fidelity and inpainting quality, outperforming prior diffusion-based novel-view methods on standard benchmarks and enabling robust synthesis from sparse, unposed image collections.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12003v1",
        "pdf": "https://arxiv.org/pdf/2602.12003v1"
      },
      "arxiv_id": "2602.12003v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.12002v1",
      "title": "Can Local Vision-Language Models improve Activity Recognition over Vision Transformers? -- Case Study on Newborn Resuscitation",
      "authors": [
        "Enrico Guerriero",
        "Kjersti Engan",
        "Øyvind Meinich-Bache"
      ],
      "abstract": "Accurate documentation of newborn resuscitation is essential for quality improvement and adherence to clinical guidelines, yet remains underutilized in practice. Previous work using 3D-CNNs and Vision Transformers (ViT) has shown promising results in detecting key activities from newborn resuscitation videos, but also highlighted the challenges in recognizing such fine-grained activities. This work investigates the potential of generative AI (GenAI) methods to improve activity recognition from such videos. Specifically, we explore the use of local vision-language models (VLMs), combined with large language models (LLMs), and compare them to a supervised TimeSFormer baseline. Using a simulated dataset comprising 13.26 hours of newborn resuscitation videos, we evaluate several zero-shot VLM-based strategies and fine-tuned VLMs with classification heads, including Low-Rank Adaptation (LoRA). Our results suggest that small (local) VLMs struggle with hallucinations, but when fine-tuned with LoRA, the results reach F1 score at 0.91, surpassing the TimeSformer results of 0.70.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.12002v1",
        "pdf": "https://arxiv.org/pdf/2602.12002v1"
      },
      "arxiv_id": "2602.12002v1",
      "comment": "Presented at the Satellite Workshop on Workshop 15: Generative AI for World Simulations and Communications & Celebrating 40 Years of Excellence in Education: Honoring Professor Aggelos Katsaggelos, IEEE International Conference on Image Processing (ICIP), 2025",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.11995v1",
      "title": "Momentum LMS Theory beyond Stationarity: Stability, Tracking, and Regret",
      "authors": [
        "Yifei Jin",
        "Xin Zheng",
        "Lei Guo"
      ],
      "abstract": "In large-scale data processing scenarios, data often arrive in sequential streams generated by complex systems that exhibit drifting distributions and time-varying system parameters. This nonstationarity challenges theoretical analysis, as it violates classical assumptions of i.i.d. (independent and identically distributed) samples, necessitating algorithms capable of real-time updates without expensive retraining. An effective approach should process each sample in a single pass, while maintaining computational and memory complexities independent of the data stream length. Motivated by these challenges, this paper investigates the Momentum Least Mean Squares (MLMS) algorithm as an adaptive identification tool, leveraging its computational simplicity and online processing capabilities. Theoretically, we derive tracking performance and regret bounds for the MLMS in time-varying stochastic linear systems under various practical conditions. Unlike classical LMS, whose stability can be characterized by first-order random vector difference equations, MLMS introduces an additional dynamical state due to momentum, leading to second-order time-varying random vector difference equations whose stability analysis hinges on more complicated products of random matrices, which poses a substantially challenging problem to resolve. Experiments on synthetic and real-world data streams demonstrate that MLMS achieves rapid adaptation and robust tracking, in agreement with our theoretical results especially in nonstationary settings, highlighting its promise for modern streaming and online learning applications.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.11995v1",
        "pdf": "https://arxiv.org/pdf/2602.11995v1"
      },
      "arxiv_id": "2602.11995v1",
      "comment": "9 pages, 3 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.11988v1",
      "title": "Evaluating AGENTS.md: Are Repository-Level Context Files Helpful for Coding Agents?",
      "authors": [
        "Thibaud Gloaguen",
        "Niels Mündler",
        "Mark Müller",
        "Veselin Raychev",
        "Martin Vechev"
      ],
      "abstract": "A widespread practice in software development is to tailor coding agents to repositories using context files, such as AGENTS.md, by either manually or automatically generating them. Although this practice is strongly encouraged by agent developers, there is currently no rigorous investigation into whether such context files are actually effective for real-world tasks. In this work, we study this question and evaluate coding agents' task completion performance in two complementary settings: established SWE-bench tasks from popular repositories, with LLM-generated context files following agent-developer recommendations, and a novel collection of issues from repositories containing developer-committed context files.\n  Across multiple coding agents and LLMs, we find that context files tend to reduce task success rates compared to providing no repository context, while also increasing inference cost by over 20%. Behaviorally, both LLM-generated and developer-provided context files encourage broader exploration (e.g., more thorough testing and file traversal), and coding agents tend to respect their instructions. Ultimately, we conclude that unnecessary requirements from context files make tasks harder, and human-written context files should describe only minimal requirements.",
      "published": "2026-02-12",
      "updated": "2026-02-12",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "links": {
        "paper": "http://arxiv.org/abs/2602.11988v1",
        "pdf": "https://arxiv.org/pdf/2602.11988v1"
      },
      "arxiv_id": "2602.11988v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    }
  ]
}