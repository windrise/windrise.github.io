{
  "fetched_at": "2025-12-02T00:25:28.109485",
  "total_papers": 100,
  "papers": [
    {
      "id": "2511.23478v1",
      "title": "Video-R2: Reinforcing Consistent and Grounded Reasoning in Multimodal Language Models",
      "authors": [
        "Muhammad Maaz",
        "Hanoona Rasheed",
        "Fahad Shahbaz Khan",
        "Salman Khan"
      ],
      "abstract": "Reasoning over dynamic visual content remains a central challenge for multimodal large language models. Recent thinking models generate explicit reasoning traces for interpretability; however, their reasoning often appears convincing while being logically inconsistent or weakly grounded in visual evidence. We identify and formalize these issues through two diagnostic metrics: Think Answer Consistency (TAC), which measures the alignment between reasoning and answers, and Video Attention Score (VAS), which captures the extent to which reasoning depends on visual versus textual cues. Analysis across 11 video reasoning benchmarks shows that current models rely heavily on linguistic priors rather than visual content. To address this, we propose a reinforcement learning approach that enhances both temporal precision and reasoning consistency. Our approach combines timestamp aware supervised fine tuning with Group Relative Policy Optimization (GRPO) guided by a novel Temporal Alignment Reward (TAR). This dual step post training stage encourages temporally aligned and causally coherent video reasoning. The resulting model, Video R2, achieves consistently higher TAC, VAS, and accuracy across multiple benchmarks, demonstrating that improvements in temporal alignment and reasoning coherence lead to more accurate and trustworthy video understanding. Our code, dataset, and model will be open sourced.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23478v1",
        "pdf": "https://arxiv.org/pdf/2511.23478v1"
      },
      "arxiv_id": "2511.23478v1",
      "comment": "Video-R2 Technical Report",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23477v1",
      "title": "Video-CoM: Interactive Video Reasoning via Chain of Manipulations",
      "authors": [
        "Hanoona Rasheed",
        "Mohammed Zumri",
        "Muhammad Maaz",
        "Ming-Hsuan Yang",
        "Fahad Shahbaz Khan",
        "Salman Khan"
      ],
      "abstract": "Recent multimodal large language models (MLLMs) have advanced video understanding, yet most still \"think about videos\" ie once a video is encoded, reasoning unfolds entirely in text, treating visual input as a static context. This passive paradigm creates a semantic bottleneck: models cannot rewatch, refocus, or verify evidence, leading to shallow visual reasoning on tasks requiring fine grained spatio temporal understanding. In this work, we introduce Interactive Video Reasoning, a new paradigm that transforms video into an active cognitive workspace, enabling models to \"think with videos\". Our model, Video CoM, reasons through a Chain of Manipulations (CoM), performing iterative visual actions to gather and refine evidence. To support this behavior, we construct Video CoM Instruct, an 18K instruction tuning dataset curated for multi step manipulation reasoning. Beyond supervised learning, we further optimize the manipulation policy via reinforcement learning with reasoning aware Group Relative Policy Optimization (GRPO). Unlike prior work that relies solely on sparse answer rewards, our method introduces step level reasoning rewards, guiding the model toward grounded and consistent reasoning. Video CoM achieves strong results across nine video reasoning benchmarks, improving average performance by 3.6 percent over recent state of the art models, while training on only 25K SFT and 3K GRPO video samples, significantly fewer than comparable large scale models. Ablation studies demonstrate that reasoning aware rewards improve both accuracy and interpretability. Code: https://github.com/mbzuai-oryx/Video-CoM",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23477v1",
        "pdf": "https://arxiv.org/pdf/2511.23477v1"
      },
      "arxiv_id": "2511.23477v1",
      "comment": "Technical Report",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23476v1",
      "title": "Thinking by Doing: Building Efficient World Model Reasoning in LLMs via Multi-turn Interaction",
      "authors": [
        "Bao Shu",
        "Yan Cai",
        "Jianjian Sun",
        "Chunrui Han",
        "En Yu",
        "Liang Zhao",
        "Jingcheng Hu",
        "Yinmin Zhang",
        "Haoran Lv",
        "Yuang Peng",
        "Zheng Ge",
        "Xiangyu Zhang",
        "Daxin Jiang",
        "Xiangyu Yue"
      ],
      "abstract": "Developing robust world model reasoning is crucial for large language model (LLM) agents to plan and interact in complex environments. While multi-turn interaction offers a superior understanding of environmental dynamics via authentic feedback, current approaches often impose a rigid reasoning process, which constrains the model's active learning, ultimately hindering efficient world model reasoning. To address these issues, we explore world-model internalization through efficient interaction and active reasoning (WMAct), which liberates the model from structured reasoning, allowing the model to shape thinking directly through its doing, and achieves effective and efficient world model reasoning with two key mechanisms: (1) a reward rescaling mechanism adjusting outcome reward based on action efficacy to incentivize redundancy reduction and purposeful interaction; (2) an interaction frequency annealing strategy to progressively reduce the maximum allowed interaction turns, which compels the model to condense its learning and internalize environmental dynamics rather than over-relying on environmental cues. Our experiments on Sokoban, Maze, and Taxi show that WMAct yields effective world model reasoning capable of resolving tasks in a single turn that previously required multiple interactions and fosters strong transferability to complex environments, improving performance on a suite of reasoning benchmarks.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23476v1",
        "pdf": "https://arxiv.org/pdf/2511.23476v1"
      },
      "arxiv_id": "2511.23476v1",
      "comment": "17 pages, 9 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23475v1",
      "title": "AnyTalker: Scaling Multi-Person Talking Video Generation with Interactivity Refinement",
      "authors": [
        "Zhizhou Zhong",
        "Yicheng Ji",
        "Zhe Kong",
        "Yiying Liu",
        "Jiarui Wang",
        "Jiasun Feng",
        "Lupeng Liu",
        "Xiangyi Wang",
        "Yanjia Li",
        "Yuqing She",
        "Ying Qin",
        "Huan Li",
        "Shuiyang Mao",
        "Wei Liu",
        "Wenhan Luo"
      ],
      "abstract": "Recently, multi-person video generation has started to gain prominence. While a few preliminary works have explored audio-driven multi-person talking video generation, they often face challenges due to the high costs of diverse multi-person data collection and the difficulty of driving multiple identities with coherent interactivity. To address these challenges, we propose AnyTalker, a multi-person generation framework that features an extensible multi-stream processing architecture. Specifically, we extend Diffusion Transformer's attention block with a novel identity-aware attention mechanism that iteratively processes identity-audio pairs, allowing arbitrary scaling of drivable identities. Besides, training multi-person generative models demands massive multi-person data. Our proposed training pipeline depends solely on single-person videos to learn multi-person speaking patterns and refines interactivity with only a few real multi-person clips. Furthermore, we contribute a targeted metric and dataset designed to evaluate the naturalness and interactivity of the generated multi-person videos. Extensive experiments demonstrate that AnyTalker achieves remarkable lip synchronization, visual quality, and natural interactivity, striking a favorable balance between data costs and identity scalability.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23475v1",
        "pdf": "https://arxiv.org/pdf/2511.23475v1"
      },
      "arxiv_id": "2511.23475v1",
      "comment": "Homepage: https://hkust-c4g.github.io/AnyTalker-homepage",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2511.23473v1",
      "title": "ThetaEvolve: Test-time Learning on Open Problems",
      "authors": [
        "Yiping Wang",
        "Shao-Rong Su",
        "Zhiyuan Zeng",
        "Eva Xu",
        "Liliang Ren",
        "Xinyu Yang",
        "Zeyi Huang",
        "Xuehai He",
        "Luyao Ma",
        "Baolin Peng",
        "Hao Cheng",
        "Pengcheng He",
        "Weizhu Chen",
        "Shuohang Wang",
        "Simon Shaolei Du",
        "Yelong Shen"
      ],
      "abstract": "Recent advances in large language models (LLMs) have enabled breakthroughs in mathematical discovery, exemplified by AlphaEvolve, a closed-source system that evolves programs to improve bounds on open problems. However, it relies on ensembles of frontier LLMs to achieve new bounds and is a pure inference system that models cannot internalize the evolving strategies. We introduce ThetaEvolve, an open-source framework that simplifies and extends AlphaEvolve to efficiently scale both in-context learning and Reinforcement Learning (RL) at test time, allowing models to continually learn from their experiences in improving open optimization problems. ThetaEvolve features a single LLM, a large program database for enhanced exploration, batch sampling for higher throughput, lazy penalties to discourage stagnant outputs, and optional reward shaping for stable training signals, etc. ThetaEvolve is the first evolving framework that enable a small open-source model, like DeepSeek-R1-0528-Qwen3-8B, to achieve new best-known bounds on open problems (circle packing and first auto-correlation inequality) mentioned in AlphaEvolve. Besides, across two models and four open tasks, we find that ThetaEvolve with RL at test-time consistently outperforms inference-only baselines, and the model indeed learns evolving capabilities, as the RL-trained checkpoints demonstrate faster progress and better final performance on both trained target task and other unseen tasks. We release our code publicly: https://github.com/ypwang61/ThetaEvolve",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23473v1",
        "pdf": "https://arxiv.org/pdf/2511.23473v1"
      },
      "arxiv_id": "2511.23473v1",
      "comment": "30 pages, link: https://github.com/ypwang61/ThetaEvolve",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2511.23469v1",
      "title": "Visual Generation Tuning",
      "authors": [
        "Jiahao Guo",
        "Sinan Du",
        "Jingfeng Yao",
        "Wenyu Liu",
        "Bo Li",
        "Haoxiang Cao",
        "Kun Gai",
        "Chun Yuan",
        "Kai Wu",
        "Xinggang Wang"
      ],
      "abstract": "Large Vision Language Models (VLMs) effectively bridge the modality gap through extensive pretraining, acquiring sophisticated visual representations aligned with language. However, it remains underexplored whether these representations, optimized for multimodal understanding tasks, harbor an inherent potential for visual generation. In this paper, we propose VGT, Visual Generation Tuning, a novel paradigm designed to stimulate the underlying capabilities of visual generation within any vision language models. By performing efficient visual generation tuning on well-pretrained VLMs, we significantly mitigate the alignment costs and accelerate the convergence of autoregressive modeling in the continuous space (20x speedup). Specifically, we dismiss the entangled pixel-level VAEs designed for diffusion transformers and formulate VGT-AE through aligning the semantic encoders from pretrained VLMs with the latent representations of pixel decoders. In image reconstruction tasks, we achieve 26.67 PSNR and 0.50 rFID at a 28x compression ratio, outperforming specialized VAEs; in visual generation tasks, we achieve state-of-the-art outcomes among autoregressive models, 0.77 on GenEval and 78.73 on DPG-Bench. Furthermore, our proposed VGT showcases significant scaling promise and is versatile for endowing any VLMs trained for multimodal understanding with the capabilities of visual generation, which paves the new avenue to explore next-generation unified multimodal foundation models. Models and codes are available at https://github.com/hustvl/VGT.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23469v1",
        "pdf": "https://arxiv.org/pdf/2511.23469v1"
      },
      "arxiv_id": "2511.23469v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23465v1",
      "title": "SmallWorlds: Assessing Dynamics Understanding of World Models in Isolated Environments",
      "authors": [
        "Xinyi Li",
        "Zaishuo Xia",
        "Weyl Lu",
        "Chenjie Hao",
        "Yubei Chen"
      ],
      "abstract": "Current world models lack a unified and controlled setting for systematic evaluation, making it difficult to assess whether they truly capture the underlying rules that govern environment dynamics. In this work, we address this open challenge by introducing the SmallWorld Benchmark, a testbed designed to assess world model capability under isolated and precisely controlled dynamics without relying on handcrafted reward signals. Using this benchmark, we conduct comprehensive experiments in the fully observable state space on representative architectures including Recurrent State Space Model, Transformer, Diffusion model, and Neural ODE, examining their behavior across six distinct domains. The experimental results reveal how effectively these models capture environment structure and how their predictions deteriorate over extended rollouts, highlighting both the strengths and limitations of current modeling paradigms and offering insights into future improvement directions in representation learning and dynamics modeling.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23465v1",
        "pdf": "https://arxiv.org/pdf/2511.23465v1"
      },
      "arxiv_id": "2511.23465v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23455v1",
      "title": "The Price of Progress: Algorithmic Efficiency and the Falling Cost of AI Inference",
      "authors": [
        "Hans Gundlach",
        "Jayson Lynch",
        "Matthias Mertens",
        "Neil Thompson"
      ],
      "abstract": "Language models have seen enormous progress on advanced benchmarks in recent years, but much of this progress has only been possible by using more costly models. Benchmarks may therefore present a warped picture of progress in practical capabilities per dollar. To remedy this, we use data from Artificial Analysis and Epoch AI to form the largest dataset of current and historical prices to run benchmarks to date. We find that the price for a given level of benchmark performance has decreased remarkably fast, around $5\\times$ to $10\\times$ per year, for frontier models on knowledge, reasoning, math, and software engineering benchmarks. These reductions in the cost of AI inference are due to economic forces, hardware efficiency improvements, and algorithmic efficiency improvements. Isolating out open models to control for competition effects and dividing by hardware price declines, we estimate that algorithmic efficiency progress is around $3\\times$ per year. Finally, we recommend that evaluators both publicize and take into account the price of benchmarking as an essential part of measuring the real-world impact of AI.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23455v1",
        "pdf": "https://arxiv.org/pdf/2511.23455v1"
      },
      "arxiv_id": "2511.23455v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23450v1",
      "title": "Object-Centric Data Synthesis for Category-level Object Detection",
      "authors": [
        "Vikhyat Agarwal",
        "Jiayi Cora Guo",
        "Declan Hoban",
        "Sissi Zhang",
        "Nicholas Moran",
        "Peter Cho",
        "Srilakshmi Pattabiraman",
        "Shantanu Joshi"
      ],
      "abstract": "Deep learning approaches to object detection have achieved reliable detection of specific object classes in images. However, extending a model's detection capability to new object classes requires large amounts of annotated training data, which is costly and time-consuming to acquire, especially for long-tailed classes with insufficient representation in existing datasets. Here, we introduce the object-centric data setting, when limited data is available in the form of object-centric data (multi-view images or 3D models), and systematically evaluate the performance of four different data synthesis methods to finetune object detection models on novel object categories in this setting. The approaches are based on simple image processing techniques, 3D rendering, and image diffusion models, and use object-centric data to synthesize realistic, cluttered images with varying contextual coherence and complexity. We assess how these methods enable models to achieve category-level generalization in real-world data, and demonstrate significant performance boosts within this data-constrained experimental setting.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23450v1",
        "pdf": "https://arxiv.org/pdf/2511.23450v1"
      },
      "arxiv_id": "2511.23450v1",
      "comment": "10 pages, 10 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23449v1",
      "title": "Physics-Informed Neural Networks for Thermophysical Property Retrieval",
      "authors": [
        "Ali Waseem",
        "Malcolm Mielle"
      ],
      "abstract": "Inverse heat problems refer to the estimation of material thermophysical properties given observed or known heat diffusion behaviour. Inverse heat problems have wide-ranging uses, but a critical application lies in quantifying how building facade renovation reduces thermal transmittance, a key determinant of building energy efficiency. However, solving inverse heat problems with non-invasive data collected in situ is error-prone due to environmental variability or deviations from theoretically assumed conditions. Hence, current methods for measuring thermal conductivity are either invasive, require lengthy observation periods, or are sensitive to environmental and experimental conditions. Here, we present a PINN-based iterative framework to estimate the thermal conductivity k of a wall from a set of thermographs; our framework alternates between estimating the forward heat problem with a PINN for a fixed k, and optimizing k by comparing the thermographs and surface temperatures predicted by the PINN, repeating until the estimated k's convergence. Using both environmental data captured by a weather station and data generated from Finite-Volume-Method software simulations, we accurately predict k across different environmental conditions and data collection sampling times, given the temperature profile of the wall at dawn is close to steady state. Although violating the steady-state assumption impacts the accuracy of k's estimation, we show that our proposed framework still only exhibits a maximum MAE of 4.0851. Our work demonstrates the potential of PINN-based methods for reliable estimation of material properties in situ and under realistic conditions, without lengthy measurement campaigns. Given the lack of research on using machine learning, and more specifically on PINNs, for solving in-situ inverse problems, we expect our work to be a starting point for more research on the topic.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23449v1",
        "pdf": "https://arxiv.org/pdf/2511.23449v1"
      },
      "arxiv_id": "2511.23449v1",
      "comment": "26 pages, 4 figures, 3 tables",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23443v1",
      "title": "Provable Benefits of Sinusoidal Activation for Modular Addition",
      "authors": [
        "Tianlong Huang",
        "Zhiyuan Li"
      ],
      "abstract": "This paper studies the role of activation functions in learning modular addition with two-layer neural networks. We first establish a sharp expressivity gap: sine MLPs admit width-$2$ exact realizations for any fixed length $m$ and, with bias, width-$2$ exact realizations uniformly over all lengths. In contrast, the width of ReLU networks must scale linearly with $m$ to interpolate, and they cannot simultaneously fit two lengths with different residues modulo $p$. We then provide a novel Natarajan-dimension generalization bound for sine networks, yielding nearly optimal sample complexity $\\widetilde{\\mathcal{O}}(p)$ for ERM over constant-width sine networks. We also derive width-independent, margin-based generalization for sine networks in the overparametrized regime and validate it. Empirically, sine networks generalize consistently better than ReLU networks across regimes and exhibit strong length extrapolation.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23443v1",
        "pdf": "https://arxiv.org/pdf/2511.23443v1"
      },
      "arxiv_id": "2511.23443v1",
      "comment": "60 pages, 15 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23442v1",
      "title": "ASTRO: Adaptive Stitching via Dynamics-Guided Trajectory Rollouts",
      "authors": [
        "Hang Yu",
        "Di Zhang",
        "Qiwei Du",
        "Yanping Zhao",
        "Hai Zhang",
        "Guang Chen",
        "Eduardo E. Veas",
        "Junqiao Zhao"
      ],
      "abstract": "Offline reinforcement learning (RL) enables agents to learn optimal policies from pre-collected datasets. However, datasets containing suboptimal and fragmented trajectories present challenges for reward propagation, resulting in inaccurate value estimation and degraded policy performance. While trajectory stitching via generative models offers a promising solution, existing augmentation methods frequently produce trajectories that are either confined to the support of the behavior policy or violate the underlying dynamics, thereby limiting their effectiveness for policy improvement. We propose ASTRO, a data augmentation framework that generates distributionally novel and dynamics-consistent trajectories for offline RL. ASTRO first learns a temporal-distance representation to identify distinct and reachable stitch targets. We then employ a dynamics-guided stitch planner that adaptively generates connecting action sequences via Rollout Deviation Feedback, defined as the gap between target state sequence and the actual arrived state sequence by executing predicted actions, to improve trajectory stitching's feasibility and reachability. This approach facilitates effective augmentation through stitching and ultimately enhances policy learning. ASTRO outperforms prior offline RL augmentation methods across various algorithms, achieving notable performance gain on the challenging OGBench suite and demonstrating consistent improvements on standard offline RL benchmarks such as D4RL.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23442v1",
        "pdf": "https://arxiv.org/pdf/2511.23442v1"
      },
      "arxiv_id": "2511.23442v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23440v1",
      "title": "Accelerated Execution of Bayesian Neural Networks using a Single Probabilistic Forward Pass and Code Generation",
      "authors": [
        "Bernhard Klein",
        "Falk Selker",
        "Hendrik Borras",
        "Sophie Steger",
        "Franz Pernkopf",
        "Holger Fröning"
      ],
      "abstract": "Machine learning models perform well across domains such as diagnostics, weather forecasting, NLP, and autonomous driving, but their limited uncertainty handling restricts use in safety-critical settings. Traditional neural networks often fail to detect out-of-domain (OOD) data and may output confident yet incorrect predictions. Bayesian neural networks (BNNs) address this by providing probabilistic estimates, but incur high computational cost because predictions require sampling weight distributions and multiple forward passes. The Probabilistic Forward Pass (PFP) offers a highly efficient approximation to Stochastic Variational Inference (SVI) by assuming Gaussian-distributed weights and activations, enabling fully analytic uncertainty propagation and replacing sampling with a single deterministic forward pass. We present an end-to-end pipeline for training, compiling, optimizing, and deploying PFP-based BNNs on embedded ARM CPUs. Using the TVM deep learning compiler, we implement a dedicated library of Gaussian-propagating operators for multilayer perceptrons and convolutional neural networks, combined with manual and automated tuning strategies. Ablation studies show that PFP consistently outperforms SVI in computational efficiency, achieving speedups of up to 4200x for small mini-batches. PFP-BNNs match SVI-BNNs on Dirty-MNIST in accuracy, uncertainty estimation, and OOD detection while greatly reducing compute cost. These results highlight the potential of combining Bayesian approximations with code generation to enable efficient BNN deployment on resource-constrained systems.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.LG",
        "cs.AR",
        "cs.DC",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23440v1",
        "pdf": "https://arxiv.org/pdf/2511.23440v1"
      },
      "arxiv_id": "2511.23440v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23436v1",
      "title": "Towards Continuous Intelligence Growth: Self-Training, Continual Learning, and Dual-Scale Memory in SuperIntelliAgent",
      "authors": [
        "Jianzhe Lin",
        "Zeyu Pan",
        "Yun Zhu",
        "Ruiqi Song",
        "Jining Yang"
      ],
      "abstract": "We introduce SuperIntelliAgent, an agentic learning framework that couples a trainable small diffusion model (the learner) with a frozen large language model (the verifier) to enable continual intelligence growth through self-supervised interaction. Unlike conventional supervised fine-tuning, SuperIntelliAgent learns autonomously without annotation: the learner generates candidate outputs, the verifier evaluates them through step-by-step reasoning, and their interaction produces chosen/rejected pairs for Direct Preference Optimization (DPO). This converts each input into a pseudo-training signal for continual improvement. The framework integrates dual-scale memory: short-term in-context memory that preserves reasoning traces across refinement cycles, and long-term memory that consolidates acquired knowledge through lightweight on-the-fly fine-tuning. A replay buffer retains samples that show verifiable progress and replays them as auxiliary supervision, reinforcing recent learning while forming adaptive curricula. SuperIntelliAgent is infrastructure-agnostic and can be plugged into existing agentic frameworks while turning ordinary inference loops into a lifelong optimization process. We posit that pairing a trainable learner with a reasoning-capable verifier forms a minimal reliable unit of growing intelligence, as paired feedback and partial-history replay yield richer learning curricula and stronger preference alignment. With a small number of automatically generated DPO pairs, the learner improves across all benchmarks, indicating that this mechanism provides a promising direction for continual intelligence accumulation and real-world deployment.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23436v1",
        "pdf": "https://arxiv.org/pdf/2511.23436v1"
      },
      "arxiv_id": "2511.23436v1",
      "comment": "15 pages, 4 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23429v1",
      "title": "Hunyuan-GameCraft-2: Instruction-following Interactive Game World Model",
      "authors": [
        "Junshu Tang",
        "Jiacheng Liu",
        "Jiaqi Li",
        "Longhuang Wu",
        "Haoyu Yang",
        "Penghao Zhao",
        "Siruis Gong",
        "Xiang Yuan",
        "Shuai Shao",
        "Qinglin Lu"
      ],
      "abstract": "Recent advances in generative world models have enabled remarkable progress in creating open-ended game environments, evolving from static scene synthesis toward dynamic, interactive simulation. However, current approaches remain limited by rigid action schemas and high annotation costs, restricting their ability to model diverse in-game interactions and player-driven dynamics. To address these challenges, we introduce Hunyuan-GameCraft-2, a new paradigm of instruction-driven interaction for generative game world modeling. Instead of relying on fixed keyboard inputs, our model allows users to control game video contents through natural language prompts, keyboard, or mouse signals, enabling flexible and semantically rich interaction within generated worlds. We formally defined the concept of interactive video data and developed an automated process to transform large-scale, unstructured text-video pairs into causally aligned interactive datasets. Built upon a 14B image-to-video Mixture-of-Experts(MoE) foundation model, our model incorporates a text-driven interaction injection mechanism for fine-grained control over camera motion, character behavior, and environment dynamics. We introduce an interaction-focused benchmark, InterBench, to evaluate interaction performance comprehensively. Extensive experiments demonstrate that our model generates temporally coherent and causally grounded interactive game videos that faithfully respond to diverse and free-form user instructions such as \"open the door\", \"draw a torch\", or \"trigger an explosion\".",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23429v1",
        "pdf": "https://arxiv.org/pdf/2511.23429v1"
      },
      "arxiv_id": "2511.23429v1",
      "comment": "Technical Report, Project page:https://hunyuan-gamecraft-2.github.io/",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2511.23428v1",
      "title": "DisMo: Disentangled Motion Representations for Open-World Motion Transfer",
      "authors": [
        "Thomas Ressler-Antal",
        "Frank Fundel",
        "Malek Ben Alaya",
        "Stefan Andreas Baumann",
        "Felix Krause",
        "Ming Gui",
        "Björn Ommer"
      ],
      "abstract": "Recent advances in text-to-video (T2V) and image-to-video (I2V) models, have enabled the creation of visually compelling and dynamic videos from simple textual descriptions or initial frames. However, these models often fail to provide an explicit representation of motion separate from content, limiting their applicability for content creators. To address this gap, we propose DisMo, a novel paradigm for learning abstract motion representations directly from raw video data via an image-space reconstruction objective. Our representation is generic and independent of static information such as appearance, object identity, or pose. This enables open-world motion transfer, allowing motion to be transferred across semantically unrelated entities without requiring object correspondences, even between vastly different categories. Unlike prior methods, which trade off motion fidelity and prompt adherence, are overfitting to source structure or drifting from the described action, our approach disentangles motion semantics from appearance, enabling accurate transfer and faithful conditioning. Furthermore, our motion representation can be combined with any existing video generator via lightweight adapters, allowing us to effortlessly benefit from future advancements in video models. We demonstrate the effectiveness of our method through a diverse set of motion transfer tasks. Finally, we show that the learned representations are well-suited for downstream motion understanding tasks, consistently outperforming state-of-the-art video representation models such as V-JEPA in zero-shot action classification on benchmarks including Something-Something v2 and Jester. Project page: https://compvis.github.io/DisMo",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23428v1",
        "pdf": "https://arxiv.org/pdf/2511.23428v1"
      },
      "arxiv_id": "2511.23428v1",
      "comment": "Accepted at NeurIPS 2025",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23408v1",
      "title": "Evaluating LLMs for One-Shot Patching of Real and Artificial Vulnerabilities",
      "authors": [
        "Aayush Garg",
        "Zanis Ali Khan",
        "Renzo Degiovanni",
        "Qiang Tang"
      ],
      "abstract": "Automated vulnerability patching is crucial for software security, and recent advancements in Large Language Models (LLMs) present promising capabilities for automating this task. However, existing research has primarily assessed LLMs using publicly disclosed vulnerabilities, leaving their effectiveness on related artificial vulnerabilities largely unexplored. In this study, we empirically evaluate the patching effectiveness and complementarity of several prominent LLMs, such as OpenAI's GPT variants, LLaMA, DeepSeek, and Mistral models, using both real and artificial vulnerabilities. Our evaluation employs Proof-of-Vulnerability (PoV) test execution to concretely assess whether LLM-generated source code successfully patches vulnerabilities. Our results reveal that LLMs patch real vulnerabilities more effectively compared to artificial ones. Additionally, our analysis reveals significant variability across LLMs in terms of overlapping (multiple LLMs patching the same vulnerabilities) and complementarity (vulnerabilities patched exclusively by a single LLM), emphasizing the importance of selecting appropriate LLMs for effective vulnerability patching.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23408v1",
        "pdf": "https://arxiv.org/pdf/2511.23408v1"
      },
      "arxiv_id": "2511.23408v1",
      "comment": "Pre-print - Extended version of the poster paper accepted at the 41st ACM/SIGAPP Symposium on Applied Computing (SAC) Smarter Engineering-Building AI and Building with AI (SEAI) 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23405v1",
      "title": "MANTA: Physics-Informed Generalized Underwater Object Tracking",
      "authors": [
        "Suhas Srinath",
        "Hemang Jamadagni",
        "Aditya Chadrasekar",
        "Prathosh AP"
      ],
      "abstract": "Underwater object tracking is challenging due to wavelength dependent attenuation and scattering, which severely distort appearance across depths and water conditions. Existing trackers trained on terrestrial data fail to generalize to these physics-driven degradations. We present MANTA, a physics-informed framework integrating representation learning with tracking design for underwater scenarios. We propose a dual-positive contrastive learning strategy coupling temporal consistency with Beer-Lambert augmentations to yield features robust to both temporal and underwater distortions. We further introduce a multi-stage pipeline augmenting motion-based tracking with a physics-informed secondary association algorithm that integrates geometric consistency and appearance similarity for re-identification under occlusion and drift. To complement standard IoU metrics, we propose Center-Scale Consistency (CSC) and Geometric Alignment Score (GAS) to assess geometric fidelity. Experiments on four underwater benchmarks (WebUOT-1M, UOT32, UTB180, UWCOT220) show that MANTA achieves state-of-the-art performance, improving Success AUC by up to 6 percent, while ensuring stable long-term generalized underwater tracking and efficient runtime.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23405v1",
        "pdf": "https://arxiv.org/pdf/2511.23405v1"
      },
      "arxiv_id": "2511.23405v1",
      "comment": "Accepted to the IEEE/CVF WACV 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23404v1",
      "title": "LFM2 Technical Report",
      "authors": [
        "Alexander Amini",
        "Anna Banaszak",
        "Harold Benoit",
        "Arthur Böök",
        "Tarek Dakhran",
        "Song Duong",
        "Alfred Eng",
        "Fernando Fernandes",
        "Marc Härkönen",
        "Anne Harrington",
        "Ramin Hasani",
        "Saniya Karwa",
        "Yuri Khrustalev",
        "Maxime Labonne",
        "Mathias Lechner",
        "Valentine Lechner",
        "Simon Lee",
        "Zetian Li",
        "Noel Loo",
        "Jacob Marks",
        "Edoardo Mosca",
        "Samuel J. Paech",
        "Paul Pak",
        "Rom N. Parnichkun",
        "Alex Quach",
        "Ryan Rogers",
        "Daniela Rus",
        "Nayan Saxena",
        "Bettina Schlager",
        "Tim Seyde",
        "Jimmy T. H. Smith",
        "Aditya Tadimeti",
        "Neehal Tumma"
      ],
      "abstract": "We present LFM2, a family of Liquid Foundation Models designed for efficient on-device deployment and strong task capabilities. Using hardware-in-the-loop architecture search under edge latency and memory constraints, we obtain a compact hybrid backbone that combines gated short convolutions with a small number of grouped query attention blocks, delivering up to 2x faster prefill and decode on CPUs compared to similarly sized models. The LFM2 family covers 350M-8.3B parameters, including dense models (350M, 700M, 1.2B, 2.6B) and a mixture-of-experts variant (8.3B total, 1.5B active), all with 32K context length. LFM2's training pipeline includes a tempered, decoupled Top-K knowledge distillation objective that avoids support mismatch; curriculum learning with difficulty-ordered data; and a three-stage post-training recipe of supervised fine-tuning, length-normalized preference optimization, and model merging. Pre-trained on 10-12T tokens, LFM2 models achieve strong results across diverse benchmarks; for example, LFM2-2.6B reaches 79.56% on IFEval and 82.41% on GSM8K. We further build multimodal and retrieval variants: LFM2-VL for vision-language tasks, LFM2-Audio for speech, and LFM2-ColBERT for retrieval. LFM2-VL supports tunable accuracy-latency tradeoffs via token-efficient visual processing, while LFM2-Audio separates audio input and output pathways to enable real-time speech-to-speech interaction competitive with models 3x larger. LFM2-ColBERT provides a low-latency encoder for queries and documents, enabling high-performance retrieval across multiple languages. All models are released with open weights and deployment packages for ExecuTorch, llama.cpp, and vLLM, making LFM2 a practical base for edge applications that need fast, memory-efficient inference and strong task capabilities.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23404v1",
        "pdf": "https://arxiv.org/pdf/2511.23404v1"
      },
      "arxiv_id": "2511.23404v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23402v1",
      "title": "Quantized-Tinyllava: a new multimodal foundation model enables efficient split learning",
      "authors": [
        "Jiajun Guo",
        "Xin Luo",
        "Jie Liu"
      ],
      "abstract": "Split learning is well known as a method for resolving data privacy concerns by training a model on distributed devices, thereby avoiding data sharing that raises privacy issues. However, high network communication costs are always an impediment to split learning, especially for large foundation models that require transmitting large amounts of high-dimensional data. To resolve this issue, we present a new multimodal model structure that incorporates a learning-based data compression method, which compresses model embeddings into low-bit integers while preserving the model's performance, greatly reducing the transmission costs between partitions. We then determine the optimal number of discrete representation levels based on a solid theoretical foundation from entropy coding.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23402v1",
        "pdf": "https://arxiv.org/pdf/2511.23402v1"
      },
      "arxiv_id": "2511.23402v1",
      "comment": "14pages, 5 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23397v1",
      "title": "MegaChat: A Synthetic Persian Q&A Dataset for High-Quality Sales Chatbot Evaluation",
      "authors": [
        "Mahdi Rahmani",
        "AmirHossein Saffari",
        "Reyhane Rahmani"
      ],
      "abstract": "Small and medium-sized enterprises (SMEs) in Iran increasingly leverage Telegram for sales, where real-time engagement is essential for conversion. However, developing AI-driven chatbots for this purpose requires large, high-quality question-and-answer (Q&A) datasets, which are typically expensive and resource-intensive to produce, especially for low-resource languages like Persian. In this paper, we introduce MegaChat, the first fully synthetic Persian Q&A dataset designed to evaluate intelligent sales chatbots in Telegram-based e-commerce. We propose a novel, automated multi-agent architecture that generates persona-aware Q&A pairs by collecting data from active Telegram shopping channels. The system employs specialized agents for question generation, validation, and refinement, ensuring the production of realistic and diverse conversational data. To evaluate answer generation, we compare three classic retrieval-augmented generation (RAG) models with our advanced agentic system, which features multi-query retrieval, reranking, and persona-aligned response synthesis. Using GPT-5.1 for evaluation across six quality dimensions, our results show that the agentic architecture outperformed traditional RAG models in 4 out of 5 diverse channels, demonstrating its ability to generate scalable, high-quality datasets without relying on expensive human annotation or complex fine-tuning. MegaChat provides SMEs with an efficient, cost-effective solution for building intelligent customer engagement systems in specialized commercial domains, enabling advancements in multilingual conversational AI for low-resource languages. Download: https://github.com/MegaChat-Tech/MegaChat-DataSet",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23397v1",
        "pdf": "https://arxiv.org/pdf/2511.23397v1"
      },
      "arxiv_id": "2511.23397v1",
      "comment": "6 pages, 11 figures, 2 tables",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23388v1",
      "title": "Learning-Augmented Online Bipartite Matching in the Random Arrival Order Model",
      "authors": [
        "Kunanon Burathep",
        "Thomas Erlebach",
        "William K. Moses"
      ],
      "abstract": "We study the online unweighted bipartite matching problem in the random arrival order model, with $n$ offline and $n$ online vertices, in the learning-augmented setting: The algorithm is provided with untrusted predictions of the types (neighborhoods) of the online vertices. We build upon the work of Choo et al. (ICML 2024, pp. 8762-8781) who proposed an approach that uses a prefix of the arrival sequence as a sample to determine whether the predictions are close to the true arrival sequence and then either follows the predictions or uses a known baseline algorithm that ignores the predictions and is $β$-competitive. Their analysis is limited to the case that the optimal matching has size $n$, i.e., every online vertex can be matched. We generalize their approach and analysis by removing any assumptions on the size of the optimal matching while only requiring that the size of the predicted matching is at least $αn$ for any constant $0 < α\\le 1$. Our learning-augmented algorithm achieves $(1-o(1))$-consistency and $(β-o(1))$-robustness. Additionally, we show that the competitive ratio degrades smoothly between consistency and robustness with increasing prediction error.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.LG",
        "cs.DS"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23388v1",
        "pdf": "https://arxiv.org/pdf/2511.23388v1"
      },
      "arxiv_id": "2511.23388v1",
      "comment": "17 pages, 1 figure, 1 table. An extended abstract of this paper appears in the proceedings of the 51st International Conference on Current Trends in Theory and Practice of Computer Science (SOFSEM 2026)",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23387v1",
      "title": "Hierarchical AI-Meteorologist: LLM-Agent System for Multi-Scale and Explainable Weather Forecast Reporting",
      "authors": [
        "Daniil Sukhorukov",
        "Andrei Zakharov",
        "Nikita Glazkov",
        "Katsiaryna Yanchanka",
        "Vladimir Kirilin",
        "Maxim Dubovitsky",
        "Roman Sultimov",
        "Yuri Maksimov",
        "Ilya Makarov"
      ],
      "abstract": "We present the Hierarchical AI-Meteorologist, an LLM-agent system that generates explainable weather reports using a hierarchical forecast reasoning and weather keyword generation. Unlike standard approaches that treat forecasts as flat time series, our framework performs multi-scale reasoning across hourly, 6-hour, and daily aggregations to capture both short-term dynamics and long-term trends. Its core reasoning agent converts structured meteorological inputs into coherent narratives while simultaneously extracting a few keywords effectively summarizing the dominant meteorological events. These keywords serve as semantic anchors for validating consistency, temporal coherence and factual alignment of the generated reports. Using OpenWeather and Meteostat data, we demonstrate that hierarchical context and keyword-based validation substantially improve interpretability and robustness of LLM-generated weather narratives, offering a reproducible framework for semantic evaluation of automated meteorological reporting and advancing agent-based scientific reasoning.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23387v1",
        "pdf": "https://arxiv.org/pdf/2511.23387v1"
      },
      "arxiv_id": "2511.23387v1",
      "comment": "9 pages, 4 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23386v1",
      "title": "VQRAE: Representation Quantization Autoencoders for Multimodal Understanding, Generation and Reconstruction",
      "authors": [
        "Sinan Du",
        "Jiahao Guo",
        "Bo Li",
        "Shuhao Cui",
        "Zhengzhuo Xu",
        "Yifu Luo",
        "Yongxian Wei",
        "Kun Gai",
        "Xinggang Wang",
        "Kai Wu",
        "Chun Yuan"
      ],
      "abstract": "Unifying multimodal understanding, generation and reconstruction representation in a single tokenizer remains a key challenge in building unified models. Previous research predominantly attempts to address this in a dual encoder paradigm, e.g., utilizing the separate encoders for understanding and generation respectively or balancing semantic representations and low-level features with contrastive loss. In this paper, we propose VQRAE, a Vector Quantization version of Representation AutoEncoders, which pioneers the first exploration in unified representation to produce Continuous semantic features for image understanding and Discrete tokens for visual generation within a unified tokenizer. Specifically, we build upon pretrained vision foundation models with a symmetric ViT decoder and adopt a two-stage training strategy: first, it freezes the encoder and learns a high-dimensional semantic VQ codebook with pixel reconstruction objective; then jointly optimizes the encoder with self-distillation constraints. This design enables negligible semantic information for maintaining the ability of multimodal understanding, discrete tokens that are compatible for generation and fine-grained reconstruction. Besides, we identify the intriguing property in quantizing semantic encoders that rely on high-dimensional codebook in contrast to the previous common practice of low-dimensional codebook in image reconstruction. The semantic VQ codebook can achieve a 100% utilization ratio at a dimension of 1536. VQRAE presents competitive performance on several benchmarks of visual understanding, generation and reconstruction with promising scaling property in the autoregressive paradigm for its discrete merits.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23386v1",
        "pdf": "https://arxiv.org/pdf/2511.23386v1"
      },
      "arxiv_id": "2511.23386v1",
      "comment": "19 pages, 10 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23377v1",
      "title": "DEAL-300K: Diffusion-based Editing Area Localization with a 300K-Scale Dataset and Frequency-Prompted Baseline",
      "authors": [
        "Rui Zhang",
        "Hongxia Wang",
        "Hangqing Liu",
        "Yang Zhou",
        "Qiang Zeng"
      ],
      "abstract": "Diffusion-based image editing has made semantic level image manipulation easy for general users, but it also enables realistic local forgeries that are hard to localize. Existing benchmarks mainly focus on the binary detection of generated images or the localization of manually edited regions and do not reflect the properties of diffusion-based edits, which often blend smoothly into the original content. We present Diffusion-Based Image Editing Area Localization Dataset (DEAL-300K), a large scale dataset for diffusion-based image manipulation localization (DIML) with more than 300,000 annotated images. We build DEAL-300K by using a multi-modal large language model to generate editing instructions, a mask-free diffusion editor to produce manipulated images, and an active-learning change detection pipeline to obtain pixel-level annotations. On top of this dataset, we propose a localization framework that uses a frozen Visual Foundation Model (VFM) together with Multi Frequency Prompt Tuning (MFPT) to capture both semantic and frequency-domain cues of edited regions. Trained on DEAL-300K, our method reaches a pixel-level F1 score of 82.56% on our test split and 80.97% on the external CoCoGlide benchmark, providing strong baselines and a practical foundation for future DIML research.The dataset can be accessed via https://github.com/ymhzyj/DEAL-300K.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23377v1",
        "pdf": "https://arxiv.org/pdf/2511.23377v1"
      },
      "arxiv_id": "2511.23377v1",
      "comment": "13pages,12 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23375v1",
      "title": "Optimizing Multimodal Language Models through Attention-based Interpretability",
      "authors": [
        "Alexander Sergeev",
        "Evgeny Kotelnikov"
      ],
      "abstract": "Modern large language models become multimodal, analyzing various data formats like text and images. While fine-tuning is effective for adapting these multimodal language models (MLMs) to downstream tasks, full fine-tuning is computationally expensive. Parameter-Efficient Fine-Tuning (PEFT) methods address this by training only a small portion of model weights. However, MLMs are difficult to interpret, making it challenging to identify which components are most effective for training to balance efficiency and performance. We propose an attention-based interpretability method for MLMs by analyzing attention scores relative to image tokens. The core idea is to identify attention heads that focus on image key objects. We utilize this information to select optimal model components for PEFT in multimodal models. Our contributions include a method for identifying attention heads associated with image key objects, its application to PEFT for image captioning, and the creation of a new dataset containing images, key object masks, and their textual descriptions. We conducted experiments on MLMs with 2-3 billion parameters to validate the method's effectiveness. By calculating Head Impact (HI) scores we quantify an attention head's focus on key objects, indicating its significance in image understanding. Our fine-tuning experiments demonstrate that adapting layers with the highest HI scores leads to the most significant shifts in metrics compared to pre-trained, randomly selected, or lowest-HI-score layers. This indicates that fine-tuning a small percentage (around 0.01%) of parameters in these crucial layers can substantially influence image understanding capabilities.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23375v1",
        "pdf": "https://arxiv.org/pdf/2511.23375v1"
      },
      "arxiv_id": "2511.23375v1",
      "comment": "Accepted for ICAI-2025 conference",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23369v1",
      "title": "SimScale: Learning to Drive via Real-World Simulation at Scale",
      "authors": [
        "Haochen Tian",
        "Tianyu Li",
        "Haochen Liu",
        "Jiazhi Yang",
        "Yihang Qiu",
        "Guang Li",
        "Junli Wang",
        "Yinfeng Gao",
        "Zhang Zhang",
        "Liang Wang",
        "Hangjun Ye",
        "Tieniu Tan",
        "Long Chen",
        "Hongyang Li"
      ],
      "abstract": "Achieving fully autonomous driving systems requires learning rational decisions in a wide span of scenarios, including safety-critical and out-of-distribution ones. However, such cases are underrepresented in real-world corpus collected by human experts. To complement for the lack of data diversity, we introduce a novel and scalable simulation framework capable of synthesizing massive unseen states upon existing driving logs. Our pipeline utilizes advanced neural rendering with a reactive environment to generate high-fidelity multi-view observations controlled by the perturbed ego trajectory. Furthermore, we develop a pseudo-expert trajectory generation mechanism for these newly simulated states to provide action supervision. Upon the synthesized data, we find that a simple co-training strategy on both real-world and simulated samples can lead to significant improvements in both robustness and generalization for various planning methods on challenging real-world benchmarks, up to +6.8 EPDMS on navhard and +2.9 on navtest. More importantly, such policy improvement scales smoothly by increasing simulation data only, even without extra real-world data streaming in. We further reveal several crucial findings of such a sim-real learning system, which we term SimScale, including the design of pseudo-experts and the scaling properties for different policy architectures. Our simulation data and code would be released.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23369v1",
        "pdf": "https://arxiv.org/pdf/2511.23369v1"
      },
      "arxiv_id": "2511.23369v1",
      "comment": "Project page: https://opendrivelab.com/SimScale",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23366v1",
      "title": "Agentic AI Framework for Smart Inventory Replenishment",
      "authors": [
        "Toqeer Ali Syed",
        "Salman Jan",
        "Gohar Ali",
        "Ali Akarma",
        "Ahmad Ali",
        "Qurat-ul-Ain Mastoi"
      ],
      "abstract": "In contemporary retail, the variety of products available (e.g. clothing, groceries, cosmetics, frozen goods) make it difficult to predict the demand, prevent stockouts, and find high-potential products. We suggest an agentic AI model that will be used to monitor the inventory, initiate purchase attempts to the appropriate suppliers, and scan for trending or high-margin products to incorporate. The system applies demand forecasting, supplier selection optimization, multi-agent negotiation and continuous learning. We apply a prototype to a setting in the store of a middle scale mart, test its performance on three conventional and artificial data tables, and compare the results to the base heuristics. Our findings indicate that there is a decrease in stockouts, a reduction of inventory holding costs, and an improvement in product mix turnover. We address constraints, scalability as well as improvement prospect.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23366v1",
        "pdf": "https://arxiv.org/pdf/2511.23366v1"
      },
      "arxiv_id": "2511.23366v1",
      "comment": "Presented at International Conference on Business and Digital Technology, Bahrain, Springer Nature, 27 November 2025",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23355v1",
      "title": "A Hierarchical Computer Vision Pipeline for Physiological Data Extraction from Bedside Monitors",
      "authors": [
        "Vinh Chau",
        "Khoa Le Dinh Van",
        "Hon Huynh Ngoc",
        "Binh Nguyen Thien",
        "Hao Nguyen Thien",
        "Vy Nguyen Quang",
        "Phuc Vo Hong",
        "Yen Lam Minh",
        "Kieu Pham Tieu",
        "Trinh Nguyen Thi Diem",
        "Louise Thwaites",
        "Hai Ho Bich"
      ],
      "abstract": "In many low-resource healthcare settings, bedside monitors remain standalone legacy devices without network connectivity, creating a persistent interoperability gap that prevents seamless integration of physiological data into electronic health record (EHR) systems. To address this challenge without requiring costly hardware replacement, we present a computer vision-based pipeline for the automated capture and digitisation of vital sign data directly from bedside monitor screens. Our method employs a hierarchical detection framework combining YOLOv11 for accurate monitor and region of interest (ROI) localisation with PaddleOCR for robust text extraction. To enhance reliability across variable camera angles and lighting conditions, a geometric rectification module standardizes the screen perspective before character recognition. We evaluated the system on a dataset of 6,498 images collected from open-source corpora and real-world intensive care units in Vietnam. The model achieved a mean Average Precision (mAP@50-95) of 99.5% for monitor detection and 91.5% for vital sign ROI localisation. The end-to-end extraction accuracy exceeded 98.9% for core physiological parameters, including heart rate, oxygen saturation SpO2, and arterial blood pressure. These results demonstrate that a lightweight, camera-based approach can reliably transform unstructured information from screen captures into structured digital data, providing a practical and scalable pathway to improve information accessibility and clinical documentation in low-resource settings.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23355v1",
        "pdf": "https://arxiv.org/pdf/2511.23355v1"
      },
      "arxiv_id": "2511.23355v1",
      "comment": "11 pages, 3 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23347v1",
      "title": "Distributed Dynamic Associative Memory via Online Convex Optimization",
      "authors": [
        "Bowen Wang",
        "Matteo Zecchin",
        "Osvaldo Simeone"
      ],
      "abstract": "An associative memory (AM) enables cue-response recall, and it has recently been recognized as a key mechanism underlying modern neural architectures such as Transformers. In this work, we introduce the concept of distributed dynamic associative memory (DDAM), which extends classical AM to settings with multiple agents and time-varying data streams. In DDAM, each agent maintains a local AM that must not only store its own associations but also selectively memorize information from other agents based on a specified interest matrix. To address this problem, we propose a novel tree-based distributed online gradient descent algorithm, termed DDAM-TOGD, which enables each agent to update its memory on the fly via inter-agent communication over designated routing trees. We derive rigorous performance guarantees for DDAM-TOGD, proving sublinear static regret in stationary environments and a path-length dependent dynamic regret bound in non-stationary environments. These theoretical results provide insights into how communication delays and network structure impact performance. Building on the regret analysis, we further introduce a combinatorial tree design strategy that optimizes the routing trees to minimize communication delays, thereby improving regret bounds. Numerical experiments demonstrate that the proposed DDAM-TOGD framework achieves superior accuracy and robustness compared to representative online learning baselines such as consensus-based distributed optimization, confirming the benefits of the proposed approach in dynamic, distributed environments.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23347v1",
        "pdf": "https://arxiv.org/pdf/2511.23347v1"
      },
      "arxiv_id": "2511.23347v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23342v1",
      "title": "Flow Straighter and Faster: Efficient One-Step Generative Modeling via MeanFlow on Rectified Trajectories",
      "authors": [
        "Xinxi Zhang",
        "Shiwei Tan",
        "Quang Nguyen",
        "Quan Dao",
        "Ligong Han",
        "Xiaoxiao He",
        "Tunyu Zhang",
        "Alen Mrdovic",
        "Dimitris Metaxas"
      ],
      "abstract": "Flow-based generative models have recently demonstrated strong performance, yet sampling typically relies on expensive numerical integration of ordinary differential equations (ODEs). Rectified Flow enables one-step sampling by learning nearly straight probability paths, but achieving such straightness requires multiple computationally intensive reflow iterations. MeanFlow achieves one-step generation by directly modeling the average velocity over time; however, when trained on highly curved flows, it suffers from slow convergence and noisy supervision. To address these limitations, we propose Rectified MeanFlow, a framework that models the mean velocity field along the rectified trajectory using only a single reflow step. This eliminates the need for perfectly straightened trajectories while enabling efficient training. Furthermore, we introduce a simple yet effective truncation heuristic that aims to reduce residual curvature and further improve performance. Extensive experiments on ImageNet at 64, 256, and 512 resolutions show that Re-MeanFlow consistently outperforms prior one-step flow distillation and Rectified Flow methods in both sample quality and training efficiency. Code is available at https://github.com/Xinxi-Zhang/Re-MeanFlow.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23342v1",
        "pdf": "https://arxiv.org/pdf/2511.23342v1"
      },
      "arxiv_id": "2511.23342v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23340v1",
      "title": "ParaGate: Parasitic-Driven Domain Adaptation Transfer Learning for Netlist Performance Prediction",
      "authors": [
        "Bin Sun",
        "Jingyi Zhou",
        "Jianan Mu",
        "Zhiteng Chao",
        "Tianmeng Yang",
        "Ziyue Xu",
        "Jing Ye",
        "Huawei Li"
      ],
      "abstract": "In traditional EDA flows, layout-level performance metrics are only obtainable after placement and routing, hindering global optimization at earlier stages. Although some neural-network-based solutions predict layout-level performance directly from netlists, they often face generalization challenges due to the black-box heuristics of commercial placement-and-routing tools, which create disparate data across designs. To this end, we propose ParaGate, a three-step cross-stage prediction framework that infers layout-level timing and power from netlists. First, we propose a two-phase transfer-learning approach to predict parasitic parameters, pre-training on mid-scale circuits and fine-tuning on larger ones to capture extreme conditions. Next, we rely on EDA tools for timing analysis, offloading the long-path numerical reasoning. Finally, ParaGate performs global calibration using subgraph features. Experiments show that ParaGate achieves strong generalization with minimal fine-tuning data: on openE906, its arrival-time R2 from 0.119 to 0.897. These results demonstrate that ParaGate could provide guidance for global optimization in the synthesis and placement stages.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23340v1",
        "pdf": "https://arxiv.org/pdf/2511.23340v1"
      },
      "arxiv_id": "2511.23340v1",
      "comment": "8 pages, 6 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23335v1",
      "title": "Towards Improving Interpretability of Language Model Generation through a Structured Knowledge Discovery Approach",
      "authors": [
        "Shuqi Liu",
        "Han Wu",
        "Guanzhi Deng",
        "Jianshu Chen",
        "Xiaoyang Wang",
        "Linqi Song"
      ],
      "abstract": "Knowledge-enhanced text generation aims to enhance the quality of generated text by utilizing internal or external knowledge sources. While language models have demonstrated impressive capabilities in generating coherent and fluent text, the lack of interpretability presents a substantial obstacle. The limited interpretability of generated text significantly impacts its practical usability, particularly in knowledge-enhanced text generation tasks that necessitate reliability and explainability. Existing methods often employ domain-specific knowledge retrievers that are tailored to specific data characteristics, limiting their generalizability to diverse data types and tasks. To overcome this limitation, we directly leverage the two-tier architecture of structured knowledge, consisting of high-level entities and low-level knowledge triples, to design our task-agnostic structured knowledge hunter. Specifically, we employ a local-global interaction scheme for structured knowledge representation learning and a hierarchical transformer-based pointer network as the backbone for selecting relevant knowledge triples and entities. By combining the strong generative ability of language models with the high faithfulness of the knowledge hunter, our model achieves high interpretability, enabling users to comprehend the model output generation process. Furthermore, we empirically demonstrate the effectiveness of our model in both internal knowledge-enhanced table-to-text generation on the RotoWireFG dataset and external knowledge-enhanced dialogue response generation on the KdConv dataset. Our task-agnostic model outperforms state-of-the-art methods and corresponding language models, setting new standards on the benchmark.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23335v1",
        "pdf": "https://arxiv.org/pdf/2511.23335v1"
      },
      "arxiv_id": "2511.23335v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23334v1",
      "title": "Markovian Scale Prediction: A New Era of Visual Autoregressive Generation",
      "authors": [
        "Yu Zhang",
        "Jingyi Liu",
        "Yiwei Shi",
        "Qi Zhang",
        "Duoqian Miao",
        "Changwei Wang",
        "Longbing Cao"
      ],
      "abstract": "Visual AutoRegressive modeling (VAR) based on next-scale prediction has revitalized autoregressive visual generation. Although its full-context dependency, i.e., modeling all previous scales for next-scale prediction, facilitates more stable and comprehensive representation learning by leveraging complete information flow, the resulting computational inefficiency and substantial overhead severely hinder VAR's practicality and scalability. This motivates us to develop a new VAR model with better performance and efficiency without full-context dependency. To address this, we reformulate VAR as a non-full-context Markov process, proposing Markov-VAR. It is achieved via Markovian Scale Prediction: we treat each scale as a Markov state and introduce a sliding window that compresses certain previous scales into a compact history vector to compensate for historical information loss owing to non-full-context dependency. Integrating the history vector with the Markov state yields a representative dynamic state that evolves under a Markov process. Extensive experiments demonstrate that Markov-VAR is extremely simple yet highly effective: Compared to VAR on ImageNet, Markov-VAR reduces FID by 10.5% (256 $\\times$ 256) and decreases peak memory consumption by 83.8% (1024 $\\times$ 1024). We believe that Markov-VAR can serve as a foundation for future research on visual autoregressive generation and other downstream tasks.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23334v1",
        "pdf": "https://arxiv.org/pdf/2511.23334v1"
      },
      "arxiv_id": "2511.23334v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23332v1",
      "title": "UniGeoSeg: Towards Unified Open-World Segmentation for Geospatial Scenes",
      "authors": [
        "Shuo Ni",
        "Di Wang",
        "He Chen",
        "Haonan Guo",
        "Ning Zhang",
        "Jing Zhang"
      ],
      "abstract": "Instruction-driven segmentation in remote sensing generates masks from guidance, offering great potential for accessible and generalizable applications. However, existing methods suffer from fragmented task formulations and limited instruction data, hindering effective understanding and generalization. To address these issues, we introduce GeoSeg-1M, the first million-scale dataset for remote sensing instruction-driven segmentation, constructed via an automatic mask filtering and instruction generation pipeline that synthesizes referring, interactive, and reasoning segmentation instructions from multiple public datasets. GeoSeg-1M contains 590K images, 117 categories, and 1.1M image-mask-instruction triplets. Building upon this foundation, we further curate GeoSeg-Bench, a challenging benchmark designed to evaluate contextual understanding and reasoning capabilities across diverse instruction-driven tasks and complex geospatial scenes. Furthermore, we present UniGeoSeg, a unified framework that serves as a strong baseline, incorporating task-aware text enhancement, latent knowledge memory, and a progressive training strategy to facilitate multi-task learning. Extensive experiments demonstrate the state-of-the-art performance of UniGeoSeg across GeoSeg-Bench and diverse public benchmarks, while exhibiting strong zero-shot generalization. Datasets and source code were released at https://github.com/MiliLab/UniGeoSeg.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23332v1",
        "pdf": "https://arxiv.org/pdf/2511.23332v1"
      },
      "arxiv_id": "2511.23332v1",
      "comment": "Datasets and source code were released at https://github.com/MiliLab/UniGeoSeg",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2511.23329v1",
      "title": "A Perceptually Inspired Variational Framework for Color Enhancement",
      "authors": [
        "Rodrigo Palma-Amestoy",
        "Edoardo Provenzi",
        "Marcelo Bertalmío",
        "Vicent Caselles"
      ],
      "abstract": "Basic phenomenology of human color vision has been widely taken as an inspiration to devise explicit color correction algorithms. The behavior of these models in terms of significative image features (such as contrast and dispersion) can be difficult to characterize. To cope with this, we propose to use a variational formulation of color contrast enhancement that is inspired by the basic phenomenology of color perception. In particular, we devise a set of basic requirements to be fulfilled by an energy to be considered as `perceptually inspired', showing that there is an explicit class of functionals satisfying all of them. We single out three explicit functionals that we consider of basic interest, showing similarities and differences with existing models. The minima of such functionals is computed using a gradient descent approach. We also present a general methodology to reduce the computational cost of the algorithms under analysis from ${\\cal O}(N^2)$ to ${\\cal O}(N\\log N)$, being $N$ the number of input pixels.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23329v1",
        "pdf": "https://arxiv.org/pdf/2511.23329v1"
      },
      "arxiv_id": "2511.23329v1",
      "comment": "",
      "journal_ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence, 31 (3), 458-474, March 2009",
      "has_code": false
    },
    {
      "id": "2511.23319v1",
      "title": "Every Token Counts: Generalizing 16M Ultra-Long Context in Large Language Models",
      "authors": [
        "Xiang Hu",
        "Zhanchao Zhou",
        "Ruiqi Liang",
        "Zehuan Li",
        "Wei Wu",
        "Jianguo Li"
      ],
      "abstract": "This work explores the challenge of building ``Machines that Can Remember'', framing long-term memory as the problem of efficient ultra-long context modeling. We argue that this requires three key properties: \\textbf{sparsity}, \\textbf{random-access flexibility}, and \\textbf{length generalization}. To address ultra-long-context modeling, we leverage Hierarchical Sparse Attention (HSA), a novel attention mechanism that satisfies all three properties. We integrate HSA into Transformers to build HSA-UltraLong, which is an 8B-parameter MoE model trained on over 8 trillion tokens and is rigorously evaluated on different tasks with in-domain and out-of-domain context lengths to demonstrate its capability in handling ultra-long contexts. Results show that our model performs comparably to full-attention baselines on in-domain lengths while achieving over 90\\% accuracy on most in-context retrieval tasks with contexts up to 16M. This report outlines our experimental insights and open problems, contributing a foundation for future research in ultra-long context modeling.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23319v1",
        "pdf": "https://arxiv.org/pdf/2511.23319v1"
      },
      "arxiv_id": "2511.23319v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23315v1",
      "title": "Emergent Coordination and Phase Structure in Independent Multi-Agent Reinforcement Learning",
      "authors": [
        "Azusa Yamaguchi"
      ],
      "abstract": "A clearer understanding of when coordination emerges, fluctuates, or collapses in decentralized multi-agent reinforcement learning (MARL) is increasingly sought in order to characterize the dynamics of multi-agent learning systems. We revisit fully independent Q-learning (IQL) as a minimal decentralized testbed and run large-scale experiments across environment size L and agent density rho. We construct a phase map using two axes - the cooperative success rate (CSR) and a stability index derived from TD-error variance - revealing three distinct regimes: a coordinated and stable phase, a fragile transition region, and a jammed or disordered phase. A sharp double Instability Ridge separates these regimes and corresponds to persistent kernel drift, the time-varying shift of each agent's effective transition kernel induced by others' policy updates. Synchronization analysis further shows that temporal alignment is required for sustained cooperation, and that competition between drift and synchronization generates the fragile regime. Removing agent identifiers eliminates drift entirely and collapses the three-phase structure, demonstrating that small inter-agent asymmetries are a necessary driver of drift. Overall, the results show that decentralized MARL exhibits a coherent phase structure governed by the interaction between scale, density, and kernel drift, suggesting that emergent coordination behaves as a distribution-interaction-driven phase phenomenon.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23315v1",
        "pdf": "https://arxiv.org/pdf/2511.23315v1"
      },
      "arxiv_id": "2511.23315v1",
      "comment": "22 pages, 19 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23311v1",
      "title": "Toward Automatic Safe Driving Instruction: A Large-Scale Vision Language Model Approach",
      "authors": [
        "Haruki Sakajo",
        "Hiroshi Takato",
        "Hiroshi Tsutsui",
        "Komei Soda",
        "Hidetaka Kamigaito",
        "Taro Watanabe"
      ],
      "abstract": "Large-scale Vision Language Models (LVLMs) exhibit advanced capabilities in tasks that require visual information, including object detection. These capabilities have promising applications in various industrial domains, such as autonomous driving. For example, LVLMs can generate safety-oriented descriptions of videos captured by road-facing cameras. However, ensuring comprehensive safety requires monitoring driver-facing views as well to detect risky events, such as the use of mobiles while driving. Thus, the ability to process synchronized inputs is necessary from both driver-facing and road-facing cameras. In this study, we develop models and investigate the capabilities of LVLMs by constructing a dataset and evaluating their performance on this dataset. Our experimental results demonstrate that while pre-trained LVLMs have limited effectiveness, fine-tuned LVLMs can generate accurate and safety-aware driving instructions. Nonetheless, several challenges remain, particularly in detecting subtle or complex events in the video. Our findings and error analysis provide valuable insights that can contribute to the improvement of LVLM-based systems in this domain.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23311v1",
        "pdf": "https://arxiv.org/pdf/2511.23311v1"
      },
      "arxiv_id": "2511.23311v1",
      "comment": "Accepted to MMLoSo 2025",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23310v1",
      "title": "OBLR-PO: A Theoretical Framework for Stable Reinforcement Learning",
      "authors": [
        "Zixun Huang",
        "Jiayi Sheng",
        "Zeyu Zheng"
      ],
      "abstract": "Existing reinforcement learning (RL)-based post-training methods for large language models have advanced rapidly, yet their design has largely been guided by heuristics rather than systematic theoretical principles. This gap limits our understanding of the properties of the gradient estimators and the associated optimization algorithms, thereby constraining opportunities to improve training stability and overall performance. In this work, we provide a unified theoretical framework that characterizes the statistical properties of commonly used policy-gradient estimators under mild assumptions. Our analysis establishes unbiasedness, derives exact variance expressions, and yields an optimization-loss upper bound that enables principled reasoning about learning dynamics. Building on these results, we prove convergence guarantees and derive an adaptive learning-rate schedule governed by the signal-to-noise ratio (SNR) of gradients. We further show that the variance-optimal baseline is a gradient-weighted estimator, offering a new principle for variance reduction and naturally enhancing stability beyond existing methods. These insights motivate Optimal Baseline and Learning-Rate Policy Optimization (OBLR-PO), an algorithm that jointly adapts learning rates and baselines in a theoretically grounded manner. Experiments on Qwen3-4B-Base and Qwen3-8B-Base demonstrate consistent gains over existing policy optimization methods, validating that our theoretical contributions translate into practical improvements in large-scale post-training.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23310v1",
        "pdf": "https://arxiv.org/pdf/2511.23310v1"
      },
      "arxiv_id": "2511.23310v1",
      "comment": "19 pages, 7 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23307v1",
      "title": "Hard-Constrained Neural Networks with Physics-Embedded Architecture for Residual Dynamics Learning and Invariant Enforcement in Cyber-Physical Systems",
      "authors": [
        "Enzo Nicolás Spotorno",
        "Josafat Leal Filho",
        "Antônio Augusto Fröhlich"
      ],
      "abstract": "This paper presents a framework for physics-informed learning in complex cyber-physical systems governed by differential equations with both unknown dynamics and algebraic invariants. First, we formalize the Hybrid Recurrent Physics-Informed Neural Network (HRPINN), a general-purpose architecture that embeds known physics as a hard structural constraint within a recurrent integrator to learn only residual dynamics. Second, we introduce the Projected HRPINN (PHRPINN), a novel extension that integrates a predict-project mechanism to strictly enforce algebraic invariants by design. The framework is supported by a theoretical analysis of its representational capacity. We validate HRPINN on a real-world battery prognostics DAE and evaluate PHRPINN on a suite of standard constrained benchmarks. The results demonstrate the framework's potential for achieving high accuracy and data efficiency, while also highlighting critical trade-offs between physical consistency, computational cost, and numerical stability, providing practical guidance for its deployment.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23307v1",
        "pdf": "https://arxiv.org/pdf/2511.23307v1"
      },
      "arxiv_id": "2511.23307v1",
      "comment": "41 pages (30 pages main text + 11 pages appendices), 3 figures, 8 tables. Submitted to JMLR",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23304v1",
      "title": "Multi-Modal Scene Graph with Kolmogorov-Arnold Experts for Audio-Visual Question Answering",
      "authors": [
        "Zijian Fu",
        "Changsheng Lv",
        "Mengshi Qi",
        "Huadong Ma"
      ],
      "abstract": "In this paper, we propose a novel Multi-Modal Scene Graph with Kolmogorov-Arnold Expert Network for Audio-Visual Question Answering (SHRIKE). The task aims to mimic human reasoning by extracting and fusing information from audio-visual scenes, with the main challenge being the identification of question-relevant cues from the complex audio-visual content. Existing methods fail to capture the structural information within video, and suffer from insufficient fine-grained modeling of multi-modal features. To address these issues, we are the first to introduce a new multi-modal scene graph that explicitly models the objects and their relationship as a visually grounded, structured representation of the audio-visual scene. Furthermore, we design a Kolmogorov-Arnold Network~(KAN)-based Mixture of Experts (MoE) to enhance the expressive power of the temporal integration stage. This enables more fine-grained modeling of cross-modal interactions within the question-aware fused audio-visual representation, leading to capture richer and more nuanced patterns and then improve temporal reasoning performance. We evaluate the model on the established MUSIC-AVQA and MUSIC-AVQA v2 benchmarks, where it achieves state-of-the-art performance. Code and model checkpoints will be publicly released.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23304v1",
        "pdf": "https://arxiv.org/pdf/2511.23304v1"
      },
      "arxiv_id": "2511.23304v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23292v1",
      "title": "FACT-GS: Frequency-Aligned Complexity-Aware Texture Reparameterization for 2D Gaussian Splatting",
      "authors": [
        "Tianhao Xie",
        "Linlian Jiang",
        "Xinxin Zuo",
        "Yang Wang",
        "Tiberiu Popa"
      ],
      "abstract": "Realistic scene appearance modeling has advanced rapidly with Gaussian Splatting, which enables real-time, high-quality rendering. Recent advances introduced per-primitive textures that incorporate spatial color variations within each Gaussian, improving their expressiveness. However, texture-based Gaussians parameterize appearance with a uniform per-Gaussian sampling grid, allocating equal sampling density regardless of local visual complexity. This leads to inefficient texture space utilization, where high-frequency regions are under-sampled and smooth regions waste capacity, causing blurred appearance and loss of fine structural detail. We introduce FACT-GS, a Frequency-Aligned Complexity-aware Texture Gaussian Splatting framework that allocates texture sampling density according to local visual frequency. Grounded in adaptive sampling theory, FACT-GS reformulates texture parameterization as a differentiable sampling-density allocation problem, replacing the uniform textures with a learnable frequency-aware allocation strategy implemented via a deformation field whose Jacobian modulates local sampling density. Built on 2D Gaussian Splatting, FACT-GS performs non-uniform sampling on fixed-resolution texture grids, preserving real-time performance while recovering sharper high-frequency details under the same parameter budget.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CV",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23292v1",
        "pdf": "https://arxiv.org/pdf/2511.23292v1"
      },
      "arxiv_id": "2511.23292v1",
      "comment": "11 pages, 6 figures, preprint",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23290v1",
      "title": "Machine Learning for Scientific Visualization: Ensemble Data Analysis",
      "authors": [
        "Hamid Gadirov"
      ],
      "abstract": "Scientific simulations and experimental measurements produce vast amounts of spatio-temporal data, yet extracting meaningful insights remains challenging due to high dimensionality, complex structures, and missing information. Traditional analysis methods often struggle with these issues, motivating the need for more robust, data-driven approaches. This dissertation explores deep learning methodologies to improve the analysis and visualization of spatio-temporal scientific ensembles, focusing on dimensionality reduction, flow estimation, and temporal interpolation. First, we address high-dimensional data representation through autoencoder-based dimensionality reduction for scientific ensembles. We evaluate the stability of projection metrics under partial labeling and introduce a Pareto-efficient selection strategy to identify optimal autoencoder variants, ensuring expressive and reliable low-dimensional embeddings. Next, we present FLINT, a deep learning model for high-quality flow estimation and temporal interpolation in both flow-supervised and flow-unsupervised settings. FLINT reconstructs missing velocity fields and generates high-fidelity temporal interpolants for scalar fields across 2D+time and 3D+time ensembles without domain-specific assumptions or extensive finetuning. To further improve adaptability and generalization, we introduce HyperFLINT, a hypernetwork-based approach that conditions on simulation parameters to estimate flow fields and interpolate scalar data. This parameter-aware adaptation yields more accurate reconstructions across diverse scientific domains, even with sparse or incomplete data. Overall, this dissertation advances deep learning techniques for scientific visualization, providing scalable, adaptable, and high-quality solutions for interpreting complex spatio-temporal ensembles.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.GR"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23290v1",
        "pdf": "https://arxiv.org/pdf/2511.23290v1"
      },
      "arxiv_id": "2511.23290v1",
      "comment": "PhD thesis, University of Groningen, 2025",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23287v1",
      "title": "Transformer-Driven Triple Fusion Framework for Enhanced Multimodal Author Intent Classification in Low-Resource Bangla",
      "authors": [
        "Ariful Islam",
        "Tanvir Mahmud",
        "Md Rifat Hossen"
      ],
      "abstract": "The expansion of the Internet and social networks has led to an explosion of user-generated content. Author intent understanding plays a crucial role in interpreting social media content. This paper addresses author intent classification in Bangla social media posts by leveraging both textual and visual data. Recognizing limitations in previous unimodal approaches, we systematically benchmark transformer-based language models (mBERT, DistilBERT, XLM-RoBERTa) and vision architectures (ViT, Swin, SwiftFormer, ResNet, DenseNet, MobileNet), utilizing the Uddessho dataset of 3,048 posts spanning six practical intent categories. We introduce a novel intermediate fusion strategy that significantly outperforms early and late fusion on this task. Experimental results show that intermediate fusion, particularly with mBERT and Swin Transformer, achieves 84.11% macro-F1 score, establishing a new state-of-the-art with an 8.4 percentage-point improvement over prior Bangla multimodal approaches. Our analysis demonstrates that integrating visual context substantially enhances intent classification. Cross-modal feature integration at intermediate levels provides optimal balance between modality-specific representation and cross-modal learning. This research establishes new benchmarks and methodological standards for Bangla and other low-resource languages. We call our proposed framework BangACMM (Bangla Author Content MultiModal).",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23287v1",
        "pdf": "https://arxiv.org/pdf/2511.23287v1"
      },
      "arxiv_id": "2511.23287v1",
      "comment": "Accepted at the 28th International Conference on Computer and Information Technology (ICCIT 2025). To be published in IEEE proceedings",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23282v1",
      "title": "Closing the Generalization Gap in Parameter-efficient Federated Edge Learning",
      "authors": [
        "Xinnong Du",
        "Zhonghao Lyu",
        "Xiaowen Cao",
        "Chunyang Wen",
        "Shuguang Cui",
        "Jie Xu"
      ],
      "abstract": "Federated edge learning (FEEL) provides a promising foundation for edge artificial intelligence (AI) by enabling collaborative model training while preserving data privacy. However, limited and heterogeneous local datasets, as well as resource-constrained deployment, severely degrade both model generalization and resource utilization, leading to a compromised learning performance. Therefore, we propose a parameter-efficient FEEL framework that jointly leverages model pruning and client selection to tackle such challenges. First, we derive an information-theoretic generalization statement that characterizes the discrepancy between training and testing function losses and embed it into the convergence analysis. It reveals that a larger local generalization statement can undermine the global convergence. Then, we formulate a generalization-aware average squared gradient norm bound minimization problem, by jointly optimizing the pruning ratios, client selection, and communication-computation resources under energy and delay constraints. Despite its non-convexity, the resulting mixed-integer problem is efficiently solved via an alternating optimization algorithm. Extensive experiments demonstrate that the proposed design achieves superior learning performance than state-of-the-art baselines, validating the effectiveness of coupling generalization-aware analysis with system-level optimization for efficient FEEL.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.LG",
        "cs.DC",
        "cs.IT"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23282v1",
        "pdf": "https://arxiv.org/pdf/2511.23282v1"
      },
      "arxiv_id": "2511.23282v1",
      "comment": "13 pages, 8 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23276v1",
      "title": "Beyond Curve Fitting: Neuro-Symbolic Agents for Context-Aware Epidemic Forecasting",
      "authors": [
        "Joongwon Chae",
        "Runming Wang",
        "Chen Xiong",
        "Gong Yunhan",
        "Lian Zhang",
        "Ji Jiansong",
        "Dongmei Yu",
        "Peiwu Qin"
      ],
      "abstract": "Effective surveillance of hand, foot and mouth disease (HFMD) requires forecasts accounting for epidemiological patterns and contextual drivers like school calendars and weather. While classical models and recent foundation models (e.g., Chronos, TimesFM) incorporate covariates, they often lack the semantic reasoning to interpret the causal interplay between conflicting drivers. In this work, we propose a two-agent framework decoupling contextual interpretation from probabilistic forecasting. An LLM \"event interpreter\" processes heterogeneous signals-including school schedules, meteorological summaries, and reports-into a scalar transmission-impact signal. A neuro-symbolic core then combines this with historical case counts to produce calibrated probabilistic forecasts. We evaluate the framework on real-world HFMD datasets from Hong Kong (2023-2024) and Lishui, China (2024). Compared to traditional and foundation-model baselines, our approach achieves competitive point forecasting accuracy while providing robust 90% prediction intervals (coverage 0.85-1.00) and human-interpretable rationales. Our results suggest that structurally integrating domain knowledge through LLMs can match state-of-the-art performance while yielding context-aware forecasts that align with public health workflows. Code is available at https://github.com/jw-chae/forecast_MED .",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23276v1",
        "pdf": "https://arxiv.org/pdf/2511.23276v1"
      },
      "arxiv_id": "2511.23276v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23274v1",
      "title": "Simultaneous Image Quality Improvement and Artefacts Correction in Accelerated MRI",
      "authors": [
        "Georgia Kanli",
        "Daniele Perlo",
        "Selma Boudissa",
        "Radovan Jirik",
        "Olivier Keunen"
      ],
      "abstract": "MR data are acquired in the frequency domain, known as k-space. Acquiring high-quality and high-resolution MR images can be time-consuming, posing a significant challenge when multiple sequences providing complementary contrast information are needed or when the patient is unable to remain in the scanner for an extended period of time. Reducing k-space measurements is a strategy to speed up acquisition, but often leads to reduced quality in reconstructed images. Additionally, in real-world MRI, both under-sampled and full-sampled images are prone to artefacts, and correcting these artefacts is crucial for maintaining diagnostic accuracy. Deep learning methods have been proposed to restore image quality from under-sampled data, while others focused on the correction of artefacts that result from the noise or motion. No approach has however been proposed so far that addresses both acceleration and artefacts correction, limiting the performance of these models when these degradation factors occur simultaneously. To address this gap, we present a method for recovering high-quality images from under-sampled data with simultaneously correction for noise and motion artefact called USArt (Under-Sampling and Artifact correction model). Customized for 2D brain anatomical images acquired with Cartesian sampling, USArt employs a dual sub-model approach. The results demonstrate remarkable increase of signal-to-noise ratio (SNR) and contrast in the images restored. Various under-sampling strategies and degradation levels were explored, with the gradient under-sampling strategy yielding the best outcomes. We achieved up to 5x acceleration and simultaneously artefacts correction without significant degradation, showcasing the model's robustness in real-world settings.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CV",
        "cs.AI",
        "physics.med-ph"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23274v1",
        "pdf": "https://arxiv.org/pdf/2511.23274v1"
      },
      "arxiv_id": "2511.23274v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23269v1",
      "title": "OctoMed: Data Recipes for State-of-the-Art Multimodal Medical Reasoning",
      "authors": [
        "Timothy Ossowski",
        "Sheng Zhang",
        "Qianchu Liu",
        "Guanghui Qin",
        "Reuben Tan",
        "Tristan Naumann",
        "Junjie Hu",
        "Hoifung Poon"
      ],
      "abstract": "High-quality and carefully curated data is a cornerstone of training medical large language models, as it directly impacts both generalization and robustness to unseen clinical tasks. We investigate strategies for training and data curation to develop a robust multimodal reasoning model in the medical domain. Our work focuses on supervised fine-tuning (SFT) and explores data recipes that leverage structured reasoning traces. Using our proposed data recipe, we scale experiments to a dataset of over 8 million examples and 6.8 billion response tokens, achieving state-of-the-art performance among open-source models across diverse out-of-distribution medical benchmark tasks. Our results further indicate that curating a high-quality, diverse training dataset with varying structured reasoning trace lengths enables the fine-tuned model to self-calibrate its reasoning trajectory lengths based on the downstream task, without explicit supervision. We present key insights, describe the data curation strategy, and outline next steps toward developing robust medical vision-language reasoning system.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23269v1",
        "pdf": "https://arxiv.org/pdf/2511.23269v1"
      },
      "arxiv_id": "2511.23269v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23264v1",
      "title": "BanglaSentNet: An Explainable Hybrid Deep Learning Framework for Multi-Aspect Sentiment Analysis with Cross-Domain Transfer Learning",
      "authors": [
        "Ariful Islam",
        "Md Rifat Hossen",
        "Tanvir Mahmud"
      ],
      "abstract": "Multi-aspect sentiment analysis of Bangla e-commerce reviews remains challenging due to limited annotated datasets, morphological complexity, code-mixing phenomena, and domain shift issues, affecting 300 million Bangla-speaking users. Existing approaches lack explainability and cross-domain generalization capabilities crucial for practical deployment. We present BanglaSentNet, an explainable hybrid deep learning framework integrating LSTM, BiLSTM, GRU, and BanglaBERT through dynamic weighted ensemble learning for multi-aspect sentiment classification. We introduce a dataset of 8,755 manually annotated Bangla product reviews across four aspects (Quality, Service, Price, Decoration) from major Bangladeshi e-commerce platforms. Our framework incorporates SHAP-based feature attribution and attention visualization for transparent insights. BanglaSentNet achieves 85% accuracy and 0.88 F1-score, outperforming standalone deep learning models by 3-7% and traditional approaches substantially. The explainability suite achieves 9.4/10 interpretability score with 87.6% human agreement. Cross-domain transfer learning experiments reveal robust generalization: zero-shot performance retains 67-76% effectiveness across diverse domains (BanglaBook reviews, social media, general e-commerce, news headlines); few-shot learning with 500-1000 samples achieves 90-95% of full fine-tuning performance, significantly reducing annotation costs. Real-world deployment demonstrates practical utility for Bangladeshi e-commerce platforms, enabling data-driven decision-making for pricing optimization, service improvement, and customer experience enhancement. This research establishes a new state-of-the-art benchmark for Bangla sentiment analysis, advances ensemble learning methodologies for low-resource languages, and provides actionable solutions for commercial applications.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23264v1",
        "pdf": "https://arxiv.org/pdf/2511.23264v1"
      },
      "arxiv_id": "2511.23264v1",
      "comment": "Submitted to Springer Nature Computer Science (SNCS) as an extended version of our ICDSAIA 2025 conference paper",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23262v1",
      "title": "Adapting Like Humans: A Metacognitive Agent with Test-time Reasoning",
      "authors": [
        "Yang Li",
        "Zhiyuan He",
        "Yuxuan Huang",
        "Zhuhanling Xiao",
        "Chao Yu",
        "Meng Fang",
        "Kun Shao",
        "Jun Wang"
      ],
      "abstract": "Recent Vision-Language Models (VLMs) exhibit strong perceptual reasoning abilities, yet they often struggle to adapt efficiently when encountering novel tasks at test time. In contrast, humans leverage the metacognitive model with memory, enabling continuous strategy refinement through metacognitive control when faced with new challenges. To bridge this gap, we propose metacognitive test-time reasoning (MCTR), a framework that equips models with the ability to learn, adapt, and improve during test time through metacognitive self-updating. Inspired by the dual structure of human metacognition, MCTR comprises meta-level and object-level VLM reasoning modules, each equipped with dedicated memory systems for hierarchical adaptive reasoning. Specifically, MCTR consists of (1) a meta-reasoning module which incrementally builds a structured memory by discovering and storing task-relevant rules, environmental patterns, and action-outcome relationships from test-time observations as natural language descriptions; and (2) an action-reasoning module that determines optimal actions through context-aware perception and strategic reasoning by dynamically retrieving and integrating knowledge from memory. The action-reasoning module continuously updates its policy through proposed metacognitive test-time reinforcement learning, adapting as knowledge memory evolves. We evaluate MCTR on 45 Atari games (33 seen, 12 unseen). MCTR demonstrates robust test-time adaptation, achieving 9/12 top-1 results on unseen games compared with baselines. Analyses through ablations, learning dynamics, and case studies reveal the complementary contributions of both components and show meta-reasoning evolving toward human-like adaptation strategies.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23262v1",
        "pdf": "https://arxiv.org/pdf/2511.23262v1"
      },
      "arxiv_id": "2511.23262v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23261v1",
      "title": "An Improved and Generalised Analysis for Spectral Clustering",
      "authors": [
        "George Tyler",
        "Luca Zanetti"
      ],
      "abstract": "We revisit the theoretical performances of Spectral Clustering, a classical algorithm for graph partitioning that relies on the eigenvectors of a matrix representation of the graph. Informally, we show that Spectral Clustering works well as long as the smallest eigenvalues appear in groups well separated from the rest of the matrix representation's spectrum. This arises, for example, whenever there exists a hierarchy of clusters at different scales, a regime not captured by previous analyses. Our results are very general and can be applied beyond the traditional graph Laplacian. In particular, we study Hermitian representations of digraphs and show Spectral Clustering can recover partitions where edges between clusters are oriented mostly in the same direction. This has applications in, for example, the analysis of trophic levels in ecological networks. We demonstrate that our results accurately predict the performances of Spectral Clustering on synthetic and real-world data sets.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23261v1",
        "pdf": "https://arxiv.org/pdf/2511.23261v1"
      },
      "arxiv_id": "2511.23261v1",
      "comment": "11 pages, 7 figures. Accepted to Learning on Graphs Conference 2025",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23260v1",
      "title": "Time Series Forecasting via Direct Per-Step Probability Distribution Modeling",
      "authors": [
        "Linghao Kong",
        "Xiaopeng Hong"
      ],
      "abstract": "Deep neural network-based time series prediction models have recently demonstrated superior capabilities in capturing complex temporal dependencies. However, it is challenging for these models to account for uncertainty associated with their predictions, because they directly output scalar values at each time step. To address such a challenge, we propose a novel model named interleaved dual-branch Probability Distribution Network (interPDN), which directly constructs discrete probability distributions per step instead of a scalar. The regression output at each time step is derived by computing the expectation of the predictive distribution on a predefined support set. To mitigate prediction anomalies, a dual-branch architecture is introduced with interleaved support sets, augmented by coarse temporal-scale branches for long-term trend forecasting. Outputs from another branch are treated as auxiliary signals to impose self-supervised consistency constraints on the current branch's prediction. Extensive experiments on multiple real-world datasets demonstrate the superior performance of interPDN.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23260v1",
        "pdf": "https://arxiv.org/pdf/2511.23260v1"
      },
      "arxiv_id": "2511.23260v1",
      "comment": "16 pages, 8 figures. This is the preprint version of the paper and supplemental material to appear in AAAI, 2026. Please cite the final published version. Code is available at https://github.com/leonardokong486/interPDN",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2511.23256v1",
      "title": "Robust HRRP Recognition under Interrupted Sampling Repeater Jamming using a Prior Jamming Information-Guided Network",
      "authors": [
        "Guozheng Sun",
        "Lei Wang",
        "Yanhao Wang",
        "Jie Wang",
        "Yimin Liu"
      ],
      "abstract": "Radar automatic target recognition (RATR) based on high-resolution range profile (HRRP) has attracted increasing attention due to its ability to capture fine-grained structural features. However, recognizing targets under electronic countermeasures (ECM), especially the mainstream interrupted-sampling repeater jamming (ISRJ), remains a significant challenge, as HRRPs often suffer from serious feature distortion. To address this, we propose a robust HRRP recognition method guided by prior jamming information. Specifically, we introduce a point spread function (PSF) as prior information to model the HRRP distortion induced by ISRJ. Based on this, we design a recognition network that leverages this prior through a prior-guided feature interaction module and a hybrid loss function to enhance the model's discriminative capability. With the aid of prior information, the model can learn invariant features within distorted HRRP under different jamming parameters. Both the simulated and measured-data experiments demonstrate that our method consistently outperforms state-of-the-art approaches and exhibits stronger generalization capabilities when facing unseen jamming parameters.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23256v1",
        "pdf": "https://arxiv.org/pdf/2511.23256v1"
      },
      "arxiv_id": "2511.23256v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23253v1",
      "title": "AgriCoT: A Chain-of-Thought Benchmark for Evaluating Reasoning in Vision-Language Models for Agriculture",
      "authors": [
        "Yibin Wen",
        "Qingmei Li",
        "Zi Ye",
        "Jiarui Zhang",
        "Jing Wu",
        "Zurong Mai",
        "Shuohong Lou",
        "Yuhang Chen",
        "Henglian Huang",
        "Xiaoya Fan",
        "Yang Zhang",
        "Lingyuan Zhao",
        "Haohuan Fu",
        "Huang Jianxi",
        "Juepeng Zheng"
      ],
      "abstract": "Recent advancements in Vision-Language Models (VLMs) have significantly transformed various industries. In agriculture, these dual-modal capabilities offer promising applications such as precision farming, crop monitoring, pest detection, and environmental sustainability. While several Visual Question Answering (VQA) datasets and benchmarks have been developed to evaluate VLM performance, they often fail to adequately assess the critical reasoning and problem-solving skills required in complex agricultural contexts. To address this gap, we introduce AgriCoT, a VQA dataset that incorporates Chain-of-Thought (CoT) reasoning, specifically designed to evaluate the reasoning capabilities of VLMs. With 4,535 carefully curated samples, AgriCoT offers a comprehensive and robust evaluation of reasoning abilities for VLMs, particularly in zero-shot scenarios, by focusing on their capacity to engage in logical reasoning and effective problem-solving. Our evaluations, conducted with 26 representative VLMs, including both proprietary and open-source models, reveal that while some proprietary models excel at answering questions, there is a notable and significant gap in their reasoning capabilities. This underscores the importance of incorporating CoT for more precise and effective assessments. Our dataset are available at https://huggingface.co/datasets/wenyb/AgriCoT.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23253v1",
        "pdf": "https://arxiv.org/pdf/2511.23253v1"
      },
      "arxiv_id": "2511.23253v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23252v1",
      "title": "One-Shot Secure Aggregation: A Hybrid Cryptographic Protocol for Private Federated Learning in IoT",
      "authors": [
        "Imraul Emmaka",
        "Tran Viet Xuan Phuong"
      ],
      "abstract": "Federated Learning (FL) offers a promising approach to collaboratively train machine learning models without centralizing raw data, yet its scalability is often throttled by excessive communication overhead. This challenge is magnified in Internet of Things (IoT) environments, where devices face stringent bandwidth, latency, and energy constraints. Conventional secure aggregation protocols, while essential for protecting model updates, frequently require multiple interaction rounds, large payload sizes, and per-client costs rendering them impractical for many edge deployments.\n  In this work, we present Hyb-Agg, a lightweight and communication-efficient secure aggregation protocol that integrates Multi-Key CKKS (MK-CKKS) homomorphic encryption with Elliptic Curve Diffie-Hellman (ECDH)-based additive masking. Hyb-Agg reduces the secure aggregation process to a single, non-interactive client-to-server transmission per round, ensuring that per-client communication remains constant regardless of the number of participants. This design eliminates partial decryption exchanges, preserves strong privacy under the RLWE, CDH, and random oracle assumptions, and maintains robustness against collusion by the server and up to $N-2$ clients.\n  We implement and evaluate Hyb-Agg on both high-performance and resource-constrained devices, including a Raspberry Pi 4, demonstrating that it delivers sub-second execution times while achieving a constant communication expansion factor of approximately 12x over plaintext size. By directly addressing the communication bottleneck, Hyb-Agg enables scalable, privacy-preserving federated learning that is practical for real-world IoT deployments.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23252v1",
        "pdf": "https://arxiv.org/pdf/2511.23252v1"
      },
      "arxiv_id": "2511.23252v1",
      "comment": "11 pages, 6 figures. Accepted at The 7th IEEE International Conference on Trust, Privacy and Security in Intelligent Systems, and Applications (TPS-ISA 2025)",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23251v1",
      "title": "Deep Learning for Restoring MPI System Matrices Using Simulated Training Data",
      "authors": [
        "Artyom Tsanda",
        "Sarah Reiss",
        "Marija Boberg",
        "Tobias Knopp"
      ],
      "abstract": "Magnetic particle imaging reconstructs tracer distributions using a system matrix obtained through time-consuming, noise-prone calibration measurements. Methods for addressing imperfections in measured system matrices increasingly rely on deep neural networks, yet curated training data remain scarce. This study evaluates whether physics-based simulated system matrices can be used to train deep learning models for different system matrix restoration tasks, i.e., denoising, accelerated calibration, upsampling, and inpainting, that generalize to measured data. A large system matrices dataset was generated using an equilibrium magnetization model extended with uniaxial anisotropy. The dataset spans particle, scanner, and calibration parameters for 2D and 3D trajectories, and includes background noise injected from empty-frame measurements. For each restoration task, deep learning models were compared with classical non-learning baseline methods. The models trained solely on simulated system matrices generalized to measured data across all tasks: for denoising, DnCNN/RDN/SwinIR outperformed DCT-F baseline by >10 dB PSNR and up to 0.1 SSIM on simulations and led to perceptually better reconstuctions of real data; for 2D upsampling, SMRnet exceeded bicubic by 20 dB PSNR and 0.08 SSIM at $\\times 2$-$\\times 4$ which did not transfer qualitatively to real measurements. For 3D accelerated calibration, SMRnet matched tricubic in noiseless cases and was more robust under noise, and for 3D inpainting, biharmonic inpainting was superior when noise-free but degraded with noise, while a PConvUNet maintained quality and yielded less blurry reconstructions. The demonstrated transferability of deep learning models trained on simulations to real measurements mitigates the data-scarcity problem and enables the development of new methods beyond current measurement capabilities.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "eess.IV"
      ],
      "primary_category": "eess.IV",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23251v1",
        "pdf": "https://arxiv.org/pdf/2511.23251v1"
      },
      "arxiv_id": "2511.23251v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23249v1",
      "title": "Learning to Predict Aboveground Biomass from RGB Images with 3D Synthetic Scenes",
      "authors": [
        "Silvia Zuffi"
      ],
      "abstract": "Forests play a critical role in global ecosystems by supporting biodiversity and mitigating climate change via carbon sequestration. Accurate aboveground biomass (AGB) estimation is essential for assessing carbon storage and wildfire fuel loads, yet traditional methods rely on labor-intensive field measurements or remote sensing approaches with significant limitations in dense vegetation. In this work, we propose a novel learning-based method for estimating AGB from a single ground-based RGB image. We frame this as a dense prediction task, introducing AGB density maps, where each pixel represents tree biomass normalized by the plot area and each tree's image area. We leverage the recently introduced synthetic 3D SPREAD dataset, which provides realistic forest scenes with per-image tree attributes (height, trunk and canopy diameter) and instance segmentation masks. Using these assets, we compute AGB via allometric equations and train a model to predict AGB density maps, integrating them to recover the AGB estimate for the captured scene. Our approach achieves a median AGB estimation error of 1.22 kg/m^2 on held-out SPREAD data and 1.94 kg/m^2 on a real-image dataset. To our knowledge, this is the first method to estimate aboveground biomass directly from a single RGB image, opening up the possibility for a scalable, interpretable, and cost-effective solution for forest monitoring, while also enabling broader participation through citizen science initiatives.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23249v1",
        "pdf": "https://arxiv.org/pdf/2511.23249v1"
      },
      "arxiv_id": "2511.23249v1",
      "comment": "Presented at STAG 2025",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23243v1",
      "title": "Heteroscedastic Neural Networks for Path Loss Prediction with Link-Specific Uncertainty",
      "authors": [
        "Jonathan Ethier"
      ],
      "abstract": "Traditional and modern machine learning-based path loss models typically assume a constant prediction variance. We propose a neural network that jointly predicts the mean and link-specific variance by minimizing a Gaussian negative log-likelihood, enabling heteroscedastic uncertainty estimates. We compare shared, partially shared, and independent-parameter architectures using accuracy, calibration, and sharpness metrics on blind test sets from large public RF drive-test datasets. The shared-parameter architecture performs best, achieving an RMSE of 7.4 dB, 95.1 percent coverage for 95 percent prediction intervals, and a mean interval width of 29.6 dB. These uncertainty estimates further support link-specific coverage margins, improve RF planning and interference analyses, and provide effective self-diagnostics of model weaknesses.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23243v1",
        "pdf": "https://arxiv.org/pdf/2511.23243v1"
      },
      "arxiv_id": "2511.23243v1",
      "comment": "Submitted to IEEE AWPL in December 2025. 5 pages, 2 figures, 4 tables",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23241v1",
      "title": "Synthetic Industrial Object Detection: GenAI vs. Feature-Based Methods",
      "authors": [
        "Jose Moises Araya-Martinez",
        "Adrián Sanchis Reig",
        "Gautham Mohan",
        "Sarvenaz Sardari",
        "Jens Lambrecht",
        "Jörg Krüger"
      ],
      "abstract": "Reducing the burden of data generation and annotation remains a major challenge for the cost-effective deployment of machine learning in industrial and robotics settings. While synthetic rendering is a promising solution, bridging the sim-to-real gap often requires expert intervention. In this work, we benchmark a range of domain randomization (DR) and domain adaptation (DA) techniques, including feature-based methods, generative AI (GenAI), and classical rendering approaches, for creating contextualized synthetic data without manual annotation. Our evaluation focuses on the effectiveness and efficiency of low-level and high-level feature alignment, as well as a controlled diffusion-based DA method guided by prompts generated from real-world contexts. We validate our methods on two datasets: a proprietary industrial dataset (automotive and logistics) and a public robotics dataset. Results show that if render-based data with enough variability is available as seed, simpler feature-based methods, such as brightness-based and perceptual hashing filtering, outperform more complex GenAI-based approaches in both accuracy and resource efficiency. Perceptual hashing consistently achieves the highest performance, with mAP50 scores of 98% and 67% on the industrial and robotics datasets, respectively. Additionally, GenAI methods present significant time overhead for data generation at no apparent improvement of sim-to-real mAP values compared to simpler methods. Our findings offer actionable insights for efficiently bridging the sim-to-real gap, enabling high real-world performance from models trained exclusively on synthetic data.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23241v1",
        "pdf": "https://arxiv.org/pdf/2511.23241v1"
      },
      "arxiv_id": "2511.23241v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23239v1",
      "title": "Towards Understanding Transformers in Learning Random Walks",
      "authors": [
        "Wei Shi",
        "Yuan Cao"
      ],
      "abstract": "Transformers have proven highly effective across various applications, especially in handling sequential data such as natural languages and time series. However, transformer models often lack clear interpretability, and the success of transformers has not been well understood in theory. In this paper, we study the capability and interpretability of transformers in learning a family of classic statistical models, namely random walks on circles. We theoretically demonstrate that, after training with gradient descent, a one-layer transformer model can achieve optimal accuracy in predicting random walks. Importantly, our analysis reveals that the trained model is interpretable: the trained softmax attention serves as a token selector, focusing on the direct parent state; subsequently, the value matrix executes a one-step probability transition to predict the location of the next state based on this parent state. We also show that certain edge cases not covered by our theory are indeed failure cases, demonstrating that our theoretical conditions are tight. By investigating these success and failure cases, it is revealed that gradient descent with small initialization may fail or struggle to converge to a good solution in certain simple tasks even beyond random walks. Experiments are conducted to support our theoretical findings.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23239v1",
        "pdf": "https://arxiv.org/pdf/2511.23239v1"
      },
      "arxiv_id": "2511.23239v1",
      "comment": "45 pages, 13 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23238v1",
      "title": "SDE-Attention: Latent Attention in SDE-RNNs for Irregularly Sampled Time Series with Missing Data",
      "authors": [
        "Yuting Fang",
        "Qouc Le Gia",
        "Flora Salim"
      ],
      "abstract": "Irregularly sampled time series with substantial missing observations are common in healthcare and sensor networks. We introduce SDE-Attention, a family of SDE-RNNs equipped with channel-level attention on the latent pre-RNN state, including channel recalibration, time-varying feature attention, and pyramidal multi-scale self-attention. We therefore conduct a comparison on a synthetic periodic dataset and real-world benchmarks, under varying missing rate. Latent-space attention consistently improves over a vanilla SDE-RNN. On the univariate UCR datasets, the LSTM-based time-varying feature model SDE-TVF-L achieves the highest average accuracy, raising mean performance by approximately 4, 6, and 10 percentage points over the baseline at 30%, 60% and 90% missingness, respectively (averaged across datasets). On multivariate UEA benchmarks, attention-augmented models again outperform the backbone, with SDE-TVF-L yielding up to a 7% gain in mean accuracy under high missingness. Among the proposed mechanisms, time-varying feature attention is the most robust on univariate datasets. On multivariate datasets, different attention types excel on different tasks, showing that SDE-Attention can be flexibly adapted to the structure of each problem.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23238v1",
        "pdf": "https://arxiv.org/pdf/2511.23238v1"
      },
      "arxiv_id": "2511.23238v1",
      "comment": "11 pages, 6 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23235v1",
      "title": "Tourism Question Answer System in Indian Language using Domain-Adapted Foundation Models",
      "authors": [
        "Praveen Gatla",
        "Anushka",
        "Nikita Kanwar",
        "Gouri Sahoo",
        "Rajesh Kumar Mundotiya"
      ],
      "abstract": "This article presents the first comprehensive study on designing a baseline extractive question-answering (QA) system for the Hindi tourism domain, with a specialized focus on the Varanasi-a cultural and spiritual hub renowned for its Bhakti-Bhaav (devotional ethos). Targeting ten tourism-centric subdomains-Ganga Aarti, Cruise, Food Court, Public Toilet, Kund, Museum, General, Ashram, Temple and Travel, the work addresses the absence of language-specific QA resources in Hindi for culturally nuanced applications. In this paper, a dataset comprising 7,715 Hindi QA pairs pertaining to Varanasi tourism was constructed and subsequently augmented with 27,455 pairs generated via Llama zero-shot prompting. We propose a framework leveraging foundation models-BERT and RoBERTa, fine-tuned using Supervised Fine-Tuning (SFT) and Low-Rank Adaptation (LoRA), to optimize parameter efficiency and task performance. Multiple variants of BERT, including pre-trained languages (e.g., Hindi-BERT), are evaluated to assess their suitability for low-resource domain-specific QA. Evaluation metrics - F1, BLEU, and ROUGE-L - highlight trade-offs between answer precision and linguistic fluency. Experiments demonstrate that LoRA-based fine-tuning achieves competitive performance (85.3\\% F1) while reducing trainable parameters by 98\\% compared to SFT, striking a balance between efficiency and accuracy. Comparative analysis across models reveals that RoBERTa with SFT outperforms BERT variants in capturing contextual nuances, particularly for culturally embedded terms (e.g., Aarti, Kund). This work establishes a foundational baseline for Hindi tourism QA systems, emphasizing the role of LORA in low-resource settings and underscoring the need for culturally contextualized NLP frameworks in the tourism domain.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23235v1",
        "pdf": "https://arxiv.org/pdf/2511.23235v1"
      },
      "arxiv_id": "2511.23235v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23231v1",
      "title": "Unlocking Multilingual Reasoning Capability of LLMs and LVLMs through Representation Engineering",
      "authors": [
        "Qiming Li",
        "Xiaocheng Feng",
        "Yixuan Ma",
        "Zekai Ye",
        "Ruihan Chen",
        "Xiachong Feng",
        "Bing Qin"
      ],
      "abstract": "Large Language Models (LLMs) and Large Vision-Language Models (LVLMs) demonstrate strong reasoning capabilities, yet their performance in English significantly outperforms that in low-resource languages, raising fairness concerns in multilingual applications. Existing approaches either rely on costly multilingual training or employ prompting with external translation tools, both of which are resource-intensive and sensitive to translation quality. To address these limitations, we propose a training-free inference-time method to enhance Multilingual Reasoning capabilities via Representation Engineering (MRRE) without using any additional training data or tools. MRRE sequentially injects two precomputed vectors at specific layers during inference processing: cross-lingual reasoning enhancement vectors, which steer non-English reasoning representations toward English space to unlock multilingual reasoning, and target-language output anchoring vectors, which restore the distribution of the target language to preserve input-output language consistency. Comprehensive experiments across six advanced LLMs and LVLMs on four reasoning benchmarks demonstrate that MRRE consistently enhances non-English reasoning by an average gain of 5.48% and up to 7.54% in low-resource languages (Thai and Swahili), while improving input-output language consistency by 3.78%.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23231v1",
        "pdf": "https://arxiv.org/pdf/2511.23231v1"
      },
      "arxiv_id": "2511.23231v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23230v1",
      "title": "Language-guided 3D scene synthesis for fine-grained functionality understanding",
      "authors": [
        "Jaime Corsetti",
        "Francesco Giuliari",
        "Davide Boscaini",
        "Pedro Hermosilla",
        "Andrea Pilzer",
        "Guofeng Mei",
        "Alexandros Delitzas",
        "Francis Engelmann",
        "Fabio Poiesi"
      ],
      "abstract": "Functionality understanding in 3D, which aims to identify the functional element in a 3D scene to complete an action (e.g., the correct handle to \"Open the second drawer of the cabinet near the bed\"), is hindered by the scarcity of real-world data due to the substantial effort needed for its collection and annotation. To address this, we introduce SynthFun3D, the first method for task-based 3D scene synthesis. Given the action description, SynthFun3D generates a 3D indoor environment using a furniture asset database with part-level annotation, ensuring the action can be accomplished. It reasons about the action to automatically identify and retrieve the 3D mask of the correct functional element, enabling the inexpensive and large-scale generation of high-quality annotated data. We validate SynthFun3D through user studies, which demonstrate improved scene-prompt coherence compared to other approaches. Our quantitative results further show that the generated data can either replace real data with minor performance loss or supplement real data for improved performance, thereby providing an inexpensive and scalable solution for data-hungry 3D applications. Project page: github.com/tev-fbk/synthfun3d.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23230v1",
        "pdf": "https://arxiv.org/pdf/2511.23230v1"
      },
      "arxiv_id": "2511.23230v1",
      "comment": "Technical report. 24 pages, 19 figures, 2 tables",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23227v1",
      "title": "PointCNN++: Performant Convolution on Native Points",
      "authors": [
        "Lihan Li",
        "Haofeng Zhong",
        "Rui Bu",
        "Mingchao Sun",
        "Wenzheng Chen",
        "Baoquan Chen",
        "Yangyan Li"
      ],
      "abstract": "Existing convolutional learning methods for 3D point cloud data are divided into two paradigms: point-based methods that preserve geometric precision but often face performance challenges, and voxel-based methods that achieve high efficiency through quantization at the cost of geometric fidelity. This loss of precision is a critical bottleneck for tasks such as point cloud registration. We propose PointCNN++, a novel architectural design that fundamentally mitigates this precision-performance trade-off. It \\textbf{generalizes sparse convolution from voxels to points}, treating voxel-based convolution as a specialized, degraded case of our more general point-based convolution. First, we introduce a point-centric convolution where the receptive field is centered on the original, high-precision point coordinates. Second, to make this high-fidelity operation performant, we design a computational strategy that operates \\textbf{natively} on points. We formulate the convolution on native points as a Matrix-Vector Multiplication and Reduction (MVMR) problem, for which we develop a dedicated, highly-optimized GPU kernel. Experiments demonstrate that PointCNN++ \\textbf{uses an order of magnitude less memory and is several times faster} than representative point-based methods. Furthermore, when used as a simple replacement for the voxel-based backbones it generalizes, it \\textbf{significantly improves point cloud registration accuracies while proving both more memory-efficient and faster}. PointCNN++ shows that preserving geometric detail and achieving high performance are not mutually exclusive, paving the way for a new class of 3D learning with high fidelity and efficiency. Our code will be open sourced.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23227v1",
        "pdf": "https://arxiv.org/pdf/2511.23227v1"
      },
      "arxiv_id": "2511.23227v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23225v1",
      "title": "TWEO: Transformers Without Extreme Outliers Enables FP8 Training And Quantization For Dummies",
      "authors": [
        "Guang Liang",
        "Jie Shao",
        "Ningyuan Tang",
        "Xinyao Liu",
        "Jianxin Wu"
      ],
      "abstract": "Native FP8 support in modern hardware is essential for training large Transformers, but is severely hindered by extreme activation outliers. Existing solutions either rely on complex mixed-precision engineering or invasive architectural modifications. This paper fundamentally challenges the conventional wisdom that outliers are data-driven. We demonstrate that extreme outliers are a data-independent, mechanically-produced artifact of training, originating from specific structural properties of the weight matrices (i.e., colinearity). Based on this insight, we propose TWEO (Transformers Without Extreme Outliers), a novel, non-invasive loss function. TWEO effectively prevents extreme outliers via a very simple loss term, which reduces outliers from 10000+ to less than 20. TWEO then enables full-model FP8 pre-training with neither engineering tricks nor architectural changes for both LLM and ViT. When standard FP8 training catastrophically collapses, TWEO achieves performance comparable to the BF16 baseline while delivering a 36% increase in training throughput. Also, TWEO enables a new quantization paradigm. Hardware-friendly W8A8 per-tensor static quantization of LLMs, previously considered completely unusable due to outliers, achieves SOTA performance for the first time on TWEO-trained models.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23225v1",
        "pdf": "https://arxiv.org/pdf/2511.23225v1"
      },
      "arxiv_id": "2511.23225v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23224v1",
      "title": "Nonstabilizerness Estimation using Graph Neural Networks",
      "authors": [
        "Vincenzo Lipardi",
        "Domenica Dibenedetto",
        "Georgios Stamoulis",
        "Evert van Nieuwenburg",
        "Mark H. M. Winands"
      ],
      "abstract": "This article proposes a Graph Neural Network (GNN) approach to estimate nonstabilizerness in quantum circuits, measured by the stabilizer Rényi entropy (SRE). Nonstabilizerness is a fundamental resource for quantum advantage, and efficient SRE estimations are highly beneficial in practical applications. We address the nonstabilizerness estimation problem through three supervised learning formulations starting from easier classification tasks to the more challenging regression task. Experimental results show that the proposed GNN manages to capture meaningful features from the graph-based circuit representation, resulting in robust generalization performances achieved across diverse scenarios. In classification tasks, the GNN is trained on product states and generalizes on circuits evolved under Clifford operations, entangled states, and circuits with higher number of qubits. In the regression task, the GNN significantly improves the SRE estimation on out-of-distribution circuits with higher number of qubits and gate counts compared to previous work, for both random quantum circuits and structured circuits derived from the transverse-field Ising model. Moreover, the graph representation of quantum circuits naturally integrates hardware-specific information. Simulations on noisy quantum hardware highlight the potential of the proposed GNN to predict the SRE measured on quantum devices.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "quant-ph",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23224v1",
        "pdf": "https://arxiv.org/pdf/2511.23224v1"
      },
      "arxiv_id": "2511.23224v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23222v1",
      "title": "DAONet-YOLOv8: An Occlusion-Aware Dual-Attention Network for Tea Leaf Pest and Disease Detection",
      "authors": [
        "Yefeng Wu",
        "Shan Wan",
        "Ling Wu",
        "Yecheng Zhao"
      ],
      "abstract": "Accurate detection of tea leaf pests and diseases in real plantations remains challenging due to complex backgrounds, variable illumination, and frequent occlusions among dense branches and leaves. Existing detectors often suffer from missed detections and false positives in such scenarios. To address these issues, we propose DAONet-YOLOv8, an enhanced YOLOv8 variant with three key improvements: (1) a Dual-Attention Fusion Module (DAFM) that combines convolutional local feature extraction with self-attention based global context modeling to focus on subtle lesion regions while suppressing background noise; (2) an occlusion-aware detection head (Detect-OAHead) that learns the relationship between visible and occluded parts to compensate for missing lesion features; and (3) a C2f-DSConv module employing dynamic synthesis convolutions with multiple kernel shapes to better capture irregular lesion boundaries. Experiments on our real-world tea plantation dataset containing six pest and disease categories demonstrate that DAONet-YOLOv8 achieves 92.97% precision, 92.80% recall, 97.10% mAP@50 and 76.90% mAP@50:95, outperforming the YOLOv8n baseline by 2.34, 4.68, 1.40 and 1.80 percentage points respectively, while reducing parameters by 16.7%. Comparative experiments further confirm that DAONet-YOLOv8 achieves superior performance over mainstream detection models.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23222v1",
        "pdf": "https://arxiv.org/pdf/2511.23222v1"
      },
      "arxiv_id": "2511.23222v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23221v1",
      "title": "Robust 3DGS-based SLAM via Adaptive Kernel Smoothing",
      "authors": [
        "Shouhe Zhang",
        "Dayong Ren",
        "Sensen Song",
        "Wenjie Li",
        "Piaopiao Yu",
        "Yurong Qian"
      ],
      "abstract": "In this paper, we challenge the conventional notion in 3DGS-SLAM that rendering quality is the primary determinant of tracking accuracy. We argue that, compared to solely pursuing a perfect scene representation, it is more critical to enhance the robustness of the rasterization process against parameter errors to ensure stable camera pose tracking. To address this challenge, we propose a novel approach that leverages a smooth kernel strategy to enhance the robustness of 3DGS-based SLAM. Unlike conventional methods that focus solely on minimizing rendering error, our core insight is to make the rasterization process more resilient to imperfections in the 3DGS parameters. We hypothesize that by allowing each Gaussian to influence a smoother, wider distribution of pixels during rendering, we can mitigate the detrimental effects of parameter noise from outlier Gaussians. This approach intentionally introduces a controlled blur to the rendered image, which acts as a regularization term, stabilizing the subsequent pose optimization. While a complete redesign of the rasterization pipeline is an ideal solution, we propose a practical and effective alternative that is readily integrated into existing 3DGS frameworks. Our method, termed Corrective Blurry KNN (CB-KNN), adaptively modifies the RGB values and locations of the K-nearest neighboring Gaussians within a local region. This dynamic adjustment generates a smoother local rendering, reducing the impact of erroneous GS parameters on the overall image. Experimental results demonstrate that our approach, while maintaining the overall quality of the scene reconstruction (mapping), significantly improves the robustness and accuracy of camera pose tracking.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23221v1",
        "pdf": "https://arxiv.org/pdf/2511.23221v1"
      },
      "arxiv_id": "2511.23221v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23220v1",
      "title": "Instruction Tuning of Large Language Models for Tabular Data Generation-in One Day",
      "authors": [
        "Milad Abdollahzadeh",
        "Abdul Raheem",
        "Zilong Zhao",
        "Uzair Javaid",
        "Kevin Yee",
        "Nalam Venkata Abhishek",
        "Tram Truong-Huu",
        "Biplab Sikdar"
      ],
      "abstract": "Tabular instruction tuning has emerged as a promising research direction for improving LLMs understanding of tabular data. However, the majority of existing works only consider question-answering and reasoning tasks over tabular data, leaving tabular data generation largely unnoticed. In this work, for the first time, we explore the efficacy of instruction tuning in improving LLMs tabular data generation capabilities. More specifically, given the high data and computation requirements of tabular instruction tuning, we aim to address the possibility of instruction tuning for tabular data generation with limited data and computational resources. To achieve this, we first create a high-quality instruction dataset for tabular data, enabling efficient LLM comprehension. We then instruction-tune an open-source LLM (Llama3.1-8B-Instruct) on the training set of this dataset to improve its tabular data generation performance. Our experimental results show that by using our high-quality dataset and instruction-tuning on only 7K instructions with an A100 GPU, for less than 6 hours, we achieve tabular data generation performance on par with the most capable commercial LLM, GPT-4o.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23220v1",
        "pdf": "https://arxiv.org/pdf/2511.23220v1"
      },
      "arxiv_id": "2511.23220v1",
      "comment": "Accepted International Conference on Machine Learning (ICML 2025), 1st Workshop on Foundation Models for Structured Data",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23214v1",
      "title": "Zero-Shot Multi-Criteria Visual Quality Inspection for Semi-Controlled Industrial Environments via Real-Time 3D Digital Twin Simulation",
      "authors": [
        "Jose Moises Araya-Martinez",
        "Gautham Mohan",
        "Kenichi Hayakawa Bolaños",
        "Roberto Mendieta",
        "Sarvenaz Sardari",
        "Jens Lambrecht",
        "Jörg Krüger"
      ],
      "abstract": "Early-stage visual quality inspection is vital for achieving Zero-Defect Manufacturing and minimizing production waste in modern industrial environments. However, the complexity of robust visual inspection systems and their extensive data requirements hinder widespread adoption in semi-controlled industrial settings. In this context, we propose a pose-agnostic, zero-shot quality inspection framework that compares real scenes against real-time Digital Twins (DT) in the RGB-D space. Our approach enables efficient real-time DT rendering by semantically describing industrial scenes through object detection and pose estimation of known Computer-Aided Design models. We benchmark tools for real-time, multimodal RGB-D DT creation while tracking consumption of computational resources. Additionally, we provide an extensible and hierarchical annotation strategy for multi-criteria defect detection, unifying pose labelling with logical and structural defect annotations. Based on an automotive use case featuring the quality inspection of an axial flux motor, we demonstrate the effectiveness of our framework. Our results demonstrate detection performace, achieving intersection-over-union (IoU) scores of up to 63.3% compared to ground-truth masks, even if using simple distance measurements under semi-controlled industrial conditions. Our findings lay the groundwork for future research on generalizable, low-data defect detection methods in dynamic manufacturing settings.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23214v1",
        "pdf": "https://arxiv.org/pdf/2511.23214v1"
      },
      "arxiv_id": "2511.23214v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23212v1",
      "title": "Asymptotic Theory and Phase Transitions for Variable Importance in Quantile Regression Forests",
      "authors": [
        "Tomoshige Nakamura",
        "Hiroshi Shiraishi"
      ],
      "abstract": "Quantile Regression Forests (QRF) are widely used for non-parametric conditional quantile estimation, yet statistical inference for variable importance measures remains challenging due to the non-smoothness of the loss function and the complex bias-variance trade-off. In this paper, we develop a asymptotic theory for variable importance defined as the difference in pinball loss risks. We first establish the asymptotic normality of the QRF estimator by handling the non-differentiable pinball loss via Knight's identity. Second, we uncover a \"phase transition\" phenomenon governed by the subsampling rate $β$ (where $s \\asymp n^β$). We prove that in the bias-dominated regime ($β\\ge 1/2$), which corresponds to large subsample sizes typically favored in practice to maximize predictive accuracy, standard inference breaks down as the estimator converges to a deterministic bias constant rather than a zero-mean normal distribution. Finally, we derive the explicit analytic form of this asymptotic bias and discuss the theoretical feasibility of restoring valid inference via analytic bias correction. Our results highlight a fundamental trade-off between predictive performance and inferential validity, providing a theoretical foundation for understanding the intrinsic limitations of random forest inference in high-dimensional settings.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "stat.ML",
        "cs.LG",
        "math.ST"
      ],
      "primary_category": "stat.ML",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23212v1",
        "pdf": "https://arxiv.org/pdf/2511.23212v1"
      },
      "arxiv_id": "2511.23212v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23205v1",
      "title": "A PLS-Integrated LASSO Method with Application in Index Tracking",
      "authors": [
        "Shiqin Tang",
        "Yining Dong",
        "S. Joe Qin"
      ],
      "abstract": "In traditional multivariate data analysis, dimension reduction and regression have been treated as distinct endeavors. Established techniques such as principal component regression (PCR) and partial least squares (PLS) regression traditionally compute latent components as intermediary steps -- although with different underlying criteria -- before proceeding with the regression analysis. In this paper, we introduce an innovative regression methodology named PLS-integrated Lasso (PLS-Lasso) that integrates the concept of dimension reduction directly into the regression process. We present two distinct formulations for PLS-Lasso, denoted as PLS-Lasso-v1 and PLS-Lasso-v2, along with clear and effective algorithms that ensure convergence to global optima. PLS-Lasso-v1 and PLS-Lasso-v2 are compared with Lasso on the task of financial index tracking and show promising results.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "stat.ML",
        "cs.LG",
        "stat.ME"
      ],
      "primary_category": "stat.ML",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23205v1",
        "pdf": "https://arxiv.org/pdf/2511.23205v1"
      },
      "arxiv_id": "2511.23205v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23204v1",
      "title": "Pathryoshka: Compressing Pathology Foundation Models via Multi-Teacher Knowledge Distillation with Nested Embeddings",
      "authors": [
        "Christian Grashei",
        "Christian Brechenmacher",
        "Rao Muhammad Umer",
        "Jingsong Liu",
        "Carsten Marr",
        "Ewa Szczurek",
        "Peter J. Schüffler"
      ],
      "abstract": "Pathology foundation models (FMs) have driven significant progress in computational pathology. However, these high-performing models can easily exceed a billion parameters and produce high-dimensional embeddings, thus limiting their applicability for research or clinical use when computing resources are tight. Here, we introduce Pathryoshka, a multi-teacher distillation framework inspired by RADIO distillation and Matryoshka Representation Learning to reduce pathology FM sizes while allowing for adaptable embedding dimensions. We evaluate our framework with a distilled model on ten public pathology benchmarks with varying downstream tasks. Compared to its much larger teachers, Pathryoshka reduces the model size by 86-92% at on-par performance. It outperforms state-of-the-art single-teacher distillation models of comparable size by a median margin of 7.0 in accuracy. By enabling efficient local deployment without sacrificing accuracy or representational richness, Pathryoshka democratizes access to state-of-the-art pathology FMs for the broader research and clinical community.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23204v1",
        "pdf": "https://arxiv.org/pdf/2511.23204v1"
      },
      "arxiv_id": "2511.23204v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23203v1",
      "title": "GAVINA: flexible aggressive undervolting for bit-serial mixed-precision DNN acceleration",
      "authors": [
        "Jordi Fornt",
        "Pau Fontova-Musté",
        "Adrian Gras",
        "Omar Lahyani",
        "Martí Caro",
        "Jaume Abella",
        "Francesc Moll",
        "Josep Altet"
      ],
      "abstract": "Voltage overscaling, or undervolting, is an enticing approximate technique in the context of energy-efficient Deep Neural Network (DNN) acceleration, given the quadratic relationship between power and voltage. Nevertheless, its very high error rate has thwarted its general adoption. Moreover, recent undervolting accelerators rely on 8-bit arithmetic and cannot compete with state-of-the-art low-precision (<8b) architectures. To overcome these issues, we propose a new technique called Guarded Aggressive underVolting (GAV), which combines the ideas of undervolting and bit-serial computation to create a flexible approximation method based on aggressively lowering the supply voltage on a select number of least significant bit combinations. Based on this idea, we implement GAVINA (GAV mIxed-precisioN Accelerator), a novel architecture that supports arbitrary mixed precision and flexible undervolting, with an energy efficiency of up to 89 TOP/sW in its most aggressive configuration. By developing an error model of GAVINA, we show that GAV can achieve an energy efficiency boost of 20% via undervolting, with negligible accuracy degradation on ResNet-18.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23203v1",
        "pdf": "https://arxiv.org/pdf/2511.23203v1"
      },
      "arxiv_id": "2511.23203v1",
      "comment": "Presented in the 2025 IEEE/ACM International Symposium on Low Power Electronics and Design (ISLPED). Conference proceedings pending to be published",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23199v1",
      "title": "Vision Bridge Transformer at Scale",
      "authors": [
        "Zhenxiong Tan",
        "Zeqing Wang",
        "Xingyi Yang",
        "Songhua Liu",
        "Xinchao Wang"
      ],
      "abstract": "We introduce Vision Bridge Transformer (ViBT), a large-scale instantiation of Brownian Bridge Models designed for conditional generation. Unlike traditional diffusion models that transform noise into data, Bridge Models directly model the trajectory between inputs and outputs, creating an efficient data-to-data translation paradigm. By scaling these models to 20B and 1.3B parameters, we demonstrate their effectiveness for image and video translation tasks. To support this scale, we adopt a Transformer architecture and propose a variance-stabilized velocity-matching objective for robust training. Together, these advances highlight the power of scaling Bridge Models for instruction-based image editing and complex video translation.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23199v1",
        "pdf": "https://arxiv.org/pdf/2511.23199v1"
      },
      "arxiv_id": "2511.23199v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23198v1",
      "title": "Clustering Malware at Scale: A First Full-Benchmark Study",
      "authors": [
        "Martin Mocko",
        "Jakub Ševcech",
        "Daniela Chudá"
      ],
      "abstract": "Recent years have shown that malware attacks still happen with high frequency. Malware experts seek to categorize and classify incoming samples to confirm their trustworthiness or prove their maliciousness. One of the ways in which groups of malware samples can be identified is through malware clustering. Despite the efforts of the community, malware clustering which incorporates benign samples has been under-explored. Moreover, despite the availability of larger public benchmark malware datasets, malware clustering studies have avoided fully utilizing these datasets in their experiments, often resorting to small datasets with only a few families. Additionally, the current state-of-the-art solutions for malware clustering remain unclear. In our study, we evaluate malware clustering quality and establish the state-of-the-art on Bodmas and Ember - two large public benchmark malware datasets. Ours is the first study of malware clustering performed on whole malware benchmark datasets. Additionally, we extend the malware clustering task by incorporating benign samples. Our results indicate that incorporating benign samples does not significantly degrade clustering quality. We find that there are significant differences in the quality of the created clusters between Ember and Bodmas, as well as a private industry dataset. Contrary to popular opinion, our top clustering performers are K-Means and BIRCH, with DBSCAN and HAC falling behind.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23198v1",
        "pdf": "https://arxiv.org/pdf/2511.23198v1"
      },
      "arxiv_id": "2511.23198v1",
      "comment": "pre-print of the paper (i.e. \"submitted manuscript\" version)",
      "journal_ref": "ARES 2025. Lecture Notes in Computer Science vol 15993. pp 231-251",
      "has_code": false
    },
    {
      "id": "2511.23193v1",
      "title": "Fault-Tolerant MARL for CAVs under Observation Perturbations for Highway On-Ramp Merging",
      "authors": [
        "Yuchen Shi",
        "Huaxin Pei",
        "Yi Zhang",
        "Danya Yao"
      ],
      "abstract": "Multi-Agent Reinforcement Learning (MARL) holds significant promise for enabling cooperative driving among Connected and Automated Vehicles (CAVs). However, its practical application is hindered by a critical limitation, i.e., insufficient fault tolerance against observational faults. Such faults, which appear as perturbations in the vehicles' perceived data, can substantially compromise the performance of MARL-based driving systems. Addressing this problem presents two primary challenges. One is to generate adversarial perturbations that effectively stress the policy during training, and the other is to equip vehicles with the capability to mitigate the impact of corrupted observations. To overcome the challenges, we propose a fault-tolerant MARL method for cooperative on-ramp vehicles incorporating two key agents. First, an adversarial fault injection agent is co-trained to generate perturbations that actively challenge and harden the vehicle policies. Second, we design a novel fault-tolerant vehicle agent equipped with a self-diagnosis capability, which leverages the inherent spatio-temporal correlations in vehicle state sequences to detect faults and reconstruct credible observations, thereby shielding the policy from misleading inputs. Experiments in a simulated highway merging scenario demonstrate that our method significantly outperforms baseline MARL approaches, achieving near-fault-free levels of safety and efficiency under various observation fault patterns.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.RO",
        "cs.LG",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23193v1",
        "pdf": "https://arxiv.org/pdf/2511.23193v1"
      },
      "arxiv_id": "2511.23193v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23191v1",
      "title": "GeoWorld: Unlocking the Potential of Geometry Models to Facilitate High-Fidelity 3D Scene Generation",
      "authors": [
        "Yuhao Wan",
        "Lijuan Liu",
        "Jingzhi Zhou",
        "Zihan Zhou",
        "Xuying Zhang",
        "Dongbo Zhang",
        "Shaohui Jiao",
        "Qibin Hou",
        "Ming-Ming Cheng"
      ],
      "abstract": "Previous works leveraging video models for image-to-3D scene generation tend to suffer from geometric distortions and blurry content. In this paper, we renovate the pipeline of image-to-3D scene generation by unlocking the potential of geometry models and present our GeoWorld. Instead of exploiting geometric information obtained from a single-frame input, we propose to first generate consecutive video frames and then take advantage of the geometry model to provide full-frame geometry features, which contain richer information than single-frame depth maps or camera embeddings used in previous methods, and use these geometry features as geometrical conditions to aid the video generation model. To enhance the consistency of geometric structures, we further propose a geometry alignment loss to provide the model with real-world geometric constraints and a geometry adaptation module to ensure the effective utilization of geometry features. Extensive experiments show that our GeoWorld can generate high-fidelity 3D scenes from a single image and a given camera trajectory, outperforming prior methods both qualitatively and quantitatively. Project Page: https://peaes.github.io/GeoWorld/.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23191v1",
        "pdf": "https://arxiv.org/pdf/2511.23191v1"
      },
      "arxiv_id": "2511.23191v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23186v1",
      "title": "Obstruction reasoning for robotic grasping",
      "authors": [
        "Runyu Jiao",
        "Matteo Bortolon",
        "Francesco Giuliari",
        "Alice Fasoli",
        "Sergio Povoli",
        "Guofeng Mei",
        "Yiming Wang",
        "Fabio Poiesi"
      ],
      "abstract": "Successful robotic grasping in cluttered environments not only requires a model to visually ground a target object but also to reason about obstructions that must be cleared beforehand. While current vision-language embodied reasoning models show emergent spatial understanding, they remain limited in terms of obstruction reasoning and accessibility planning. To bridge this gap, we present UNOGrasp, a learning-based vision-language model capable of performing visually-grounded obstruction reasoning to infer the sequence of actions needed to unobstruct the path and grasp the target object. We devise a novel multi-step reasoning process based on obstruction paths originated by the target object. We anchor each reasoning step with obstruction-aware visual cues to incentivize reasoning capability. UNOGrasp combines supervised and reinforcement finetuning through verifiable reasoning rewards. Moreover, we construct UNOBench, a large-scale dataset for both training and benchmarking, based on MetaGraspNetV2, with over 100k obstruction paths annotated by humans with obstruction ratios, contact points, and natural-language instructions. Extensive experiments and real-robot evaluations show that UNOGrasp significantly improves obstruction reasoning and grasp success across both synthetic and real-world environments, outperforming generalist and proprietary alternatives. Project website: https://tev-fbk.github.io/UnoGrasp/.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23186v1",
        "pdf": "https://arxiv.org/pdf/2511.23186v1"
      },
      "arxiv_id": "2511.23186v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23184v1",
      "title": "Listwise Preference Optimization with Element-wise Confusions for Aspect Sentiment Quad Prediction",
      "authors": [
        "Wenna Lai",
        "Haoran Xie",
        "Guandong Xu",
        "Qing Li",
        "S. Joe Qin"
      ],
      "abstract": "Aspect sentiment quad prediction (ASQP) is inherently challenging to predict a structured quadruple with four core sentiment elements, including aspect term (a), aspect category (c), opinion term (o), and sentiment polarity (s). Prior methods relying on marker-based prediction struggle with modeling the intricate relationships among elements and experience sharp performance declines when predicting higher-order elements (e.g., c and s) under standard supervised fine-tuning. To address these limitations, we employ reasoning-based generation to output both the quadruple and a natural language rationale under element prefixes within a unified template, encouraging explicit relational reasoning and interpretability. To further enhance element-wise alignment, we introduce a listwise preference optimization framework for improving structural validity and relational coherence. Specifically, we generate element-wise confusable candidates via syntactic and semantic proximity, then train the model with listwise objectives to prefer the gold candidates over closely competing alternatives. Extensive experiments on four benchmark datasets demonstrate that our framework effectively improves quadruple prediction accuracy and explanation consistency.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23184v1",
        "pdf": "https://arxiv.org/pdf/2511.23184v1"
      },
      "arxiv_id": "2511.23184v1",
      "comment": "11 pages, 7 figures, and 6 tables",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23183v1",
      "title": "Identification of Malicious Posts on the Dark Web Using Supervised Machine Learning",
      "authors": [
        "Sebastião Alves de Jesus Filho",
        "Gustavo Di Giovanni Bernardo",
        "Paulo Henrique Ribeiro Gabriel",
        "Bruno Bogaz Zarpelão",
        "Rodrigo Sanches Miani"
      ],
      "abstract": "Given the constant growth and increasing sophistication of cyberattacks, cybersecurity can no longer rely solely on traditional defense techniques and tools. Proactive detection of cyber threats has become essential to help security teams identify potential risks and implement effective mitigation measures. Cyber Threat Intelligence (CTI) plays a key role by providing security analysts with evidence-based knowledge about cyber threats. CTI information can be extracted using various techniques and data sources; however, machine learning has proven promising. As for data sources, social networks and online discussion forums are commonly explored. In this study, we apply text mining techniques and machine learning to data collected from Dark Web forums in Brazilian Portuguese to identify malicious posts. Our contributions include the creation of three original datasets, a novel multi-stage labeling process combining indicators of compromise (IoCs), contextual keywords, and manual analysis, and a comprehensive evaluation of text representations and classifiers. To our knowledge, this is the first study to focus specifically on Brazilian Portuguese content in this domain. The best-performing model, using LightGBM and TF-IDF, was able to detect relevant posts with high accuracy. We also applied topic modeling to validate the model's outputs on unlabeled data, confirming its robustness in real-world scenarios.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23183v1",
        "pdf": "https://arxiv.org/pdf/2511.23183v1"
      },
      "arxiv_id": "2511.23183v1",
      "comment": "Manuscript under review (SN Computer Science)",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23172v1",
      "title": "Fast Multi-view Consistent 3D Editing with Video Priors",
      "authors": [
        "Liyi Chen",
        "Ruihuang Li",
        "Guowen Zhang",
        "Pengfei Wang",
        "Lei Zhang"
      ],
      "abstract": "Text-driven 3D editing enables user-friendly 3D object or scene editing with text instructions. Due to the lack of multi-view consistency priors, existing methods typically resort to employing 2D generation or editing models to process each view individually, followed by iterative 2D-3D-2D updating. However, these methods are not only time-consuming but also prone to over-smoothed results because the different editing signals gathered from different views are averaged during the iterative process. In this paper, we propose generative Video Prior based 3D Editing (ViP3DE) to employ the temporal consistency priors from pre-trained video generation models for multi-view consistent 3D editing in a single forward pass. Our key insight is to condition the video generation model on a single edited view to generate other consistent edited views for 3D updating directly, thereby bypassing the iterative editing paradigm. Since 3D updating requires edited views to be paired with specific camera poses, we propose motion-preserved noise blending for the video model to generate edited views at predefined camera poses. In addition, we introduce geometry-aware denoising to further enhance multi-view consistency by integrating 3D geometric priors into video models. Extensive experiments demonstrate that our proposed ViP3DE can achieve high-quality 3D editing results even within a single forward pass, significantly outperforming existing methods in both editing quality and speed.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23172v1",
        "pdf": "https://arxiv.org/pdf/2511.23172v1"
      },
      "arxiv_id": "2511.23172v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23170v1",
      "title": "PowerCLIP: Powerset Alignment for Contrastive Pre-Training",
      "authors": [
        "Masaki Kawamura",
        "Nakamasa Inoue",
        "Rintaro Yanagi",
        "Hirokatsu Kataoka",
        "Rio Yokota"
      ],
      "abstract": "Contrastive vision-language pre-training frameworks such as CLIP have demonstrated impressive zero-shot performance across a range of vision-language tasks. Recent studies have shown that aligning individual text tokens with specific image patches or regions enhances fine-grained compositional understanding. However, it remains challenging to capture compositional semantics that span multiple image regions. To address this limitation, we propose PowerCLIP, a novel contrastive pre-training framework enhanced by powerset alignment, which exhaustively optimizes region-to-phrase alignments by minimizing the loss defined between powersets of image regions and textual parse trees. Since the naive powerset construction incurs exponential computational cost due to the combinatorial explosion in the number of region subsets, we introduce efficient non-linear aggregators (NLAs) that reduce complexity from O(2^M) to O(M) with respect to the number of regions M, while approximating the exact loss value with arbitrary precision. Our extensive experiments demonstrate that PowerCLIP outperforms state-of-the-art methods in zero-shot classification and retrieval tasks, underscoring the compositionality and robustness of our approach. Our code will be made publicly available.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23170v1",
        "pdf": "https://arxiv.org/pdf/2511.23170v1"
      },
      "arxiv_id": "2511.23170v1",
      "comment": "Submitted to CVPR 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23166v1",
      "title": "Energy-Efficient Vision Transformer Inference for Edge-AI Deployment",
      "authors": [
        "Nursultan Amanzhol",
        "Jurn-Gyu Park"
      ],
      "abstract": "The growing deployment of Vision Transformers (ViTs) on energy-constrained devices requires evaluation methods that go beyond accuracy alone. We present a two-stage pipeline for assessing ViT energy efficiency that combines device-agnostic model selection with device-related measurements. We benchmark 13 ViT models on ImageNet-1K and CIFAR-10, running inference on NVIDIA Jetson TX2 (edge device) and an NVIDIA RTX 3050 (mobile GPU). The device-agnostic stage uses the NetScore metric for screening; the device-related stage ranks models with the Sustainable Accuracy Metric (SAM). Results show that hybrid models such as LeViT_Conv_192 reduce energy by up to 53% on TX2 relative to a ViT baseline (e.g., SAM5=1.44 on TX2/CIFAR-10), while distilled models such as TinyViT-11M_Distilled excel on the mobile GPU (e.g., SAM5=1.72 on RTX 3050/CIFAR-10 and SAM5=0.76 on RTX 3050/ImageNet-1K).",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23166v1",
        "pdf": "https://arxiv.org/pdf/2511.23166v1"
      },
      "arxiv_id": "2511.23166v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23162v1",
      "title": "Estimating the Event-Related Potential from Few EEG Trials",
      "authors": [
        "Anders Vestergaard Nørskov",
        "Kasper Jørgensen",
        "Alexander Neergaard Zahid",
        "Morten Mørup"
      ],
      "abstract": "Event-related potentials (ERP) are measurements of brain activity with wide applications in basic and clinical neuroscience, that are typically estimated using the average of many trials of electroencephalography signals (EEG) to sufficiently reduce noise and signal variability. We introduce EEG2ERP, a novel uncertainty-aware autoencoder approach that maps an arbitrary number of EEG trials to their associated ERP. To account for the ERP uncertainty we use bootstrapped training targets and introduce a separate variance decoder to model the uncertainty of the estimated ERP. We evaluate our approach in the challenging zero-shot scenario of generalizing to new subjects considering three different publicly available data sources; i) the comprehensive ERP CORE dataset that includes over 50,000 EEG trials across six ERP paradigms from 40 subjects, ii) the large P300 Speller BCI dataset, and iii) a neuroimaging dataset on face perception consisting of both EEG and magnetoencephalography (MEG) data. We consistently find that our method in the few trial regime provides substantially better ERP estimates than commonly used conventional and robust averaging procedures. EEG2ERP is the first deep learning approach to map EEG signals to their associated ERP, moving toward reducing the number of trials necessary for ERP research. Code is available at https://github.com/andersxa/EEG2ERP",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23162v1",
        "pdf": "https://arxiv.org/pdf/2511.23162v1"
      },
      "arxiv_id": "2511.23162v1",
      "comment": "Accepted by Transactions on Machine Learning Research (TMLR). 15 pages main manuscript, 30 pages total including supplementary material",
      "journal_ref": "Transactions on Machine Learning Research, 2025",
      "has_code": false
    },
    {
      "id": "2511.23159v1",
      "title": "AI for software engineering: from probable to provable",
      "authors": [
        "Bertrand Meyer"
      ],
      "abstract": "Vibe coding, the much-touted use of AI techniques for programming, faces two overwhelming obstacles: the difficulty of specifying goals (\"prompt engineering\" is a form of requirements engineering, one of the toughest disciplines of software engineering); and the hallucination phenomenon. Programs are only useful if they are correct or very close to correct.\n  The solution? Combine the creativity of artificial intelligence with the rigor of formal specification methods and the power of formal program verification, supported by modern proof tools.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23159v1",
        "pdf": "https://arxiv.org/pdf/2511.23159v1"
      },
      "arxiv_id": "2511.23159v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23158v1",
      "title": "REVEAL: Reasoning-enhanced Forensic Evidence Analysis for Explainable AI-generated Image Detection",
      "authors": [
        "Huangsen Cao",
        "Qin Mei",
        "Zhiheng Li",
        "Yuxi Li",
        "Ying Zhang",
        "Chen Li",
        "Zhimeng Zhang",
        "Xin Ding",
        "Yongwei Wang",
        "Jing Lyu",
        "Fei Wu"
      ],
      "abstract": "With the rapid advancement of generative models, visually realistic AI-generated images have become increasingly difficult to distinguish from authentic ones, posing severe threats to social trust and information integrity. Consequently, there is an urgent need for efficient and truly explainable image forensic methods. Recent detection paradigms have shifted towards explainable forensics. However, state-of-the-art approaches primarily rely on post-hoc rationalizations or visual discrimination, lacking a verifiable chain of evidence. This reliance on surface-level pattern matching limits the generation of causally grounded explanations and often results in poor generalization. To bridge this critical gap, we introduce \\textbf{REVEAL-Bench}, the first reasoning-enhanced multimodal benchmark for AI-generated image detection that is explicitly structured around a chain-of-evidence derived from multiple lightweight expert models, then records step-by-step reasoning traces and evidential justifications. Building upon this dataset, we propose \\textbf{REVEAL} (\\underline{R}easoning-\\underline{e}nhanced Forensic E\\underline{v}id\\underline{e}nce \\underline{A}na\\underline{l}ysis), an effective and explainable forensic framework that integrates detection with a novel expert-grounded reinforcement learning. Our reward mechanism is specially tailored to jointly optimize detection accuracy, explanation fidelity, and logical coherence grounded in explicit forensic evidence, enabling REVEAL to produce fine-grained, interpretable, and verifiable reasoning chains alongside its detection outcomes. Extensive experimental results demonstrate that REVEAL significantly enhances detection accuracy, explanation fidelity, and robust cross-model generalization, benchmarking a new state of the art for explainable image forensics.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23158v1",
        "pdf": "https://arxiv.org/pdf/2511.23158v1"
      },
      "arxiv_id": "2511.23158v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23152v1",
      "title": "A Theoretical Framework for Discovering Groups and Unitary Representations via Tensor Factorization",
      "authors": [
        "Dongsung Huh",
        "Halyun Jeong"
      ],
      "abstract": "We analyze the HyperCube model, an \\textit{operator-valued} tensor factorization architecture that discovers group structures and their unitary representations. We provide a rigorous theoretical explanation for this inductive bias by decomposing its objective into a term regulating factor scales ($\\mathcal{B}$) and a term enforcing directional alignment ($\\mathcal{R} \\geq 0$). This decomposition isolates the \\textit{collinear manifold} ($\\mathcal{R}=0$), to which numerical optimization consistently converges for group isotopes. We prove that this manifold admits feasible solutions exclusively for group isotopes, and that within it, $\\mathcal{B}$ exerts a variational pressure toward unitarity. To bridge the gap to the global landscape, we formulate a \\textit{Collinearity Dominance Conjecture}, supported by empirical observations. Conditional on this dominance, we prove two key results: (1) the global minimum is achieved by the unitary regular representation for groups, and (2) non-group operations incur a strictly higher objective value, formally quantifying the model's inductive bias toward the associative structure of groups (up to isotopy).",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23152v1",
        "pdf": "https://arxiv.org/pdf/2511.23152v1"
      },
      "arxiv_id": "2511.23152v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23151v1",
      "title": "Learning to Refuse: Refusal-Aware Reinforcement Fine-Tuning for Hard-Irrelevant Queries in Video Temporal Grounding",
      "authors": [
        "Jin-Seop Lee",
        "SungJoon Lee",
        "SeongJun Jung",
        "Boyang Li",
        "Jee-Hyong Lee"
      ],
      "abstract": "Video Temporal Grounding (VTG) aims to localize a temporal segment in a video corresponding to a natural language query. However, existing VTG models assume that a relevant segment always exists, causing them to always predict a target segment even when the query is irrelevant to the video. While recent approaches attempt to handle irrelevant queries, they can only reject those that are entirely unrelated to the video and still fail to handle hard-irrelevant queries that are semantically similar but not actually relevant. To address this, we propose Refusal-Aware Reinforcement Fine-Tuning (RA-RFT) to effectively refuse hard-irrelevant queries in VTG. Our method is based on the Group Relative Policy Optimization (GRPO) framework and integrates four reward objectives-format, refuse-IoU, explain, and query correction-to improve both relevance discrimination and fine-grained semantic reasoning. In addition, to effectively support RA-RFT, we construct a Hard-Irrelevant VTG (HI-VTG) dataset, which includes hard-irrelevant queries and their refusal answers. We demonstrate the effectiveness of our method across various relevance-aware VTG scenarios, including hard-irrelevant VTG, simply-shuffled RA-VTG, and human-annotated RA-VTG settings. We also show that the proposed method is scalable by applying it to various LVLM-based VTG models. Our code is available at https://github.com/JINSUBY/RA-RFT.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23151v1",
        "pdf": "https://arxiv.org/pdf/2511.23151v1"
      },
      "arxiv_id": "2511.23151v1",
      "comment": "19 pages",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23150v1",
      "title": "Cascaded Robust Rectification for Arbitrary Document Images",
      "authors": [
        "Chaoyun Wang",
        "Quanxin Huang",
        "I-Chao Shen",
        "Takeo Igarashi",
        "Nanning Zheng",
        "Caigui Jiang"
      ],
      "abstract": "Document rectification in real-world scenarios poses significant challenges due to extreme variations in camera perspectives and physical distortions. Driven by the insight that complex transformations can be decomposed and resolved progressively, we introduce a novel multi-stage framework that progressively reverses distinct distortion types in a coarse-to-fine manner. Specifically, our framework first performs a global affine transformation to correct perspective distortions arising from the camera's viewpoint, then rectifies geometric deformations resulting from physical paper curling and folding, and finally employs a content-aware iterative process to eliminate fine-grained content distortions. To address limitations in existing evaluation protocols, we also propose two enhanced metrics: layout-aligned OCR metrics (AED/ACER) for a stable assessment that decouples geometric rectification quality from the layout analysis errors of OCR engines, and masked AD/AAD (AD-M/AAD-M) tailored for accurately evaluating geometric distortions in documents with incomplete boundaries. Extensive experiments show that our method establishes new state-of-the-art performance on multiple challenging benchmarks, yielding a substantial reduction of 14.1\\%--34.7\\% in the AAD metric and demonstrating superior efficacy in real-world applications. The code will be publicly available at https://github.com/chaoyunwang/ArbDR.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23150v1",
        "pdf": "https://arxiv.org/pdf/2511.23150v1"
      },
      "arxiv_id": "2511.23150v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23148v1",
      "title": "Peer-to-Peer Energy Trading in Dairy Farms using Multi-Agent Reinforcement Learning",
      "authors": [
        "Mian Ibad Ali Shah",
        "Marcos Eduardo Cruz Victorio",
        "Maeve Duffy",
        "Enda Barrett",
        "Karl Mason"
      ],
      "abstract": "The integration of renewable energy resources in rural areas, such as dairy farming communities, enables decentralized energy management through Peer-to-Peer (P2P) energy trading. This research highlights the role of P2P trading in efficient energy distribution and its synergy with advanced optimization techniques. While traditional rule-based methods perform well under stable conditions, they struggle in dynamic environments. To address this, Multi-Agent Reinforcement Learning (MARL), specifically Proximal Policy Optimization (PPO) and Deep Q-Networks (DQN), is combined with community/distributed P2P trading mechanisms. By incorporating auction-based market clearing, a price advisor agent, and load and battery management, the approach achieves significant improvements. Results show that, compared to baseline models, DQN reduces electricity costs by 14.2% in Ireland and 5.16% in Finland, while increasing electricity revenue by 7.24% and 12.73%, respectively. PPO achieves the lowest peak hour demand, reducing it by 55.5% in Ireland, while DQN reduces peak hour demand by 50.0% in Ireland and 27.02% in Finland. These improvements are attributed to both MARL algorithms and P2P energy trading, which together results in electricity cost and peak hour demand reduction, and increase electricity selling revenue. This study highlights the complementary strengths of DQN, PPO, and P2P trading in achieving efficient, adaptable, and sustainable energy management in rural communities.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23148v1",
        "pdf": "https://arxiv.org/pdf/2511.23148v1"
      },
      "arxiv_id": "2511.23148v1",
      "comment": "51 pages, 7 figures, 11 tables, Preprint of the article published in Applied Energy: Shah, M.I.A., Victorio, M.E.C., Duffy, M., Barrett, E. and Mason, K. (2026). Peer-to-peer energy trading in dairy farms using multi-agent reinforcement learning. Applied Energy, 402, 127041. doi:10.1016/j.apenergy.2025.127041",
      "journal_ref": "Applied Energy (2026), 402, 127041",
      "has_code": false
    },
    {
      "id": "2511.23146v1",
      "title": "InstanceV: Instance-Level Video Generation",
      "authors": [
        "Yuheng Chen",
        "Teng Hu",
        "Jiangning Zhang",
        "Zhucun Xue",
        "Ran Yi",
        "Lizhuang Ma"
      ],
      "abstract": "Recent advances in text-to-video diffusion models have enabled the generation of high-quality videos conditioned on textual descriptions. However, most existing text-to-video models rely solely on textual conditions, lacking general fine-grained controllability over video generation. To address this challenge, we propose InstanceV, a video generation framework that enables i) instance-level control and ii) global semantic consistency. Specifically, with the aid of proposed Instance-aware Masked Cross-Attention mechanism, InstanceV maximizes the utilization of additional instance-level grounding information to generate correctly attributed instances at designated spatial locations. To improve overall consistency, We introduce the Shared Timestep-Adaptive Prompt Enhancement module, which connects local instances with global semantics in a parameter-efficient manner. Furthermore, we incorporate Spatially-Aware Unconditional Guidance during both training and inference to alleviate the disappearance of small instances. Finally, we propose a new benchmark, named InstanceBench, which combines general video quality metrics with instance-aware metrics for more comprehensive evaluation on instance-level video generation. Extensive experiments demonstrate that InstanceV not only achieves remarkable instance-level controllability in video generation, but also outperforms existing state-of-the-art models in both general quality and instance-aware metrics across qualitative and quantitative evaluations.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23146v1",
        "pdf": "https://arxiv.org/pdf/2511.23146v1"
      },
      "arxiv_id": "2511.23146v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23143v1",
      "title": "Automated Generation of MDPs Using Logic Programming and LLMs for Robotic Applications",
      "authors": [
        "Enrico Saccon",
        "Davide De Martini",
        "Matteo Saveriano",
        "Edoardo Lamon",
        "Luigi Palopoli",
        "Marco Roveri"
      ],
      "abstract": "We present a novel framework that integrates Large Language Models (LLMs) with automated planning and formal verification to streamline the creation and use of Markov Decision Processes (MDP). Our system leverages LLMs to extract structured knowledge in the form of a Prolog knowledge base from natural language (NL) descriptions. It then automatically constructs an MDP through reachability analysis, and synthesises optimal policies using the Storm model checker. The resulting policy is exported as a state-action table for execution. We validate the framework in three human-robot interaction scenarios, demonstrating its ability to produce executable policies with minimal manual effort. This work highlights the potential of combining language models with formal methods to enable more accessible and scalable probabilistic planning in robotics.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23143v1",
        "pdf": "https://arxiv.org/pdf/2511.23143v1"
      },
      "arxiv_id": "2511.23143v1",
      "comment": "9 pages, 11 figures, 2 tables, 2 algorithms, accepted for publication in IEEE Robotics and Automation Letters",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23142v1",
      "title": "Adapting Neural Audio Codecs to EEG",
      "authors": [
        "Ard Kastrati",
        "Luca Lanzendörfer",
        "Riccardo Rigoni",
        "John Staib Matilla",
        "Roger Wattenhofer"
      ],
      "abstract": "EEG and audio are inherently distinct modalities, differing in sampling rate, channel structure, and scale. Yet, we show that pretrained neural audio codecs can serve as effective starting points for EEG compression, provided that the data are preprocessed to be suitable to the codec's input constraints. Using DAC, a state-of-the-art neural audio codec as our base, we demonstrate that raw EEG can be mapped into the codec's stride-based framing, enabling direct reuse of the audio-pretrained encoder-decoder. Even without modification, this setup yields stable EEG reconstructions, and fine-tuning on EEG data further improves fidelity and generalization compared to training from scratch. We systematically explore compression-quality trade-offs by varying residual codebook depth, codebook (vocabulary) size, and input sampling rate. To capture spatial dependencies across electrodes, we propose DAC-MC, a multi-channel extension with attention-based cross-channel aggregation and channel-specific decoding, while retaining the audio-pretrained initialization. Evaluations on the TUH Abnormal and Epilepsy datasets show that the adapted codecs preserve clinically relevant information, as reflected in spectrogram-based reconstruction loss and downstream classification accuracy.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23142v1",
        "pdf": "https://arxiv.org/pdf/2511.23142v1"
      },
      "arxiv_id": "2511.23142v1",
      "comment": "Foundation Models for the Brain and Body (BrainBodyFM@NeurIPS)",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23141v1",
      "title": "Automated Discovery of Laser Dicing Processes with Bayesian Optimization for Semiconductor Manufacturing",
      "authors": [
        "David Leeftink",
        "Roman Doll",
        "Heleen Visserman",
        "Marco Post",
        "Faysal Boughorbel",
        "Max Hinne",
        "Marcel van Gerven"
      ],
      "abstract": "Laser dicing of semiconductor wafers is a critical step in microelectronic manufacturing, where multiple sequential laser passes precisely separate individual dies from the wafer. Adapting this complex sequential process to new wafer materials typically requires weeks of expert effort to balance process speed, separation quality, and material integrity. We present the first automated discovery of production-ready laser dicing processes on an industrial LASER1205 dicing system. We formulate the problem as a high-dimensional, constrained multi-objective Bayesian optimization task, and introduce a sequential two-level fidelity strategy to minimize expensive destructive die-strength evaluations. On bare silicon and product wafers, our method autonomously delivers feasible configurations that match or exceed expert baselines in production speed, die strength, and structural integrity, using only technician-level operation. Post-hoc validation of different weight configurations of the utility functions reveals that multiple feasible solutions with qualitatively different trade-offs can be obtained from the final surrogate model. Expert-refinement of the discovered process can further improve production speed while preserving die strength and structural integrity, surpassing purely manual or automated methods.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.LG",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23141v1",
        "pdf": "https://arxiv.org/pdf/2511.23141v1"
      },
      "arxiv_id": "2511.23141v1",
      "comment": "18 pages, 9 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23136v1",
      "title": "Multi-chain Graph Refinement and Selection for Reliable Reasoning in Large Language Models",
      "authors": [
        "Yujiao Yang",
        "Jing Lian",
        "Linhui Li"
      ],
      "abstract": "The complex reasoning ability of Large Language Models (LLMs) poses a critical bottleneck for their practical applications. Test-time expansion methods such as Tree-of-Thought (ToT) and Graph-of-Thought (GoT) enhance reasoning by introducing intermediate reasoning structures, tree search, or graph-based exploration mechanisms. However, their reasoning strategies suffer from limited diversity, redundant search branches, and inadequate integration and error correction across heterogeneous reasoning paths. To address these limitations, we propose a novel reasoning framework called Multi-chain Graph Refinement & Selection (MGRS), which first generates multiple diverse reasoning trajectories for a given problem, refines candidate responses using a composite self- and cross-verification strategy, then constructs a reasoning relation graph and estimates the success rate of intermediate nodes, and finally computes cumulative success rates to select the most reliable answer and corresponding reasoning trajectory. Experimental results demonstrate that MGRS significantly advances both the reasoning capability and computational efficiency of reasoning enhancement methods. Across six benchmark datasets spanning four distinct tasks, MGRS achieves an average accuracy of 82.9%, outperforming state-of-the-art baselines by a clear margin of 2.1%. Remarkably, on the 24-point game, MGRS attains 100% accuracy for the first time, while delivering a 13.6x speed-up compared to the leading Forest of Thoughts framework.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23136v1",
        "pdf": "https://arxiv.org/pdf/2511.23136v1"
      },
      "arxiv_id": "2511.23136v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23127v1",
      "title": "DualCamCtrl: Dual-Branch Diffusion Model for Geometry-Aware Camera-Controlled Video Generation",
      "authors": [
        "Hongfei Zhang",
        "Kanghao Chen",
        "Zixin Zhang",
        "Harold Haodong Chen",
        "Yuanhuiyi Lyu",
        "Yuqi Zhang",
        "Shuai Yang",
        "Kun Zhou",
        "Yingcong Chen"
      ],
      "abstract": "This paper presents DualCamCtrl, a novel end-to-end diffusion model for camera-controlled video generation. Recent works have advanced this field by representing camera poses as ray-based conditions, yet they often lack sufficient scene understanding and geometric awareness. DualCamCtrl specifically targets this limitation by introducing a dual-branch framework that mutually generates camera-consistent RGB and depth sequences. To harmonize these two modalities, we further propose the Semantic Guided Mutual Alignment (SIGMA) mechanism, which performs RGB-depth fusion in a semantics-guided and mutually reinforced manner. These designs collectively enable DualCamCtrl to better disentangle appearance and geometry modeling, generating videos that more faithfully adhere to the specified camera trajectories. Additionally, we analyze and reveal the distinct influence of depth and camera poses across denoising stages and further demonstrate that early and late stages play complementary roles in forming global structure and refining local details. Extensive experiments demonstrate that DualCamCtrl achieves more consistent camera-controlled video generation, with over 40\\% reduction in camera motion errors compared with prior methods. Our project page: https://soyouthinkyoucantell.github.io/dualcamctrl\\-page/",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23127v1",
        "pdf": "https://arxiv.org/pdf/2511.23127v1"
      },
      "arxiv_id": "2511.23127v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2511.23124v1",
      "title": "DNA-Prior: Unsupervised Denoise Anything via Dual-Domain Prior",
      "authors": [
        "Yanqi Cheng",
        "Chun-Wun Cheng",
        "Jim Denholm",
        "Thiago Lima",
        "Javier A. Montoya-Zegarra",
        "Richard Goodwin",
        "Carola-Bibiane Schönlieb",
        "Angelica I Aviles-Rivero"
      ],
      "abstract": "Medical imaging pipelines critically rely on robust denoising to stabilise downstream tasks such as segmentation and reconstruction. However, many existing denoisers depend on large annotated datasets or supervised learning, which restricts their usability in clinical environments with heterogeneous modalities and limited ground-truth data. To address this limitation, we introduce DNA-Prior, a universal unsupervised denoising framework that reconstructs clean images directly from corrupted observations through a mathematically principled hybrid prior. DNA-Prior integrates (i) an implicit architectural prior, enforced through a deep network parameterisation, with (ii) an explicit spectral-spatial prior composed of a frequency-domain fidelity term and a spatial regularisation functional. This dual-domain formulation yields a well-structured optimisation problem that jointly preserves global frequency characteristics and local anatomical structure, without requiring any external training data or modality-specific tuning. Experiments across multiple modalities show that DNA achieves consistent noise suppression and structural preservation under diverse noise conditions.",
      "published": "2025-11-28",
      "updated": "2025-11-28",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2511.23124v1",
        "pdf": "https://arxiv.org/pdf/2511.23124v1"
      },
      "arxiv_id": "2511.23124v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    }
  ]
}