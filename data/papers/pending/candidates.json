{
  "fetched_at": "2026-02-24T00:31:55.056612",
  "total_papers": 100,
  "papers": [
    {
      "id": "2602.18435v1",
      "title": "Assigning Confidence: K-partition Ensembles",
      "authors": [
        "Aggelos Semoglou",
        "John Pavlopoulos"
      ],
      "abstract": "Clustering is widely used for unsupervised structure discovery, yet it offers limited insight into how reliable each individual assignment is. Diagnostics, such as convergence behavior or objective values, may reflect global quality, but they do not indicate whether particular instances are assigned confidently, especially for initialization-sensitive algorithms like k-means. This assignment-level instability can undermine both accuracy and robustness. Ensemble approaches improve global consistency by aggregating multiple runs, but they typically lack tools for quantifying pointwise confidence in a way that combines cross-run agreement with geometric support from the learned cluster structure. We introduce CAKE (Confidence in Assignments via K-partition Ensembles), a framework that evaluates each point using two complementary statistics computed over a clustering ensemble: assignment stability and consistency of local geometric fit. These are combined into a single, interpretable score in [0,1]. Our theoretical analysis shows that CAKE remains effective under noise and separates stable from unstable points. Experiments on synthetic and real-world datasets indicate that CAKE effectively highlights ambiguous points and stable core members, providing a confidence ranking that can guide filtering or prioritization to improve clustering quality.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18435v1",
        "pdf": "https://arxiv.org/pdf/2602.18435v1"
      },
      "arxiv_id": "2602.18435v1",
      "comment": "31 pages including appendix",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18434v1",
      "title": "Going Down Memory Lane: Scaling Tokens for Video Stream Understanding with Dynamic KV-Cache Memory",
      "authors": [
        "Vatsal Agarwal",
        "Saksham Suri",
        "Matthew Gwilliam",
        "Pulkit Kumar",
        "Abhinav Shrivastava"
      ],
      "abstract": "Streaming video understanding requires models to robustly encode, store, and retrieve information from a continuous video stream to support accurate video question answering (VQA). Existing state-of-the-art approaches rely on key-value caching to accumulate frame-level information over time, but use a limited number of tokens per frame, leading to the loss of fine-grained visual details. In this work, we propose scaling the token budget to enable more granular spatiotemporal understanding and reasoning. First, we find that current methods are ill-equipped to handle dense streams: their feature encoding causes query-frame similarity scores to increase over time, biasing retrieval toward later frames. To address this, we introduce an adaptive selection strategy that reduces token redundancy while preserving local spatiotemporal information. We further propose a training-free retrieval mixture-of-experts that leverages external models to better identify relevant frames. Our method, MemStream, achieves +8.0% on CG-Bench, +8.5% on LVBench, and +2.4% on VideoMME (Long) over ReKV with Qwen2.5-VL-7B.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18434v1",
        "pdf": "https://arxiv.org/pdf/2602.18434v1"
      },
      "arxiv_id": "2602.18434v1",
      "comment": "Project page: see https://vatsalag99.github.io/memstream/",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2602.18432v1",
      "title": "SARAH: Spatially Aware Real-time Agentic Humans",
      "authors": [
        "Evonne Ng",
        "Siwei Zhang",
        "Zhang Chen",
        "Michael Zollhoefer",
        "Alexander Richard"
      ],
      "abstract": "As embodied agents become central to VR, telepresence, and digital human applications, their motion must go beyond speech-aligned gestures: agents should turn toward users, respond to their movement, and maintain natural gaze. Current methods lack this spatial awareness. We close this gap with the first real-time, fully causal method for spatially-aware conversational motion, deployable on a streaming VR headset. Given a user's position and dyadic audio, our approach produces full-body motion that aligns gestures with speech while orienting the agent according to the user. Our architecture combines a causal transformer-based VAE with interleaved latent tokens for streaming inference and a flow matching model conditioned on user trajectory and audio. To support varying gaze preferences, we introduce a gaze scoring mechanism with classifier-free guidance to decouple learning from control: the model captures natural spatial alignment from data, while users can adjust eye contact intensity at inference time. On the Embody 3D dataset, our method achieves state-of-the-art motion quality at over 300 FPS -- 3x faster than non-causal baselines -- while capturing the subtle spatial dynamics of natural conversation. We validate our approach on a live VR system, bringing spatially-aware conversational agents to real-time deployment. Please see https://evonneng.github.io/sarah/ for details.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18432v1",
        "pdf": "https://arxiv.org/pdf/2602.18432v1"
      },
      "arxiv_id": "2602.18432v1",
      "comment": "Project page: https://evonneng.github.io/sarah/",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2602.18428v1",
      "title": "The Geometry of Noise: Why Diffusion Models Don't Need Noise Conditioning",
      "authors": [
        "Mojtaba Sahraee-Ardakan",
        "Mauricio Delbracio",
        "Peyman Milanfar"
      ],
      "abstract": "Autonomous (noise-agnostic) generative models, such as Equilibrium Matching and blind diffusion, challenge the standard paradigm by learning a single, time-invariant vector field that operates without explicit noise-level conditioning. While recent work suggests that high-dimensional concentration allows these models to implicitly estimate noise levels from corrupted observations, a fundamental paradox remains: what is the underlying landscape being optimized when the noise level is treated as a random variable, and how can a bounded, noise-agnostic network remain stable near the data manifold where gradients typically diverge? We resolve this paradox by formalizing Marginal Energy, $E_{\\text{marg}}(\\mathbf{u}) = -\\log p(\\mathbf{u})$, where $p(\\mathbf{u}) = \\int p(\\mathbf{u}|t)p(t)dt$ is the marginal density of the noisy data integrated over a prior distribution of unknown noise levels. We prove that generation using autonomous models is not merely blind denoising, but a specific form of Riemannian gradient flow on this Marginal Energy. Through a novel relative energy decomposition, we demonstrate that while the raw Marginal Energy landscape possesses a $1/t^p$ singularity normal to the data manifold, the learned time-invariant field implicitly incorporates a local conformal metric that perfectly counteracts the geometric singularity, converting an infinitely deep potential well into a stable attractor. We also establish the structural stability conditions for sampling with autonomous models. We identify a ``Jensen Gap'' in noise-prediction parameterizations that acts as a high-gain amplifier for estimation errors, explaining the catastrophic failure observed in deterministic blind models. Conversely, we prove that velocity-based parameterizations are inherently stable because they satisfy a bounded-gain condition that absorbs posterior uncertainty into a smooth geometric drift.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.LG",
        "cs.CV",
        "eess.IV"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18428v1",
        "pdf": "https://arxiv.org/pdf/2602.18428v1"
      },
      "arxiv_id": "2602.18428v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18426v1",
      "title": "Spatio-Spectroscopic Representation Learning using Unsupervised Convolutional Long-Short Term Memory Networks",
      "authors": [
        "Kameswara Bharadwaj Mantha",
        "Lucy Fortson",
        "Ramanakumar Sankar",
        "Claudia Scarlata",
        "Chris Lintott",
        "Sandor Kruk",
        "Mike Walmsley",
        "Hugh Dickinson",
        "Karen Masters",
        "Brooke Simmons",
        "Rebecca Smethurst"
      ],
      "abstract": "Integral Field Spectroscopy (IFS) surveys offer a unique new landscape in which to learn in both spatial and spectroscopic dimensions and could help uncover previously unknown insights into galaxy evolution. In this work, we demonstrate a new unsupervised deep learning framework using Convolutional Long-Short Term Memory Network Autoencoders to encode generalized feature representations across both spatial and spectroscopic dimensions spanning $19$ optical emission lines (3800A $< λ<$ 8000A) among a sample of $\\sim 9000$ galaxies from the MaNGA IFS survey. As a demonstrative exercise, we assess our model on a sample of $290$ Active Galactic Nuclei (AGN) and highlight scientifically interesting characteristics of some highly anomalous AGN.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "astro-ph.GA",
        "cs.CV"
      ],
      "primary_category": "astro-ph.GA",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18426v1",
        "pdf": "https://arxiv.org/pdf/2602.18426v1"
      },
      "arxiv_id": "2602.18426v1",
      "comment": "This manuscript was previously submitted to ICML for peer review. Reviewers noted that while the underlying VAE-based architecture builds on established methods, its application to spatially-resolved IFS data is promising for unsupervised representation learning in astronomy. This version is released for community visibility. Reviewer decisions: Weak accept and Weak reject (Final: Reject)",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18424v1",
      "title": "CapNav: Benchmarking Vision Language Models on Capability-conditioned Indoor Navigation",
      "authors": [
        "Xia Su",
        "Ruiqi Chen",
        "Benlin Liu",
        "Jingwei Ma",
        "Zonglin Di",
        "Ranjay Krishna",
        "Jon Froehlich"
      ],
      "abstract": "Vision-Language Models (VLMs) have shown remarkable progress in Vision-Language Navigation (VLN), offering new possibilities for navigation decision-making that could benefit both robotic platforms and human users. However, real-world navigation is inherently conditioned by the agent's mobility constraints. For example, a sweeping robot cannot traverse stairs, while a quadruped can. We introduce Capability-Conditioned Navigation (CapNav), a benchmark designed to evaluate how well VLMs can navigate complex indoor spaces given an agent's specific physical and operational capabilities. CapNav defines five representative human and robot agents, each described with physical dimensions, mobility capabilities, and environmental interaction abilities. CapNav provides 45 real-world indoor scenes, 473 navigation tasks, and 2365 QA pairs to test if VLMs can traverse indoor environments based on agent capabilities. We evaluate 13 modern VLMs and find that current VLM's navigation performance drops sharply as mobility constraints tighten, and that even state-of-the-art models struggle with obstacle types that require reasoning on spatial dimensions. We conclude by discussing the implications for capability-aware navigation and the opportunities for advancing embodied spatial reasoning in future VLMs. The benchmark is available at https://github.com/makeabilitylab/CapNav",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18424v1",
        "pdf": "https://arxiv.org/pdf/2602.18424v1"
      },
      "arxiv_id": "2602.18424v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18422v1",
      "title": "Generated Reality: Human-centric World Simulation using Interactive Video Generation with Hand and Camera Control",
      "authors": [
        "Linxi Xie",
        "Lisong C. Sun",
        "Ashley Neall",
        "Tong Wu",
        "Shengqu Cai",
        "Gordon Wetzstein"
      ],
      "abstract": "Extended reality (XR) demands generative models that respond to users' tracked real-world motion, yet current video world models accept only coarse control signals such as text or keyboard input, limiting their utility for embodied interaction. We introduce a human-centric video world model that is conditioned on both tracked head pose and joint-level hand poses. For this purpose, we evaluate existing diffusion transformer conditioning strategies and propose an effective mechanism for 3D head and hand control, enabling dexterous hand--object interactions. We train a bidirectional video diffusion model teacher using this strategy and distill it into a causal, interactive system that generates egocentric virtual environments. We evaluate this generated reality system with human subjects and demonstrate improved task performance as well as a significantly higher level of perceived amount of control over the performed actions compared with relevant baselines.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18422v1",
        "pdf": "https://arxiv.org/pdf/2602.18422v1"
      },
      "arxiv_id": "2602.18422v1",
      "comment": "Project page here: https://codeysun.github.io/generated-reality",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2602.18419v1",
      "title": "Benchmarking Graph Neural Networks in Solving Hard Constraint Satisfaction Problems",
      "authors": [
        "Geri Skenderi",
        "Lorenzo Buffoni",
        "Francesco D'Amico",
        "David Machado",
        "Raffaele Marino",
        "Matteo Negri",
        "Federico Ricci-Tersenghi",
        "Carlo Lucibello",
        "Maria Chiara Angelini"
      ],
      "abstract": "Graph neural networks (GNNs) are increasingly applied to hard optimization problems, often claiming superiority over classical heuristics. However, such claims risk being unsolid due to a lack of standard benchmarks on truly hard instances. From a statistical physics perspective, we propose new hard benchmarks based on random problems. We provide these benchmarks, along with performance results from both classical heuristics and GNNs. Our fair comparison shows that classical algorithms still outperform GNNs. We discuss the challenges for neural networks in this domain. Future claims of superiority can be made more robust using our benchmarks, available at https://github.com/ArtLabBocconi/RandCSPBench.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cond-mat.dis-nn",
        "cs.LG"
      ],
      "primary_category": "cond-mat.dis-nn",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18419v1",
        "pdf": "https://arxiv.org/pdf/2602.18419v1"
      },
      "arxiv_id": "2602.18419v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18417v1",
      "title": "Subgroups of $U(d)$ Induce Natural RNN and Transformer Architectures",
      "authors": [
        "Joshua Nunley"
      ],
      "abstract": "This paper presents a direct framework for sequence models with hidden states on closed subgroups of U(d). We use a minimal axiomatic setup and derive recurrent and transformer templates from a shared skeleton in which subgroup choice acts as a drop-in replacement for state space, tangent projection, and update map. We then specialize to O(d) and evaluate orthogonal-state RNN and transformer models on Tiny Shakespeare and Penn Treebank under parameter-matched settings. We also report a general linear-mixing extension in tangent space, which applies across subgroup choices and improves finite-budget performance in the current O(d) experiments.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18417v1",
        "pdf": "https://arxiv.org/pdf/2602.18417v1"
      },
      "arxiv_id": "2602.18417v1",
      "comment": "12 pages, 3 figures, 8 tables",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18409v1",
      "title": "Unifying approach to uniform expressivity of graph neural networks",
      "authors": [
        "Huan Luo",
        "Jonni Virtema"
      ],
      "abstract": "The expressive power of Graph Neural Networks (GNNs) is often analysed via correspondence to the Weisfeiler-Leman (WL) algorithm and fragments of first-order logic. Standard GNNs are limited to performing aggregation over immediate neighbourhoods or over global read-outs. To increase their expressivity, recent attempts have been made to incorporate substructural information (e.g. cycle counts and subgraph properties). In this paper, we formalize this architectural trend by introducing Template GNNs (T-GNNs), a generalized framework where node features are updated by aggregating over valid template embeddings from a specified set of graph templates. We propose a corresponding logic, Graded template modal logic (GML(T)), and generalized notions of template-based bisimulation and WL algorithm. We establish an equivalence between the expressive power of T-GNNs and GML(T), and provide a unifying approach for analysing GNN expressivity: we show how standard AC-GNNs and its recent variants can be interpreted as instantiations of T-GNNs.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18409v1",
        "pdf": "https://arxiv.org/pdf/2602.18409v1"
      },
      "arxiv_id": "2602.18409v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18406v1",
      "title": "Latent Equivariant Operators for Robust Object Recognition: Promise and Challenges",
      "authors": [
        "Minh Dinh",
        "Stéphane Deny"
      ],
      "abstract": "Despite the successes of deep learning in computer vision, difficulties persist in recognizing objects that have undergone group-symmetric transformations rarely seen during training-for example objects seen in unusual poses, scales, positions, or combinations thereof. Equivariant neural networks are a solution to the problem of generalizing across symmetric transformations, but require knowledge of transformations a priori. An alternative family of architectures proposes to earn equivariant operators in a latent space from examples of symmetric transformations. Here, using simple datasets of rotated and translated noisy MNIST, we illustrate how such architectures can successfully be harnessed for out-of-distribution classification, thus overcoming the limitations of both traditional and equivariant networks. While conceptually enticing, we discuss challenges ahead on the path of scaling these architectures to more complex datasets.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18406v1",
        "pdf": "https://arxiv.org/pdf/2602.18406v1"
      },
      "arxiv_id": "2602.18406v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18403v1",
      "title": "Scientific Knowledge-Guided Machine Learning for Vessel Power Prediction: A Comparative Study",
      "authors": [
        "Orfeas Bourchas",
        "George Papalambrou"
      ],
      "abstract": "Accurate prediction of main engine power is essential for vessel performance optimization, fuel efficiency, and compliance with emission regulations. Conventional machine learning approaches, such as Support Vector Machines, variants of Artificial Neural Networks (ANNs), and tree-based methods like Random Forests, Extra Tree Regressors, and XGBoost, can capture nonlinearities but often struggle to respect the fundamental propeller law relationship between power and speed, resulting in poor extrapolation outside the training envelope. This study introduces a hybrid modeling framework that integrates physics-based knowledge from sea trials with data-driven residual learning. The baseline component, derived from calm-water power curves of the form $P = cV^n$, captures the dominant power-speed dependence, while another, nonlinear, regressor is then trained to predict the residual power, representing deviations caused by environmental and operational conditions. By constraining the machine learning task to residual corrections, the hybrid model simplifies learning, improves generalization, and ensures consistency with the underlying physics. In this study, an XGBoost, a simple Neural Network, and a Physics-Informed Neural Network (PINN) coupled with the baseline component were compared to identical models without the baseline component. Validation on in-service data demonstrates that the hybrid model consistently outperformed a pure data-driven baseline in sparse data regions while maintaining similar performance in populated ones. The proposed framework provides a practical and computationally efficient tool for vessel performance monitoring, with applications in weather routing, trim optimization, and energy efficiency planning.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18403v1",
        "pdf": "https://arxiv.org/pdf/2602.18403v1"
      },
      "arxiv_id": "2602.18403v1",
      "comment": "Accepted to the KGML Bridge at AAAI 2026 (non-archival)",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18401v1",
      "title": "Leakage and Second-Order Dynamics Improve Hippocampal RNN Replay",
      "authors": [
        "Josue Casco-Rodriguez",
        "Nanda H. Krishna",
        "Richard G. Baraniuk"
      ],
      "abstract": "Biological neural networks (like the hippocampus) can internally generate \"replay\" resembling stimulus-driven activity. Recent computational models of replay use noisy recurrent neural networks (RNNs) trained to path-integrate. Replay in these networks has been described as Langevin sampling, but new modifiers of noisy RNN replay have surpassed this description. We re-examine noisy RNN replay as sampling to understand or improve it in three ways: (1) Under simple assumptions, we prove that the gradients replay activity should follow are time-varying and difficult to estimate, but readily motivate the use of hidden state leakage in RNNs for replay. (2) We confirm that hidden state adaptation (negative feedback) encourages exploration in replay, but show that it incurs non-Markov sampling that also slows replay. (3) We propose the first model of temporally compressed replay in noisy path-integrating RNNs through hidden state momentum, connect it to underdamped Langevin sampling, and show that, together with adaptation, it counters slowness while maintaining exploration. We verify our findings via path-integration of 2D triangular and T-maze paths and of high-dimensional paths of synthetic rat place cell activity.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.NC",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18401v1",
        "pdf": "https://arxiv.org/pdf/2602.18401v1"
      },
      "arxiv_id": "2602.18401v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18400v1",
      "title": "Exploiting Completeness Perception with Diffusion Transformer for Unified 3D MRI Synthesis",
      "authors": [
        "Junkai Liu",
        "Nay Aung",
        "Theodoros N. Arvanitis",
        "Joao A. C. Lima",
        "Steffen E. Petersen",
        "Daniel C. Alexander",
        "Le Zhang"
      ],
      "abstract": "Missing data problems, such as missing modalities in multi-modal brain MRI and missing slices in cardiac MRI, pose significant challenges in clinical practice. Existing methods rely on external guidance to supply detailed missing state for instructing generative models to synthesize missing MRIs. However, manual indicators are not always available or reliable in real-world scenarios due to the unpredictable nature of clinical environments. Moreover, these explicit masks are not informative enough to provide guidance for improving semantic consistency. In this work, we argue that generative models should infer and recognize missing states in a self-perceptive manner, enabling them to better capture subtle anatomical and pathological variations. Towards this goal, we propose CoPeDiT, a general-purpose latent diffusion model equipped with completeness perception for unified synthesis of 3D MRIs. Specifically, we incorporate dedicated pretext tasks into our tokenizer, CoPeVAE, empowering it to learn completeness-aware discriminative prompts, and design MDiT3D, a specialized diffusion transformer architecture for 3D MRI synthesis, that effectively uses the learned prompts as guidance to enhance semantic consistency in 3D space. Comprehensive evaluations on three large-scale MRI datasets demonstrate that CoPeDiT significantly outperforms state-of-the-art methods, achieving superior robustness, generalizability, and flexibility. The code is available at https://github.com/JK-Liu7/CoPeDiT .",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "eess.IV",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18400v1",
        "pdf": "https://arxiv.org/pdf/2602.18400v1"
      },
      "arxiv_id": "2602.18400v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18396v1",
      "title": "PRISM-FCP: Byzantine-Resilient Federated Conformal Prediction via Partial Sharing",
      "authors": [
        "Ehsan Lari",
        "Reza Arablouei",
        "Stefan Werner"
      ],
      "abstract": "We propose PRISM-FCP (Partial shaRing and robust calIbration with Statistical Margins for Federated Conformal Prediction), a Byzantine-resilient federated conformal prediction framework that utilizes partial model sharing to improve robustness against Byzantine attacks during both model training and conformal calibration. Existing approaches address adversarial behavior only in the calibration stage, leaving the learned model susceptible to poisoned updates. In contrast, PRISM-FCP mitigates attacks end-to-end. During training, clients partially share updates by transmitting only $M$ of $D$ parameters per round. This attenuates the expected energy of an adversary's perturbation in the aggregated update by a factor of $M/D$, yielding lower mean-square error (MSE) and tighter prediction intervals. During calibration, clients convert nonconformity scores into characterization vectors, compute distance-based maliciousness scores, and downweight or filter suspected Byzantine contributions before estimating the conformal quantile. Extensive experiments on both synthetic data and the UCI Superconductivity dataset demonstrate that PRISM-FCP maintains nominal coverage guarantees under Byzantine attacks while avoiding the interval inflation observed in standard FCP with reduced communication, providing a robust and communication-efficient approach to federated uncertainty quantification.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.LG",
        "eess.SP",
        "math.PR",
        "stat.AP",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18396v1",
        "pdf": "https://arxiv.org/pdf/2602.18396v1"
      },
      "arxiv_id": "2602.18396v1",
      "comment": "13 pages, 5 figures, 2 tables, Submitted to IEEE Transactions on Signal Processing (TSP)",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18394v1",
      "title": "Self-Aware Object Detection via Degradation Manifolds",
      "authors": [
        "Stefan Becker",
        "Simon Weiss",
        "Wolfgang Hübner",
        "Michael Arens"
      ],
      "abstract": "Object detectors achieve strong performance under nominal imaging conditions but can fail silently when exposed to blur, noise, compression, adverse weather, or resolution changes. In safety-critical settings, it is therefore insufficient to produce predictions without assessing whether the input remains within the detector's nominal operating regime. We refer to this capability as self-aware object detection.\n  We introduce a degradation-aware self-awareness framework based on degradation manifolds, which explicitly structure a detector's feature space according to image degradation rather than semantic content. Our method augments a standard detection backbone with a lightweight embedding head trained via multi-layer contrastive learning. Images sharing the same degradation composition are pulled together, while differing degradation configurations are pushed apart, yielding a geometrically organized representation that captures degradation type and severity without requiring degradation labels or explicit density modeling.\n  To anchor the learned geometry, we estimate a pristine prototype from clean training embeddings, defining a nominal operating point in representation space. Self-awareness emerges as geometric deviation from this reference, providing an intrinsic, image-level signal of degradation-induced shift that is independent of detection confidence.\n  Extensive experiments on synthetic corruption benchmarks, cross-dataset zero-shot transfer, and natural weather-induced distribution shifts demonstrate strong pristine-degraded separability, consistent behavior across multiple detector architectures, and robust generalization under semantic shift. These results suggest that degradation-aware representation geometry provides a practical and detector-agnostic foundation.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18394v1",
        "pdf": "https://arxiv.org/pdf/2602.18394v1"
      },
      "arxiv_id": "2602.18394v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18386v1",
      "title": "Learning to Tune Pure Pursuit in Autonomous Racing: Joint Lookahead and Steering-Gain Control with PPO",
      "authors": [
        "Mohamed Elgouhary",
        "Amr S. El-Wakeel"
      ],
      "abstract": "Pure Pursuit (PP) is widely used in autonomous racing for real-time path tracking due to its efficiency and geometric clarity, yet performance is highly sensitive to how key parameters-lookahead distance and steering gain-are chosen. Standard velocity-based schedules adjust these only approximately and often fail to transfer across tracks and speed profiles. We propose a reinforcement-learning (RL) approach that jointly chooses the lookahead Ld and a steering gain g online using Proximal Policy Optimization (PPO). The policy observes compact state features (speed and curvature taps) and outputs (Ld, g) at each control step. Trained in F1TENTH Gym and deployed in a ROS 2 stack, the policy drives PP directly (with light smoothing) and requires no per-map retuning. Across simulation and real-car tests, the proposed RL-PP controller that jointly selects (Ld, g) consistently outperforms fixed-lookahead PP, velocity-scheduled adaptive PP, and an RL lookahead-only variant, and it also exceeds a kinematic MPC raceline tracker under our evaluated settings in lap time, path-tracking accuracy, and steering smoothness, demonstrating that policy-guided parameter tuning can reliably improve classical geometry-based control.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18386v1",
        "pdf": "https://arxiv.org/pdf/2602.18386v1"
      },
      "arxiv_id": "2602.18386v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18384v1",
      "title": "FedZMG: Efficient Client-Side Optimization in Federated Learning",
      "authors": [
        "Fotios Zantalis",
        "Evangelos Zervas",
        "Grigorios Koulouras"
      ],
      "abstract": "Federated Learning (FL) enables distributed model training on edge devices while preserving data privacy. However, clients tend to have non-Independent and Identically Distributed (non-IID) data, which often leads to client-drift, and therefore diminishing convergence speed and model performance. While adaptive optimizers have been proposed to mitigate these effects, they frequently introduce computational complexity or communication overhead unsuitable for resource-constrained IoT environments. This paper introduces Federated Zero Mean Gradients (FedZMG), a novel, parameter-free, client-side optimization algorithm designed to tackle client-drift by structurally regularizing the optimization space. Advancing the idea of Gradient Centralization, FedZMG projects local gradients onto a zero-mean hyperplane, effectively neutralizing the \"intensity\" or \"bias\" shifts inherent in heterogeneous data distributions without requiring additional communication or hyperparameter tuning. A theoretical analysis is provided, proving that FedZMG reduces the effective gradient variance and guarantees tighter convergence bounds compared to standard FedAvg. Extensive empirical evaluations on EMNIST, CIFAR100, and Shakespeare datasets demonstrate that FedZMG achieves better convergence speed and final validation accuracy compared to the baseline FedAvg and the adaptive optimizer FedAdam, particularly in highly non-IID settings.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18384v1",
        "pdf": "https://arxiv.org/pdf/2602.18384v1"
      },
      "arxiv_id": "2602.18384v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18377v1",
      "title": "Theory and interpretability of Quantum Extreme Learning Machines: a Pauli-transfer matrix approach",
      "authors": [
        "Markus Gross",
        "Hans-Martin Rieser"
      ],
      "abstract": "Quantum reservoir computers (QRCs) have emerged as a promising approach to quantum machine learning, since they utilize the natural dynamics of quantum systems for data processing and are simple to train. Here, we consider n-qubit quantum extreme learning machines (QELMs) with continuous-time reservoir dynamics. QELMs are memoryless QRCs capable of various ML tasks, including image classification and time series forecasting. We apply the Pauli transfer matrix (PTM) formalism to theoretically analyze the influence of encoding, reservoir dynamics, and measurement operations, including temporal multiplexing, on the QELM performance. This formalism makes explicit that the encoding determines the complete set of (nonlinear) features available to the QELM, while the quantum channels linearly transform these features before they are probed by the chosen measurement operators. Optimizing a QELM can therefore be cast as a decoding problem in which one shapes the channel-induced transformations such that task-relevant features become available to the regressor. The PTM formalism allows one to identify the classical representation of a QELM and thereby guide its design towards a given training objective. As a specific application, we focus on learning nonlinear dynamical systems and show that a QELM trained on such trajectories learns a surrogate-approximation to the underlying flow map.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "quant-ph",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18377v1",
        "pdf": "https://arxiv.org/pdf/2602.18377v1"
      },
      "arxiv_id": "2602.18377v1",
      "comment": "34 pages, 12 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18374v1",
      "title": "Zero-shot Interactive Perception",
      "authors": [
        "Venkatesh Sripada",
        "Frank Guerin",
        "Amir Ghalamzan"
      ],
      "abstract": "Interactive perception (IP) enables robots to extract hidden information in their workspace and execute manipulation plans by physically interacting with objects and altering the state of the environment -- crucial for resolving occlusions and ambiguity in complex, partially observable scenarios. We present Zero-Shot IP (ZS-IP), a novel framework that couples multi-strategy manipulation (pushing and grasping) with a memory-driven Vision Language Model (VLM) to guide robotic interactions and resolve semantic queries. ZS-IP integrates three key components: (1) an Enhanced Observation (EO) module that augments the VLM's visual perception with both conventional keypoints and our proposed pushlines -- a novel 2D visual augmentation tailored to pushing actions, (2) a memory-guided action module that reinforces semantic reasoning through context lookup, and (3) a robotic controller that executes pushing, pulling, or grasping based on VLM output. Unlike grid-based augmentations optimized for pick-and-place, pushlines capture affordances for contact-rich actions, substantially improving pushing performance. We evaluate ZS-IP on a 7-DOF Franka Panda arm across diverse scenes with varying occlusions and task complexities. Our experiments demonstrate that ZS-IP outperforms passive and viewpoint-based perception techniques such as Mark-Based Visual Prompting (MOKA), particularly in pushing tasks, while preserving the integrity of non-target elements.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18374v1",
        "pdf": "https://arxiv.org/pdf/2602.18374v1"
      },
      "arxiv_id": "2602.18374v1",
      "comment": "Original manuscript submitted on April 24, 2025. Timestamped and publicly available on OpenReview: https://openreview.net/forum?id=7MhpFcr5Nx",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18372v1",
      "title": "\"How Do I ...?\": Procedural Questions Predominate Student-LLM Chatbot Conversations",
      "authors": [
        "Alexandra Neagu",
        "Marcus Messer",
        "Peter Johnson",
        "Rhodri Nelson"
      ],
      "abstract": "Providing scaffolding through educational chatbots built on Large Language Models (LLM) has potential risks and benefits that remain an open area of research. When students navigate impasses, they ask for help by formulating impasse-driven questions. Within interactions with LLM chatbots, such questions shape the user prompts and drive the pedagogical effectiveness of the chatbot's response. This paper focuses on such student questions from two datasets of distinct learning contexts: formative self-study, and summative assessed coursework. We analysed 6,113 messages from both learning contexts, using 11 different LLMs and three human raters to classify student questions using four existing schemas. On the feasibility of using LLMs as raters, results showed moderate-to-good inter-rater reliability, with higher consistency than human raters. The data showed that 'procedural' questions predominated in both learning contexts, but more so when students prepare for summative assessment. These results provide a basis on which to use LLMs for classification of student questions. However, we identify clear limitations in both the ability to classify with schemas and the value of doing so: schemas are limited and thus struggle to accommodate the semantic richness of composite prompts, offering only partial understanding the wider risks and benefits of chatbot integration. In the future, we recommend an analysis approach that captures the nuanced, multi-turn nature of conversation, for example, by applying methods from conversation analysis in discursive psychology.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18372v1",
        "pdf": "https://arxiv.org/pdf/2602.18372v1"
      },
      "arxiv_id": "2602.18372v1",
      "comment": "14 pages, 2 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18364v1",
      "title": "Quantum Maximum Likelihood Prediction via Hilbert Space Embeddings",
      "authors": [
        "Sreejith Sreekumar",
        "Nir Weinberger"
      ],
      "abstract": "Recent works have proposed various explanations for the ability of modern large language models (LLMs) to perform in-context prediction. We propose an alternative conceptual viewpoint from an information-geometric and statistical perspective. Motivated by Bach[2023], we model training as learning an embedding of probability distributions into the space of quantum density operators, and in-context learning as maximum-likelihood prediction over a specified class of quantum models. We provide an interpretation of this predictor in terms of quantum reverse information projection and quantum Pythagorean theorem when the class of quantum models is sufficiently expressive. We further derive non-asymptotic performance guarantees in terms of convergence rates and concentration inequalities, both in trace norm and quantum relative entropy. Our approach provides a unified framework to handle both classical and quantum LLMs.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.IT",
        "cs.LG",
        "quant-ph",
        "stat.ML"
      ],
      "primary_category": "cs.IT",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18364v1",
        "pdf": "https://arxiv.org/pdf/2602.18364v1"
      },
      "arxiv_id": "2602.18364v1",
      "comment": "32+4 pages, 1 figure",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18351v1",
      "title": "Validating Political Position Predictions of Arguments",
      "authors": [
        "Jordan Robinson",
        "Angus R. Williams",
        "Katie Atkinson",
        "Anthony G. Cohn"
      ],
      "abstract": "Real-world knowledge representation often requires capturing subjective, continuous attributes -- such as political positions -- that conflict with pairwise validation, the widely accepted gold standard for human evaluation. We address this challenge through a dual-scale validation framework applied to political stance prediction in argumentative discourse, combining pointwise and pairwise human annotation. Using 22 language models, we construct a large-scale knowledge base of political position predictions for 23,228 arguments drawn from 30 debates that appeared on the UK politicial television programme \\textit{Question Time}. Pointwise evaluation shows moderate human-model agreement (Krippendorff's $α=0.578$), reflecting intrinsic subjectivity, while pairwise validation reveals substantially stronger alignment between human- and model-derived rankings ($α=0.86$ for the best model). This work contributes: (i) a practical validation methodology for subjective continuous knowledge that balances scalability with reliability; (ii) a validated structured argumentation knowledge base enabling graph-based reasoning and retrieval-augmented generation in political domains; and (iii) evidence that ordinal structure can be extracted from pointwise language models predictions from inherently subjective real-world discourse, advancing knowledge representation capabilities for domains where traditional symbolic or categorical approaches are insufficient.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18351v1",
        "pdf": "https://arxiv.org/pdf/2602.18351v1"
      },
      "arxiv_id": "2602.18351v1",
      "comment": "13 pages, 6 figures, 6 tables. Under review",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18350v1",
      "title": "Quantum-enhanced satellite image classification",
      "authors": [
        "Qi Zhang",
        "Anton Simen",
        "Carlos Flores-Garrigós",
        "Gabriel Alvarado Barrios",
        "Paolo A. Erdman",
        "Enrique Solano",
        "Aaron C. Kemp",
        "Vincent Beltrani",
        "Vedangi Pathak",
        "Hamed Mohammadbagherpoor"
      ],
      "abstract": "We demonstrate the application of a quantum feature extraction method to enhance multi-class image classification for space applications. By harnessing the dynamics of many-body spin Hamiltonians, the method generates expressive quantum features that, when combined with classical processing, lead to quantum-enhanced classification accuracy. Using a strong and well-established ResNet50 baseline, we achieved a maximum classical accuracy of 83%, which can be improved to 84% with a transfer learning approach. In contrast, applying our quantum-classical method the performance is increased to 87% accuracy, demonstrating a clear and reproducible improvement over robust classical approaches. Implemented on several of IBM's quantum processors, our hybrid quantum-classical approach delivers consistent gains of 2-3% in absolute accuracy. These results highlight the practical potential of current and near-term quantum processors in high-stakes, data-driven domains such as satellite imaging and remote sensing, while suggesting broader applicability in real-world machine learning tasks.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "quant-ph",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18350v1",
        "pdf": "https://arxiv.org/pdf/2602.18350v1"
      },
      "arxiv_id": "2602.18350v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18348v1",
      "title": "Explaining AutoClustering: Uncovering Meta-Feature Contribution in AutoML for Clustering",
      "authors": [
        "Matheus Camilo da Silva",
        "Leonardo Arrighi",
        "Ana Carolina Lorena",
        "Sylvio Barbon Junior"
      ],
      "abstract": "AutoClustering methods aim to automate unsupervised learning tasks, including algorithm selection (AS), hyperparameter optimization (HPO), and pipeline synthesis (PS), by often leveraging meta-learning over dataset meta-features. While these systems often achieve strong performance, their recommendations are often difficult to justify: the influence of dataset meta-features on algorithm and hyperparameter choices is typically not exposed, limiting reliability, bias diagnostics, and efficient meta-feature engineering. This limits reliability and diagnostic insight for further improvements. In this work, we investigate the explainability of the meta-models in AutoClustering. We first review 22 existing methods and organize their meta-features into a structured taxonomy. We then apply a global explainability technique (i.e., Decision Predicate Graphs) to assess feature importance within meta-models from selected frameworks. Finally, we use local explainability tools such as SHAP (SHapley Additive exPlanations) to analyse specific clustering decisions. Our findings highlight consistent patterns in meta-feature relevance, identify structural weaknesses in current meta-learning strategies that can distort recommendations, and provide actionable guidance for more interpretable Automated Machine Learning (AutoML) design. This study therefore offers a practical foundation for increasing decision transparency in unsupervised learning automation.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18348v1",
        "pdf": "https://arxiv.org/pdf/2602.18348v1"
      },
      "arxiv_id": "2602.18348v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18346v1",
      "title": "Vichara: Appellate Judgment Prediction and Explanation for the Indian Judicial System",
      "authors": [
        "Pavithra PM Nair",
        "Preethu Rose Anish"
      ],
      "abstract": "In jurisdictions like India, where courts face an extensive backlog of cases, artificial intelligence offers transformative potential for legal judgment prediction. A critical subset of this backlog comprises appellate cases, which are formal decisions issued by higher courts reviewing the rulings of lower courts. To this end, we present Vichara, a novel framework tailored to the Indian judicial system that predicts and explains appellate judgments. Vichara processes English-language appellate case proceeding documents and decomposes them into decision points. Decision points are discrete legal determinations that encapsulate the legal issue, deciding authority, outcome, reasoning, and temporal context. The structured representation isolates the core determinations and their context, enabling accurate predictions and interpretable explanations. Vichara's explanations follow a structured format inspired by the IRAC (Issue-Rule-Application-Conclusion) framework and adapted for Indian legal reasoning. This enhances interpretability, allowing legal professionals to assess the soundness of predictions efficiently. We evaluate Vichara on two datasets, PredEx and the expert-annotated subset of the Indian Legal Documents Corpus (ILDC_expert), using four large language models: GPT-4o mini, Llama-3.1-8B, Mistral-7B, and Qwen2.5-7B. Vichara surpasses existing judgment prediction benchmarks on both datasets, with GPT-4o mini achieving the highest performance (F1: 81.5 on PredEx, 80.3 on ILDC_expert), followed by Llama-3.1-8B. Human evaluation of the generated explanations across Clarity, Linking, and Usefulness metrics highlights GPT-4o mini's superior interpretability.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18346v1",
        "pdf": "https://arxiv.org/pdf/2602.18346v1"
      },
      "arxiv_id": "2602.18346v1",
      "comment": "",
      "journal_ref": "AI and Law @ AAAI 2026",
      "has_code": false
    },
    {
      "id": "2602.18333v1",
      "title": "On the \"Induction Bias\" in Sequence Models",
      "authors": [
        "M. Reza Ebrahimi",
        "Michaël Defferrard",
        "Sunny Panchal",
        "Roland Memisevic"
      ],
      "abstract": "Despite the remarkable practical success of transformer-based language models, recent work has raised concerns about their ability to perform state tracking. In particular, a growing body of literature has shown this limitation primarily through failures in out-of-distribution (OOD) generalization, such as length extrapolation. In this work, we shift attention to the in-distribution implications of these limitations. We conduct a large-scale experimental study of the data efficiency of transformers and recurrent neural networks (RNNs) across multiple supervision regimes. We find that the amount of training data required by transformers grows much more rapidly with state-space size and sequence length than for RNNs. Furthermore, we analyze the extent to which learned state-tracking mechanisms are shared across different sequence lengths. We show that transformers exhibit negligible or even detrimental weight sharing across lengths, indicating that they learn length-specific solutions in isolation. In contrast, recurrent models exhibit effective amortized learning by sharing weights across lengths, allowing data from one sequence length to improve performance on others. Together, these results demonstrate that state tracking remains a fundamental challenge for transformers, even when training and evaluation distributions match.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18333v1",
        "pdf": "https://arxiv.org/pdf/2602.18333v1"
      },
      "arxiv_id": "2602.18333v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18329v1",
      "title": "G-LoG Bi-filtration for Medical Image Classification",
      "authors": [
        "Qingsong Wang",
        "Jiaxing He",
        "Bingzhe Hou",
        "Tieru Wu",
        "Yang Cao",
        "Cailing Yao"
      ],
      "abstract": "Building practical filtrations on objects to detect topological and geometric features is an important task in the field of Topological Data Analysis (TDA). In this paper, leveraging the ability of the Laplacian of Gaussian operator to enhance the boundaries of medical images, we define the G-LoG (Gaussian-Laplacian of Gaussian) bi-filtration to generate the features more suitable for multi-parameter persistence module. By modeling volumetric images as bounded functions, then we prove the interleaving distance on the persistence modules obtained from our bi-filtrations on the bounded functions is stable with respect to the maximum norm of the bounded functions. Finally, we conduct experiments on the MedMNIST dataset, comparing our bi-filtration against single-parameter filtration and the established deep learning baselines, including Google AutoML Vision, ResNet, AutoKeras and auto-sklearn. Experiments results demonstrate that our bi-filtration significantly outperforms single-parameter filtration. Notably, a simple Multi-Layer Perceptron (MLP) trained on the topological features generated by our bi-filtration achieves performance comparable to complex deep learning models trained on the original dataset.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.CV",
        "math.AT"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18329v1",
        "pdf": "https://arxiv.org/pdf/2602.18329v1"
      },
      "arxiv_id": "2602.18329v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18322v1",
      "title": "Unifying Color and Lightness Correction with View-Adaptive Curve Adjustment for Robust 3D Novel View Synthesis",
      "authors": [
        "Ziteng Cui",
        "Shuhong Liu",
        "Xiaoyu Dong",
        "Xuangeng Chu",
        "Lin Gu",
        "Ming-Hsuan Yang",
        "Tatsuya Harada"
      ],
      "abstract": "High-quality image acquisition in real-world environments remains challenging due to complex illumination variations and inherent limitations of camera imaging pipelines. These issues are exacerbated in multi-view capture, where differences in lighting, sensor responses, and image signal processor (ISP) configurations introduce photometric and chromatic inconsistencies that violate the assumptions of photometric consistency underlying modern 3D novel view synthesis (NVS) methods, including Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS), leading to degraded reconstruction and rendering quality. We propose Luminance-GS++, a 3DGS-based framework for robust NVS under diverse illumination conditions. Our method combines a globally view-adaptive lightness adjustment with a local pixel-wise residual refinement for precise color correction. We further design unsupervised objectives that jointly enforce lightness correction and multi-view geometric and photometric consistency. Extensive experiments demonstrate state-of-the-art performance across challenging scenarios, including low-light, overexposure, and complex luminance and chromatic variations. Unlike prior approaches that modify the underlying representation, our method preserves the explicit 3DGS formulation, improving reconstruction fidelity while maintaining real-time rendering efficiency.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18322v1",
        "pdf": "https://arxiv.org/pdf/2602.18322v1"
      },
      "arxiv_id": "2602.18322v1",
      "comment": "Journal extension version of CVPR 2025 paper: arXiv:2504.01503",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18319v1",
      "title": "Robo-Saber: Generating and Simulating Virtual Reality Players",
      "authors": [
        "Nam Hee Kim",
        "Jingjing May Liu",
        "Jaakko Lehtinen",
        "Perttu Hämäläinen",
        "James F. O'Brien",
        "Xue Bin Peng"
      ],
      "abstract": "We present the first motion generation system for playtesting virtual reality (VR) games. Our player model generates VR headset and handheld controller movements from in-game object arrangements, guided by style exemplars and aligned to maximize simulated gameplay score. We train on the large BOXRR-23 dataset and apply our framework on the popular VR game Beat Saber. The resulting model Robo-Saber produces skilled gameplay and captures diverse player behaviors, mirroring the skill levels and movement patterns specified by input style exemplars. Robo-Saber demonstrates promise in synthesizing rich gameplay data for predictive applications and enabling a physics-based whole-body VR playtesting agent.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.GR",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18319v1",
        "pdf": "https://arxiv.org/pdf/2602.18319v1"
      },
      "arxiv_id": "2602.18319v1",
      "comment": "13 pages, 15 figures. Accepted to Eurographics 2026. Project page: https://robo-saber.github.io/",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2602.18314v1",
      "title": "Diff2DGS: Reliable Reconstruction of Occluded Surgical Scenes via 2D Gaussian Splatting",
      "authors": [
        "Tianyi Song",
        "Danail Stoyanov",
        "Evangelos Mazomenos",
        "Francisco Vasconcelos"
      ],
      "abstract": "Real-time reconstruction of deformable surgical scenes is vital for advancing robotic surgery, improving surgeon guidance, and enabling automation. Recent methods achieve dense reconstructions from da Vinci robotic surgery videos, with Gaussian Splatting (GS) offering real-time performance via graphics acceleration. However, reconstruction quality in occluded regions remains limited, and depth accuracy has not been fully assessed, as benchmarks like EndoNeRF and StereoMIS lack 3D ground truth. We propose Diff2DGS, a novel two-stage framework for reliable 3D reconstruction of occluded surgical scenes. In the first stage, a diffusion-based video module with temporal priors inpaints tissue occluded by instruments with high spatial-temporal consistency. In the second stage, we adapt 2D Gaussian Splatting (2DGS) with a Learnable Deformation Model (LDM) to capture dynamic tissue deformation and anatomical geometry. We also extend evaluation beyond prior image-quality metrics by performing quantitative depth accuracy analysis on the SCARED dataset. Diff2DGS outperforms state-of-the-art approaches in both appearance and geometry, reaching 38.02 dB PSNR on EndoNeRF and 34.40 dB on StereoMIS. Furthermore, our experiments demonstrate that optimizing for image quality alone does not necessarily translate into optimal 3D reconstruction accuracy. To address this, we further optimize the depth quality of the reconstructed 3D results, ensuring more faithful geometry in addition to high-fidelity appearance.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.CV",
        "cs.GR",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18314v1",
        "pdf": "https://arxiv.org/pdf/2602.18314v1"
      },
      "arxiv_id": "2602.18314v1",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18313v1",
      "title": "Clapeyron Neural Networks for Single-Species Vapor-Liquid Equilibria",
      "authors": [
        "Jan Pavšek",
        "Alexander Mitsos",
        "Elvis J. Sim",
        "Jan G. Rittig"
      ],
      "abstract": "Machine learning (ML) approaches have shown promising results for predicting molecular properties relevant for chemical process design. However, they are often limited by scarce experimental property data and lack thermodynamic consistency. As such, thermodynamics-informed ML, i.e., incorporating thermodynamic relations into the loss function as regularization term for training, has been proposed. We herein transfer the concept of thermodynamics-informed graph neural networks (GNNs) from the Gibbs-Duhem to the Clapeyron equation, predicting several pure component properties in a multi-task manner, namely: vapor pressure, liquid molar volume, vapor molar volume and enthalpy of vaporization. We find improved prediction accuracy of the Clapeyron-GNN compared to the single-task learning setting, and improved approximation of the Clapeyron equation compared to the purely data-driven multi-task learning setting. In fact, we observe the largest improvement in prediction accuracy for the properties with the lowest availability of data, making our model promising for practical application in data scarce scenarios of chemical engineering practice.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "physics.chem-ph",
        "cs.LG"
      ],
      "primary_category": "physics.chem-ph",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18313v1",
        "pdf": "https://arxiv.org/pdf/2602.18313v1"
      },
      "arxiv_id": "2602.18313v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18309v1",
      "title": "Multi-Level Conditioning by Pairing Localized Text and Sketch for Fashion Image Generation",
      "authors": [
        "Ziyue Liu",
        "Davide Talon",
        "Federico Girella",
        "Zanxi Ruan",
        "Mattia Mondo",
        "Loris Bazzani",
        "Yiming Wang",
        "Marco Cristani"
      ],
      "abstract": "Sketches offer designers a concise yet expressive medium for early-stage fashion ideation by specifying structure, silhouette, and spatial relationships, while textual descriptions complement sketches to convey material, color, and stylistic details. Effectively combining textual and visual modalities requires adherence to the sketch visual structure when leveraging the guidance of localized attributes from text. We present LOcalized Text and Sketch with multi-level guidance (LOTS), a framework that enhances fashion image generation by combining global sketch guidance with multiple localized sketch-text pairs. LOTS employs a Multi-level Conditioning Stage to independently encode local features within a shared latent space while maintaining global structural coordination. Then, the Diffusion Pair Guidance stage integrates both local and global conditioning via attention-based guidance within the diffusion model's multi-step denoising process. To validate our method, we develop Sketchy, the first fashion dataset where multiple text-sketch pairs are provided per image. Sketchy provides high-quality, clean sketches with a professional look and consistent structure. To assess robustness beyond this setting, we also include an \"in the wild\" split with non-expert sketches, featuring higher variability and imperfections. Experiments demonstrate that our method strengthens global structural adherence while leveraging richer localized semantic guidance, achieving improvement over state-of-the-art. The dataset, platform, and code are publicly available.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18309v1",
        "pdf": "https://arxiv.org/pdf/2602.18309v1"
      },
      "arxiv_id": "2602.18309v1",
      "comment": "Project page: https://intelligolabs.github.io/lots/",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2602.18308v1",
      "title": "JPmHC Dynamical Isometry via Orthogonal Hyper-Connections",
      "authors": [
        "Biswa Sengupta",
        "Jinhua Wang",
        "Leo Brunswic"
      ],
      "abstract": "Recent advances in deep learning, exemplified by Hyper-Connections (HC), have expanded the residual connection paradigm by introducing wider residual streams and diverse connectivity patterns. While these innovations yield significant performance gains, they compromise the identity mapping property of residual connections, leading to training instability, limited scalability, and increased memory overhead. To address these challenges, we propose JPmHC (Jacobian-spectrum Preserving manifold-constrained Hyper-Connections), a framework that replaces identity skips with a trainable linear mixer acting on n parallel streams while explicitly controlling gradient conditioning. By constraining the mixer M on operator-norm-bounded manifolds (e.g., bistochastic, Stiefel, Grassmann), JPmHC prevents gradient pathologies and enhances stability. JPmHC introduces three key contributions: (i) a free-probability analysis that predicts Jacobian spectra for structured skips, providing actionable design rules for mixer selection; (ii) memory-efficient implicit differentiation for fixed-point projections, reducing activation memory and synchronization overhead; and (iii) a Stiefel-constrained mixer via Cayley transforms, ensuring orthogonality without post-hoc normalization. Empirical evaluations on ARC-AGI demonstrate that JPmHC achieves faster convergence, higher accuracy, and lower computational cost compared to bistochastic baselines. As a flexible and scalable extension of HC, JPmHC advances spectrum-aware, stable, and efficient deep learning, offering insights into topological architecture design and foundational model evolution.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18308v1",
        "pdf": "https://arxiv.org/pdf/2602.18308v1"
      },
      "arxiv_id": "2602.18308v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18307v1",
      "title": "VeriSoftBench: Repository-Scale Formal Verification Benchmarks for Lean",
      "authors": [
        "Yutong Xin",
        "Qiaochu Chen",
        "Greg Durrett",
        "Işil Dillig"
      ],
      "abstract": "Large language models have achieved striking results in interactive theorem proving, particularly in Lean. However, most benchmarks for LLM-based proof automation are drawn from mathematics in the Mathlib ecosystem, whereas proofs in software verification are developed inside definition-rich codebases with substantial project-specific libraries. We introduce VeriSoftBench, a benchmark of 500 Lean 4 proof obligations drawn from open-source formal-methods developments and packaged to preserve realistic repository context and cross-file dependencies. Our evaluation of frontier LLMs and specialized provers yields three observations. First, provers tuned for Mathlib-style mathematics transfer poorly to this repository-centric setting. Second, success is strongly correlated with transitive repository dependence: tasks whose proofs draw on large, multi-hop dependency closures are less likely to be solved. Third, providing curated context restricted to a proof's dependency closure improves performance relative to exposing the full repository, but nevertheless leaves substantial room for improvement. Our benchmark and evaluation suite are released at https://github.com/utopia-group/VeriSoftBench.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.SE",
        "cs.CL",
        "cs.LG",
        "cs.PL"
      ],
      "primary_category": "cs.SE",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18307v1",
        "pdf": "https://arxiv.org/pdf/2602.18307v1"
      },
      "arxiv_id": "2602.18307v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18301v1",
      "title": "On the Semantic and Syntactic Information Encoded in Proto-Tokens for One-Step Text Reconstruction",
      "authors": [
        "Ivan Bondarenko",
        "Egor Palkin",
        "Fedor Tikunov"
      ],
      "abstract": "Autoregressive large language models (LLMs) generate text token-by-token, requiring n forward passes to produce a sequence of length n. Recent work, Exploring the Latent Capacity of LLMs for One-Step Text Reconstruction (Mezentsev and Oseledets), shows that frozen LLMs can reconstruct hundreds of tokens from only two learned proto-tokens in a single forward pass, suggesting a path beyond the autoregressive paradigm. In this paper, we study what information these proto-tokens encode and how they behave under reconstruction and controlled constraints. We perform a series of experiments aimed at disentangling semantic and syntactic content in the two proto-tokens, analyzing stability properties of the e-token, and visualizing attention patterns to the e-token during reconstruction. Finally, we test two regularization schemes for \"imposing\" semantic structure on the e-token using teacher embeddings, including an anchor-based loss and a relational distillation objective. Our results indicate that the m-token tends to capture semantic information more strongly than the e-token under standard optimization; anchor-based constraints trade off sharply with reconstruction accuracy; and relational distillation can transfer batch-level semantic relations into the proto-token space without sacrificing reconstruction quality, supporting the feasibility of future non-autoregressive seq2seq systems that predict proto-tokens as an intermediate representation.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18301v1",
        "pdf": "https://arxiv.org/pdf/2602.18301v1"
      },
      "arxiv_id": "2602.18301v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18297v1",
      "title": "Analyzing and Improving Chain-of-Thought Monitorability Through Information Theory",
      "authors": [
        "Usman Anwar",
        "Tim Bakker",
        "Dana Kianfar",
        "Cristina Pinneri",
        "Christos Louizos"
      ],
      "abstract": "Chain-of-thought (CoT) monitors are LLM-based systems that analyze reasoning traces to detect when outputs may exhibit attributes of interest, such as test-hacking behavior during code generation. In this paper, we use information-theoretic analysis to show that non-zero mutual information between CoT and output is a necessary but not sufficient condition for CoT monitorability. We identify two sources of approximation error that may undermine the performance of CoT monitors in practice: information gap, which measures the extent to which the monitor can extract the information available in CoT, and elicitation error, which measures the extent to which the monitor approximates the optimal monitoring function. We further demonstrate that CoT monitorability can be systematically improved through targeted training objectives. To this end, we propose two complementary approaches: (a) an oracle-based method that directly rewards the monitored model for producing CoTs that maximize monitor accuracy, and (b) a more practical, label-free approach that maximizes conditional mutual information between outputs and CoTs. Across multiple different environments, we show both methods significantly improve monitor accuracy while preventing CoT degeneration even when training against a monitor, thereby mitigating reward hacking when the task reward is imperfectly specified.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.IT"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18297v1",
        "pdf": "https://arxiv.org/pdf/2602.18297v1"
      },
      "arxiv_id": "2602.18297v1",
      "comment": "First two authors contributed equally",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18292v1",
      "title": "Decoding as Optimisation on the Probability Simplex: From Top-K to Top-P (Nucleus) to Best-of-K Samplers",
      "authors": [
        "Xiaotong Ji",
        "Rasul Tutunov",
        "Matthieu Zimmer",
        "Haitham Bou-Ammar"
      ],
      "abstract": "Decoding sits between a language model and everything we do with it, yet it is still treated as a heuristic knob-tuning exercise. We argue decoding should be understood as a principled optimisation layer: at each token, we solve a regularised problem over the probability simplex that trades off model score against structural preferences and constraints. This single template recovers greedy decoding, Softmax sampling, Top-K, Top-P, and Sparsemax-style sparsity as special cases, and explains their common structure through optimality conditions. More importantly, the framework makes it easy to invent new decoders without folklore. We demonstrate this by designing Best-of-K (BoK), a KL-anchored coverage objective aimed at multi-sample pipelines (self-consistency, reranking, verifier selection). BoK targets the probability of covering good alternatives within a fixed K-sample budget and improves empirical performance. We show that such samples can improve accuracy by, for example, +18.6% for Qwen2.5-Math-7B on MATH500 at high sampling temperatures.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18292v1",
        "pdf": "https://arxiv.org/pdf/2602.18292v1"
      },
      "arxiv_id": "2602.18292v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18291v1",
      "title": "Diffusing to Coordinate: Efficient Online Multi-Agent Diffusion Policies",
      "authors": [
        "Zhuoran Li",
        "Hai Zhong",
        "Xun Wang",
        "Qingxin Xia",
        "Lihua Zhang",
        "Longbo Huang"
      ],
      "abstract": "Online Multi-Agent Reinforcement Learning (MARL) is a prominent framework for efficient agent coordination. Crucially, enhancing policy expressiveness is pivotal for achieving superior performance. Diffusion-based generative models are well-positioned to meet this demand, having demonstrated remarkable expressiveness and multimodal representation in image generation and offline settings. Yet, their potential in online MARL remains largely under-explored. A major obstacle is that the intractable likelihoods of diffusion models impede entropy-based exploration and coordination. To tackle this challenge, we propose among the first \\underline{O}nline off-policy \\underline{MA}RL framework using \\underline{D}iffusion policies (\\textbf{OMAD}) to orchestrate coordination. Our key innovation is a relaxed policy objective that maximizes scaled joint entropy, facilitating effective exploration without relying on tractable likelihood. Complementing this, within the centralized training with decentralized execution (CTDE) paradigm, we employ a joint distributional value function to optimize decentralized diffusion policies. It leverages tractable entropy-augmented targets to guide the simultaneous updates of diffusion policies, thereby ensuring stable coordination. Extensive evaluations on MPE and MAMuJoCo establish our method as the new state-of-the-art across $10$ diverse tasks, demonstrating a remarkable $2.5\\times$ to $5\\times$ improvement in sample efficiency.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18291v1",
        "pdf": "https://arxiv.org/pdf/2602.18291v1"
      },
      "arxiv_id": "2602.18291v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18283v1",
      "title": "HyTRec: A Hybrid Temporal-Aware Attention Architecture for Long Behavior Sequential Recommendation",
      "authors": [
        "Lei Xin",
        "Yuhao Zheng",
        "Ke Cheng",
        "Changjiang Jiang",
        "Zifan Zhang",
        "Fanhu Zeng"
      ],
      "abstract": "Modeling long sequences of user behaviors has emerged as a critical frontier in generative recommendation. However, existing solutions face a dilemma: linear attention mechanisms achieve efficiency at the cost of retrieval precision due to limited state capacity, while softmax attention suffers from prohibitive computational overhead. To address this challenge, we propose HyTRec, a model featuring a Hybrid Attention architecture that explicitly decouples long-term stable preferences from short-term intent spikes. By assigning massive historical sequences to a linear attention branch and reserving a specialized softmax attention branch for recent interactions, our approach restores precise retrieval capabilities within industrial-scale contexts involving ten thousand interactions. To mitigate the lag in capturing rapid interest drifts within the linear layers, we furthermore design Temporal-Aware Delta Network (TADN) to dynamically upweight fresh behavioral signals while effectively suppressing historical noise. Empirical results on industrial-scale datasets confirm the superiority that our model maintains linear inference speed and outperforms strong baselines, notably delivering over 8% improvement in Hit Rate for users with ultra-long sequences with great efficiency.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18283v1",
        "pdf": "https://arxiv.org/pdf/2602.18283v1"
      },
      "arxiv_id": "2602.18283v1",
      "comment": "Preprint",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18282v1",
      "title": "DEIG: Detail-Enhanced Instance Generation with Fine-Grained Semantic Control",
      "authors": [
        "Shiyan Du",
        "Conghan Yue",
        "Xinyu Cheng",
        "Dongyu Zhang"
      ],
      "abstract": "Multi-Instance Generation has advanced significantly in spatial placement and attribute binding. However, existing approaches still face challenges in fine-grained semantic understanding, particularly when dealing with complex textual descriptions. To overcome these limitations, we propose DEIG, a novel framework for fine-grained and controllable multi-instance generation. DEIG integrates an Instance Detail Extractor (IDE) that transforms text encoder embeddings into compact, instance-aware representations, and a Detail Fusion Module (DFM) that applies instance-based masked attention to prevent attribute leakage across instances. These components enable DEIG to generate visually coherent multi-instance scenes that precisely match rich, localized textual descriptions. To support fine-grained supervision, we construct a high-quality dataset with detailed, compositional instance captions generated by VLMs. We also introduce DEIG-Bench, a new benchmark with region-level annotations and multi-attribute prompts for both humans and objects. Experiments demonstrate that DEIG consistently outperforms existing approaches across multiple benchmarks in spatial consistency, semantic accuracy, and compositional generalization. Moreover, DEIG functions as a plug-and-play module, making it easily integrable into standard diffusion-based pipelines.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18282v1",
        "pdf": "https://arxiv.org/pdf/2602.18282v1"
      },
      "arxiv_id": "2602.18282v1",
      "comment": "Accepted by AAAI 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18277v1",
      "title": "PRISM: Parallel Reward Integration with Symmetry for MORL",
      "authors": [
        "Finn van der Knaap",
        "Kejiang Qian",
        "Zheng Xu",
        "Fengxiang He"
      ],
      "abstract": "This work studies heterogeneous Multi-Objective Reinforcement Learning (MORL), where objectives can differ sharply in temporal frequency. Such heterogeneity allows dense objectives to dominate learning, while sparse long-horizon rewards receive weak credit assignment, leading to poor sample efficiency. We propose a Parallel Reward Integration with Symmetry (PRISM) algorithm that enforces reflectional symmetry as an inductive bias in aligning reward channels. PRISM introduces ReSymNet, a theory-motivated model that reconciles temporal-frequency mismatches across objectives, using residual blocks to learn a scaled opportunity value that accelerates exploration while preserving the optimal policy. We also propose SymReg, a reflectional equivariance regulariser that enforces agent mirroring and constrains policy search to a reflection-equivariant subspace. This restriction provably reduces hypothesis complexity and improves generalisation. Across MuJoCo benchmarks, PRISM consistently outperforms both a sparse-reward baseline and an oracle trained with full dense rewards, improving Pareto coverage and distributional balance: it achieves hypervolume gains exceeding 100\\% over the baseline and up to 32\\% over the oracle. The code is at \\href{https://github.com/EVIEHub/PRISM}{https://github.com/EVIEHub/PRISM}.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18277v1",
        "pdf": "https://arxiv.org/pdf/2602.18277v1"
      },
      "arxiv_id": "2602.18277v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18266v1",
      "title": "A Probabilistic Framework for LLM-Based Model Discovery",
      "authors": [
        "Stefan Wahl",
        "Raphaela Schenk",
        "Ali Farnoud",
        "Jakob H. Macke",
        "Daniel Gedon"
      ],
      "abstract": "Automated methods for discovering mechanistic simulator models from observational data offer a promising path toward accelerating scientific progress. Such methods often take the form of agentic-style iterative workflows that repeatedly propose and revise candidate models by imitating human discovery processes. However, existing LLM-based approaches typically implement such workflows via hand-crafted heuristic procedures, without an explicit probabilistic formulation. We recast model discovery as probabilistic inference, i.e., as sampling from an unknown distribution over mechanistic models capable of explaining the data. This perspective provides a unified way to reason about model proposal, refinement, and selection within a single inference framework. As a concrete instantiation of this view, we introduce ModelSMC, an algorithm based on Sequential Monte Carlo sampling. ModelSMC represents candidate models as particles which are iteratively proposed and refined by an LLM, and weighted using likelihood-based criteria. Experiments on real-world scientific systems illustrate that this formulation discovers models with interpretable mechanisms and improves posterior predictive checks. More broadly, this perspective provides a probabilistic lens for understanding and developing LLM-based approaches to model discovery.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18266v1",
        "pdf": "https://arxiv.org/pdf/2602.18266v1"
      },
      "arxiv_id": "2602.18266v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18262v1",
      "title": "Simplifying Outcomes of Language Model Component Analyses with ELIA",
      "authors": [
        "Aaron Louis Eidt",
        "Nils Feldhus"
      ],
      "abstract": "While mechanistic interpretability has developed powerful tools to analyze the internal workings of Large Language Models (LLMs), their complexity has created an accessibility gap, limiting their use to specialists. We address this challenge by designing, building, and evaluating ELIA (Explainable Language Interpretability Analysis), an interactive web application that simplifies the outcomes of various language model component analyses for a broader audience. The system integrates three key techniques -- Attribution Analysis, Function Vector Analysis, and Circuit Tracing -- and introduces a novel methodology: using a vision-language model to automatically generate natural language explanations (NLEs) for the complex visualizations produced by these methods. The effectiveness of this approach was empirically validated through a mixed-methods user study, which revealed a clear preference for interactive, explorable interfaces over simpler, static visualizations. A key finding was that the AI-powered explanations helped bridge the knowledge gap for non-experts; a statistical analysis showed no significant correlation between a user's prior LLM experience and their comprehension scores, suggesting that the system reduced barriers to comprehension across experience levels. We conclude that an AI system can indeed simplify complex model analyses, but its true power is unlocked when paired with thoughtful, user-centered design that prioritizes interactivity, specificity, and narrative guidance.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18262v1",
        "pdf": "https://arxiv.org/pdf/2602.18262v1"
      },
      "arxiv_id": "2602.18262v1",
      "comment": "EACL 2026 System Demonstrations. GitHub: https://github.com/aaron0eidt/ELIA",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2602.18258v1",
      "title": "RoEL: Robust Event-based 3D Line Reconstruction",
      "authors": [
        "Gwangtak Bae",
        "Jaeho Shin",
        "Seunggu Kang",
        "Junho Kim",
        "Ayoung Kim",
        "Young Min Kim"
      ],
      "abstract": "Event cameras in motion tend to detect object boundaries or texture edges, which produce lines of brightness changes, especially in man-made environments. While lines can constitute a robust intermediate representation that is consistently observed, the sparse nature of lines may lead to drastic deterioration with minor estimation errors. Only a few previous works, often accompanied by additional sensors, utilize lines to compensate for the severe domain discrepancies of event sensors along with unpredictable noise characteristics. We propose a method that can stably extract tracks of varying appearances of lines using a clever algorithmic process that observes multiple representations from various time slices of events, compensating for potential adversaries within the event data. We then propose geometric cost functions that can refine the 3D line maps and camera poses, eliminating projective distortions and depth ambiguities. The 3D line maps are highly compact and can be equipped with our proposed cost function, which can be adapted for any observations that can detect and extract line structures or projections of them, including 3D point cloud maps or image observations. We demonstrate that our formulation is powerful enough to exhibit a significant performance boost in event-based mapping and pose refinement across diverse datasets, and can be flexibly applied to multimodal scenarios. Our results confirm that the proposed line-based formulation is a robust and effective approach for the practical deployment of event-based perceptual modules. Project page: https://gwangtak.github.io/roel/",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.RO",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18258v1",
        "pdf": "https://arxiv.org/pdf/2602.18258v1"
      },
      "arxiv_id": "2602.18258v1",
      "comment": "IEEE Transactions on Robotics (T-RO)",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18253v1",
      "title": "MEG-to-MEG Transfer Learning and Cross-Task Speech/Silence Detection with Limited Data",
      "authors": [
        "Xabier de Zuazo",
        "Vincenzo Verbeni",
        "Eva Navas",
        "Ibon Saratxaga",
        "Mathieu Bourguignon",
        "Nicola Molinaro"
      ],
      "abstract": "Data-efficient neural decoding is a central challenge for speech brain-computer interfaces. We present the first demonstration of transfer learning and cross-task decoding for MEG-based speech models spanning perception and production. We pre-train a Conformer-based model on 50 hours of single-subject listening data and fine-tune on just 5 minutes per subject across 18 participants. Transfer learning yields consistent improvements, with in-task accuracy gains of 1-4% and larger cross-task gains of up to 5-6%. Not only does pre-training improve performance within each task, but it also enables reliable cross-task decoding between perception and production. Critically, models trained on speech production decode passive listening above chance, confirming that learned representations reflect shared neural processes rather than task-specific motor activity.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18253v1",
        "pdf": "https://arxiv.org/pdf/2602.18253v1"
      },
      "arxiv_id": "2602.18253v1",
      "comment": "6 pages, 3 figures, 3 tables, submitted to Interspeech 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18252v1",
      "title": "On the Adversarial Robustness of Discrete Image Tokenizers",
      "authors": [
        "Rishika Bhagwatkar",
        "Irina Rish",
        "Nicolas Flammarion",
        "Francesco Croce"
      ],
      "abstract": "Discrete image tokenizers encode visual inputs as sequences of tokens from a finite vocabulary and are gaining popularity in multimodal systems, including encoder-only, encoder-decoder, and decoder-only models. However, unlike CLIP encoders, their vulnerability to adversarial attacks has not been explored. Ours being the first work studying this topic, we first formulate attacks that aim to perturb the features extracted by discrete tokenizers, and thus change the extracted tokens. These attacks are computationally efficient, application-agnostic, and effective across classification, multimodal retrieval, and captioning tasks. Second, to defend against this vulnerability, inspired by recent work on robust CLIP encoders, we fine-tune popular tokenizers with unsupervised adversarial training, keeping all other components frozen. While unsupervised and task-agnostic, our approach significantly improves robustness to both unsupervised and end-to-end supervised attacks and generalizes well to unseen tasks and data. Unlike supervised adversarial training, our approach can leverage unlabeled images, making it more versatile. Overall, our work highlights the critical role of tokenizer robustness in downstream tasks and presents an important step in the development of safe multimodal foundation models.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18252v1",
        "pdf": "https://arxiv.org/pdf/2602.18252v1"
      },
      "arxiv_id": "2602.18252v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18250v1",
      "title": "Variational Distributional Neuron",
      "authors": [
        "Yves Ruffenach"
      ],
      "abstract": "We propose a proof of concept for a variational distributional neuron: a compute unit formulated as a VAE brick, explicitly carrying a prior, an amortized posterior and a local ELBO. The unit is no longer a deterministic scalar but a distribution: computing is no longer about propagating values, but about contracting a continuous space of possibilities under constraints. Each neuron parameterizes a posterior, propagates a reparameterized sample and is regularized by the KL term of a local ELBO - hence, the activation is distributional. This \"contraction\" becomes testable through local constraints and can be monitored via internal measures. The amount of contextual information carried by the unit, as well as the temporal persistence of this information, are locally tuned by distinct constraints. This proposal addresses a structural tension: in sequential generation, causality is predominantly organized in the symbolic space and, even when latents exist, they often remain auxiliary, while the effective dynamics are carried by a largely deterministic decoder. In parallel, probabilistic latent models capture factors of variation and uncertainty, but that uncertainty typically remains borne by global or parametric mechanisms, while units continue to propagate scalars - hence the pivot question: if uncertainty is intrinsic to computation, why does the compute unit not carry it explicitly? We therefore draw two axes: (i) the composition of probabilistic constraints, which must be made stable, interpretable and controllable; and (ii) granularity: if inference is a negotiation of distributions under constraints, should the primitive unit remain deterministic or become distributional? We analyze \"collapse\" modes and the conditions for a \"living neuron\", then extend the contribution over time via autoregressive priors over the latent, per unit.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18250v1",
        "pdf": "https://arxiv.org/pdf/2602.18250v1"
      },
      "arxiv_id": "2602.18250v1",
      "comment": "29 pages, 7 figures. Code available at GitHub (link in paper)",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2602.18248v1",
      "title": "Neural-HSS: Hierarchical Semi-Separable Neural PDE Solver",
      "authors": [
        "Pietro Sittoni",
        "Emanuele Zangrando",
        "Angelo A. Casulli",
        "Nicola Guglielmi",
        "Francesco Tudisco"
      ],
      "abstract": "Deep learning-based methods have shown remarkable effectiveness in solving PDEs, largely due to their ability to enable fast simulations once trained. However, despite the availability of high-performance computing infrastructure, many critical applications remain constrained by the substantial computational costs associated with generating large-scale, high-quality datasets and training models. In this work, inspired by studies on the structure of Green's functions for elliptic PDEs, we introduce Neural-HSS, a parameter-efficient architecture built upon the Hierarchical Semi-Separable (HSS) matrix structure that is provably data-efficient for a broad class of PDEs. We theoretically analyze the proposed architecture, proving that it satisfies exactness properties even in very low-data regimes. We also investigate its connections with other architectural primitives, such as the Fourier neural operator layer and convolutional layers. We experimentally validate the data efficiency of Neural-HSS on the three-dimensional Poisson equation over a grid of two million points, demonstrating its superior ability to learn from data generated by elliptic PDEs in the low-data regime while outperforming baseline methods. Finally, we demonstrate its capability to learn from data arising from a broad class of PDEs in diverse domains, including electromagnetism, fluid dynamics, and biology.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.LG",
        "math.NA"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18248v1",
        "pdf": "https://arxiv.org/pdf/2602.18248v1"
      },
      "arxiv_id": "2602.18248v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18232v1",
      "title": "Thinking by Subtraction: Confidence-Driven Contrastive Decoding for LLM Reasoning",
      "authors": [
        "Lexiang Tang",
        "Weihao Gao",
        "Bingchen Zhao",
        "Lu Ma",
        "Qiao jin",
        "Bang Yang",
        "Yuexian Zou"
      ],
      "abstract": "Recent work on test-time scaling for large language model (LLM) reasoning typically assumes that allocating more inference-time computation uniformly improves correctness. However, prior studies show that reasoning uncertainty is highly localized: a small subset of low-confidence tokens disproportionately contributes to reasoning errors and unnecessary output expansion. Motivated by this observation, we propose Thinking by Subtraction, a confidence-driven contrastive decoding approach that improves reasoning reliability through targeted token-level intervention. Our method, Confidence-Driven Contrastive Decoding, detects low-confidence tokens during decoding and intervenes selectively at these positions. It constructs a contrastive reference by replacing high-confidence tokens with minimal placeholders, and refines predictions by subtracting this reference distribution at low-confidence locations. Experiments show that CCD significantly improves accuracy across mathematical reasoning benchmarks while substantially reducing output length, with minimal KV-cache overhead. As a training-free method, CCD enhances reasoning reliability through targeted low-confidence intervention without computational redundancy. Our code will be made available at: https://github.com/bolo-web/CCD.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18232v1",
        "pdf": "https://arxiv.org/pdf/2602.18232v1"
      },
      "arxiv_id": "2602.18232v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18230v1",
      "title": "[Re] Benchmarking LLM Capabilities in Negotiation through Scoreable Games",
      "authors": [
        "Jorge Carrasco Pollo",
        "Ioannis Kapetangeorgis",
        "Joshua Rosenthal",
        "John Hua Yao"
      ],
      "abstract": "Large Language Models (LLMs) demonstrate significant potential in multi-agent negotiation tasks, yet evaluation in this domain remains challenging due to a lack of robust and generalizable benchmarks. Abdelnabi et al. (2024) introduce a negotiation benchmark based on Scoreable Games, with the aim of developing a highly complex and realistic evaluation framework for LLMs. Our work investigates the reproducibility of claims in their benchmark, and provides a deeper understanding of its usability and generalizability. We replicate the original experiments on additional models, and introduce additional metrics to verify negotiation quality and evenness of evaluation. Our findings reveal that while the benchmark is indeed complex, model comparison is ambiguous, raising questions about its objectivity. Furthermore, we identify limitations in the experimental setup, particularly in information leakage detection and thoroughness of the ablation study. By examining and analyzing the behavior of a wider range of models on an extended version of the benchmark, we reveal insights that provide additional context to potential users. Our results highlight the importance of context in model-comparative evaluations.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18230v1",
        "pdf": "https://arxiv.org/pdf/2602.18230v1"
      },
      "arxiv_id": "2602.18230v1",
      "comment": "Accepted for publication at Transactions on Machine Learning Research (TMLR) and MLRC Journal Track, 2025. Code available at: https://github.com/joshrosie/FACT29",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2602.18227v1",
      "title": "Parameter-Efficient Domain Adaptation of Physics-Informed Self-Attention based GNNs for AC Power Flow Prediction",
      "authors": [
        "Redwanul Karim",
        "Changhun Kim",
        "Timon Conrad",
        "Nora Gourmelon",
        "Julian Oelhaf",
        "David Riebesel",
        "Tomás Arias-Vergara",
        "Andreas Maier",
        "Johann Jäger",
        "Siming Bayer"
      ],
      "abstract": "Accurate AC-PF prediction under domain shift is critical when models trained on medium-voltage (MV) grids are deployed on high-voltage (HV) networks. Existing physics-informed graph neural solvers typically rely on full fine-tuning for cross-regime transfer, incurring high retraining cost and offering limited control over the stability-plasticity trade-off between target-domain adaptation and source-domain retention. We study parameter-efficient domain adaptation for physics-informed self-attention based GNN, encouraging Kirchhoff-consistent behavior via a physics-based loss while restricting adaptation to low-rank updates. Specifically, we apply LoRA to attention projections with selective unfreezing of the prediction head to regulate adaptation capacity. This design yields a controllable efficiency-accuracy trade-off for physics-constrained inverse estimation under voltage-regime shift. Across multiple grid topologies, the proposed LoRA+PHead adaptation recovers near-full fine-tuning accuracy with a target-domain RMSE gap of $2.6\\times10^{-4}$ while reducing the number of trainable parameters by 85.46%. The physics-based residual remains comparable to full fine-tuning; however, relative to Full FT, LoRA+PHead reduces MV source retention by 4.7 percentage points (17.9% vs. 22.6%) under domain shift, while still enabling parameter-efficient and physically consistent AC-PF estimation.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18227v1",
        "pdf": "https://arxiv.org/pdf/2602.18227v1"
      },
      "arxiv_id": "2602.18227v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18224v1",
      "title": "SimVLA: A Simple VLA Baseline for Robotic Manipulation",
      "authors": [
        "Yuankai Luo",
        "Woping Chen",
        "Tong Liang",
        "Baiqiao Wang",
        "Zhenguo Li"
      ],
      "abstract": "Vision-Language-Action (VLA) models have emerged as a promising paradigm for general-purpose robotic manipulation, leveraging large-scale pre-training to achieve strong performance. The field has rapidly evolved with additional spatial priors and diverse architectural innovations. However, these advancements are often accompanied by varying training recipes and implementation details, which can make it challenging to disentangle the precise source of empirical gains. In this work, we introduce SimVLA, a streamlined baseline designed to establish a transparent reference point for VLA research. By strictly decoupling perception from control, using a standard vision-language backbone and a lightweight action head, and standardizing critical training dynamics, we demonstrate that a minimal design can achieve state-of-the-art performance. Despite having only 0.5B parameters, SimVLA outperforms multi-billion-parameter models on standard simulation benchmarks without robot pretraining. SimVLA also reaches on-par real-robot performance compared to pi0.5. Our results establish SimVLA as a robust, reproducible baseline that enables clear attribution of empirical gains to future architectural innovations. Website: https://frontierrobo.github.io/SimVLA",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.RO",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18224v1",
        "pdf": "https://arxiv.org/pdf/2602.18224v1"
      },
      "arxiv_id": "2602.18224v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18216v1",
      "title": "Generative Model via Quantile Assignment",
      "authors": [
        "Georgi Hrusanov",
        "Oliver Y. Chén",
        "Julien S. Bodelet"
      ],
      "abstract": "Deep Generative models (DGMs) play two key roles in modern machine learning: (i) producing new information (e.g., image synthesis) and (ii) reducing dimensionality. However, traditional architectures often rely on auxiliary networks such as encoders in Variational Autoencoders (VAEs) or discriminators in Generative Adversarial Networks (GANs), which introduce training instability, computational overhead, and risks like mode collapse. We present NeuroSQL, a new generative paradigm that eliminates the need for auxiliary networks by learning low-dimensional latent representations implicitly. NeuroSQL leverages an asymptotic approximation that expresses the latent variables as the solution to an optimal transportation problem. Specifically, NeuroSQL learns the latent variables by solving a linear assignment problem and then passes the latent information to a standalone generator. We benchmark its performance against GANs, VAEs, and a budget-matched diffusion baseline on four datasets: handwritten digits (MNIST), faces (CelebA), animal faces (AFHQ), and brain images (OASIS). Compared to VAEs, GANs, and diffusion models: (1) in terms of image quality, NeuroSQL achieves overall lower mean pixel distance between synthetic and authentic images and stronger perceptual/structural fidelity; (2) computationally, NeuroSQL requires the least training time; and (3) practically, NeuroSQL provides an effective solution for generating synthetic data with limited training samples. By embracing quantile assignment rather than an encoder, NeuroSQL provides a fast, stable, and robust way to generate synthetic data with minimal information loss.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18216v1",
        "pdf": "https://arxiv.org/pdf/2602.18216v1"
      },
      "arxiv_id": "2602.18216v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18213v1",
      "title": "Machine-learning force-field models for dynamical simulations of metallic magnets",
      "authors": [
        "Gia-Wei Chern",
        "Yunhao Fan",
        "Sheng Zhang",
        "Puhan Zhang"
      ],
      "abstract": "We review recent advances in machine learning (ML) force-field methods for Landau-Lifshitz-Gilbert (LLG) simulations of itinerant electron magnets, focusing on scalability and transferability. Built on the principle of locality, a deep neural network model is developed to efficiently and accurately predict the electron-mediated forces governing spin dynamics. Symmetry-aware descriptors constructed through a group-theoretical approach ensure rigorous incorporation of both lattice and spin-rotation symmetries. The framework is demonstrated using the prototypical s-d exchange model widely employed in spintronics. ML-enabled large-scale simulations reveal novel nonequilibrium phenomena, including anomalous coarsening of tetrahedral spin order on the triangular lattice and the freezing of phase separation dynamics in lightly hole-doped, strong-coupling square-lattice systems. These results establish ML force-field frameworks as scalable, accurate, and versatile tools for modeling nonequilibrium spin dynamics in itinerant magnets.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cond-mat.str-el",
        "cs.LG",
        "physics.comp-ph"
      ],
      "primary_category": "cond-mat.str-el",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18213v1",
        "pdf": "https://arxiv.org/pdf/2602.18213v1"
      },
      "arxiv_id": "2602.18213v1",
      "comment": "9 pages, 5 figures",
      "journal_ref": "AIP Advances 16, 025031 (2026)",
      "has_code": false
    },
    {
      "id": "2602.18201v1",
      "title": "SOMtime the World Ain$'$t Fair: Violating Fairness Using Self-Organizing Maps",
      "authors": [
        "Joseph Bingham",
        "Netanel Arussy",
        "Dvir Aran"
      ],
      "abstract": "Unsupervised representations are widely assumed to be neutral with respect to sensitive attributes when those attributes are withheld from training. We show that this assumption is false. Using SOMtime, a topology-preserving representation method based on high-capacity Self-Organizing Maps, we demonstrate that sensitive attributes such as age and income emerge as dominant latent axes in purely unsupervised embeddings, even when explicitly excluded from the input. On two large-scale real-world datasets (the World Values Survey across five countries and the Census-Income dataset), SOMtime recovers monotonic orderings aligned with withheld sensitive attributes, achieving Spearman correlations of up to 0.85, whereas PCA and UMAP typically remain below 0.23 (with a single exception reaching 0.31), and against t-SNE and autoencoders which achieve at most 0.34. Furthermore, unsupervised segmentation of SOMtime embeddings produces demographically skewed clusters, demonstrating downstream fairness risks without any supervised task. These findings establish that \\textit{fairness through unawareness} fails at the representation level for ordinal sensitive attributes and that fairness auditing must extend to unsupervised components of machine learning pipelines. We have made the code available at~ https://github.com/JosephBingham/SOMtime",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18201v1",
        "pdf": "https://arxiv.org/pdf/2602.18201v1"
      },
      "arxiv_id": "2602.18201v1",
      "comment": "10 pages, 2 figures, preprint",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18199v1",
      "title": "A Self-Supervised Approach on Motion Calibration for Enhancing Physical Plausibility in Text-to-Motion",
      "authors": [
        "Gahyeon Shim",
        "Soogeun Park",
        "Hyemin Ahn"
      ],
      "abstract": "Generating semantically aligned human motion from textual descriptions has made rapid progress, but ensuring both semantic and physical realism in motion remains a challenge. In this paper, we introduce the Distortion-aware Motion Calibrator (DMC), a post-hoc module that refines physically implausible motions (e.g., foot floating) while preserving semantic consistency with the original textual description. Rather than relying on complex physical modeling, we propose a self-supervised and data-driven approach, whereby DMC learns to obtain physically plausible motions when an intentionally distorted motion and the original textual descriptions are given as inputs. We evaluate DMC as a post-hoc module to improve motions obtained from various text-to-motion generation models and demonstrate its effectiveness in improving physical plausibility while enhancing semantic consistency. The experimental results show that DMC reduces FID score by 42.74% on T2M and 13.20% on T2M-GPT, while also achieving the highest R-Precision. When applied to high-quality models like MoMask, DMC improves the physical plausibility of motions by reducing penetration by 33.0% as well as adjusting floating artifacts closer to the ground-truth reference. These results highlight that DMC can serve as a promising post-hoc motion refinement framework for any kind of text-to-motion models by incorporating textual semantics and physical plausibility.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18199v1",
        "pdf": "https://arxiv.org/pdf/2602.18199v1"
      },
      "arxiv_id": "2602.18199v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18196v1",
      "title": "RAT+: Train Dense, Infer Sparse -- Recurrence Augmented Attention for Dilated Inference",
      "authors": [
        "Xiuying Wei",
        "Caglar Gulcehre"
      ],
      "abstract": "Structured dilated attention has an appealing inference-time efficiency knob: it reduces the FLOPs of the attention and the KV cache size by a factor of the dilation size D, while preserving long-range connectivity. However, we find a persistent failure mode of them -- sparsifying a pretrained attention model to a dilated pattern leads to severe accuracy degradation. We introduce RAT+, a dense-pretraining architecture that augments attention with full-sequence recurrence and active recurrence learning. A single RAT+ model is pretrained densely once, then flexibly switched at inference time to dilated attention (optionally with local windows) or hybrid layer/head compositions, requiring only a short 1B-token resolution adaptation rather than retraining separate sparse models. At 1.5B parameters trained on 100B tokens, RAT+ closely matches dense accuracy at 16 and drops by about 2-3 points at 64 on commonsense reasoning and LongBench tasks, respectively. Moreover, RAT+ outperforms attention when sparsifying to the top-k block attention. We further scale to 2.6B parameters and 200B tokens and observe the same trend.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18196v1",
        "pdf": "https://arxiv.org/pdf/2602.18196v1"
      },
      "arxiv_id": "2602.18196v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18195v1",
      "title": "LERD: Latent Event-Relational Dynamics for Neurodegenerative Classification",
      "authors": [
        "Hairong Chen",
        "Yicheng Feng",
        "Ziyu Jia",
        "Samir Bhatt",
        "Hengguan Huang"
      ],
      "abstract": "Alzheimer's disease (AD) alters brain electrophysiology and disrupts multichannel EEG dynamics, making accurate and clinically useful EEG-based diagnosis increasingly important for screening and disease monitoring. However, many existing approaches rely on black-box classifiers and do not explicitly model the underlying dynamics that generate observed signals. To address these limitations, we propose LERD, an end-to-end Bayesian electrophysiological neural dynamical system that infers latent neural events and their relational structure directly from multichannel EEG without event or interaction annotations. LERD combines a continuous-time event inference module with a stochastic event-generation process to capture flexible temporal patterns, while incorporating an electrophysiology-inspired dynamical prior to guide learning in a principled way. We further provide theoretical analysis that yields a tractable bound for training and stability guarantees for the inferred relational dynamics. Extensive experiments on synthetic benchmarks and two real-world AD EEG cohorts demonstrate that LERD consistently outperforms strong baselines and yields physiology-aligned latent summaries that help characterize group-level dynamical differences.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18195v1",
        "pdf": "https://arxiv.org/pdf/2602.18195v1"
      },
      "arxiv_id": "2602.18195v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18193v1",
      "title": "BLM-Guard: Explainable Multimodal Ad Moderation with Chain-of-Thought and Policy-Aligned Rewards",
      "authors": [
        "Yiran Yang",
        "Zhaowei Liu",
        "Yuan Yuan",
        "Yukun Song",
        "Xiong Ma",
        "Yinghao Song",
        "Xiangji Zeng",
        "Lu Sun",
        "Yulu Wang",
        "Hai Zhou",
        "Shuai Cui",
        "Zhaohan Gong",
        "Jiefei Zhang"
      ],
      "abstract": "Short-video platforms now host vast multimodal ads whose deceptive visuals, speech and subtitles demand finer-grained, policy-driven moderation than community safety filters. We present BLM-Guard, a content-audit framework for commercial ads that fuses Chain-of-Thought reasoning with rule-based policy principles and a critic-guided reward. A rule-driven ICoT data-synthesis pipeline jump-starts training by generating structured scene descriptions, reasoning chains and labels, cutting annotation costs. Reinforcement learning then refines the model using a composite reward balancing causal coherence with policy adherence. A multitask architecture models intra-modal manipulations (e.g., exaggerated imagery) and cross-modal mismatches (e.g., subtitle-speech drift), boosting robustness. Experiments on real short-video ads show BLM-Guard surpasses strong baselines in accuracy, consistency and generalization.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18193v1",
        "pdf": "https://arxiv.org/pdf/2602.18193v1"
      },
      "arxiv_id": "2602.18193v1",
      "comment": "7 pages, 3 figures. To appear in AAAI 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18186v1",
      "title": "Box Thirding: Anytime Best Arm Identification under Insufficient Sampling",
      "authors": [
        "Seohwa Hwang",
        "Junyong Park"
      ],
      "abstract": "We introduce Box Thirding (B3), a flexible and efficient algorithm for Best Arm Identification (BAI) under fixed-budget constraints. It is designed for both anytime BAI and scenarios with large N, where the number of arms is too large for exhaustive evaluation within a limited budget T. The algorithm employs an iterative ternary comparison: in each iteration, three arms are compared--the best-performing arm is explored further, the median is deferred for future comparisons, and the weakest is discarded. Even without prior knowledge of T, B3 achieves an epsilon-best arm misidentification probability comparable to Successive Halving (SH), which requires T as a predefined parameter, applied to a randomly selected subset of c0 arms that fit within the budget. Empirical results show that B3 outperforms existing methods under limited-budget constraints in terms of simple regret, as demonstrated on the New Yorker Cartoon Caption Contest dataset.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18186v1",
        "pdf": "https://arxiv.org/pdf/2602.18186v1"
      },
      "arxiv_id": "2602.18186v1",
      "comment": "29 pages, 5 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18182v1",
      "title": "Capabilities Ain't All You Need: Measuring Propensities in AI",
      "authors": [
        "Daniel Romero-Alvarado",
        "Fernando Martínez-Plumed",
        "Lorenzo Pacchiardi",
        "Hugo Save",
        "Siddhesh Milind Pawar",
        "Behzad Mehrbakhsh",
        "Pablo Antonio Moreno Casares",
        "Ben Slater",
        "Paolo Bova",
        "Peter Romero",
        "Zachary R. Tyler",
        "Jonathan Prunty",
        "Luning Sun",
        "Jose Hernandez-Orallo"
      ],
      "abstract": "AI evaluation has primarily focused on measuring capabilities, with formal approaches inspired from Item Response Theory (IRT) being increasingly applied. Yet propensities - the tendencies of models to exhibit particular behaviours - play a central role in determining both performance and safety outcomes. However, traditional IRT describes a model's success on a task as a monotonic function of model capabilities and task demands, an approach unsuited to propensities, where both excess and deficiency can be problematic. Here, we introduce the first formal framework for measuring AI propensities by using a bilogistic formulation for model success, which attributes high success probability when the model's propensity is within an \"ideal band\". Further, we estimate the limits of the ideal band using LLMs equipped with newly developed task-agnostic rubrics. Applying our framework to six families of LLM models whose propensities are incited in either direction, we find that we can measure how much the propensity is shifted and what effect this has on the tasks. Critically, propensities estimated using one benchmark successfully predict behaviour on held-out tasks. Moreover, we obtain stronger predictive power when combining propensities and capabilities than either separately. More broadly, our framework showcases how rigorous propensity measurements can be conducted and how it yields gains over solely using capability evaluations to predict AI behaviour.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18182v1",
        "pdf": "https://arxiv.org/pdf/2602.18182v1"
      },
      "arxiv_id": "2602.18182v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18181v1",
      "title": "SeedFlood: A Step Toward Scalable Decentralized Training of LLMs",
      "authors": [
        "Jihun Kim",
        "Namhoon Lee"
      ],
      "abstract": "This work presents a new approach to decentralized training-SeedFlood-designed to scale for large models across complex network topologies and achieve global consensus with minimal communication overhead. Traditional gossip-based methods suffer from message communication costs that grow with model size, while information decay over network hops renders global consensus inefficient. SeedFlood departs from these practices by exploiting the seed-reconstructible structure of zeroth-order updates and effectively making the messages near-zero in size, allowing them to be flooded to every client in the network. This mechanism makes communication overhead negligible and independent of model size, removing the primary scalability bottleneck in decentralized training. Consequently, SeedFlood enables training in regimes previously considered impractical, such as billion-parameter models distributed across hundreds of clients. Our experiments on decentralized LLM fine-tuning demonstrate thatSeedFlood consistently outperforms gossip-based baselines in both generalization performance and communication efficiency, and even achieves results comparable to first-order methods in large scale settings.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18181v1",
        "pdf": "https://arxiv.org/pdf/2602.18181v1"
      },
      "arxiv_id": "2602.18181v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18178v1",
      "title": "Evaluating Graphical Perception Capabilities of Vision Transformers",
      "authors": [
        "Poonam Poonam",
        "Pere-Pau Vázquez",
        "Timo Ropinski"
      ],
      "abstract": "Vision Transformers, ViTs, have emerged as a powerful alternative to convolutional neural networks, CNNs, in a variety of image-based tasks. While CNNs have previously been evaluated for their ability to perform graphical perception tasks, which are essential for interpreting visualizations, the perceptual capabilities of ViTs remain largely unexplored. In this work, we investigate the performance of ViTs in elementary visual judgment tasks inspired by the foundational studies of Cleveland and McGill, which quantified the accuracy of human perception across different visual encodings. Inspired by their study, we benchmark ViTs against CNNs and human participants in a series of controlled graphical perception tasks. Our results reveal that, although ViTs demonstrate strong performance in general vision tasks, their alignment with human-like graphical perception in the visualization domain is limited. This study highlights key perceptual gaps and points to important considerations for the application of ViTs in visualization systems and graphical perceptual modeling.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18178v1",
        "pdf": "https://arxiv.org/pdf/2602.18178v1"
      },
      "arxiv_id": "2602.18178v1",
      "comment": "",
      "journal_ref": "Computer & Graphics 2025",
      "has_code": false
    },
    {
      "id": "2602.18172v1",
      "title": "Can AI Lower the Barrier to Cybersecurity? A Human-Centered Mixed-Methods Study of Novice CTF Learning",
      "authors": [
        "Cathrin Schachner",
        "Jasmin Wachter"
      ],
      "abstract": "Capture-the-Flag (CTF) competitions serve as gateways into offensive cybersecurity, yet they often present steep barriers for novices due to complex toolchains and opaque workflows. Recently, agentic AI frameworks for cybersecurity promise to lower these barriers by automating and coordinating penetration testing tasks. However, their role in shaping novice learning remains underexplored.\n  We present a human-centered, mixed-methods case study examining how agentic AI frameworks -- here Cybersecurity AI (CAI) -- mediates novice entry into CTF-based penetration testing. An undergraduate student without prior hacking experience attempted to approach performance benchmarks from a national cybersecurity challenge using CAI. Quantitative performance metrics were complemented by structured reflective analysis of learning progression and AI interaction patterns.\n  Our thematic analysis suggest that agentic AI reduces initial entry barriers by providing overview, structure and guidance, thereby lowering the cognitive workload during early engagement. Quantitatively, the observed extensive exploration of strategies and low per-strategy execution time potetially facilitatates cybersecurity training on meta, i.e. strategic levels. At the same time, AI-assisted cybersecurity education introduces new challenges related to trust, dependency, and responsible use. We discuss implications for human-centered AI-supported cybersecurity education and outline open questions for future research.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18172v1",
        "pdf": "https://arxiv.org/pdf/2602.18172v1"
      },
      "arxiv_id": "2602.18172v1",
      "comment": "A Preprint",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18171v1",
      "title": "Click it or Leave it: Detecting and Spoiling Clickbait with Informativeness Measures and Large Language Models",
      "authors": [
        "Wojciech Michaluk",
        "Tymoteusz Urban",
        "Mateusz Kubita",
        "Soveatin Kuntur",
        "Anna Wroblewska"
      ],
      "abstract": "Clickbait headlines degrade the quality of online information and undermine user trust. We present a hybrid approach to clickbait detection that combines transformer-based text embeddings with linguistically motivated informativeness features. Using natural language processing techniques, we evaluate classical vectorizers, word embedding baselines, and large language model embeddings paired with tree-based classifiers. Our best-performing model, XGBoost over embeddings augmented with 15 explicit features, achieves an F1-score of 91\\%, outperforming TF-IDF, Word2Vec, GloVe, LLM prompt based classification, and feature-only baselines. The proposed feature set enhances interpretability by highlighting salient linguistic cues such as second-person pronouns, superlatives, numerals, and attention-oriented punctuation, enabling transparent and well-calibrated clickbait predictions. We release code and trained models to support reproducible research.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18171v1",
        "pdf": "https://arxiv.org/pdf/2602.18171v1"
      },
      "arxiv_id": "2602.18171v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18168v1",
      "title": "A Deep Surrogate Model for Robust and Generalizable Long-Term Blast Wave Prediction",
      "authors": [
        "Danning Jing",
        "Xinhai Chen",
        "Xifeng Pu",
        "Jie Hu",
        "Chao Huang",
        "Xuguang Chen",
        "Qinglin Wang",
        "Jie Liu"
      ],
      "abstract": "Accurately modeling the spatio-temporal dynamics of blast wave propagation remains a longstanding challenge due to its highly nonlinear behavior, sharp gradients, and burdensome computational cost. While machine learning-based surrogate models offer fast inference as a promising alternative, they suffer from degraded accuracy, particularly evaluated on complex urban layouts or out-of-distribution scenarios. Moreover, autoregressive prediction strategies in such models are prone to error accumulation over long forecasting horizons, limiting their robustness for extended-time simulations. To address these limitations, we propose RGD-Blast, a robust and generalizable deep surrogate model for high-fidelity, long-term blast wave forecasting. RGD-Blast incorporates a multi-scale module to capture both global flow patterns and local boundary interactions, effectively mitigating error accumulation during autoregressive prediction. We introduce a dynamic-static feature coupling mechanism that fuses time-varying pressure fields with static source and layout features, thereby enhancing out-of-distribution generalization. Experiments demonstrate that RGD-Blast achieves a two-order-of-magnitude speedup over traditional numerical methods while maintaining comparable accuracy. In generalization tests on unseen building layouts, the model achieves an average RMSE below 0.01 and an R2 exceeding 0.89 over 280 consecutive time steps. Additional evaluations under varying blast source locations and explosive charge weights further validate its generalization, substantially advancing the state of the art in long-term blast wave modeling.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18168v1",
        "pdf": "https://arxiv.org/pdf/2602.18168v1"
      },
      "arxiv_id": "2602.18168v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18160v1",
      "title": "Unifying Formal Explanations: A Complexity-Theoretic Perspective",
      "authors": [
        "Shahaf Bassan",
        "Xuanxiang Huang",
        "Guy Katz"
      ],
      "abstract": "Previous work has explored the computational complexity of deriving two fundamental types of explanations for ML model predictions: (1) *sufficient reasons*, which are subsets of input features that, when fixed, determine a prediction, and (2) *contrastive reasons*, which are subsets of input features that, when modified, alter a prediction. Prior studies have examined these explanations in different contexts, such as non-probabilistic versus probabilistic frameworks and local versus global settings. In this study, we introduce a unified framework for analyzing these explanations, demonstrating that they can all be characterized through the minimization of a unified probabilistic value function. We then prove that the complexity of these computations is influenced by three key properties of the value function: (1) *monotonicity*, (2) *submodularity*, and (3) *supermodularity* - which are three fundamental properties in *combinatorial optimization*. Our findings uncover some counterintuitive results regarding the nature of these properties within the explanation settings examined. For instance, although the *local* value functions do not exhibit monotonicity or submodularity/supermodularity whatsoever, we demonstrate that the *global* value functions do possess these properties. This distinction enables us to prove a series of novel polynomial-time results for computing various explanations with provable guarantees in the global explainability setting, across a range of ML models that span the interpretability spectrum, such as neural networks, decision trees, and tree ensembles. In contrast, we show that even highly simplified versions of these explanations become NP-hard to compute in the corresponding local explainability setting.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.LG",
        "cs.CC",
        "cs.DS",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18160v1",
        "pdf": "https://arxiv.org/pdf/2602.18160v1"
      },
      "arxiv_id": "2602.18160v1",
      "comment": "To appear in ICLR 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18154v1",
      "title": "FENCE: A Financial and Multimodal Jailbreak Detection Dataset",
      "authors": [
        "Mirae Kim",
        "Seonghun Jeong",
        "Youngjun Kwak"
      ],
      "abstract": "Jailbreaking poses a significant risk to the deployment of Large Language Models (LLMs) and Vision Language Models (VLMs). VLMs are particularly vulnerable because they process both text and images, creating broader attack surfaces. However, available resources for jailbreak detection are scarce, particularly in finance. To address this gap, we present FENCE, a bilingual (Korean-English) multimodal dataset for training and evaluating jailbreak detectors in financial applications. FENCE emphasizes domain realism through finance-relevant queries paired with image-grounded threats. Experiments with commercial and open-source VLMs reveal consistent vulnerabilities, with GPT-4o showing measurable attack success rates and open-source models displaying greater exposure. A baseline detector trained on FENCE achieves 99 percent in-distribution accuracy and maintains strong performance on external benchmarks, underscoring the dataset's robustness for training reliable detection models. FENCE provides a focused resource for advancing multimodal jailbreak detection in finance and for supporting safer, more reliable AI systems in sensitive domains. Warning: This paper includes example data that may be offensive.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18154v1",
        "pdf": "https://arxiv.org/pdf/2602.18154v1"
      },
      "arxiv_id": "2602.18154v1",
      "comment": "lrec 2026 accepted paper",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18151v1",
      "title": "Rethinking Beam Management: Generalization Limits Under Hardware Heterogeneity",
      "authors": [
        "Nikita Zeulin",
        "Olga Galinina",
        "Ibrahim Kilinc",
        "Sergey Andreev",
        "Robert W. Heath"
      ],
      "abstract": "Hardware heterogeneity across diverse user devices poses new challenges for beam-based communication in 5G and beyond. This heterogeneity limits the applicability of machine learning (ML)-based algorithms. This article highlights the critical need to treat hardware heterogeneity as a first-class design concern in ML-aided beam management. We analyze key failure modes in the presence of heterogeneity and present case studies demonstrating their performance impact. Finally, we discuss potential strategies to improve generalization in beam management.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.NI",
        "cs.IT",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18151v1",
        "pdf": "https://arxiv.org/pdf/2602.18151v1"
      },
      "arxiv_id": "2602.18151v1",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18148v1",
      "title": "BONNI: Gradient-Informed Bayesian and Interior Point Optimization for Efficient Inverse Design in Nanophotonics",
      "authors": [
        "Yannik Mahlau",
        "Yannick Augenstein",
        "Tyler W. Hughes",
        "Marius Lindauer",
        "Bodo Rosenhahn"
      ],
      "abstract": "Inverse design, particularly geometric shape optimization, provides a systematic approach for developing high-performance nanophotonic devices. While numerous optimization algorithms exist, previous global approaches exhibit slow convergence and conversely local search strategies frequently become trapped in local optima. To address the limitations inherent to both local and global approaches, we introduce BONNI: Bayesian optimization through neural network ensemble surrogates with interior point optimization. It augments global optimization with an efficient incorporation of gradient information to determine optimal sampling points. This capability allows BONNI to circumvent the local optima found in many nanophotonic applications, while capitalizing on the efficiency of gradient-based optimization. We demonstrate BONNI's capabilities in the design of a distributed Bragg reflector as well as a dual-layer grating coupler through an exhaustive comparison against other optimization algorithms commonly used in literature. Using BONNI, we were able to design a 10-layer distributed Bragg reflector with only 4.5% mean spectral error, compared to the previously reported results of 7.8% error with 16 layers. Further designs of a broadband waveguide taper and photonic crystal waveguide transition validate the capabilities of BONNI.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "physics.optics",
        "cs.LG"
      ],
      "primary_category": "physics.optics",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18148v1",
        "pdf": "https://arxiv.org/pdf/2602.18148v1"
      },
      "arxiv_id": "2602.18148v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18146v1",
      "title": "Stable Long-Horizon Spatiotemporal Prediction on Meshes Using Latent Multiscale Recurrent Graph Neural Networks",
      "authors": [
        "Lionel Salesses",
        "Larbi Arbaoui",
        "Tariq Benamara",
        "Arnaud Francois",
        "Caroline Sainvitu"
      ],
      "abstract": "Accurate long-horizon prediction of spatiotemporal fields on complex geometries is a fundamental challenge in scientific machine learning, with applications such as additive manufacturing where temperature histories govern defect formation and mechanical properties. High-fidelity simulations are accurate but computationally costly, and despite recent advances, machine learning methods remain challenged by long-horizon temperature and gradient prediction. We propose a deep learning framework for predicting full temperature histories directly on meshes, conditioned on geometry and process parameters, while maintaining stability over thousands of time steps and generalizing across heterogeneous geometries. The framework adopts a temporal multiscale architecture composed of two coupled models operating at complementary time scales. Both models rely on a latent recurrent graph neural network to capture spatiotemporal dynamics on meshes, while a variational graph autoencoder provides a compact latent representation that reduces memory usage and improves training stability. Experiments on simulated powder bed fusion data demonstrate accurate and temporally stable long-horizon predictions across diverse geometries, outperforming existing baseline. Although evaluated in two dimensions, the framework is general and extensible to physics-driven systems with multiscale dynamics and to three-dimensional geometries.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.LG",
        "cond-mat.mtrl-sci",
        "physics.app-ph"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18146v1",
        "pdf": "https://arxiv.org/pdf/2602.18146v1"
      },
      "arxiv_id": "2602.18146v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18141v1",
      "title": "Advection-Diffusion on Graphs: A Bakry-Emery Laplacian for Spectral Graph Neural Networks",
      "authors": [
        "Pierre-Gabriel Berlureau",
        "Ali Hariri",
        "Victor Kawasaki-Borruat",
        "Mia Zosso",
        "Pierre Vandergheynst"
      ],
      "abstract": "Graph Neural Networks (GNNs) often struggle to propagate information across long distances due to oversmoothing and oversquashing. Existing remedies such as graph transformers or rewiring typically incur high computational cost or require altering the graph structure. We introduce a Bakry-Emery graph Laplacian that integrates diffusion and advection through a learnable node-wise potential, inducing task-dependent propagation dynamics without modifying topology. This operator has a well-behaved spectral decomposition and acts as a drop-in replacement for standard Laplacians in spectral GNNs. Building on this insight, we develop mu-ChebNet, a spectral architecture that jointly learns the potential and Chebyshev filters, effectively bridging message-passing adaptivity and spectral efficiency. Our theoretical analysis shows how the potential modulates the spectrum, enabling control of key graph properties. Empirically, mu-ChebNet delivers consistent gains on synthetic long-range reasoning tasks, as well as real-world benchmarks, while offering an interpretable routing field that reveals how information flows through the graph. This establishes the Bakry-Emery Laplacian as a principled and efficient foundation for adaptive spectral graph learning.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18141v1",
        "pdf": "https://arxiv.org/pdf/2602.18141v1"
      },
      "arxiv_id": "2602.18141v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18137v1",
      "title": "Agentic Adversarial QA for Improving Domain-Specific LLMs",
      "authors": [
        "Vincent Grari",
        "Ciprian Tomoiaga",
        "Sylvain Lamprier",
        "Tatsunori Hashimoto",
        "Marcin Detyniecki"
      ],
      "abstract": "Large Language Models (LLMs), despite extensive pretraining on broad internet corpora, often struggle to adapt effectively to specialized domains. There is growing interest in fine-tuning these models for such domains; however, progress is constrained by the scarcity and limited coverage of high-quality, task-relevant data. To address this, synthetic data generation methods such as paraphrasing or knowledge extraction are commonly applied. Although these approaches excel at factual recall and conceptual knowledge, they suffer from two critical shortcomings: (i) they provide minimal support for interpretive reasoning capabilities in these specialized domains, and (ii) they often produce synthetic corpora that are excessively large and redundant, resulting in poor sample efficiency. To overcome these gaps, we propose an adversarial question-generation framework that produces a compact set of semantically challenging questions. These questions are constructed by comparing the outputs of the model to be adapted and a robust expert model grounded in reference documents, using an iterative, feedback-driven process designed to reveal and address comprehension gaps. Evaluation on specialized subsets of the LegalBench corpus demonstrates that our method achieves greater accuracy with substantially fewer synthetic samples.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18137v1",
        "pdf": "https://arxiv.org/pdf/2602.18137v1"
      },
      "arxiv_id": "2602.18137v1",
      "comment": "9 pages, 1 Figure",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18131v1",
      "title": "Learning Long-Range Dependencies with Temporal Predictive Coding",
      "authors": [
        "Tom Potter",
        "Oliver Rhodes"
      ],
      "abstract": "Predictive Coding (PC) is a biologically-inspired learning framework characterised by local, parallelisable operations, properties that enable energy-efficient implementation on neuromorphic hardware. Despite this, extending PC effectively to recurrent neural networks (RNNs) has been challenging, particularly for tasks involving long-range temporal dependencies. Backpropagation Through Time (BPTT) remains the dominant method for training RNNs, but its non-local computation, lack of spatial parallelism, and requirement to store extensive activation histories results in significant energy consumption. This work introduces a novel method combining Temporal Predictive Coding (tPC) with approximate Real-Time Recurrent Learning (RTRL), enabling effective spatio-temporal credit assignment. Results indicate that the proposed method can closely match the performance of BPTT on both synthetic benchmarks and real-world tasks. On a challenging machine translation task, with a 15-million parameter model, the proposed method achieves a test perplexity of 7.62 (vs. 7.49 for BPTT), marking one of the first applications of tPC to tasks of this scale. These findings demonstrate the potential of this method to learn complex temporal dependencies whilst retaining the local, parallelisable, and flexible properties of the original PC framework, paving the way for more energy-efficient learning systems.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18131v1",
        "pdf": "https://arxiv.org/pdf/2602.18131v1"
      },
      "arxiv_id": "2602.18131v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18119v1",
      "title": "RamanSeg: Interpretability-driven Deep Learning on Raman Spectra for Cancer Diagnosis",
      "authors": [
        "Chris Tomy",
        "Mo Vali",
        "David Pertzborn",
        "Tammam Alamatouri",
        "Anna Mühlig",
        "Orlando Guntinas-Lichius",
        "Anna Xylander",
        "Eric Michele Fantuzzi",
        "Matteo Negro",
        "Francesco Crisafi",
        "Pietro Lio",
        "Tiago Azevedo"
      ],
      "abstract": "Histopathology, the current gold standard for cancer diagnosis, involves the manual examination of tissue samples after chemical staining, a time-consuming process requiring expert analysis. Raman spectroscopy is an alternative, stain-free method of extracting information from samples. Using nnU-Net, we trained a segmentation model on a novel dataset of spatial Raman spectra aligned with tumour annotations, achieving a mean foreground Dice score of 80.9%, surpassing previous work. Furthermore, we propose a novel, interpretable, prototype-based architecture called RamanSeg. RamanSeg classifies pixels based on discovered regions of the training set, generating a segmentation mask. Two variants of RamanSeg allow a trade-off between interpretability and performance: one with prototype projection and another projection-free version. The projection-free RamanSeg outperformed a U-Net baseline with a mean foreground Dice score of 67.3%, offering a meaningful improvement over a black-box training approach.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18119v1",
        "pdf": "https://arxiv.org/pdf/2602.18119v1"
      },
      "arxiv_id": "2602.18119v1",
      "comment": "12 pages, 8 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18117v1",
      "title": "Flow Matching with Injected Noise for Offline-to-Online Reinforcement Learning",
      "authors": [
        "Yongjae Shin",
        "Jongseong Chae",
        "Jongeui Park",
        "Youngchul Sung"
      ],
      "abstract": "Generative models have recently demonstrated remarkable success across diverse domains, motivating their adoption as expressive policies in reinforcement learning (RL). While they have shown strong performance in offline RL, particularly where the target distribution is well defined, their extension to online fine-tuning has largely been treated as a direct continuation of offline pre-training, leaving key challenges unaddressed. In this paper, we propose Flow Matching with Injected Noise for Offline-to-Online RL (FINO), a novel method that leverages flow matching-based policies to enhance sample efficiency for offline-to-online RL. FINO facilitates effective exploration by injecting noise into policy training, thereby encouraging a broader range of actions beyond those observed in the offline dataset. In addition to exploration-enhanced flow policy training, we combine an entropy-guided sampling mechanism to balance exploration and exploitation, allowing the policy to adapt its behavior throughout online fine-tuning. Experiments across diverse, challenging tasks demonstrate that FINO consistently achieves superior performance under limited online budgets.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18117v1",
        "pdf": "https://arxiv.org/pdf/2602.18117v1"
      },
      "arxiv_id": "2602.18117v1",
      "comment": "ICLR 2026 camera-ready",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18116v1",
      "title": "Cut Less, Fold More: Model Compression through the Lens of Projection Geometry",
      "authors": [
        "Olga Saukh",
        "Dong Wang",
        "Haris Šikić",
        "Yun Cheng",
        "Lothar Thiele"
      ],
      "abstract": "Compressing neural networks without retraining is vital for deployment at scale. We study calibration-free compression through the lens of projection geometry: structured pruning is an axis-aligned projection, whereas model folding performs a low-rank projection via weight clustering. We formalize both as orthogonal operators and show that, within a rank distance of one, folding provably yields smaller parameter reconstruction error, and under mild smoothness assumptions, smaller functional perturbations than pruning. At scale, we evaluate >1000 checkpoints spanning ResNet18, PreActResNet18, ViT-B/32, and CLIP ViT-B/32 on CIFAR-10 and ImageNet-1K, covering diverse training hyperparameters (optimizers, learning rates, augmentations, regularization, sharpness-aware training), as well as multiple LLaMA-family 60M and 130M parameter models trained on C4. We show that folding typically achieves higher post-compression accuracy, with the largest gains at moderate-high compression. The gap narrows and occasionally reverses at specific training setups. Our results position folding as a geometry-aware, calibration-free alternative to pruning that is often superior in practice and principled in theory.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18116v1",
        "pdf": "https://arxiv.org/pdf/2602.18116v1"
      },
      "arxiv_id": "2602.18116v1",
      "comment": "Accepted by ICLR 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18114v1",
      "title": "Non-Stationary Online Resource Allocation: Learning from a Single Sample",
      "authors": [
        "Yiding Feng",
        "Jiashuo Jiang",
        "Yige Wang"
      ],
      "abstract": "We study online resource allocation under non-stationary demand with a minimum offline data requirement. In this problem, a decision-maker must allocate multiple types of resources to sequentially arriving queries over a finite horizon. Each query belongs to a finite set of types with fixed resource consumption and a stochastic reward drawn from an unknown, type-specific distribution. Critically, the environment exhibits arbitrary non-stationarity -- arrival distributions may shift unpredictably-while the algorithm requires only one historical sample per period to operate effectively. We distinguish two settings based on sample informativeness: (i) reward-observed samples containing both query type and reward realization, and (ii) the more challenging type-only samples revealing only query type information.\n  We propose a novel type-dependent quantile-based meta-policy that decouples the problem into modular components: reward distribution estimation, optimization of target service probabilities via fluid relaxation, and real-time decisions through dynamic acceptance thresholds. For reward-observed samples, our static threshold policy achieves $\\tilde{O}(\\sqrt{T})$ regret. For type-only samples, we first establish that sublinear regret is impossible without additional structure; under a mild minimum-arrival-probability assumption, we design both a partially adaptive policy attaining the same $\\tilde{O}({T})$ bound and, more significantly, a fully adaptive resolving policy with careful rounding that achieves the first poly-logarithmic regret guarantee of $O((\\log T)^3)$ for non-stationary multi-resource allocation. Our framework advances prior work by operating with minimal offline data (one sample per period), handling arbitrary non-stationarity without variation-budget assumptions, and supporting multiple resource constraints.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.LG",
        "cs.DS",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18114v1",
        "pdf": "https://arxiv.org/pdf/2602.18114v1"
      },
      "arxiv_id": "2602.18114v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18109v1",
      "title": "TempoNet: Slack-Quantized Transformer-Guided Reinforcement Scheduler for Adaptive Deadline-Centric Real-Time Dispatchs",
      "authors": [
        "Rong Fu",
        "Yibo Meng",
        "Guangzhen Yao",
        "Jiaxuan Lu",
        "Zeyu Zhang",
        "Zhaolu Kang",
        "Ziming Guo",
        "Jia Yee Tan",
        "Xiaojing Du",
        "Simon James Fong"
      ],
      "abstract": "Real-time schedulers must reason about tight deadlines under strict compute budgets. We present TempoNet, a reinforcement learning scheduler that pairs a permutation-invariant Transformer with a deep Q-approximation. An Urgency Tokenizer discretizes temporal slack into learnable embeddings, stabilizing value learning and capturing deadline proximity. A latency-aware sparse attention stack with blockwise top-k selection and locality-sensitive chunking enables global reasoning over unordered task sets with near-linear scaling and sub-millisecond inference. A multicore mapping layer converts contextualized Q-scores into processor assignments through masked-greedy selection or differentiable matching. Extensive evaluations on industrial mixed-criticality traces and large multiprocessor settings show consistent gains in deadline fulfillment over analytic schedulers and neural baselines, together with improved optimization stability. Diagnostics include sensitivity analyses for slack quantization, attention-driven policy interpretation, hardware-in-the-loop and kernel micro-benchmarks, and robustness under stress with simple runtime mitigations; we also report sample-efficiency benefits from behavioral-cloning pretraining and compatibility with an actor-critic variant without altering the inference pipeline. These results establish a practical framework for Transformer-based decision making in high-throughput real-time scheduling.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.LG",
        "cs.OS",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18109v1",
        "pdf": "https://arxiv.org/pdf/2602.18109v1"
      },
      "arxiv_id": "2602.18109v1",
      "comment": "43 pages, 12 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18104v1",
      "title": "MeanVoiceFlow: One-step Nonparallel Voice Conversion with Mean Flows",
      "authors": [
        "Takuhiro Kaneko",
        "Hirokazu Kameoka",
        "Kou Tanaka",
        "Yuto Kondo"
      ],
      "abstract": "In voice conversion (VC) applications, diffusion and flow-matching models have exhibited exceptional speech quality and speaker similarity performances. However, they are limited by slow conversion owing to their iterative inference. Consequently, we propose MeanVoiceFlow, a novel one-step nonparallel VC model based on mean flows, which can be trained from scratch without requiring pretraining or distillation. Unlike conventional flow matching that uses instantaneous velocity, mean flows employ average velocity to more accurately compute the time integral along the inference path in a single step. However, training the average velocity requires its derivative to compute the target velocity, which can cause instability. Therefore, we introduce a structural margin reconstruction loss as a zero-input constraint, which moderately regularizes the input-output behavior of the model without harmful statistical averaging. Furthermore, we propose conditional diffused-input training in which a mixture of noise and source data is used as input to the model during both training and inference. This enables the model to effectively leverage source information while maintaining consistency between training and inference. Experimental results validate the effectiveness of these techniques and demonstrate that MeanVoiceFlow achieves performance comparable to that of previous multi-step and distillation-based models, even when trained from scratch. Audio samples are available at https://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/meanvoiceflow/.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18104v1",
        "pdf": "https://arxiv.org/pdf/2602.18104v1"
      },
      "arxiv_id": "2602.18104v1",
      "comment": "Accepted to ICASSP 2026. Project page: https://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/meanvoiceflow/",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18097v1",
      "title": "Interacting safely with cyclists using Hamilton-Jacobi reachability and reinforcement learning",
      "authors": [
        "Aarati Andrea Noronha",
        "Jean Oh"
      ],
      "abstract": "In this paper, we present a framework for enabling autonomous vehicles to interact with cyclists in a manner that balances safety and optimality. The approach integrates Hamilton-Jacobi reachability analysis with deep Q-learning to jointly address safety guarantees and time-efficient navigation. A value function is computed as the solution to a time-dependent Hamilton-Jacobi-Bellman inequality, providing a quantitative measure of safety for each system state. This safety metric is incorporated as a structured reward signal within a reinforcement learning framework. The method further models the cyclist's latent response to the vehicle, allowing disturbance inputs to reflect human comfort and behavioral adaptation. The proposed framework is evaluated through simulation and comparison with human driving behavior and an existing state-of-the-art method.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.RO",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18097v1",
        "pdf": "https://arxiv.org/pdf/2602.18097v1"
      },
      "arxiv_id": "2602.18097v1",
      "comment": "7 pages. This manuscript was completed in 2020 as part of the first author's graduate thesis at Carnegie Mellon University",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18095v1",
      "title": "Neurosymbolic Language Reasoning as Satisfiability Modulo Theory",
      "authors": [
        "Hyunseok Oh",
        "Sam Stern",
        "Youngki Lee",
        "Matthai Philipose"
      ],
      "abstract": "Natural language understanding requires interleaving textual and logical reasoning, yet large language models often fail to perform such reasoning reliably. Existing neurosymbolic systems combine LLMs with solvers but remain limited to fully formalizable tasks such as math or program synthesis, leaving natural documents with only partial logical structure unaddressed. We introduce Logitext, a neurosymbolic language that represents documents as natural language text constraints (NLTCs), making partial logical structure explicit. We develop an algorithm that integrates LLM-based constraint evaluation with satisfiability modulo theory (SMT) solving, enabling joint textual-logical reasoning. Experiments on a new content moderation benchmark, together with LegalBench and Super-Natural Instructions, show that Logitext improves both accuracy and coverage. This work is the first that treats LLM-based reasoning as an SMT theory, extending neurosymbolic methods beyond fully formalizable domains.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18095v1",
        "pdf": "https://arxiv.org/pdf/2602.18095v1"
      },
      "arxiv_id": "2602.18095v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18094v1",
      "title": "OODBench: Out-of-Distribution Benchmark for Large Vision-Language Models",
      "authors": [
        "Ling Lin",
        "Yang Bai",
        "Heng Su",
        "Congcong Zhu",
        "Yaoxing Wang",
        "Yang Zhou",
        "Huazhu Fu",
        "Jingrun Chen"
      ],
      "abstract": "Existing Visual-Language Models (VLMs) have achieved significant progress by being trained on massive-scale datasets, typically under the assumption that data are independent and identically distributed (IID). However, in real-world scenarios, it is often impractical to expect that all data processed by an AI system satisfy this assumption. Furthermore, failure to appropriately handle out-of-distribution (OOD) objects may introduce safety risks in real-world applications (e.g., autonomous driving or medical assistance). Unfortunately, current research has not yet provided valid benchmarks that can comprehensively assess the performance of VLMs in response to OOD data. Therefore, we propose OODBench, a predominantly automated method with minimal human verification, for constructing new benchmarks and evaluating the ability of VLMs to process OOD data. OODBench contains 40K instance-level OOD instance-category pairs, and we show that current VLMs still exhibit notable performance degradation on OODBench, even when the underlying image categories are common. In addition, we propose a reliable automated assessment metric that employs a Basic-to-Advanced Progression of prompted questions to assess the impact of OOD data on questions of varying difficulty more fully. Lastly, we summarize substantial findings and insights to facilitate future research in the acquisition and evaluation of OOD data.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18094v1",
        "pdf": "https://arxiv.org/pdf/2602.18094v1"
      },
      "arxiv_id": "2602.18094v1",
      "comment": "54 pages, 21 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18093v1",
      "title": "Predict to Skip: Linear Multistep Feature Forecasting for Efficient Diffusion Transformers",
      "authors": [
        "Hanshuai Cui",
        "Zhiqing Tang",
        "Qianli Ma",
        "Zhi Yao",
        "Weijia Jia"
      ],
      "abstract": "Diffusion Transformers (DiT) have emerged as a widely adopted backbone for high-fidelity image and video generation, yet their iterative denoising process incurs high computational costs. Existing training-free acceleration methods rely on feature caching and reuse under the assumption of temporal stability. However, reusing features for multiple steps may lead to latent drift and visual degradation. We observe that model outputs evolve smoothly along much of the diffusion trajectory, enabling principled predictions rather than naive reuse. Based on this insight, we propose \\textbf{PrediT}, a training-free acceleration framework that formulates feature prediction as a linear multistep problem. We employ classical linear multistep methods to forecast future model outputs from historical information, combined with a corrector that activates in high-dynamics regions to prevent error accumulation. A dynamic step modulation mechanism adaptively adjusts the prediction horizon by monitoring the feature change rate. Together, these components enable substantial acceleration while preserving generation fidelity. Extensive experiments validate that our method achieves up to $5.54\\times$ latency reduction across various DiT-based image and video generation models, while incurring negligible quality degradation.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18093v1",
        "pdf": "https://arxiv.org/pdf/2602.18093v1"
      },
      "arxiv_id": "2602.18093v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18092v1",
      "title": "Perceived Political Bias in LLMs Reduces Persuasive Abilities",
      "authors": [
        "Matthew DiGiuseppe",
        "Joshua Robison"
      ],
      "abstract": "Conversational AI has been proposed as a scalable way to correct public misconceptions and spread misinformation. Yet its effectiveness may depend on perceptions of its political neutrality. As LLMs enter partisan conflict, elites increasingly portray them as ideologically aligned. We test whether these credibility attacks reduce LLM-based persuasion. In a preregistered U.S. survey experiment (N=2144), participants completed a three-round conversation with ChatGPT about a personally held economic policy misconception. Compared to a neutral control, a short message indicating that the LLM was biased against the respondent's party attenuated persuasion by 28%. Transcript analysis indicates that the warnings alter the interaction: respondents push back more and engage less receptively. These findings suggest that the persuasive impact of conversational AI is politically contingent, constrained by perceptions of partisan alignment.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18092v1",
        "pdf": "https://arxiv.org/pdf/2602.18092v1"
      },
      "arxiv_id": "2602.18092v1",
      "comment": "39 pages, 10 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18089v1",
      "title": "DohaScript: A Large-Scale Multi-Writer Dataset for Continuous Handwritten Hindi Text",
      "authors": [
        "Kunwar Arpit Singh",
        "Ankush Prakash",
        "Haroon R Lone"
      ],
      "abstract": "Despite having hundreds of millions of speakers, handwritten Devanagari text remains severely underrepresented in publicly available benchmark datasets. Existing resources are limited in scale, focus primarily on isolated characters or short words, and lack controlled lexical content and writer level diversity, which restricts their utility for modern data driven handwriting analysis. As a result, they fail to capture the continuous, fused, and structurally complex nature of Devanagari handwriting, where characters are connected through a shared shirorekha (horizontal headline) and exhibit rich ligature formations. We introduce DohaScript, a large scale, multi writer dataset of handwritten Hindi text collected from 531 unique contributors. The dataset is designed as a parallel stylistic corpus, in which all writers transcribe the same fixed set of six traditional Hindi dohas (couplets). This controlled design enables systematic analysis of writer specific variation independent of linguistic content, and supports tasks such as handwriting recognition, writer identification, style analysis, and generative modeling. The dataset is accompanied by non identifiable demographic metadata, rigorous quality curation based on objective sharpness and resolution criteria, and page level layout difficulty annotations that facilitate stratified benchmarking. Baseline experiments demonstrate clear quality separation and strong generalization to unseen writers, highlighting the dataset's reliability and practical value. DohaScript is intended to serve as a standardized and reproducible benchmark for advancing research on continuous handwritten Devanagari text in low resource script settings.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18089v1",
        "pdf": "https://arxiv.org/pdf/2602.18089v1"
      },
      "arxiv_id": "2602.18089v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18084v1",
      "title": "Balancing Symmetry and Efficiency in Graph Flow Matching",
      "authors": [
        "Benjamin Honoré",
        "Alba Carballo-Castro",
        "Yiming Qin",
        "Pascal Frossard"
      ],
      "abstract": "Equivariance is central to graph generative models, as it ensures the model respects the permutation symmetry of graphs. However, strict equivariance can increase computational cost due to added architectural constraints, and can slow down convergence because the model must be consistent across a large space of possible node permutations. We study this trade-off for graph generative models. Specifically, we start from an equivariant discrete flow-matching model, and relax its equivariance during training via a controllable symmetry modulation scheme based on sinusoidal positional encodings and node permutations. Experiments first show that symmetry-breaking can accelerate early training by providing an easier learning signal, but at the expense of encouraging shortcut solutions that can cause overfitting, where the model repeatedly generates graphs that are duplicates of the training set. On the contrary, properly modulating the symmetry signal can delay overfitting while accelerating convergence, allowing the model to reach stronger performance with $19\\%$ of the baseline training epochs.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18084v1",
        "pdf": "https://arxiv.org/pdf/2602.18084v1"
      },
      "arxiv_id": "2602.18084v1",
      "comment": "15 pages, 11 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18083v1",
      "title": "Comparative Assessment of Multimodal Earth Observation Data for Soil Moisture Estimation",
      "authors": [
        "Ioannis Kontogiorgakis",
        "Athanasios Askitopoulos",
        "Iason Tsardanidis",
        "Dimitrios Bormpoudakis",
        "Ilias Tsoumas",
        "Fotios Balampanis",
        "Charalampos Kontoes"
      ],
      "abstract": "Accurate soil moisture (SM) estimation is critical for precision agriculture, water resources management and climate monitoring. Yet, existing satellite SM products are too coarse (>1km) for farm-level applications. We present a high-resolution (10m) SM estimation framework for vegetated areas across Europe, combining Sentinel-1 SAR, Sentinel-2 optical imagery and ERA-5 reanalysis data through machine learning. Using 113 International Soil Moisture Network (ISMN) stations spanning diverse vegetated areas, we compare modality combinations with temporal parameterizations, using spatial cross-validation, to ensure geographic generalization. We also evaluate whether foundation model embeddings from IBM-NASA's Prithvi model improve upon traditional hand-crafted spectral features. Results demonstrate that hybrid temporal matching - Sentinel-2 current-day acquisitions with Sentinel-1 descending orbit - achieves R^2=0.514, with 10-day ERA5 lookback window improving performance to R^2=0.518. Foundation model (Prithvi) embeddings provide negligible improvement over hand-crafted features (R^2=0.515 vs. 0.514), indicating traditional feature engineering remains highly competitive for sparse-data regression tasks. Our findings suggest that domain-specific spectral indices combined with tree-based ensemble methods offer a practical and computationally efficient solution for operational pan-European field-scale soil moisture monitoring.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18083v1",
        "pdf": "https://arxiv.org/pdf/2602.18083v1"
      },
      "arxiv_id": "2602.18083v1",
      "comment": "This paper has been submitted to IEEE IGARSS 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18072v1",
      "title": "HiAER-Spike Software-Hardware Reconfigurable Platform for Event-Driven Neuromorphic Computing at Scale",
      "authors": [
        "Gwenevere Frank",
        "Gopabandhu Hota",
        "Keli Wang",
        "Christopher Deng",
        "Krish Arora",
        "Diana Vins",
        "Abhinav Uppal",
        "Omowuyi Olajide",
        "Kenneth Yoshimoto",
        "Qingbo Wang",
        "Mari Yamaoka",
        "Johannes Leugering",
        "Stephen Deiss",
        "Leif Gibb",
        "Gert Cauwenberghs"
      ],
      "abstract": "In this work, we present HiAER-Spike, a modular, reconfigurable, event-driven neuromorphic computing platform designed to execute large spiking neural networks with up to 160 million neurons and 40 billion synapses - roughly twice the neurons of a mouse brain at faster than real time. This system, assembled at the UC San Diego Supercomputer Center, comprises a co-designed hard- and software stack that is optimized for run-time massively parallel processing and hierarchical address-event routing (HiAER) of spikes while promoting memory-efficient network storage and execution. The architecture efficiently handles both sparse connectivity and sparse activity for robust and low-latency event-driven inference for both edge and cloud computing. A Python programming interface to HiAER-Spike, agnostic to hardware-level detail, shields the user from complexity in the configuration and execution of general spiking neural networks with minimal constraints in topology. The system is made easily available over a web portal for use by the wider community. In the following, we provide an overview of the hard- and software stack, explain the underlying design principles, demonstrate some of the system's capabilities and solicit feedback from the broader neuromorphic community. Examples are shown demonstrating HiAER-Spike's capabilities for event-driven vision on benchmark CIFAR-10, DVS event-based gesture, MNIST, and Pong tasks.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18072v1",
        "pdf": "https://arxiv.org/pdf/2602.18072v1"
      },
      "arxiv_id": "2602.18072v1",
      "comment": "Leif Gibb, Gert Cauwenberghs are equal authors. arXiv admin note: substantial text overlap with arXiv:2504.03671",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18066v1",
      "title": "Faster Training, Fewer Labels: Self-Supervised Pretraining for Fine-Grained BEV Segmentation",
      "authors": [
        "Daniel Busch",
        "Christian Bohn",
        "Thomas Kurbiel",
        "Klaus Friedrichs",
        "Richard Meyes",
        "Tobias Meisen"
      ],
      "abstract": "Dense Bird's Eye View (BEV) semantic maps are central to autonomous driving, yet current multi-camera methods depend on costly, inconsistently annotated BEV ground truth. We address this limitation with a two-phase training strategy for fine-grained road marking segmentation that removes full supervision during pretraining and halves the amount of training data during fine-tuning while still outperforming the comparable supervised baseline model. During the self-supervised pretraining, BEVFormer predictions are differentiably reprojected into the image plane and trained against multi-view semantic pseudo-labels generated by the widely used semantic segmentation model Mask2Former. A temporal loss encourages consistency across frames. The subsequent supervised fine-tuning phase requires only 50% of the dataset and significantly less training time. With our method, the fine-tuning benefits from rich priors learned during pretraining boosting the performance and BEV segmentation quality (up to +2.5pp mIoU over the fully supervised baseline) on nuScenes. It simultaneously halves the usage of annotation data and reduces total training time by up to two thirds. The results demonstrate that differentiable reprojection plus camera perspective pseudo labels yields transferable BEV features and a scalable path toward reduced-label autonomous perception.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18066v1",
        "pdf": "https://arxiv.org/pdf/2602.18066v1"
      },
      "arxiv_id": "2602.18066v1",
      "comment": "This Paper has been accepted to the 2026 IEEE Intelligent Vehicles Symposium (IV)",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18064v1",
      "title": "3DMedAgent: Unified Perception-to-Understanding for 3D Medical Analysis",
      "authors": [
        "Ziyue Wang",
        "Linghan Cai",
        "Chang Han Low",
        "Haofeng Liu",
        "Junde Wu",
        "Jingyu Wang",
        "Rui Wang",
        "Lei Song",
        "Jiang Bian",
        "Jingjing Fu",
        "Yueming Jin"
      ],
      "abstract": "3D CT analysis spans a continuum from low-level perception to high-level clinical understanding. Existing 3D-oriented analysis methods adopt either isolated task-specific modeling or task-agnostic end-to-end paradigms to produce one-hop outputs, impeding the systematic accumulation of perceptual evidence for downstream reasoning. In parallel, recent multimodal large language models (MLLMs) exhibit improved visual perception and can integrate visual and textual information effectively, yet their predominantly 2D-oriented designs fundamentally limit their ability to perceive and analyze volumetric medical data. To bridge this gap, we propose 3DMedAgent, a unified agent that enables 2D MLLMs to perform general 3D CT analysis without 3D-specific fine-tuning. 3DMedAgent coordinates heterogeneous visual and textual tools through a flexible MLLM agent, progressively decomposing complex 3D analysis into tractable subtasks that transition from global to regional views, from 3D volumes to informative 2D slices, and from visual evidence to structured textual representations. Central to this design, 3DMedAgent maintains a long-term structured memory that aggregates intermediate tool outputs and supports query-adaptive, evidence-driven multi-step reasoning. We further introduce the DeepChestVQA benchmark for evaluating unified perception-to-understanding capabilities in 3D thoracic imaging. Experiments across over 40 tasks demonstrate that 3DMedAgent consistently outperforms general, medical, and 3D-specific MLLMs, highlighting a scalable path toward general-purpose 3D clinical assistants.Code and data are available at \\href{https://github.com/jinlab-imvr/3DMedAgent}{https://github.com/jinlab-imvr/3DMedAgent}.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18064v1",
        "pdf": "https://arxiv.org/pdf/2602.18064v1"
      },
      "arxiv_id": "2602.18064v1",
      "comment": "19 pages, 7 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18060v1",
      "title": "Deepmechanics",
      "authors": [
        "Abhay Shinde",
        "Aryan Amit Barsainyan",
        "Jose Siguenza",
        "Ankita Vaishnobi Bisoi",
        "Rakshit Kr. Singh",
        "Bharath Ramsundar"
      ],
      "abstract": "Physics-informed deep learning models have emerged as powerful tools for learning dynamical systems. These models directly encode physical principles into network architectures. However, systematic benchmarking of these approaches across diverse physical phenomena remains limited, particularly in conservative and dissipative systems. In addition, benchmarking that has been done thus far does not integrate out full trajectories to check stability. In this work, we benchmark three prominent physics-informed architectures such as Hamiltonian Neural Networks (HNN), Lagrangian Neural Networks (LNN), and Symplectic Recurrent Neural Networks (SRNN) using the DeepChem framework, an open-source scientific machine learning library. We evaluate these models on six dynamical systems spanning classical conservative mechanics (mass-spring system, simple pendulum, double pendulum, and three-body problem, spring-pendulum) and non-conservative systems with contact (bouncing ball). We evaluate models by computing error on predicted trajectories and evaluate error both quantitatively and qualitatively. We find that all benchmarked models struggle to maintain stability for chaotic or nonconservative systems. Our results suggest that more research is needed for physics-informed deep learning models to learn robust models of classical mechanical systems.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18060v1",
        "pdf": "https://arxiv.org/pdf/2602.18060v1"
      },
      "arxiv_id": "2602.18060v1",
      "comment": "11 pages, 7 figures, Submitted to KDD 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18057v1",
      "title": "Temporal Consistency-Aware Text-to-Motion Generation",
      "authors": [
        "Hongsong Wang",
        "Wenjing Yan",
        "Qiuxia Lai",
        "Xin Geng"
      ],
      "abstract": "Text-to-Motion (T2M) generation aims to synthesize realistic human motion sequences from natural language descriptions. While two-stage frameworks leveraging discrete motion representations have advanced T2M research, they often neglect cross-sequence temporal consistency, i.e., the shared temporal structures present across different instances of the same action. This leads to semantic misalignments and physically implausible motions. To address this limitation, we propose TCA-T2M, a framework for temporal consistency-aware T2M generation. Our approach introduces a temporal consistency-aware spatial VQ-VAE (TCaS-VQ-VAE) for cross-sequence temporal alignment, coupled with a masked motion transformer for text-conditioned motion generation. Additionally, a kinematic constraint block mitigates discretization artifacts to ensure physical plausibility. Experiments on HumanML3D and KIT-ML benchmarks demonstrate that TCA-T2M achieves state-of-the-art performance, highlighting the importance of temporal consistency in robust and coherent T2M generation.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18057v1",
        "pdf": "https://arxiv.org/pdf/2602.18057v1"
      },
      "arxiv_id": "2602.18057v1",
      "comment": "Code is on https://github.com/Giat995/TCA-T2M/",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2602.18055v1",
      "title": "Continual-NExT: A Unified Comprehension And Generation Continual Learning Framework",
      "authors": [
        "Jingyang Qiao",
        "Zhizhong Zhang",
        "Xin Tan",
        "Jingyu Gong",
        "Yanyun Qu",
        "Yuan Xie"
      ],
      "abstract": "Dual-to-Dual MLLMs refer to Multimodal Large Language Models, which can enable unified multimodal comprehension and generation through text and image modalities. Although exhibiting strong instantaneous learning and generalization capabilities, Dual-to-Dual MLLMs still remain deficient in lifelong evolution, significantly affecting continual adaptation to dynamic real-world scenarios. One of the challenges is that learning new tasks inevitably destroys the learned knowledge. Beyond traditional catastrophic forgetting, Dual-to-Dual MLLMs face other challenges, including hallucination, instruction unfollowing, and failures in cross-modal knowledge transfer. However, no standardized continual learning framework for Dual-to-Dual MLLMs has been established yet, leaving these challenges unexplored. Thus, in this paper, we establish Continual-NExT, a continual learning framework for Dual-to-Dual MLLMs with deliberately-architected evaluation metrics. To improve the continual learning capability of Dual-to-Dual MLLMs, we propose an efficient MAGE (Mixture and Aggregation of General LoRA and Expert LoRA) method to further facilitate knowledge transfer across modalities and mitigate forgetting. Extensive experiments demonstrate that MAGE outperforms other continual learning methods and achieves state-of-the-art performance.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18055v1",
        "pdf": "https://arxiv.org/pdf/2602.18055v1"
      },
      "arxiv_id": "2602.18055v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18053v1",
      "title": "On the Generalization and Robustness in Conditional Value-at-Risk",
      "authors": [
        "Dinesh Karthik Mulumudi",
        "Piyushi Manupriya",
        "Gholamali Aminian",
        "Anant Raj"
      ],
      "abstract": "Conditional Value-at-Risk (CVaR) is a widely used risk-sensitive objective for learning under rare but high-impact losses, yet its statistical behavior under heavy-tailed data remains poorly understood. Unlike expectation-based risk, CVaR depends on an endogenous, data-dependent quantile, which couples tail averaging with threshold estimation and fundamentally alters both generalization and robustness properties. In this work, we develop a learning-theoretic analysis of CVaR-based empirical risk minimization under heavy-tailed and contaminated data. We establish sharp, high-probability generalization and excess risk bounds under minimal moment assumptions, covering fixed hypotheses, finite and infinite classes, and extending to $β$-mixing dependent data; we further show that these rates are minimax optimal. To capture the intrinsic quantile sensitivity of CVaR, we derive a uniform Bahadur-Kiefer type expansion that isolates a threshold-driven error term absent in mean-risk ERM and essential in heavy-tailed regimes. We complement these results with robustness guarantees by proposing a truncated median-of-means CVaR estimator that achieves optimal rates under adversarial contamination. Finally, we show that CVaR decisions themselves can be intrinsically unstable under heavy tails, establishing a fundamental limitation on decision robustness even when the population optimum is well separated. Together, our results provide a principled characterization of when CVaR learning generalizes and is robust, and when instability is unavoidable due to tail scarcity.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "stat.ML",
        "cs.LG",
        "math.ST"
      ],
      "primary_category": "stat.ML",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18053v1",
        "pdf": "https://arxiv.org/pdf/2602.18053v1"
      },
      "arxiv_id": "2602.18053v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18047v1",
      "title": "CityGuard: Graph-Aware Private Descriptors for Bias-Resilient Identity Search Across Urban Cameras",
      "authors": [
        "Rong Fu",
        "Wenxin Zhang",
        "Yibo Meng",
        "Jia Yee Tan",
        "Jiaxuan Lu",
        "Rui Lu",
        "Jiekai Wu",
        "Zhaolu Kang",
        "Simon Fong"
      ],
      "abstract": "City-scale person re-identification across distributed cameras must handle severe appearance changes from viewpoint, occlusion, and domain shift while complying with data protection rules that prevent sharing raw imagery. We introduce CityGuard, a topology-aware transformer for privacy-preserving identity retrieval in decentralized surveillance. The framework integrates three components. A dispersion-adaptive metric learner adjusts instance-level margins according to feature spread, increasing intra-class compactness. Spatially conditioned attention injects coarse geometry, such as GPS or deployment floor plans, into graph-based self-attention to enable projectively consistent cross-view alignment using only coarse geometric priors without requiring survey-grade calibration. Differentially private embedding maps are coupled with compact approximate indexes to support secure and cost-efficient deployment. Together these designs produce descriptors robust to viewpoint variation, occlusion, and domain shifts, and they enable a tunable balance between privacy and utility under rigorous differential-privacy accounting. Experiments on Market-1501 and additional public benchmarks, complemented by database-scale retrieval studies, show consistent gains in retrieval precision and query throughput over strong baselines, confirming the practicality of the framework for privacy-critical urban identity matching.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18047v1",
        "pdf": "https://arxiv.org/pdf/2602.18047v1"
      },
      "arxiv_id": "2602.18047v1",
      "comment": "36 pages, 12 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18045v1",
      "title": "Conformal Tradeoffs: Guarantees Beyond Coverage",
      "authors": [
        "Petrus H. Zwart"
      ],
      "abstract": "Deployed conformal predictors are long-lived decision infrastructure operating over finite operational windows. The real-world question is not only ``Does the true label lie in the prediction set at the target rate?'' (marginal coverage), but ``How often does the system commit versus defer? What error exposure does it induce when it acts? How do these rates trade off?'' Marginal coverage does not determine these deployment-facing quantities: the same calibrated thresholds can yield different operational profiles depending on score geometry. We provide a framework for operational certification and planning beyond coverage with three contributions. (1) Small-Sample Beta Correction (SSBC): we invert the exact finite-sample Beta/rank law for split conformal to map a user request $(α^\\star,δ)$ to a calibrated grid point with PAC-style semantics, yielding explicit finite-window coverage guarantees. (2) Calibrate-and-Audit: since no distribution-free pivot exists for rates beyond coverage, we introduce a two-stage design in which an independent audit set produces a reusable region -- label table and certified finite-window envelopes (Binomial/Beta-Binomial) for operational quantities -- commitment frequency, deferral, decisive error exposure, and commit purity -- via linear projection. (3) Geometric characterization: we describe feasibility constraints, regime boundaries (hedging vs.\\ rejection), and cost-coherence conditions induced by a fixed conformal partition, explaining why operational rates are coupled and how calibration navigates their trade-offs. The output is an auditable operational menu: for a fixed scoring model, we trace attainable operational profiles across calibration settings and attach finite-window uncertainty envelopes. We demonstrate the approach on Tox21 toxicity prediction (12 endpoints) and aqueous solubility screening using AquaSolDB.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "stat.ME",
        "cs.AI"
      ],
      "primary_category": "stat.ME",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18045v1",
        "pdf": "https://arxiv.org/pdf/2602.18045v1"
      },
      "arxiv_id": "2602.18045v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18043v1",
      "title": "Spatio-temporal Decoupled Knowledge Compensator for Few-Shot Action Recognition",
      "authors": [
        "Hongyu Qu",
        "Xiangbo Shu",
        "Rui Yan",
        "Hailiang Gao",
        "Wenguan Wang",
        "Jinhui Tang"
      ],
      "abstract": "Few-Shot Action Recognition (FSAR) is a challenging task that requires recognizing novel action categories with a few labeled videos. Recent works typically apply semantically coarse category names as auxiliary contexts to guide the learning of discriminative visual features. However, such context provided by the action names is too limited to provide sufficient background knowledge for capturing novel spatial and temporal concepts in actions. In this paper, we propose DiST, an innovative Decomposition-incorporation framework for FSAR that makes use of decoupled Spatial and Temporal knowledge provided by large language models to learn expressive multi-granularity prototypes. In the decomposition stage, we decouple vanilla action names into diverse spatio-temporal attribute descriptions (action-related knowledge). Such commonsense knowledge complements semantic contexts from spatial and temporal perspectives. In the incorporation stage, we propose Spatial/Temporal Knowledge Compensators (SKC/TKC) to discover discriminative object-level and frame-level prototypes, respectively. In SKC, object-level prototypes adaptively aggregate important patch tokens under the guidance of spatial knowledge. Moreover, in TKC, frame-level prototypes utilize temporal attributes to assist in inter-frame temporal relation modeling. These learned prototypes thus provide transparency in capturing fine-grained spatial details and diverse temporal patterns. Experimental results show DiST achieves state-of-the-art results on five standard FSAR datasets.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18043v1",
        "pdf": "https://arxiv.org/pdf/2602.18043v1"
      },
      "arxiv_id": "2602.18043v1",
      "comment": "Accepted to TPAMI 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.18037v1",
      "title": "Gradient Regularization Prevents Reward Hacking in Reinforcement Learning from Human Feedback and Verifiable Rewards",
      "authors": [
        "Johannes Ackermann",
        "Michael Noukhovitch",
        "Takashi Ishida",
        "Masashi Sugiyama"
      ],
      "abstract": "Reinforcement Learning from Human Feedback (RLHF) or Verifiable Rewards (RLVR) are two key steps in the post-training of modern Language Models (LMs). A common problem is reward hacking, where the policy may exploit inaccuracies of the reward and learn an unintended behavior. Most previous works address this by limiting the policy update with a Kullback-Leibler (KL) penalty towards a reference model. We propose a different framing: Train the LM in a way that biases policy updates towards regions in which the reward is more accurate. First, we derive a theoretical connection between the accuracy of a reward model and the flatness of an optimum at convergence. Gradient regularization (GR) can then be used to bias training to flatter regions and thereby maintain reward model accuracy. We confirm these results by showing that the gradient norm and reward accuracy are empirically correlated in RLHF. We then show that Reference Resets of the KL penalty implicitly use GR to find flatter regions with higher reward accuracy. We further improve on this by proposing to use explicit GR with an efficient finite-difference estimate. Empirically, GR performs better than a KL penalty across a diverse set of RL experiments with LMs. GR achieves a higher GPT-judged win-rate in RLHF, avoids overly focusing on the format in rule-based math rewards, and prevents hacking the judge in LLM-as-a-Judge math tasks.",
      "published": "2026-02-20",
      "updated": "2026-02-20",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.18037v1",
        "pdf": "https://arxiv.org/pdf/2602.18037v1"
      },
      "arxiv_id": "2602.18037v1",
      "comment": "25 pages, 15 figures",
      "journal_ref": "",
      "has_code": false
    }
  ]
}