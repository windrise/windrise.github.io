{
  "fetched_at": "2026-02-20T00:31:14.618300",
  "total_papers": 100,
  "papers": [
    {
      "id": "2602.16711v1",
      "title": "TeCoNeRV: Leveraging Temporal Coherence for Compressible Neural Representations for Videos",
      "authors": [
        "Namitha Padmanabhan",
        "Matthew Gwilliam",
        "Abhinav Shrivastava"
      ],
      "abstract": "Implicit Neural Representations (INRs) have recently demonstrated impressive performance for video compression. However, since a separate INR must be overfit for each video, scaling to high-resolution videos while maintaining encoding efficiency remains a significant challenge. Hypernetwork-based approaches predict INR weights (hyponetworks) for unseen videos at high speeds, but with low quality, large compressed size, and prohibitive memory needs at higher resolutions. We address these fundamental limitations through three key contributions: (1) an approach that decomposes the weight prediction task spatially and temporally, by breaking short video segments into patch tubelets, to reduce the pretraining memory overhead by 20$\\times$; (2) a residual-based storage scheme that captures only differences between consecutive segment representations, significantly reducing bitstream size; and (3) a temporal coherence regularization framework that encourages changes in the weight space to be correlated with video content. Our proposed method, TeCoNeRV, achieves substantial improvements of 2.47dB and 5.35dB PSNR over the baseline at 480p and 720p on UVG, with 36% lower bitrates and 1.5-3$\\times$ faster encoding speeds. With our low memory usage, we are the first hypernetwork approach to demonstrate results at 480p, 720p and 1080p on UVG, HEVC and MCL-JCV. Our project page is available at https://namithap10.github.io/teconerv/ .",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16711v1",
        "pdf": "https://arxiv.org/pdf/2602.16711v1"
      },
      "arxiv_id": "2602.16711v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16709v1",
      "title": "Knowledge-Embedded Latent Projection for Robust Representation Learning",
      "authors": [
        "Weijing Tang",
        "Ming Yuan",
        "Zongqi Xia",
        "Tianxi Cai"
      ],
      "abstract": "Latent space models are widely used for analyzing high-dimensional discrete data matrices, such as patient-feature matrices in electronic health records (EHRs), by capturing complex dependence structures through low-dimensional embeddings. However, estimation becomes challenging in the imbalanced regime, where one matrix dimension is much larger than the other. In EHR applications, cohort sizes are often limited by disease prevalence or data availability, whereas the feature space remains extremely large due to the breadth of medical coding system. Motivated by the increasing availability of external semantic embeddings, such as pre-trained embeddings of clinical concepts in EHRs, we propose a knowledge-embedded latent projection model that leverages semantic side information to regularize representation learning. Specifically, we model column embeddings as smooth functions of semantic embeddings via a mapping in a reproducing kernel Hilbert space. We develop a computationally efficient two-step estimation procedure that combines semantically guided subspace construction via kernel principal component analysis with scalable projected gradient descent. We establish estimation error bounds that characterize the trade-off between statistical error and approximation error induced by the kernel projection. Furthermore, we provide local convergence guarantees for our non-convex optimization procedure. Extensive simulation studies and a real-world EHR application demonstrate the effectiveness of the proposed method.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.LG",
        "math.ST",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16709v1",
        "pdf": "https://arxiv.org/pdf/2602.16709v1"
      },
      "arxiv_id": "2602.16709v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16708v1",
      "title": "Policy Compiler for Secure Agentic Systems",
      "authors": [
        "Nils Palumbo",
        "Sarthak Choudhary",
        "Jihye Choi",
        "Prasad Chalasani",
        "Mihai Christodorescu",
        "Somesh Jha"
      ],
      "abstract": "LLM-based agents are increasingly being deployed in contexts requiring complex authorization policies: customer service protocols, approval workflows, data access restrictions, and regulatory compliance. Embedding these policies in prompts provides no enforcement guarantees. We present PCAS, a Policy Compiler for Agentic Systems that provides deterministic policy enforcement.\n  Enforcing such policies requires tracking information flow across agents, which linear message histories cannot capture. Instead, PCAS models the agentic system state as a dependency graph capturing causal relationships among events such as tool calls, tool results, and messages. Policies are expressed in a Datalog-derived language, as declarative rules that account for transitive information flow and cross-agent provenance. A reference monitor intercepts all actions and blocks violations before execution, providing deterministic enforcement independent of model reasoning.\n  PCAS takes an existing agent implementation and a policy specification, and compiles them into an instrumented system that is policy-compliant by construction, with no security-specific restructuring required. We evaluate PCAS on three case studies: information flow policies for prompt injection defense, approval workflows in a multi-agent pharmacovigilance system, and organizational policies for customer service. On customer service tasks, PCAS improves policy compliance from 48% to 93% across frontier models, with zero policy violations in instrumented runs.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.CR",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16708v1",
        "pdf": "https://arxiv.org/pdf/2602.16708v1"
      },
      "arxiv_id": "2602.16708v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16705v1",
      "title": "Learning Humanoid End-Effector Control for Open-Vocabulary Visual Loco-Manipulation",
      "authors": [
        "Runpei Dong",
        "Ziyan Li",
        "Xialin He",
        "Saurabh Gupta"
      ],
      "abstract": "Visual loco-manipulation of arbitrary objects in the wild with humanoid robots requires accurate end-effector (EE) control and a generalizable understanding of the scene via visual inputs (e.g., RGB-D images). Existing approaches are based on real-world imitation learning and exhibit limited generalization due to the difficulty in collecting large-scale training datasets. This paper presents a new paradigm, HERO, for object loco-manipulation with humanoid robots that combines the strong generalization and open-vocabulary understanding of large vision models with strong control performance from simulated training. We achieve this by designing an accurate residual-aware EE tracking policy. This EE tracking policy combines classical robotics with machine learning. It uses a) inverse kinematics to convert residual end-effector targets into reference trajectories, b) a learned neural forward model for accurate forward kinematics, c) goal adjustment, and d) replanning. Together, these innovations help us cut down the end-effector tracking error by 3.2x. We use this accurate end-effector tracker to build a modular system for loco-manipulation, where we use open-vocabulary large vision models for strong visual generalization. Our system is able to operate in diverse real-world environments, from offices to coffee shops, where the robot is able to reliably manipulate various everyday objects (e.g., mugs, apples, toys) on surfaces ranging from 43cm to 92cm in height. Systematic modular and end-to-end tests in simulation and the real world demonstrate the effectiveness of our proposed design. We believe the advances in this paper can open up new ways of training humanoid robots to interact with daily objects.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.RO",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16705v1",
        "pdf": "https://arxiv.org/pdf/2602.16705v1"
      },
      "arxiv_id": "2602.16705v1",
      "comment": "Project page: https://hero-humanoid.github.io/",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2602.16703v1",
      "title": "Measuring Mid-2025 LLM-Assistance on Novice Performance in Biology",
      "authors": [
        "Shen Zhou Hong",
        "Alex Kleinman",
        "Alyssa Mathiowetz",
        "Adam Howes",
        "Julian Cohen",
        "Suveer Ganta",
        "Alex Letizia",
        "Dora Liao",
        "Deepika Pahari",
        "Xavier Roberts-Gaal",
        "Luca Righetti",
        "Joe Torres"
      ],
      "abstract": "Large language models (LLMs) perform strongly on biological benchmarks, raising concerns that they may help novice actors acquire dual-use laboratory skills. Yet, whether this translates to improved human performance in the physical laboratory remains unclear. To address this, we conducted a pre-registered, investigator-blinded, randomized controlled trial (June-August 2025; n = 153) evaluating whether LLMs improve novice performance in tasks that collectively model a viral reverse genetics workflow. We observed no significant difference in the primary endpoint of workflow completion (5.2% LLM vs. 6.6% Internet; P = 0.759), nor in the success rate of individual tasks. However, the LLM arm had numerically higher success rates in four of the five tasks, most notably for the cell culture task (68.8% LLM vs. 55.3% Internet; P = 0.059). Post-hoc Bayesian modeling of pooled data estimates an approximate 1.4-fold increase (95% CrI 0.74-2.62) in success for a \"typical\" reverse genetics task under LLM assistance. Ordinal regression modelling suggests that participants in the LLM arm were more likely to progress through intermediate steps across all tasks (posterior probability of a positive effect: 81%-96%). Overall, mid-2025 LLMs did not substantially increase novice completion of complex laboratory procedures but were associated with a modest performance benefit. These results reveal a gap between in silico benchmarks and real-world utility, underscoring the need for physical-world validation of AI biosecurity assessments as model capabilities and user proficiency evolve.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16703v1",
        "pdf": "https://arxiv.org/pdf/2602.16703v1"
      },
      "arxiv_id": "2602.16703v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16702v1",
      "title": "Saliency-Aware Multi-Route Thinking: Revisiting Vision-Language Reasoning",
      "authors": [
        "Mingjia Shi",
        "Yinhan He",
        "Yaochen Zhu",
        "Jundong Li"
      ],
      "abstract": "Vision-language models (VLMs) aim to reason by jointly leveraging visual and textual modalities. While allocating additional inference-time computation has proven effective for large language models (LLMs), achieving similar scaling in VLMs remains challenging. A key obstacle is that visual inputs are typically provided only once at the start of generation, while textual reasoning (e.g., early visual summaries) is generated autoregressively, causing reasoning to become increasingly text-dominated and allowing early visual grounding errors to accumulate. Moreover, vanilla guidance for visual grounding during inference is often coarse and noisy, making it difficult to steer reasoning over long texts. To address these challenges, we propose \\emph{Saliency-Aware Principle} (SAP) selection. SAP operates on high-level reasoning principles rather than token-level trajectories, which enable stable control over discrete generation under noisy feedback while allowing later reasoning steps to re-consult visual evidence when renewed grounding is required. In addition, SAP supports multi-route inference, enabling parallel exploration of diverse reasoning behaviors. SAP is model-agnostic and data-free, requiring no additional training. Empirical results show that SAP achieves competitive performance, especially in reducing object hallucination, under comparable token-generation budgets while yielding more stable reasoning and lower response latency than CoT-style long sequential reasoning.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16702v1",
        "pdf": "https://arxiv.org/pdf/2602.16702v1"
      },
      "arxiv_id": "2602.16702v1",
      "comment": "preprint 10 pages, 4 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16699v1",
      "title": "Calibrate-Then-Act: Cost-Aware Exploration in LLM Agents",
      "authors": [
        "Wenxuan Ding",
        "Nicholas Tomlin",
        "Greg Durrett"
      ],
      "abstract": "LLMs are increasingly being used for complex problems which are not necessarily resolved in a single response, but require interacting with an environment to acquire information. In these scenarios, LLMs must reason about inherent cost-uncertainty tradeoffs in when to stop exploring and commit to an answer. For instance, on a programming task, an LLM should test a generated code snippet if it is uncertain about the correctness of that code; the cost of writing a test is nonzero, but typically lower than the cost of making a mistake. In this work, we show that we can induce LLMs to explicitly reason about balancing these cost-uncertainty tradeoffs, then perform more optimal environment exploration. We formalize multiple tasks, including information retrieval and coding, as sequential decision-making problems under uncertainty. Each problem has latent environment state that can be reasoned about via a prior which is passed to the LLM agent. We introduce a framework called Calibrate-Then-Act (CTA), where we feed the LLM this additional context to enable it to act more optimally. This improvement is preserved even under RL training of both the baseline and CTA. Our results on information-seeking QA and on a simplified coding task show that making cost-benefit tradeoffs explicit with CTA can help agents discover more optimal decision-making strategies.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16699v1",
        "pdf": "https://arxiv.org/pdf/2602.16699v1"
      },
      "arxiv_id": "2602.16699v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16698v1",
      "title": "Causality is Key for Interpretability Claims to Generalise",
      "authors": [
        "Shruti Joshi",
        "Aaron Mueller",
        "David Klindt",
        "Wieland Brendel",
        "Patrik Reizinger",
        "Dhanya Sridhar"
      ],
      "abstract": "Interpretability research on large language models (LLMs) has yielded important insights into model behaviour, yet recurring pitfalls persist: findings that do not generalise, and causal interpretations that outrun the evidence. Our position is that causal inference specifies what constitutes a valid mapping from model activations to invariant high-level structures, the data or assumptions needed to achieve it, and the inferences it can support. Specifically, Pearl's causal hierarchy clarifies what an interpretability study can justify. Observations establish associations between model behaviour and internal components. Interventions (e.g., ablations or activation patching) support claims how these edits affect a behavioural metric (\\eg, average change in token probabilities) over a set of prompts. However, counterfactual claims -- i.e., asking what the model output would have been for the same prompt under an unobserved intervention -- remain largely unverifiable without controlled supervision. We show how causal representation learning (CRL) operationalises this hierarchy, specifying which variables are recoverable from activations and under what assumptions. Together, these motivate a diagnostic framework that helps practitioners select methods and evaluations matching claims to evidence such that findings generalise.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16698v1",
        "pdf": "https://arxiv.org/pdf/2602.16698v1"
      },
      "arxiv_id": "2602.16698v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16697v1",
      "title": "Protecting the Undeleted in Machine Unlearning",
      "authors": [
        "Aloni Cohen",
        "Refael Kohen",
        "Kobbi Nissim",
        "Uri Stemmer"
      ],
      "abstract": "Machine unlearning aims to remove specific data points from a trained model, often striving to emulate \"perfect retraining\", i.e., producing the model that would have been obtained had the deleted data never been included. We demonstrate that this approach, and security definitions that enable it, carry significant privacy risks for the remaining (undeleted) data points. We present a reconstruction attack showing that for certain tasks, which can be computed securely without deletions, a mechanism adhering to perfect retraining allows an adversary controlling merely $ω(1)$ data points to reconstruct almost the entire dataset merely by issuing deletion requests. We survey existing definitions for machine unlearning, showing they are either susceptible to such attacks or too restrictive to support basic functionalities like exact summation. To address this problem, we propose a new security definition that specifically safeguards undeleted data against leakage caused by the deletion of other points. We show that our definition permits several essential functionalities, such as bulletin boards, summations, and statistical learning.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.LG",
        "cs.DS"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16697v1",
        "pdf": "https://arxiv.org/pdf/2602.16697v1"
      },
      "arxiv_id": "2602.16697v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16696v1",
      "title": "Parameter-free representations outperform single-cell foundation models on downstream benchmarks",
      "authors": [
        "Huan Souza",
        "Pankaj Mehta"
      ],
      "abstract": "Single-cell RNA sequencing (scRNA-seq) data exhibit strong and reproducible statistical structure. This has motivated the development of large-scale foundation models, such as TranscriptFormer, that use transformer-based architectures to learn a generative model for gene expression by embedding genes into a latent vector space. These embeddings have been used to obtain state-of-the-art (SOTA) performance on downstream tasks such as cell-type classification, disease-state prediction, and cross-species learning. Here, we ask whether similar performance can be achieved without utilizing computationally intensive deep learning-based representations. Using simple, interpretable pipelines that rely on careful normalization and linear methods, we obtain SOTA or near SOTA performance across multiple benchmarks commonly used to evaluate single-cell foundation models, including outperforming foundation models on out-of-distribution tasks involving novel cell types and organisms absent from the training data. Our findings highlight the need for rigorous benchmarking and suggest that the biology of cell identity can be captured by simple linear representations of single cell gene expression data.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "q-bio.GN",
        "cs.LG",
        "q-bio.QM"
      ],
      "primary_category": "q-bio.GN",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16696v1",
        "pdf": "https://arxiv.org/pdf/2602.16696v1"
      },
      "arxiv_id": "2602.16696v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16690v1",
      "title": "Synthetic-Powered Multiple Testing with FDR Control",
      "authors": [
        "Yonghoon Lee",
        "Meshi Bashari",
        "Edgar Dobriban",
        "Yaniv Romano"
      ],
      "abstract": "Multiple hypothesis testing with false discovery rate (FDR) control is a fundamental problem in statistical inference, with broad applications in genomics, drug screening, and outlier detection. In many such settings, researchers may have access not only to real experimental observations but also to auxiliary or synthetic data -- from past, related experiments or generated by generative models -- that can provide additional evidence about the hypotheses of interest. We introduce SynthBH, a synthetic-powered multiple testing procedure that safely leverages such synthetic data. We prove that SynthBH guarantees finite-sample, distribution-free FDR control under a mild PRDS-type positive dependence condition, without requiring the pooled-data p-values to be valid under the null. The proposed method adapts to the (unknown) quality of the synthetic data: it enhances the sample efficiency and may boost the power when synthetic data are of high quality, while controlling the FDR at a user-specified level regardless of their quality. We demonstrate the empirical performance of SynthBH on tabular outlier detection benchmarks and on genomic analyses of drug-cancer sensitivity associations, and further study its properties through controlled experiments on simulated data.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "stat.ME",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "stat.ME",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16690v1",
        "pdf": "https://arxiv.org/pdf/2602.16690v1"
      },
      "arxiv_id": "2602.16690v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16689v1",
      "title": "Are Object-Centric Representations Better At Compositional Generalization?",
      "authors": [
        "Ferdinand Kapl",
        "Amir Mohammad Karimi Mamaghan",
        "Maximilian Seitzer",
        "Karl Henrik Johansson",
        "Carsten Marr",
        "Stefan Bauer",
        "Andrea Dittadi"
      ],
      "abstract": "Compositional generalization, the ability to reason about novel combinations of familiar concepts, is fundamental to human cognition and a critical challenge for machine learning. Object-centric (OC) representations, which encode a scene as a set of objects, are often argued to support such generalization, but systematic evidence in visually rich settings is limited. We introduce a Visual Question Answering benchmark across three controlled visual worlds (CLEVRTex, Super-CLEVR, and MOVi-C) to measure how well vision encoders, with and without object-centric biases, generalize to unseen combinations of object properties. To ensure a fair and comprehensive comparison, we carefully account for training data diversity, sample size, representation size, downstream model capacity, and compute. We use DINOv2 and SigLIP2, two widely used vision encoders, as the foundation models and their OC counterparts. Our key findings reveal that (1) OC approaches are superior in harder compositional generalization settings; (2) original dense representations surpass OC only on easier settings and typically require substantially more downstream compute; and (3) OC models are more sample efficient, achieving stronger generalization with fewer images, whereas dense encoders catch up or surpass them only with sufficient data and diversity. Overall, object-centric representations offer stronger compositional generalization when any one of dataset size, training data diversity, or downstream compute is constrained.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16689v1",
        "pdf": "https://arxiv.org/pdf/2602.16689v1"
      },
      "arxiv_id": "2602.16689v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16688v1",
      "title": "On the Hardness of Approximation of the Fair k-Center Problem",
      "authors": [
        "Suhas Thejaswi"
      ],
      "abstract": "In this work, we study the hardness of approximation of the fair $k$-center problem. Here the data points are partitioned into groups and the task is to choose a prescribed number of data points from each group, called centers, while minimizing the maximum distance from any point to its closest center. Although a polynomial-time $3$-approximation is known for this problem in general metrics, it has remained open whether this approximation guarantee is tight or could be further improved, especially since the unconstrained $k$-center problem admits a polynomial-time factor-$2$ approximation. We resolve this open question by proving that, for every $ε>0$, achieving a $(3-ε)$-approximation is NP-hard, assuming $\\text{P} \\neq \\text{NP}$.\n  Our inapproximability results hold even when only two disjoint groups are present and at least one center must be chosen from each group. Further, it extends to the canonical one-per-group setting with $k$-groups (for arbitrary $k$), where exactly one center must be selected from each group. Consequently, the factor-$3$ barrier for fair $k$-center in general metric spaces is inherent, and existing $3$-approximation algorithms are optimal up to lower-order terms even in these restricted regimes. This result stands in sharp contrast to the $k$-supplier formulation, where both the unconstrained and fair variants admit factor-$3$ approximation in polynomial time.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.CC",
        "cs.DS",
        "cs.LG"
      ],
      "primary_category": "cs.CC",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16688v1",
        "pdf": "https://arxiv.org/pdf/2602.16688v1"
      },
      "arxiv_id": "2602.16688v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16684v1",
      "title": "Retrieval-Augmented Foundation Models for Matched Molecular Pair Transformations to Recapitulate Medicinal Chemistry Intuition",
      "authors": [
        "Bo Pan",
        "Peter Zhiping Zhang",
        "Hao-Wei Pang",
        "Alex Zhu",
        "Xiang Yu",
        "Liying Zhang",
        "Liang Zhao"
      ],
      "abstract": "Matched molecular pairs (MMPs) capture the local chemical edits that medicinal chemists routinely use to design analogs, but existing ML approaches either operate at the whole-molecule level with limited edit controllability or learn MMP-style edits from restricted settings and small models. We propose a variable-to-variable formulation of analog generation and train a foundation model on large-scale MMP transformations (MMPTs) to generate diverse variables conditioned on an input variable. To enable practical control, we develop prompting mechanisms that let the users specify preferred transformation patterns during generation. We further introduce MMPT-RAG, a retrieval-augmented framework that uses external reference analogs as contextual guidance to steer generation and generalize from project-specific series. Experiments on general chemical corpora and patent-specific datasets demonstrate improved diversity, novelty, and controllability, and show that our method recovers realistic analog structures in practical discovery scenarios.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16684v1",
        "pdf": "https://arxiv.org/pdf/2602.16684v1"
      },
      "arxiv_id": "2602.16684v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16682v1",
      "title": "Learning Situated Awareness in the Real World",
      "authors": [
        "Chuhan Li",
        "Ruilin Han",
        "Joy Hsu",
        "Yongyuan Liang",
        "Rajiv Dhawan",
        "Jiajun Wu",
        "Ming-Hsuan Yang",
        "Xin Eric Wang"
      ],
      "abstract": "A core aspect of human perception is situated awareness, the ability to relate ourselves to the surrounding physical environment and reason over possible actions in context. However, most existing benchmarks for multimodal foundation models (MFMs) emphasize environment-centric spatial relations (relations among objects in a scene), while largely overlooking observer-centric relationships that require reasoning relative to agent's viewpoint, pose, and motion. To bridge this gap, we introduce SAW-Bench (Situated Awareness in the Real World), a novel benchmark for evaluating egocentric situated awareness using real-world videos. SAW-Bench comprises 786 self-recorded videos captured with Ray-Ban Meta (Gen 2) smart glasses spanning diverse indoor and outdoor environments, and over 2,071 human-annotated question-answer pairs. It probes a model's observer-centric understanding with six different awareness tasks. Our comprehensive evaluation reveals a human-model performance gap of 37.66%, even with the best-performing MFM, Gemini 3 Flash. Beyond this gap, our in-depth analysis uncovers several notable findings; for example, while models can exploit partial geometric cues in egocentric videos, they often fail to infer a coherent camera geometry, leading to systematic spatial reasoning errors. We position SAW-Bench as a benchmark for situated spatial intelligence, moving beyond passive observation to understanding physically grounded, observer-centric dynamics.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16682v1",
        "pdf": "https://arxiv.org/pdf/2602.16682v1"
      },
      "arxiv_id": "2602.16682v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16681v1",
      "title": "VETime: Vision Enhanced Zero-Shot Time Series Anomaly Detection",
      "authors": [
        "Yingyuan Yang",
        "Tian Lan",
        "Yifei Gao",
        "Yimeng Lu",
        "Wenjun He",
        "Meng Wang",
        "Chenghao Liu",
        "Chen Zhang"
      ],
      "abstract": "Time-series anomaly detection (TSAD) requires identifying both immediate Point Anomalies and long-range Context Anomalies. However, existing foundation models face a fundamental trade-off: 1D temporal models provide fine-grained pointwise localization but lack a global contextual perspective, while 2D vision-based models capture global patterns but suffer from information bottlenecks due to a lack of temporal alignment and coarse-grained pointwise detection. To resolve this dilemma, we propose VETime, the first TSAD framework that unifies temporal and visual modalities through fine-grained visual-temporal alignment and dynamic fusion. VETime introduces a Reversible Image Conversion and a Patch-Level Temporal Alignment module to establish a shared visual-temporal timeline, preserving discriminative details while maintaining temporal sensitivity. Furthermore, we design an Anomaly Window Contrastive Learning mechanism and a Task-Adaptive Multi-Modal Fusion to adaptively integrate the complementary perceptual strengths of both modalities. Extensive experiments demonstrate that VETime significantly outperforms state-of-the-art models in zero-shot scenarios, achieving superior localization precision with lower computational overhead than current vision-based approaches. Code available at: https://github.com/yyyangcoder/VETime.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16681v1",
        "pdf": "https://arxiv.org/pdf/2602.16681v1"
      },
      "arxiv_id": "2602.16681v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16673v1",
      "title": "Neighborhood Stability as a Measure of Nearest Neighbor Searchability",
      "authors": [
        "Thomas Vecchiato",
        "Sebastian Bruch"
      ],
      "abstract": "Clustering-based Approximate Nearest Neighbor Search (ANNS) organizes a set of points into partitions, and searches only a few of them to find the nearest neighbors of a query. Despite its popularity, there are virtually no analytical tools to determine the suitability of clustering-based ANNS for a given dataset -- what we call \"searchability.\" To address that gap, we present two measures for flat clusterings of high-dimensional points in Euclidean space. First is Clustering-Neighborhood Stability Measure (clustering-NSM), an internal measure of clustering quality -- a function of a clustering of a dataset -- that we show to be predictive of ANNS accuracy. The second, Point-Neighborhood Stability Measure (point-NSM), is a measure of clusterability -- a function of the dataset itself -- that is predictive of clustering-NSM. The two together allow us to determine whether a dataset is searchable by clustering-based ANNS given only the data points. Importantly, both are functions of nearest neighbor relationships between points, not distances, making them applicable to various distance functions including inner product.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.LG",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16673v1",
        "pdf": "https://arxiv.org/pdf/2602.16673v1"
      },
      "arxiv_id": "2602.16673v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16671v1",
      "title": "SPARC: Scenario Planning and Reasoning for Automated C Unit Test Generation",
      "authors": [
        "Jaid Monwar Chowdhury",
        "Chi-An Fu",
        "Reyhaneh Jabbarvand"
      ],
      "abstract": "Automated unit test generation for C remains a formidable challenge due to the semantic gap between high-level program intent and the rigid syntactic constraints of pointer arithmetic and manual memory management. While Large Language Models (LLMs) exhibit strong generative capabilities, direct intent-to-code synthesis frequently suffers from the leap-to-code failure mode, where models prematurely emit code without grounding in program structure, constraints, and semantics. This will result in non-compilable tests, hallucinated function signatures, low branch coverage, and semantically irrelevant assertions that cannot properly capture bugs. We introduce SPARC, a neuro-symbolic, scenario-based framework that bridges this gap through four stages: (1) Control Flow Graph (CFG) analysis, (2) an Operation Map that grounds LLM reasoning in validated utility helpers, (3) Path-targeted test synthesis, and (4) an iterative, self-correction validation loop using compiler and runtime feedback. We evaluate SPARC on 59 real-world and algorithmic subjects, where it outperforms the vanilla prompt generation baseline by 31.36% in line coverage, 26.01% in branch coverage, and 20.78% in mutation score, matching or exceeding the symbolic execution tool KLEE on complex subjects. SPARC retains 94.3% of tests through iterative repair and produces code with significantly higher developer-rated readability and maintainability. By aligning LLM reasoning with program structure, SPARC provides a scalable path for industrial-grade testing of legacy C codebases.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16671v1",
        "pdf": "https://arxiv.org/pdf/2602.16671v1"
      },
      "arxiv_id": "2602.16671v1",
      "comment": "9 pages, 6 figures, 4 tables",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16669v1",
      "title": "PredMapNet: Future and Historical Reasoning for Consistent Online HD Vectorized Map Construction",
      "authors": [
        "Bo Lang",
        "Nirav Savaliya",
        "Zhihao Zheng",
        "Jinglun Feng",
        "Zheng-Hang Yeh",
        "Mooi Choo Chuah"
      ],
      "abstract": "High-definition (HD) maps are crucial to autonomous driving, providing structured representations of road elements to support navigation and planning. However, existing query-based methods often employ random query initialization and depend on implicit temporal modeling, which lead to temporal inconsistencies and instabilities during the construction of a global map. To overcome these challenges, we introduce a novel end-to-end framework for consistent online HD vectorized map construction, which jointly performs map instance tracking and short-term prediction. First, we propose a Semantic-Aware Query Generator that initializes queries with spatially aligned semantic masks to capture scene-level context globally. Next, we design a History Rasterized Map Memory to store fine-grained instance-level maps for each tracked instance, enabling explicit historical priors. A History-Map Guidance Module then integrates rasterized map information into track queries, improving temporal continuity. Finally, we propose a Short-Term Future Guidance module to forecast the immediate motion of map instances based on the stored history trajectories. These predicted future locations serve as hints for tracked instances to further avoid implausible predictions and keep temporal consistency. Extensive experiments on the nuScenes and Argoverse2 datasets demonstrate that our proposed method outperforms state-of-the-art (SOTA) methods with good efficiency.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16669v1",
        "pdf": "https://arxiv.org/pdf/2602.16669v1"
      },
      "arxiv_id": "2602.16669v1",
      "comment": "WACV 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16666v1",
      "title": "Towards a Science of AI Agent Reliability",
      "authors": [
        "Stephan Rabanser",
        "Sayash Kapoor",
        "Peter Kirgis",
        "Kangheng Liu",
        "Saiteja Utpala",
        "Arvind Narayanan"
      ],
      "abstract": "AI agents are increasingly deployed to execute important tasks. While rising accuracy scores on standard benchmarks suggest rapid progress, many agents still continue to fail in practice. This discrepancy highlights a fundamental limitation of current evaluations: compressing agent behavior into a single success metric obscures critical operational flaws. Notably, it ignores whether agents behave consistently across runs, withstand perturbations, fail predictably, or have bounded error severity. Grounded in safety-critical engineering, we provide a holistic performance profile by proposing twelve concrete metrics that decompose agent reliability along four key dimensions: consistency, robustness, predictability, and safety. Evaluating 14 agentic models across two complementary benchmarks, we find that recent capability gains have only yielded small improvements in reliability. By exposing these persistent limitations, our metrics complement traditional evaluations while offering tools for reasoning about how agents perform, degrade, and fail.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16666v1",
        "pdf": "https://arxiv.org/pdf/2602.16666v1"
      },
      "arxiv_id": "2602.16666v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16664v1",
      "title": "Unpaired Image-to-Image Translation via a Self-Supervised Semantic Bridge",
      "authors": [
        "Jiaming Liu",
        "Felix Petersen",
        "Yunhe Gao",
        "Yabin Zhang",
        "Hyojin Kim",
        "Akshay S. Chaudhari",
        "Yu Sun",
        "Stefano Ermon",
        "Sergios Gatidis"
      ],
      "abstract": "Adversarial diffusion and diffusion-inversion methods have advanced unpaired image-to-image translation, but each faces key limitations. Adversarial approaches require target-domain adversarial loss during training, which can limit generalization to unseen data, while diffusion-inversion methods often produce low-fidelity translations due to imperfect inversion into noise-latent representations. In this work, we propose the Self-Supervised Semantic Bridge (SSB), a versatile framework that integrates external semantic priors into diffusion bridge models to enable spatially faithful translation without cross-domain supervision. Our key idea is to leverage self-supervised visual encoders to learn representations that are invariant to appearance changes but capture geometric structure, forming a shared latent space that conditions the diffusion bridges. Extensive experiments show that SSB outperforms strong prior methods for challenging medical image synthesis in both in-domain and out-of-domain settings, and extends easily to high-quality text-guided editing.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16664v1",
        "pdf": "https://arxiv.org/pdf/2602.16664v1"
      },
      "arxiv_id": "2602.16664v1",
      "comment": "36 pages",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16660v1",
      "title": "Align Once, Benefit Multilingually: Enforcing Multilingual Consistency for LLM Safety Alignment",
      "authors": [
        "Yuyan Bu",
        "Xiaohao Liu",
        "ZhaoXing Ren",
        "Yaodong Yang",
        "Juntao Dai"
      ],
      "abstract": "The widespread deployment of large language models (LLMs) across linguistic communities necessitates reliable multilingual safety alignment. However, recent efforts to extend alignment to other languages often require substantial resources, either through large-scale, high-quality supervision in the target language or through pairwise alignment with high-resource languages, which limits scalability. In this work, we propose a resource-efficient method for improving multilingual safety alignment. We introduce a plug-and-play Multi-Lingual Consistency (MLC) loss that can be integrated into existing monolingual alignment pipelines. By improving collinearity between multilingual representation vectors, our method encourages directional consistency at the multilingual semantic level in a single update. This allows simultaneous alignment across multiple languages using only multilingual prompt variants without requiring additional response-level supervision in low-resource languages. We validate the proposed method across different model architectures and alignment paradigms, and demonstrate its effectiveness in enhancing multilingual safety with limited impact on general model utility. Further evaluation across languages and tasks indicates improved cross-lingual generalization, suggesting the proposed approach as a practical solution for multilingual consistency alignment under limited supervision.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16660v1",
        "pdf": "https://arxiv.org/pdf/2602.16660v1"
      },
      "arxiv_id": "2602.16660v1",
      "comment": "Accepted by ICLR 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16656v1",
      "title": "Investigating Nonlinear Quenching Effects on Polar Field Buildup in the Sun Using Physics-Informed Neural Networks",
      "authors": [
        "Jithu J. Athalathil",
        "Mohammed H. Talafha",
        "Bhargav Vaidya"
      ],
      "abstract": "The solar dynamo relies on the regeneration of the poloidal magnetic field through processes strongly modulated by nonlinear feedbacks such as tilt quenching (TQ) and latitude quenching (LQ). These mechanisms play a decisive role in regulating the buildup of the Sun's polar field and, in turn, the amplitude of future solar cycles. In this work, we employ Physics-Informed Neural Networks (PINN) to solve the surface flux transport (SFT) equation, embedding physical constraints directly into the neural network framework. By systematically varying transport parameters, we isolate the relative contributions of TQ and LQ to polar dipole buildup. We use the residual dipole moment as a diagnostic for cycle-to-cycle amplification and show that TQ suppression strengthens with increasing diffusivity, while LQ dominates in advection-dominated regimes. The ratio $ΔD_{\\mathrm{LQ}}/ΔD_{\\mathrm{TQ}}$ exhibits a smooth inverse-square dependence on the dynamo effectivity range, refining previous empirical fits with improved accuracy and reduced scatter. The results further reveal that the need for a decay term is not essential for PINN set-up due to the training process. Compared with the traditional 1D SFT model, the PINN framework achieves significantly lower error metrics and more robust recovery of nonlinear trends. Our results suggest that the nonlinear interplay between LQ and TQ can naturally produce alternations between weak and strong cycles, providing a physical explanation for the observed even-odd cycle modulation. These findings demonstrate the potential of PINN as an accurate, efficient, and physically consistent tool for solar cycle prediction.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "astro-ph.SR",
        "cs.LG"
      ],
      "primary_category": "astro-ph.SR",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16656v1",
        "pdf": "https://arxiv.org/pdf/2602.16656v1"
      },
      "arxiv_id": "2602.16656v1",
      "comment": "Accepted for publication in The Astrophysical Journal",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16653v1",
      "title": "Agent Skill Framework: Perspectives on the Potential of Small Language Models in Industrial Environments",
      "authors": [
        "Yangjie Xu",
        "Lujun Li",
        "Lama Sleem",
        "Niccolo Gentile",
        "Yewei Song",
        "Yiqun Wang",
        "Siming Ji",
        "Wenbo Wu",
        "Radu State"
      ],
      "abstract": "Agent Skill framework, now widely and officially supported by major players such as GitHub Copilot, LangChain, and OpenAI, performs especially well with proprietary models by improving context engineering, reducing hallucinations, and boosting task accuracy. Based on these observations, an investigation is conducted to determine whether the Agent Skill paradigm provides similar benefits to small language models (SLMs). This question matters in industrial scenarios where continuous reliance on public APIs is infeasible due to data-security and budget constraints requirements, and where SLMs often show limited generalization in highly customized scenarios. This work introduces a formal mathematical definition of the Agent Skill process, followed by a systematic evaluation of language models of varying sizes across multiple use cases. The evaluation encompasses two open-source tasks and a real-world insurance claims data set. The results show that tiny models struggle with reliable skill selection, while moderately sized SLMs (approximately 12B - 30B) parameters) benefit substantially from the Agent Skill approach. Moreover, code-specialized variants at around 80B parameters achieve performance comparable to closed-source baselines while improving GPU efficiency. Collectively, these findings provide a comprehensive and nuanced characterization of the capabilities and constraints of the framework, while providing actionable insights for the effective deployment of Agent Skills in SLM-centered environments.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16653v1",
        "pdf": "https://arxiv.org/pdf/2602.16653v1"
      },
      "arxiv_id": "2602.16653v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16650v1",
      "title": "Retrieval Augmented Generation of Literature-derived Polymer Knowledge: The Example of a Biodegradable Polymer Expert System",
      "authors": [
        "Sonakshi Gupta",
        "Akhlak Mahmood",
        "Wei Xiong",
        "Rampi Ramprasad"
      ],
      "abstract": "Polymer literature contains a large and growing body of experimental knowledge, yet much of it is buried in unstructured text and inconsistent terminology, making systematic retrieval and reasoning difficult. Existing tools typically extract narrow, study-specific facts in isolation, failing to preserve the cross-study context required to answer broader scientific questions. Retrieval-augmented generation (RAG) offers a promising way to overcome this limitation by combining large language models (LLMs) with external retrieval, but its effectiveness depends strongly on how domain knowledge is represented. In this work, we develop two retrieval pipelines: a dense semantic vector-based approach (VectorRAG) and a graph-based approach (GraphRAG). Using over 1,000 polyhydroxyalkanoate (PHA) papers, we construct context-preserving paragraph embeddings and a canonicalized structured knowledge graph supporting entity disambiguation and multi-hop reasoning. We evaluate these pipelines through standard retrieval metrics, comparisons with general state-of-the-art systems such as GPT and Gemini, and qualitative validation by a domain chemist. The results show that GraphRAG achieves higher precision and interpretability, while VectorRAG provides broader recall, highlighting complementary trade-offs. Expert validation further confirms that the tailored pipelines, particularly GraphRAG, produce well-grounded, citation-reliable responses with strong domain relevance. By grounding every statement in evidence, these systems enable researchers to navigate the literature, compare findings across studies, and uncover patterns that are difficult to extract manually. More broadly, this work establishes a practical framework for building materials science assistants using curated corpora and retrieval design, reducing reliance on proprietary models while enabling trustworthy literature analysis at scale.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.CE",
        "cs.AI"
      ],
      "primary_category": "cs.CE",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16650v1",
        "pdf": "https://arxiv.org/pdf/2602.16650v1"
      },
      "arxiv_id": "2602.16650v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16643v1",
      "title": "Factorization Machine with Quadratic-Optimization Annealing for RNA Inverse Folding and Evaluation of Binary-Integer Encoding and Nucleotide Assignment",
      "authors": [
        "Shuta Kikuchi",
        "Shu Tanaka"
      ],
      "abstract": "The RNA inverse folding problem aims to identify nucleotide sequences that preferentially adopt a given target secondary structure. While various heuristic and machine learning-based approaches have been proposed, many require a large number of sequence evaluations, which limits their applicability when experimental validation is costly. We propose a method to solve the problem using a factorization machine with quadratic-optimization annealing (FMQA). FMQA is a discrete black-box optimization method reported to obtain high-quality solutions with a limited number of evaluations. Applying FMQA to the problem requires converting nucleotides into binary variables. However, the influence of integer-to-nucleotide assignments and binary-integer encoding on the performance of FMQA has not been thoroughly investigated, even though such choices determine the structure of the surrogate model and the search landscape, and thus can directly affect solution quality. Therefore, this study aims both to establish a novel FMQA framework for RNA inverse folding and to analyze the effects of these assignments and encoding methods. We evaluated all 24 possible assignments of the four nucleotides to the ordered integers (0-3), in combination with four binary-integer encoding methods. Our results demonstrated that one-hot and domain-wall encodings outperform binary and unary encodings in terms of the normalized ensemble defect value. In domain-wall encoding, nucleotides assigned to the boundary integers (0 and 3) appeared with higher frequency. In the RNA inverse folding problem, assigning guanine and cytosine to these boundary integers promoted their enrichment in stem regions, which led to more thermodynamically stable secondary structures than those obtained with one-hot encoding.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.LG",
        "cond-mat.stat-mech"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16643v1",
        "pdf": "https://arxiv.org/pdf/2602.16643v1"
      },
      "arxiv_id": "2602.16643v1",
      "comment": "17 pages, 10 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16642v1",
      "title": "Optimizer choice matters for the emergence of Neural Collapse",
      "authors": [
        "Jim Zhao",
        "Tin Sum Cheng",
        "Wojciech Masarczyk",
        "Aurelien Lucchi"
      ],
      "abstract": "Neural Collapse (NC) refers to the emergence of highly symmetric geometric structures in the representations of deep neural networks during the terminal phase of training. Despite its prevalence, the theoretical understanding of NC remains limited. Existing analyses largely ignore the role of the optimizer, thereby suggesting that NC is universal across optimization methods. In this work, we challenge this assumption and demonstrate that the choice of optimizer plays a critical role in the emergence of NC. The phenomenon is typically quantified through NC metrics, which, however, are difficult to track and analyze theoretically. To overcome this limitation, we introduce a novel diagnostic metric, NC0, whose convergence to zero is a necessary condition for NC. Using NC0, we provide theoretical evidence that NC cannot emerge under decoupled weight decay in adaptive optimizers, as implemented in AdamW. Concretely, we prove that SGD, SignGD with coupled weight decay (a special case of Adam), and SignGD with decoupled weight decay (a special case of AdamW) exhibit qualitatively different NC0 dynamics. Also, we show the accelerating effect of momentum on NC (beyond convergence of train loss) when trained with SGD, being the first result concerning momentum in the context of NC. Finally, we conduct extensive empirical experiments consisting of 3,900 training runs across various datasets, architectures, optimizers, and hyperparameters, confirming our theoretical results. This work provides the first theoretical explanation for optimizer-dependent emergence of NC and highlights the overlooked role of weight-decay coupling in shaping the implicit biases of optimizers.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16642v1",
        "pdf": "https://arxiv.org/pdf/2602.16642v1"
      },
      "arxiv_id": "2602.16642v1",
      "comment": "Published as a conference paper at ICLR 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16634v1",
      "title": "Enhanced Diffusion Sampling: Efficient Rare Event Sampling and Free Energy Calculation with Diffusion Models",
      "authors": [
        "Yu Xie",
        "Ludwig Winkler",
        "Lixin Sun",
        "Sarah Lewis",
        "Adam E. Foster",
        "José Jiménez Luna",
        "Tim Hempel",
        "Michael Gastegger",
        "Yaoyi Chen",
        "Iryna Zaporozhets",
        "Cecilia Clementi",
        "Christopher M. Bishop",
        "Frank Noé"
      ],
      "abstract": "The rare-event sampling problem has long been the central limiting factor in molecular dynamics (MD), especially in biomolecular simulation. Recently, diffusion models such as BioEmu have emerged as powerful equilibrium samplers that generate independent samples from complex molecular distributions, eliminating the cost of sampling rare transition events. However, a sampling problem remains when computing observables that rely on states which are rare in equilibrium, for example folding free energies. Here, we introduce enhanced diffusion sampling, enabling efficient exploration of rare-event regions while preserving unbiased thermodynamic estimators. The key idea is to perform quantitatively accurate steering protocols to generate biased ensembles and subsequently recover equilibrium statistics via exact reweighting. We instantiate our framework in three algorithms: UmbrellaDiff (umbrella sampling with diffusion models), $Δ$G-Diff (free-energy differences via tilted ensembles), and MetaDiff (a batchwise analogue for metadynamics). Across toy systems, protein folding landscapes and folding free energies, our methods achieve fast, accurate, and scalable estimation of equilibrium properties within GPU-minutes to hours per system -- closing the rare-event sampling gap that remained after the advent of diffusion-model equilibrium samplers.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "physics.bio-ph",
        "physics.chem-ph"
      ],
      "primary_category": "stat.ML",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16634v1",
        "pdf": "https://arxiv.org/pdf/2602.16634v1"
      },
      "arxiv_id": "2602.16634v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16629v1",
      "title": "Almost Sure Convergence of Differential Temporal Difference Learning for Average Reward Markov Decision Processes",
      "authors": [
        "Ethan Blaser",
        "Jiuqi Wang",
        "Shangtong Zhang"
      ],
      "abstract": "The average reward is a fundamental performance metric in reinforcement learning (RL) focusing on the long-run performance of an agent. Differential temporal difference (TD) learning algorithms are a major advance for average reward RL as they provide an efficient online method to learn the value functions associated with the average reward in both on-policy and off-policy settings. However, existing convergence guarantees require a local clock in learning rates tied to state visit counts, which practitioners do not use and does not extend beyond tabular settings. We address this limitation by proving the almost sure convergence of on-policy $n$-step differential TD for any $n$ using standard diminishing learning rates without a local clock. We then derive three sufficient conditions under which off-policy $n$-step differential TD also converges without a local clock. These results strengthen the theoretical foundations of differential TD and bring its convergence analysis closer to practical implementations.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16629v1",
        "pdf": "https://arxiv.org/pdf/2602.16629v1"
      },
      "arxiv_id": "2602.16629v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16626v1",
      "title": "A Systematic Evaluation of Sample-Level Tokenization Strategies for MEG Foundation Models",
      "authors": [
        "SungJun Cho",
        "Chetan Gohil",
        "Rukuang Huang",
        "Oiwi Parker Jones",
        "Mark W. Woolrich"
      ],
      "abstract": "Recent success in natural language processing has motivated growing interest in large-scale foundation models for neuroimaging data. Such models often require discretization of continuous neural time series data, a process referred to as 'tokenization'. However, the impact of different tokenization strategies for neural data is currently poorly understood. In this work, we present a systematic evaluation of sample-level tokenization strategies for transformer-based large neuroimaging models (LNMs) applied to magnetoencephalography (MEG) data. We compare learnable and non-learnable tokenizers by examining their signal reconstruction fidelity and their impact on subsequent foundation modeling performance (token prediction, biological plausibility of generated data, preservation of subject-specific information, and performance on downstream tasks). For the learnable tokenizer, we introduce a novel approach based on an autoencoder. Experiments were conducted on three publicly available MEG datasets spanning different acquisition sites, scanners, and experimental paradigms. Our results show that both learnable and non-learnable discretization schemes achieve high reconstruction accuracy and broadly comparable performance across most evaluation criteria, suggesting that simple fixed sample-level tokenization strategies can be used in the development of neural foundation models. The code is available at https://github.com/OHBA-analysis/Cho2026_Tokenizer.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16626v1",
        "pdf": "https://arxiv.org/pdf/2602.16626v1"
      },
      "arxiv_id": "2602.16626v1",
      "comment": "15 pages, 10 figures, 1 table",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16612v1",
      "title": "Causal and Compositional Abstraction",
      "authors": [
        "Robin Lorenz",
        "Sean Tull"
      ],
      "abstract": "Abstracting from a low level to a more explanatory high level of description, and ideally while preserving causal structure, is fundamental to scientific practice, to causal inference problems, and to robust, efficient and interpretable AI. We present a general account of abstractions between low and high level models as natural transformations, focusing on the case of causal models. This provides a new formalisation of causal abstraction, unifying several notions in the literature, including constructive causal abstraction, Q-$τ$ consistency, abstractions based on interchange interventions, and `distributed' causal abstractions. Our approach is formalised in terms of category theory, and uses the general notion of a compositional model with a given set of queries and semantics in a monoidal, cd- or Markov category; causal models and their queries such as interventions being special cases. We identify two basic notions of abstraction: downward abstractions mapping queries from high to low level; and upward abstractions, mapping concrete queries such as Do-interventions from low to high. Although usually presented as the latter, we show how common causal abstractions may, more fundamentally, be understood in terms of the former. Our approach also leads us to consider a new stronger notion of `component-level' abstraction, applying to the individual components of a model. In particular, this yields a novel, strengthened form of constructive causal abstraction at the mechanism-level, for which we prove characterisation results. Finally, we show that abstraction can be generalised to further compositional models, including those with a quantum semantics implemented by quantum circuits, and we take first steps in exploring abstractions between quantum compositional circuit models and high-level classical causal models as a means to explainable quantum AI.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.LO",
        "cs.AI",
        "math.CT",
        "quant-ph"
      ],
      "primary_category": "cs.LO",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16612v1",
        "pdf": "https://arxiv.org/pdf/2602.16612v1"
      },
      "arxiv_id": "2602.16612v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16611v1",
      "title": "Style-Aware Gloss Control for Generative Non-Photorealistic Rendering",
      "authors": [
        "Santiago Jimenez-Navarro",
        "Belen Masia",
        "Ana Serrano"
      ],
      "abstract": "Humans can infer material characteristics of objects from their visual appearance, and this ability extends to artistic depictions, where similar perceptual strategies guide the interpretation of paintings or drawings. Among the factors that define material appearance, gloss, along with color, is widely regarded as one of the most important, and recent studies indicate that humans can perceive gloss independently of the artistic style used to depict an object. To investigate how gloss and artistic style are represented in learned models, we train an unsupervised generative model on a newly curated dataset of painterly objects designed to systematically vary such factors. Our analysis reveals a hierarchical latent space in which gloss is disentangled from other appearance factors, allowing for a detailed study of how gloss is represented and varies across artistic styles. Building on this representation, we introduce a lightweight adapter that connects our style- and gloss-aware latent space to a latent-diffusion model, enabling the synthesis of non-photorealistic images with fine-grained control of these factors. We compare our approach with previous models and observe improved disentanglement and controllability of the learned factors.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.GR",
        "cs.CV"
      ],
      "primary_category": "cs.GR",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16611v1",
        "pdf": "https://arxiv.org/pdf/2602.16611v1"
      },
      "arxiv_id": "2602.16611v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16610v1",
      "title": "Who can we trust? LLM-as-a-jury for Comparative Assessment",
      "authors": [
        "Mengjie Qian",
        "Guangzhi Sun",
        "Mark J. F. Gales",
        "Kate M. Knill"
      ],
      "abstract": "Large language models (LLMs) are increasingly applied as automatic evaluators for natural language generation assessment often using pairwise comparative judgements. Existing approaches typically rely on single judges or aggregate multiple judges assuming equal reliability. In practice, LLM judges vary substantially in performance across tasks and aspects, and their judgment probabilities may be biased and inconsistent. Furthermore, human-labelled supervision for judge calibration may be unavailable. We first empirically demonstrate that inconsistencies in LLM comparison probabilities exist and show that it limits the effectiveness of direct probability-based ranking. To address this, we study the LLM-as-a-jury setting and propose BT-sigma, a judge-aware extension of the Bradley-Terry model that introduces a discriminator parameter for each judge to jointly infer item rankings and judge reliability from pairwise comparisons alone. Experiments on benchmark NLG evaluation datasets show that BT-sigma consistently outperforms averaging-based aggregation methods, and that the learned discriminator strongly correlates with independent measures of the cycle consistency of LLM judgments. Further analysis reveals that BT-sigma can be interpreted as an unsupervised calibration mechanism that improves aggregation by modelling judge reliability.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16610v1",
        "pdf": "https://arxiv.org/pdf/2602.16610v1"
      },
      "arxiv_id": "2602.16610v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16608v1",
      "title": "Explainable AI: Context-Aware Layer-Wise Integrated Gradients for Explaining Transformer Models",
      "authors": [
        "Melkamu Abay Mersha",
        "Jugal Kalita"
      ],
      "abstract": "Transformer models achieve state-of-the-art performance across domains and tasks, yet their deeply layered representations make their predictions difficult to interpret. Existing explainability methods rely on final-layer attributions, capture either local token-level attributions or global attention patterns without unification, and lack context-awareness of inter-token dependencies and structural components. They also fail to capture how relevance evolves across layers and how structural components shape decision-making. To address these limitations, we proposed the \\textbf{Context-Aware Layer-wise Integrated Gradients (CA-LIG) Framework}, a unified hierarchical attribution framework that computes layer-wise Integrated Gradients within each Transformer block and fuses these token-level attributions with class-specific attention gradients. This integration yields signed, context-sensitive attribution maps that capture supportive and opposing evidence while tracing the hierarchical flow of relevance through the Transformer layers. We evaluate the CA-LIG Framework across diverse tasks, domains, and transformer model families, including sentiment analysis and long and multi-class document classification with BERT, hate speech detection in a low-resource language setting with XLM-R and AfroLM, and image classification with Masked Autoencoder vision Transformer model. Across all tasks and architectures, CA-LIG provides more faithful attributions, shows stronger sensitivity to contextual dependencies, and produces clearer, more semantically coherent visualizations than established explainability methods. These results indicate that CA-LIG provides a more comprehensive, context-aware, and reliable explanation of Transformer decision-making, advancing both the practical interpretability and conceptual understanding of deep neural models.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16608v1",
        "pdf": "https://arxiv.org/pdf/2602.16608v1"
      },
      "arxiv_id": "2602.16608v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16603v1",
      "title": "FlowPrefill: Decoupling Preemption from Prefill Scheduling Granularity to Mitigate Head-of-Line Blocking in LLM Serving",
      "authors": [
        "Chia-chi Hsieh",
        "Zan Zong",
        "Xinyang Chen",
        "Jianjiang Li",
        "Jidong Zhai",
        "Lijie Wen"
      ],
      "abstract": "The growing demand for large language models (LLMs) requires serving systems to handle many concurrent requests with diverse service level objectives (SLOs). This exacerbates head-of-line (HoL) blocking during the compute-intensive prefill phase, where long-running requests monopolize resources and delay higher-priority ones, leading to widespread time-to-first-token (TTFT) SLO violations. While chunked prefill enables interruptibility, it introduces an inherent trade-off between responsiveness and throughput: reducing chunk size improves response latency but degrades computational efficiency, whereas increasing chunk size maximizes throughput but exacerbates blocking. This necessitates an adaptive preemption mechanism. However, dynamically balancing execution granularity against scheduling overheads remains a key challenge.\n  In this paper, we propose FlowPrefill, a TTFT-goodput-optimized serving system that resolves this conflict by decoupling preemption granularity from scheduling frequency. To achieve adaptive prefill scheduling, FlowPrefill introduces two key innovations: 1) Operator-Level Preemption, which leverages operator boundaries to enable fine-grained execution interruption without the efficiency loss associated with fixed small chunking; and 2) Event-Driven Scheduling, which triggers scheduling decisions only upon request arrival or completion events, thereby supporting efficient preemption responsiveness while minimizing control-plane overhead. Evaluation on real-world production traces shows that FlowPrefill improves maximum goodput by up to 5.6$\\times$ compared to state-of-the-art systems while satisfying heterogeneous SLOs.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16603v1",
        "pdf": "https://arxiv.org/pdf/2602.16603v1"
      },
      "arxiv_id": "2602.16603v1",
      "comment": "13 pages",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16601v1",
      "title": "Error Propagation and Model Collapse in Diffusion Models: A Theoretical Study",
      "authors": [
        "Nail B. Khelifa",
        "Richard E. Turner",
        "Ramji Venkataramanan"
      ],
      "abstract": "Machine learning models are increasingly trained or fine-tuned on synthetic data. Recursively training on such data has been observed to significantly degrade performance in a wide range of tasks, often characterized by a progressive drift away from the target distribution. In this work, we theoretically analyze this phenomenon in the setting of score-based diffusion models. For a realistic pipeline where each training round uses a combination of synthetic data and fresh samples from the target distribution, we obtain upper and lower bounds on the accumulated divergence between the generated and target distributions. This allows us to characterize different regimes of drift, depending on the score estimation error and the proportion of fresh data used in each generation. We also provide empirical results on synthetic data and images to illustrate the theory.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16601v1",
        "pdf": "https://arxiv.org/pdf/2602.16601v1"
      },
      "arxiv_id": "2602.16601v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16600v1",
      "title": "Predicting The Cop Number Using Machine Learning",
      "authors": [
        "Meagan Mann",
        "Christian Muise",
        "Erin Meger"
      ],
      "abstract": "Cops and Robbers is a pursuit evasion game played on a graph, first introduced independently by Quilliot \\cite{quilliot1978jeux} and Nowakowski and Winkler \\cite{NOWAKOWSKI1983235} over four decades ago. A main interest in recent the literature is identifying the cop number of graph families. The cop number of a graph, $c(G)$, is defined as the minimum number of cops required to guarantee capture of the robber. Determining the cop number is computationally difficult and exact algorithms for this are typically restricted to small graph families. This paper investigates whether classical machine learning methods and graph neural networks can accurately predict a graph's cop number from its structural properties and identify which properties most strongly influence this prediction. Of the classical machine learning models, tree-based models achieve high accuracy in prediction despite class imbalance, whereas graph neural networks achieve comparable results without explicit feature engineering. The interpretability analysis shows that the most predictive features are related to node connectivity, clustering, clique structure, and width parameters, which aligns with known theoretical results. Our findings suggest that machine learning approaches can be used in complement with existing cop number algorithms by offering scalable approximations where computation is infeasible.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16600v1",
        "pdf": "https://arxiv.org/pdf/2602.16600v1"
      },
      "arxiv_id": "2602.16600v1",
      "comment": "8 pages",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16596v1",
      "title": "Sequential Membership Inference Attacks",
      "authors": [
        "Thomas Michel",
        "Debabrota Basu",
        "Emilie Kaufmann"
      ],
      "abstract": "Modern AI models are not static. They go through multiple updates in their lifecycles. Thus, exploiting the model dynamics to create stronger Membership Inference (MI) attacks and tighter privacy audits are timely questions. Though the literature empirically shows that using a sequence of model updates can increase the power of MI attacks, rigorous analysis of the `optimal' MI attacks is limited to static models with infinite samples. Hence, we develop an `optimal' MI attack, SeMI*, that uses the sequence of model updates to identify the presence of a target inserted at a certain update step. For the empirical mean computation, we derive the optimal power of SeMI*, while accessing a finite number of samples with or without privacy. Our results retrieve the existing asymptotic analysis. We observe that having access to the model sequence avoids the dilution of MI signals unlike the existing attacks on the final model, where the MI signal vanishes as training data accumulates. Furthermore, an adversary can use SeMI* to tune both the insertion time and the canary to yield tighter privacy audits. Finally, we conduct experiments across data distributions and models trained or fine-tuned with DP-SGD demonstrating that practical variants of SeMI* lead to tighter privacy audits than the baselines.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.LG",
        "cs.CR",
        "math.ST",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16596v1",
        "pdf": "https://arxiv.org/pdf/2602.16596v1"
      },
      "arxiv_id": "2602.16596v1",
      "comment": "27 pages, 10 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16590v1",
      "title": "A Contrastive Learning Framework Empowered by Attention-based Feature Adaptation for Street-View Image Classification",
      "authors": [
        "Qi You",
        "Yitai Cheng",
        "Zichao Zeng",
        "James Haworth"
      ],
      "abstract": "Street-view image attribute classification is a vital downstream task of image classification, enabling applications such as autonomous driving, urban analytics, and high-definition map construction. It remains computationally demanding whether training from scratch, initialising from pre-trained weights, or fine-tuning large models. Although pre-trained vision-language models such as CLIP offer rich image representations, existing adaptation or fine-tuning methods often rely on their global image embeddings, limiting their ability to capture fine-grained, localised attributes essential in complex, cluttered street scenes. To address this, we propose CLIP-MHAdapter, a variant of the current lightweight CLIP adaptation paradigm that appends a bottleneck MLP equipped with multi-head self-attention operating on patch tokens to model inter-patch dependencies. With approximately 1.4 million trainable parameters, CLIP-MHAdapter achieves superior or competitive accuracy across eight attribute classification tasks on the Global StreetScapes dataset, attaining new state-of-the-art results while maintaining low computational cost. The code is available at https://github.com/SpaceTimeLab/CLIP-MHAdapter.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16590v1",
        "pdf": "https://arxiv.org/pdf/2602.16590v1"
      },
      "arxiv_id": "2602.16590v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16585v1",
      "title": "DataJoint 2.0: A Computational Substrate for Agentic Scientific Workflows",
      "authors": [
        "Dimitri Yatsenko",
        "Thinh T. Nguyen"
      ],
      "abstract": "Operational rigor determines whether human-agent collaboration succeeds or fails. Scientific data pipelines need the equivalent of DevOps -- SciOps -- yet common approaches fragment provenance across disconnected systems without transactional guarantees. DataJoint 2.0 addresses this gap through the relational workflow model: tables represent workflow steps, rows represent artifacts, foreign keys prescribe execution order. The schema specifies not only what data exists but how it is derived -- a single formal system where data structure, computational dependencies, and integrity constraints are all queryable, enforceable, and machine-readable. Four technical innovations extend this foundation: object-augmented schemas integrating relational metadata with scalable object storage, semantic matching using attribute lineage to prevent erroneous joins, an extensible type system for domain-specific formats, and distributed job coordination designed for composability with external orchestration. By unifying data structure, data, and computational transformations, DataJoint creates a substrate for SciOps where agents can participate in scientific workflows without risking data corruption.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16585v1",
        "pdf": "https://arxiv.org/pdf/2602.16585v1"
      },
      "arxiv_id": "2602.16585v1",
      "comment": "20 pages, 2 figures, 1 table",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16579v1",
      "title": "AIFL: A Global Daily Streamflow Forecasting Model Using Deterministic LSTM Pre-trained on ERA5-Land and Fine-tuned on IFS",
      "authors": [
        "Maria Luisa Taccari",
        "Kenza Tazi",
        "Oisín M. Morrison",
        "Andreas Grafberger",
        "Juan Colonese",
        "Corentin Carton de Wiart",
        "Christel Prudhomme",
        "Cinzia Mazzetti",
        "Matthew Chantry",
        "Florian Pappenberger"
      ],
      "abstract": "Reliable global streamflow forecasting is essential for flood preparedness and water resource management, yet data-driven models often suffer from a performance gap when transitioning from historical reanalysis to operational forecast products. This paper introduces AIFL (Artificial Intelligence for Floods), a deterministic LSTM-based model designed for global daily streamflow forecasting. Trained on 18,588 basins curated from the CARAVAN dataset, AIFL utilises a novel two-stage training strategy to bridge the reanalysis-to-forecast domain shift. The model is first pre-trained on 40 years of ERA5-Land reanalysis (1980-2019) to capture robust hydrological processes, then fine-tuned on operational Integrated Forecasting System (IFS) control forecasts (2016-2019) to adapt to the specific error structures and biases of operational numerical weather prediction. To our knowledge, this is the first global model trained end-to-end within the CARAVAN ecosystem. On an independent temporal test set (2021-2024), AIFL achieves high predictive skill with a median modified Kling-Gupta Efficiency (KGE') of 0.66 and a median Nash-Sutcliffe Efficiency (NSE) of 0.53. Benchmarking results show that AIFL is highly competitive with current state-of-the-art global systems, achieving comparable accuracy while maintaining a transparent and reproducible forcing pipeline. The model demonstrates exceptional reliability in extreme-event detection, providing a streamlined and operationally robust baseline for the global hydrological community.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.app-ph"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16579v1",
        "pdf": "https://arxiv.org/pdf/2602.16579v1"
      },
      "arxiv_id": "2602.16579v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16578v1",
      "title": "Creating a digital poet",
      "authors": [
        "Vered Tohar",
        "Tsahi Hayat",
        "Amir Leshem"
      ],
      "abstract": "Can a machine write good poetry? Any positive answer raises fundamental questions about the nature and value of art. We report a seven-month poetry workshop in which a large language model was shaped into a digital poet through iterative in-context expert feedback, without retraining. Across sessions, the model developed a distinctive style and a coherent corpus, supported by quantitative and qualitative analyses, and it produced a pen name and author image. In a blinded authorship test with 50 humanities students and graduates (three AI poems and three poems by well-known poets each), judgments were at chance: human poems were labeled human 54% of the time and AI poems 52%, with 95% confidence intervals including 50%. After the workshop, a commercial publisher released a poetry collection authored by the model. These results show that workshop-style prompting can support long-horizon creative shaping and renew debates on creativity and authorship.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16578v1",
        "pdf": "https://arxiv.org/pdf/2602.16578v1"
      },
      "arxiv_id": "2602.16578v1",
      "comment": "24 pages, 3 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16573v1",
      "title": "MoDE-Boost: Boosting Shared Mobility Demand with Edge-Ready Prediction Models",
      "authors": [
        "Antonios Tziorvas",
        "George S. Theodoropoulos",
        "Yannis Theodoridis"
      ],
      "abstract": "Urban demand forecasting plays a critical role in optimizing routing, dispatching, and congestion management within Intelligent Transportation Systems. By leveraging data fusion and analytics techniques, traffic demand forecasting serves as a key intermediate measure for identifying emerging spatial and temporal demand patterns. In this paper, we tackle this challenge by proposing two gradient boosting model variations, one for classiffication and one for regression, both capable of generating demand forecasts at various temporal horizons, from 5 minutes up to one hour. Our overall approach effectively integrates temporal and contextual features, enabling accurate predictions that are essential for improving the efficiency of shared (micro-) mobility services. To evaluate its effectiveness, we utilize open shared mobility data derived from e-scooter and e-bike networks in five metropolitan areas. These real-world datasets allow us to compare our approach with state-of-the-art methods as well as a Generative AI-based model, demonstrating its effectiveness in capturing the complexities of modern urban mobility. Ultimately, our methodology offers novel insights on urban micro-mobility management, helping to tackle the challenges arising from rapid urbanization and thus, contributing to more sustainable, efficient, and livable cities.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16573v1",
        "pdf": "https://arxiv.org/pdf/2602.16573v1"
      },
      "arxiv_id": "2602.16573v1",
      "comment": "25 pages",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16570v1",
      "title": "Steering diffusion models with quadratic rewards: a fine-grained analysis",
      "authors": [
        "Ankur Moitra",
        "Andrej Risteski",
        "Dhruv Rohatgi"
      ],
      "abstract": "Inference-time algorithms are an emerging paradigm in which pre-trained models are used as subroutines to solve downstream tasks. Such algorithms have been proposed for tasks ranging from inverse problems and guided image generation to reasoning. However, the methods currently deployed in practice are heuristics with a variety of failure modes -- and we have very little understanding of when these heuristics can be efficiently improved.\n  In this paper, we consider the task of sampling from a reward-tilted diffusion model -- that is, sampling from $p^{\\star}(x) \\propto p(x) \\exp(r(x))$ -- given a reward function $r$ and pre-trained diffusion oracle for $p$. We provide a fine-grained analysis of the computational tractability of this task for quadratic rewards $r(x) = x^\\top A x + b^\\top x$. We show that linear-reward tilts are always efficiently sampleable -- a simple result that seems to have gone unnoticed in the literature. We use this as a building block, along with a conceptually new ingredient -- the Hubbard-Stratonovich transform -- to provide an efficient algorithm for sampling from low-rank positive-definite quadratic tilts, i.e. $r(x) = x^\\top A x$ where $A$ is positive-definite and of rank $O(1)$. For negative-definite tilts, i.e. $r(x) = - x^\\top A x$ where $A$ is positive-definite, we prove that the problem is intractable even if $A$ is of rank 1 (albeit with exponentially-large entries).",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.LG",
        "cs.DS"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16570v1",
        "pdf": "https://arxiv.org/pdf/2602.16570v1"
      },
      "arxiv_id": "2602.16570v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16569v1",
      "title": "Arc2Morph: Identity-Preserving Facial Morphing with Arc2Face",
      "authors": [
        "Nicolò Di Domenico",
        "Annalisa Franco",
        "Matteo Ferrara",
        "Davide Maltoni"
      ],
      "abstract": "Face morphing attacks are widely recognized as one of the most challenging threats to face recognition systems used in electronic identity documents. These attacks exploit a critical vulnerability in passport enrollment procedures adopted by many countries, where the facial image is often acquired without a supervised live capture process. In this paper, we propose a novel face morphing technique based on Arc2Face, an identity-conditioned face foundation model capable of synthesizing photorealistic facial images from compact identity representations. We demonstrate the effectiveness of the proposed approach by comparing the morphing attack potential metric on two large-scale sequestered face morphing attack detection datasets against several state-of-the-art morphing methods, as well as on two novel morphed face datasets derived from FEI and ONOT. Experimental results show that the proposed deep learning-based approach achieves a morphing attack potential comparable to that of landmark-based techniques, which have traditionally been regarded as the most challenging. These findings confirm the ability of the proposed method to effectively preserve and manage identity information during the morph generation process.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.CV",
        "cs.CR"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16569v1",
        "pdf": "https://arxiv.org/pdf/2602.16569v1"
      },
      "arxiv_id": "2602.16569v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16568v1",
      "title": "Separating Oblivious and Adaptive Models of Variable Selection",
      "authors": [
        "Ziyun Chen",
        "Jerry Li",
        "Kevin Tian",
        "Yusong Zhu"
      ],
      "abstract": "Sparse recovery is among the most well-studied problems in learning theory and high-dimensional statistics. In this work, we investigate the statistical and computational landscapes of sparse recovery with $\\ell_\\infty$ error guarantees. This variant of the problem is motivated by \\emph{variable selection} tasks, where the goal is to estimate the support of a $k$-sparse signal in $\\mathbb{R}^d$. Our main contribution is a provable separation between the \\emph{oblivious} (``for each'') and \\emph{adaptive} (``for all'') models of $\\ell_\\infty$ sparse recovery. We show that under an oblivious model, the optimal $\\ell_\\infty$ error is attainable in near-linear time with $\\approx k\\log d$ samples, whereas in an adaptive model, $\\gtrsim k^2$ samples are necessary for any algorithm to achieve this bound. This establishes a surprising contrast with the standard $\\ell_2$ setting, where $\\approx k \\log d$ samples suffice even for adaptive sparse recovery. We conclude with a preliminary examination of a \\emph{partially-adaptive} model, where we show nontrivial variable selection guarantees are possible with $\\approx k\\log d$ measurements.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "math.ST",
        "cs.DS",
        "cs.LG",
        "math.OC",
        "stat.ML"
      ],
      "primary_category": "math.ST",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16568v1",
        "pdf": "https://arxiv.org/pdf/2602.16568v1"
      },
      "arxiv_id": "2602.16568v1",
      "comment": "40 pages",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16564v1",
      "title": "A Scalable Approach to Solving Simulation-Based Network Security Games",
      "authors": [
        "Michael Lanier",
        "Yevgeniy Vorobeychik"
      ],
      "abstract": "We introduce MetaDOAR, a lightweight meta-controller that augments the Double Oracle / PSRO paradigm with a learned, partition-aware filtering layer and Q-value caching to enable scalable multi-agent reinforcement learning on very large cyber-network environments. MetaDOAR learns a compact state projection from per node structural embeddings to rapidly score and select a small subset of devices (a top-k partition) on which a conventional low-level actor performs focused beam search utilizing a critic agent. Selected candidate actions are evaluated with batched critic forwards and stored in an LRU cache keyed by a quantized state projection and local action identifiers, dramatically reducing redundant critic computation while preserving decision quality via conservative k-hop cache invalidation. Empirically, MetaDOAR attains higher player payoffs than SOTA baselines on large network topologies, without significant scaling issues in terms of memory usage or training time. This contribution provide a practical, theoretically motivated path to efficient hierarchical policy learning for large-scale networked decision problems.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.LG",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16564v1",
        "pdf": "https://arxiv.org/pdf/2602.16564v1"
      },
      "arxiv_id": "2602.16564v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16558v1",
      "title": "Illustration of Barren Plateaus in Quantum Computing",
      "authors": [
        "Gerhard Stenzel",
        "Tobias Rohe",
        "Michael Kölle",
        "Leo Sünkel",
        "Jonas Stein",
        "Claudia Linnhoff-Popien"
      ],
      "abstract": "Variational Quantum Circuits (VQCs) have emerged as a promising paradigm for quantum machine learning in the NISQ era. While parameter sharing in VQCs can reduce the parameter space dimensionality and potentially mitigate the barren plateau phenomenon, it introduces a complex trade-off that has been largely overlooked. This paper investigates how parameter sharing, despite creating better global optima with fewer parameters, fundamentally alters the optimization landscape through deceptive gradients -- regions where gradient information exists but systematically misleads optimizers away from global optima. Through systematic experimental analysis, we demonstrate that increasing degrees of parameter sharing generate more complex solution landscapes with heightened gradient magnitudes and measurably higher deceptiveness ratios. Our findings reveal that traditional gradient-based optimizers (Adam, SGD) show progressively degraded convergence as parameter sharing increases, with performance heavily dependent on hyperparameter selection. We introduce a novel gradient deceptiveness detection algorithm and a quantitative framework for measuring optimization difficulty in quantum circuits, establishing that while parameter sharing can improve circuit expressivity by orders of magnitude, this comes at the cost of significantly increased landscape deceptiveness. These insights provide important considerations for quantum circuit design in practical applications, highlighting the fundamental mismatch between classical optimization strategies and quantum parameter landscapes shaped by parameter sharing.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.LG",
        "quant-ph"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16558v1",
        "pdf": "https://arxiv.org/pdf/2602.16558v1"
      },
      "arxiv_id": "2602.16558v1",
      "comment": "Extended version of a short paper to be published at ICAART-QAIO 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16555v1",
      "title": "Learning Distributed Equilibria in Linear-Quadratic Stochastic Differential Games: An $α$-Potential Approach",
      "authors": [
        "Philipp Plank",
        "Yufei Zhang"
      ],
      "abstract": "We analyze independent policy-gradient (PG) learning in $N$-player linear-quadratic (LQ) stochastic differential games. Each player employs a distributed policy that depends only on its own state and updates the policy independently using the gradient of its own objective. We establish global linear convergence of these methods to an equilibrium by showing that the LQ game admits an $α$-potential structure, with $α$ determined by the degree of pairwise interaction asymmetry. For pairwise-symmetric interactions, we construct an affine distributed equilibrium by minimizing the potential function and show that independent PG methods converge globally to this equilibrium, with complexity scaling linearly in the population size and logarithmically in the desired accuracy. For asymmetric interactions, we prove that independent projected PG algorithms converge linearly to an approximate equilibrium, with suboptimality proportional to the degree of asymmetry. Numerical experiments confirm the theoretical results across both symmetric and asymmetric interaction networks.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "math.OC",
        "cs.LG",
        "math.PR"
      ],
      "primary_category": "math.OC",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16555v1",
        "pdf": "https://arxiv.org/pdf/2602.16555v1"
      },
      "arxiv_id": "2602.16555v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16554v1",
      "title": "MerLean: An Agentic Framework for Autoformalization in Quantum Computation",
      "authors": [
        "Yuanjie Ren",
        "Jinzheng Li",
        "Yidi Qi"
      ],
      "abstract": "We introduce MerLean, a fully automated agentic framework for autoformalization in quantum computation. MerLean extracts mathematical statements from \\LaTeX{} source files, formalizes them into verified Lean~4 code built on Mathlib, and translates the result back into human-readable \\LaTeX{} for semantic review. We evaluate MerLean on three theoretical quantum computing papers producing 2,050 Lean declarations from 114 statements in total. MerLean achieves end-to-end formalization on all three papers, reducing the verification burden to only the newly introduced definitions and axioms. Our results demonstrate that agentic autoformalization can scale to frontier research, offering both a practical tool for machine-verified peer review and a scalable engine for mining high-quality synthetic data to train future reasoning models. Our approach can also be generalized to any other rigorous research in mathematics and theoretical physics.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.ET",
        "quant-ph"
      ],
      "primary_category": "cs.LO",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16554v1",
        "pdf": "https://arxiv.org/pdf/2602.16554v1"
      },
      "arxiv_id": "2602.16554v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16548v1",
      "title": "RIDER: 3D RNA Inverse Design with Reinforcement Learning-Guided Diffusion",
      "authors": [
        "Tianmeng Hu",
        "Yongzheng Cui",
        "Biao Luo",
        "Ke Li"
      ],
      "abstract": "The inverse design of RNA three-dimensional (3D) structures is crucial for engineering functional RNAs in synthetic biology and therapeutics. While recent deep learning approaches have advanced this field, they are typically optimized and evaluated using native sequence recovery, which is a limited surrogate for structural fidelity, since different sequences can fold into similar 3D structures and high recovery does not necessarily indicate correct folding. To address this limitation, we propose RIDER, an RNA Inverse DEsign framework with Reinforcement learning that directly optimizes for 3D structural similarity. First, we develop and pre-train a GNN-based generative diffusion model conditioned on the target 3D structure, achieving a 9% improvement in native sequence recovery over state-of-the-art methods. Then, we fine-tune the model with an improved policy gradient algorithm using four task-specific reward functions based on 3D self-consistency metrics. Experimental results show that RIDER improves structural similarity by over 100% across all metrics and discovers designs that are distinct from native sequences.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16548v1",
        "pdf": "https://arxiv.org/pdf/2602.16548v1"
      },
      "arxiv_id": "2602.16548v1",
      "comment": "Accepted as a conference paper at ICLR 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16545v1",
      "title": "Let's Split Up: Zero-Shot Classifier Edits for Fine-Grained Video Understanding",
      "authors": [
        "Kaiting Liu",
        "Hazel Doughty"
      ],
      "abstract": "Video recognition models are typically trained on fixed taxonomies which are often too coarse, collapsing distinctions in object, manner or outcome under a single label. As tasks and definitions evolve, such models cannot accommodate emerging distinctions and collecting new annotations and retraining to accommodate such changes is costly. To address these challenges, we introduce category splitting, a new task where an existing classifier is edited to refine a coarse category into finer subcategories, while preserving accuracy elsewhere. We propose a zero-shot editing method that leverages the latent compositional structure of video classifiers to expose fine-grained distinctions without additional data. We further show that low-shot fine-tuning, while simple, is highly effective and benefits from our zero-shot initialization. Experiments on our new video benchmarks for category splitting demonstrate that our method substantially outperforms vision-language baselines, improving accuracy on the newly split categories without sacrificing performance on the rest. Project page: https://kaitingliu.github.io/Category-Splitting/.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16545v1",
        "pdf": "https://arxiv.org/pdf/2602.16545v1"
      },
      "arxiv_id": "2602.16545v1",
      "comment": "ICLR 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16543v1",
      "title": "Vulnerability Analysis of Safe Reinforcement Learning via Inverse Constrained Reinforcement Learning",
      "authors": [
        "Jialiang Fan",
        "Shixiong Jiang",
        "Mengyu Liu",
        "Fanxin Kong"
      ],
      "abstract": "Safe reinforcement learning (Safe RL) aims to ensure policy performance while satisfying safety constraints. However, most existing Safe RL methods assume benign environments, making them vulnerable to adversarial perturbations commonly encountered in real-world settings. In addition, existing gradient-based adversarial attacks typically require access to the policy's gradient information, which is often impractical in real-world scenarios. To address these challenges, we propose an adversarial attack framework to reveal vulnerabilities of Safe RL policies. Using expert demonstrations and black-box environment interaction, our framework learns a constraint model and a surrogate (learner) policy, enabling gradient-based attack optimization without requiring the victim policy's internal gradients or the ground-truth safety constraints. We further provide theoretical analysis establishing feasibility and deriving perturbation bounds. Experiments on multiple Safe RL benchmarks demonstrate the effectiveness of our approach under limited privileged access.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16543v1",
        "pdf": "https://arxiv.org/pdf/2602.16543v1"
      },
      "arxiv_id": "2602.16543v1",
      "comment": "12 pages, 6 figures, supplementary material included",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16537v1",
      "title": "Optimal training-conditional regret for online conformal prediction",
      "authors": [
        "Jiadong Liang",
        "Zhimei Ren",
        "Yuxin Chen"
      ],
      "abstract": "We study online conformal prediction for non-stationary data streams subject to unknown distribution drift. While most prior work studied this problem under adversarial settings and/or assessed performance in terms of gaps of time-averaged marginal coverage, we instead evaluate performance through training-conditional cumulative regret. We specifically focus on independently generated data with two types of distribution shift: abrupt change points and smooth drift.\n  When non-conformity score functions are pretrained on an independent dataset, we propose a split-conformal style algorithm that leverages drift detection to adaptively update calibration sets, which provably achieves minimax-optimal regret. When non-conformity scores are instead trained online, we develop a full-conformal style algorithm that again incorporates drift detection to handle non-stationarity; this approach relies on stability - rather than permutation symmetry - of the model-fitting algorithm, which is often better suited to online learning under evolving environments. We establish non-asymptotic regret guarantees for our online full conformal algorithm, which match the minimax lower bound under appropriate restrictions on the prediction sets. Numerical experiments corroborate our theoretical findings.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "math.ST",
        "cs.IT",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "math.ST",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16537v1",
        "pdf": "https://arxiv.org/pdf/2602.16537v1"
      },
      "arxiv_id": "2602.16537v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16531v1",
      "title": "Transfer Learning of Linear Regression with Multiple Pretrained Models: Benefiting from More Pretrained Models via Overparameterization Debiasing",
      "authors": [
        "Daniel Boharon",
        "Yehuda Dar"
      ],
      "abstract": "We study transfer learning for a linear regression task using several least-squares pretrained models that can be overparameterized.\n  We formulate the target learning task as optimization that minimizes squared errors on the target dataset with penalty on the distance of the learned model from the pretrained models. We analytically formulate the test error of the learned target model and provide the corresponding empirical evaluations.\n  Our results elucidate when using more pretrained models can improve transfer learning. Specifically, if the pretrained models are overparameterized, using sufficiently many of them is important for beneficial transfer learning. However, the learning may be compromised by overparameterization bias of pretrained models, i.e., the minimum $\\ell_2$-norm solution's restriction to a small subspace spanned by the training examples in the high-dimensional parameter space. We propose a simple debiasing via multiplicative correction factor that can reduce the overparameterization bias and leverage more pretrained models to learn a target predictor.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16531v1",
        "pdf": "https://arxiv.org/pdf/2602.16531v1"
      },
      "arxiv_id": "2602.16531v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16530v1",
      "title": "FEKAN: Feature-Enriched Kolmogorov-Arnold Networks",
      "authors": [
        "Sidharth S. Menon",
        "Ameya D. Jagtap"
      ],
      "abstract": "Kolmogorov-Arnold Networks (KANs) have recently emerged as a compelling alternative to multilayer perceptrons, offering enhanced interpretability via functional decomposition. However, existing KAN architectures, including spline-, wavelet-, radial-basis variants, etc., suffer from high computational cost and slow convergence, limiting scalability and practical applicability. Here, we introduce Feature-Enriched Kolmogorov-Arnold Networks (FEKAN), a simple yet effective extension that preserves all the advantages of KAN while improving computational efficiency and predictive accuracy through feature enrichment, without increasing the number of trainable parameters. By incorporating these additional features, FEKAN accelerates convergence, increases representation capacity, and substantially mitigates the computational overhead characteristic of state-of-the-art KAN architectures. We investigate FEKAN across a comprehensive set of benchmarks, including function-approximation tasks, physics-informed formulations for diverse partial differential equations (PDEs), and neural operator settings that map between input and output function spaces. For function approximation, we systematically compare FEKAN against a broad family of KAN variants, FastKAN, WavKAN, ReLUKAN, HRKAN, ChebyshevKAN, RBFKAN, and the original SplineKAN. Across all tasks, FEKAN demonstrates substantially faster convergence and consistently higher approximation accuracy than the underlying baseline architectures. We also establish the theoretical foundations for FEKAN, showing its superior representation capacity compared to KAN, which contributes to improved accuracy and efficiency.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.LG",
        "math-ph"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16530v1",
        "pdf": "https://arxiv.org/pdf/2602.16530v1"
      },
      "arxiv_id": "2602.16530v1",
      "comment": "45 pages, 45 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16525v1",
      "title": "Capacity-constrained demand response in smart grids using deep reinforcement learning",
      "authors": [
        "Shafagh Abband Pashaki",
        "Sepehr Maleki",
        "Amir Badiee"
      ],
      "abstract": "This paper presents a capacity-constrained incentive-based demand response approach for residential smart grids. It aims to maintain electricity grid capacity limits and prevent congestion by financially incentivising end users to reduce or shift their energy consumption. The proposed framework adopts a hierarchical architecture in which a service provider adjusts hourly incentive rates based on wholesale electricity prices and aggregated residential load. The financial interests of both the service provider and end users are explicitly considered. A deep reinforcement learning approach is employed to learn optimal real-time incentive rates under explicit capacity constraints. Heterogeneous user preferences are modelled through appliance-level home energy management systems and dissatisfaction costs. Using real-world residential electricity consumption and price data from three households, simulation results show that the proposed approach effectively reduces peak demand and smooths the aggregated load profile. This leads to an approximately 22.82% reduction in the peak-to-average ratio compared to the no-demand-response case.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16525v1",
        "pdf": "https://arxiv.org/pdf/2602.16525v1"
      },
      "arxiv_id": "2602.16525v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16523v1",
      "title": "Reinforcement Learning for Parameterized Quantum State Preparation: A Comparative Study",
      "authors": [
        "Gerhard Stenzel",
        "Isabella Debelic",
        "Michael Kölle",
        "Tobias Rohe",
        "Leo Sünkel",
        "Julian Hager",
        "Claudia Linnhoff-Popien"
      ],
      "abstract": "We extend directed quantum circuit synthesis (DQCS) with reinforcement learning from purely discrete gate selection to parameterized quantum state preparation with continuous single-qubit rotations \\(R_x\\), \\(R_y\\), and \\(R_z\\). We compare two training regimes: a one-stage agent that jointly selects the gate type, the affected qubit(s), and the rotation angle; and a two-stage variant that first proposes a discrete circuit and subsequently optimizes the rotation angles with Adam using parameter-shift gradients. Using Gymnasium and PennyLane, we evaluate Proximal Policy Optimization (PPO) and Advantage Actor--Critic (A2C) on systems comprising two to ten qubits and on targets of increasing complexity with \\(λ\\) ranging from one to five. Whereas A2C does not learn effective policies in this setting, PPO succeeds under stable hyperparameters (one-stage: learning rate approximately \\(5\\times10^{-4}\\) with a self-fidelity-error threshold of 0.01; two-stage: learning rate approximately \\(10^{-4}\\)). Both approaches reliably reconstruct computational basis states (between 83\\% and 99\\% success) and Bell states (between 61\\% and 77\\% success). However, scalability saturates for \\(λ\\) of approximately three to four and does not extend to ten-qubit targets even at \\(λ=2\\). The two-stage method offers only marginal accuracy gains while requiring around three times the runtime. For practicality under a fixed compute budget, we therefore recommend the one-stage PPO policy, provide explicit synthesized circuits, and contrast with a classical variational baseline to outline avenues for improved scalability.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.LG",
        "quant-ph"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16523v1",
        "pdf": "https://arxiv.org/pdf/2602.16523v1"
      },
      "arxiv_id": "2602.16523v1",
      "comment": "Extended version of a short paper to be published at ICAART 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16520v1",
      "title": "Recursive language models for jailbreak detection: a procedural defense for tool-augmented agents",
      "authors": [
        "Doron Shavit"
      ],
      "abstract": "Jailbreak prompts are a practical and evolving threat to large language models (LLMs), particularly in agentic systems that execute tools over untrusted content. Many attacks exploit long-context hiding, semantic camouflage, and lightweight obfuscations that can evade single-pass guardrails. We present RLM-JB, an end-to-end jailbreak detection framework built on Recursive Language Models (RLMs), in which a root model orchestrates a bounded analysis program that transforms the input, queries worker models over covered segments, and aggregates evidence into an auditable decision. RLM-JB treats detection as a procedure rather than a one-shot classification: it normalizes and de-obfuscates suspicious inputs, chunks text to reduce context dilution and guarantee coverage, performs parallel chunk screening, and composes cross-chunk signals to recover split-payload attacks. On AutoDAN-style adversarial inputs, RLM-JB achieves high detection effectiveness across three LLM backends (ASR/Recall 92.5-98.0%) while maintaining very high precision (98.99-100%) and low false positive rates (0.0-2.0%), highlighting a practical sensitivity-specificity trade-off as the screening backend changes.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16520v1",
        "pdf": "https://arxiv.org/pdf/2602.16520v1"
      },
      "arxiv_id": "2602.16520v1",
      "comment": "5 pages and 1 figure. Appendix: an additional 5 pages",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16512v1",
      "title": "Framework of Thoughts: A Foundation Framework for Dynamic and Optimized Reasoning based on Chains, Trees, and Graphs",
      "authors": [
        "Felix Fricke",
        "Simon Malberg",
        "Georg Groh"
      ],
      "abstract": "Prompting schemes such as Chain of Thought, Tree of Thoughts, and Graph of Thoughts can significantly enhance the reasoning capabilities of large language models. However, most existing schemes require users to define static, problem-specific reasoning structures that lack adaptability to dynamic or unseen problem types. Additionally, these schemes are often under-optimized in terms of hyperparameters, prompts, runtime, and prompting cost. To address these limitations, we introduce Framework of Thoughts (FoT)--a general-purpose foundation framework for building and optimizing dynamic reasoning schemes. FoT comes with built-in features for hyperparameter tuning, prompt optimization, parallel execution, and intelligent caching, unlocking the latent performance potential of reasoning schemes. We demonstrate FoT's capabilities by implementing three popular schemes--Tree of Thoughts, Graph of Thoughts, and ProbTree--within FoT. We empirically show that FoT enables significantly faster execution, reduces costs, and achieves better task scores through optimization. We release our codebase to facilitate the development of future dynamic and efficient reasoning schemes.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16512v1",
        "pdf": "https://arxiv.org/pdf/2602.16512v1"
      },
      "arxiv_id": "2602.16512v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16507v1",
      "title": "Small molecule retrieval from tandem mass spectrometry: what are we optimizing for?",
      "authors": [
        "Gaetan De Waele",
        "Marek Wydmuch",
        "Krzysztof Dembczyński",
        "Wojciech Kotłowski",
        "Willem Waegeman"
      ],
      "abstract": "One of the central challenges in the computational analysis of liquid chromatography-tandem mass spectrometry (LC-MS/MS) data is to identify the compounds underlying the output spectra. In recent years, this problem is increasingly tackled using deep learning methods. A common strategy involves predicting a molecular fingerprint vector from an input mass spectrum, which is then used to search for matches in a chemical compound database. While various loss functions are employed in training these predictive models, their impact on model performance remains poorly understood. In this study, we investigate commonly used loss functions, deriving novel regret bounds that characterize when Bayes-optimal decisions for these objectives must diverge. Our results reveal a fundamental trade-off between the two objectives of (1) fingerprint similarity and (2) molecular retrieval. Optimizing for more accurate fingerprint predictions typically worsens retrieval results, and vice versa. Our theoretical analysis shows this trade-off depends on the similarity structure of candidate sets, providing guidance for loss function and fingerprint selection.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16507v1",
        "pdf": "https://arxiv.org/pdf/2602.16507v1"
      },
      "arxiv_id": "2602.16507v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16505v1",
      "title": "Functional Decomposition and Shapley Interactions for Interpreting Survival Models",
      "authors": [
        "Sophie Hanna Langbein",
        "Hubert Baniecki",
        "Fabian Fumagalli",
        "Niklas Koenen",
        "Marvin N. Wright",
        "Julia Herbinger"
      ],
      "abstract": "Hazard and survival functions are natural, interpretable targets in time-to-event prediction, but their inherent non-additivity fundamentally limits standard additive explanation methods. We introduce Survival Functional Decomposition (SurvFD), a principled approach for analyzing feature interactions in machine learning survival models. By decomposing higher-order effects into time-dependent and time-independent components, SurvFD offers a previously unrecognized perspective on survival explanations, explicitly characterizing when and why additive explanations fail. Building on this theoretical decomposition, we propose SurvSHAP-IQ, which extends Shapley interactions to time-indexed functions, providing a practical estimator for higher-order, time-dependent interactions. Together, SurvFD and SurvSHAP-IQ establish an interaction- and time-aware interpretability approach for survival modeling, with broad applicability across time-to-event prediction tasks.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16505v1",
        "pdf": "https://arxiv.org/pdf/2602.16505v1"
      },
      "arxiv_id": "2602.16505v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16503v1",
      "title": "Interpretability-by-Design with Accurate Locally Additive Models and Conditional Feature Effects",
      "authors": [
        "Vasilis Gkolemis",
        "Loukas Kavouras",
        "Dimitrios Kyriakopoulos",
        "Konstantinos Tsopelas",
        "Dimitrios Rontogiannis",
        "Giuseppe Casalicchio",
        "Theodore Dalamagas",
        "Christos Diou"
      ],
      "abstract": "Generalized additive models (GAMs) offer interpretability through independent univariate feature effects but underfit when interactions are present in data. GA$^2$Ms add selected pairwise interactions which improves accuracy, but sacrifices interpretability and limits model auditing. We propose \\emph{Conditionally Additive Local Models} (CALMs), a new model class, that balances the interpretability of GAMs with the accuracy of GA$^2$Ms. CALMs allow multiple univariate shape functions per feature, each active in different regions of the input space. These regions are defined independently for each feature as simple logical conditions (thresholds) on the features it interacts with. As a result, effects remain locally additive while varying across subregions to capture interactions. We further propose a principled distillation-based training pipeline that identifies homogeneous regions with limited interactions and fits interpretable shape functions via region-aware backfitting. Experiments on diverse classification and regression tasks show that CALMs consistently outperform GAMs and achieve accuracy comparable with GA$^2$Ms. Overall, CALMs offer a compelling trade-off between predictive accuracy and interpretability.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16503v1",
        "pdf": "https://arxiv.org/pdf/2602.16503v1"
      },
      "arxiv_id": "2602.16503v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16502v1",
      "title": "DressWild: Feed-Forward Pose-Agnostic Garment Sewing Pattern Generation from In-the-Wild Images",
      "authors": [
        "Zeng Tao",
        "Ying Jiang",
        "Yunuo Chen",
        "Tianyi Xie",
        "Huamin Wang",
        "Yingnian Wu",
        "Yin Yang",
        "Abishek Sampath Kumar",
        "Kenji Tashiro",
        "Chenfanfu Jiang"
      ],
      "abstract": "Recent advances in garment pattern generation have shown promising progress. However, existing feed-forward methods struggle with diverse poses and viewpoints, while optimization-based approaches are computationally expensive and difficult to scale. This paper focuses on sewing pattern generation for garment modeling and fabrication applications that demand editable, separable, and simulation-ready garments. We propose DressWild, a novel feed-forward pipeline that reconstructs physics-consistent 2D sewing patterns and the corresponding 3D garments from a single in-the-wild image. Given an input image, our method leverages vision-language models (VLMs) to normalize pose variations at the image level, then extract pose-aware, 3D-informed garment features. These features are fused through a transformer-based encoder and subsequently used to predict sewing pattern parameters, which can be directly applied to physical simulation, texture synthesis, and multi-layer virtual try-on. Extensive experiments demonstrate that our approach robustly recovers diverse sewing patterns and the corresponding 3D garments from in-the-wild images without requiring multi-view inputs or iterative optimization, offering an efficient and scalable solution for realistic garment simulation and animation.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16502v1",
        "pdf": "https://arxiv.org/pdf/2602.16502v1"
      },
      "arxiv_id": "2602.16502v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16498v1",
      "title": "Fast and Scalable Analytical Diffusion",
      "authors": [
        "Xinyi Shang",
        "Peng Sun",
        "Jingyu Lin",
        "Zhiqiang Shen"
      ],
      "abstract": "Analytical diffusion models offer a mathematically transparent path to generative modeling by formulating the denoising score as an empirical-Bayes posterior mean. However, this interpretability comes at a prohibitive cost: the standard formulation necessitates a full-dataset scan at every timestep, scaling linearly with dataset size. In this work, we present the first systematic study addressing this scalability bottleneck. We challenge the prevailing assumption that the entire training data is necessary, uncovering the phenomenon of Posterior Progressive Concentration: the effective golden support of the denoising score is not static but shrinks asymptotically from the global manifold to a local neighborhood as the signal-to-noise ratio increases. Capitalizing on this, we propose Dynamic Time-Aware Golden Subset Diffusion (GoldDiff), a training-free framework that decouples inference complexity from dataset size. Instead of static retrieval, GoldDiff uses a coarse-to-fine mechanism to dynamically pinpoint the ''Golden Subset'' for inference. Theoretically, we derive rigorous bounds guaranteeing that our sparse approximation converges to the exact score. Empirically, GoldDiff achieves a $\\bf 71 \\times$ speedup on AFHQ while matching or achieving even better performance than full-scan baselines. Most notably, we demonstrate the first successful scaling of analytical diffusion to ImageNet-1K, unlocking a scalable, training-free paradigm for large-scale generative modeling.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16498v1",
        "pdf": "https://arxiv.org/pdf/2602.16498v1"
      },
      "arxiv_id": "2602.16498v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16494v1",
      "title": "Benchmarking Adversarial Robustness and Adversarial Training Strategies for Object Detection",
      "authors": [
        "Alexis Winter",
        "Jean-Vincent Martini",
        "Romaric Audigier",
        "Angelique Loesch",
        "Bertrand Luvison"
      ],
      "abstract": "Object detection models are critical components of automated systems, such as autonomous vehicles and perception-based robots, but their sensitivity to adversarial attacks poses a serious security risk. Progress in defending these models lags behind classification, hindered by a lack of standardized evaluation. It is nearly impossible to thoroughly compare attack or defense methods, as existing work uses different datasets, inconsistent efficiency metrics, and varied measures of perturbation cost. This paper addresses this gap by investigating three key questions: (1) How can we create a fair benchmark to impartially compare attacks? (2) How well do modern attacks transfer across different architectures, especially from Convolutional Neural Networks to Vision Transformers? (3) What is the most effective adversarial training strategy for robust defense? To answer these, we first propose a unified benchmark framework focused on digital, non-patch-based attacks. This framework introduces specific metrics to disentangle localization and classification errors and evaluates attack cost using multiple perceptual metrics. Using this benchmark, we conduct extensive experiments on state-of-the-art attacks and a wide range of detectors. Our findings reveal two major conclusions: first, modern adversarial attacks against object detection models show a significant lack of transferability to transformer-based architectures. Second, we demonstrate that the most robust adversarial training strategy leverages a dataset composed of a mix of high-perturbation attacks with different objectives (e.g., spatial and semantic), which outperforms training on any single attack.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16494v1",
        "pdf": "https://arxiv.org/pdf/2602.16494v1"
      },
      "arxiv_id": "2602.16494v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16493v1",
      "title": "MMA: Multimodal Memory Agent",
      "authors": [
        "Yihao Lu",
        "Wanru Cheng",
        "Zeyu Zhang",
        "Hao Tang"
      ],
      "abstract": "Long-horizon multimodal agents depend on external memory; however, similarity-based retrieval often surfaces stale, low-credibility, or conflicting items, which can trigger overconfident errors. We propose Multimodal Memory Agent (MMA), which assigns each retrieved memory item a dynamic reliability score by combining source credibility, temporal decay, and conflict-aware network consensus, and uses this signal to reweight evidence and abstain when support is insufficient. We also introduce MMA-Bench, a programmatically generated benchmark for belief dynamics with controlled speaker reliability and structured text-vision contradictions. Using this framework, we uncover the \"Visual Placebo Effect\", revealing how RAG-based agents inherit latent visual biases from foundation models. On FEVER, MMA matches baseline accuracy while reducing variance by 35.2% and improving selective utility; on LoCoMo, a safety-oriented configuration improves actionable accuracy and reduces wrong answers; on MMA-Bench, MMA reaches 41.18% Type-B accuracy in Vision mode, while the baseline collapses to 0.0% under the same protocol. Code: https://github.com/AIGeeksGroup/MMA.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16493v1",
        "pdf": "https://arxiv.org/pdf/2602.16493v1"
      },
      "arxiv_id": "2602.16493v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16490v1",
      "title": "From Growing to Looping: A Unified View of Iterative Computation in LLMs",
      "authors": [
        "Ferdinand Kapl",
        "Emmanouil Angelis",
        "Kaitlin Maile",
        "Johannes von Oswald",
        "Stefan Bauer"
      ],
      "abstract": "Looping, reusing a block of layers across depth, and depth growing, training shallow-to-deep models by duplicating middle layers, have both been linked to stronger reasoning, but their relationship remains unclear. We provide a mechanistic unification: looped and depth-grown models exhibit convergent depth-wise signatures, including increased reliance on late layers and recurring patterns aligned with the looped or grown block. These shared signatures support the view that their gains stem from a common form of iterative computation. Building on this connection, we show that the two techniques are adaptable and composable: applying inference-time looping to the middle blocks of a depth-grown model improves accuracy on some reasoning primitives by up to $2\\times$, despite the model never being trained to loop. Both approaches also adapt better than the baseline when given more in-context examples or additional supervised fine-tuning data. Additionally, depth-grown models achieve the largest reasoning gains when using higher-quality, math-heavy cooldown mixtures, which can be further boosted by adapting a middle block to loop. Overall, our results position depth growth and looping as complementary, practical methods for inducing and scaling iterative computation to improve reasoning.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16490v1",
        "pdf": "https://arxiv.org/pdf/2602.16490v1"
      },
      "arxiv_id": "2602.16490v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16488v1",
      "title": "Learning to Learn from Language Feedback with Social Meta-Learning",
      "authors": [
        "Jonathan Cook",
        "Diego Antognini",
        "Martin Klissarov",
        "Claudiu Musat",
        "Edward Grefenstette"
      ],
      "abstract": "Large language models (LLMs) often struggle to learn from corrective feedback within a conversational context. They are rarely proactive in soliciting this feedback, even when faced with ambiguity, which can make their dialogues feel static, one-sided, and lacking the adaptive qualities of human conversation. To address these limitations, we draw inspiration from social meta-learning (SML) in humans - the process of learning how to learn from others. We formulate SML as a finetuning methodology, training LLMs to solicit and learn from language feedback in simulated pedagogical dialogues, where static tasks are converted into interactive social learning problems. SML effectively teaches models to use conversation to solve problems they are unable to solve in a single turn. This capability generalises across domains; SML on math problems produces models that better use feedback to solve coding problems and vice versa. Furthermore, despite being trained only on fully-specified problems, these models are better able to solve underspecified tasks where critical information is revealed over multiple turns. When faced with this ambiguity, SML-trained models make fewer premature answer attempts and are more likely to ask for the information they need. This work presents a scalable approach to developing AI systems that effectively learn from language feedback.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16488v1",
        "pdf": "https://arxiv.org/pdf/2602.16488v1"
      },
      "arxiv_id": "2602.16488v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16485v1",
      "title": "Team of Thoughts: Efficient Test-time Scaling of Agentic Systems through Orchestrated Tool Calling",
      "authors": [
        "Jeffrey T. H. Wong",
        "Zixi Zhang",
        "Junyi Liu",
        "Yiren Zhao"
      ],
      "abstract": "Existing Multi-Agent Systems (MAS) typically rely on static, homogeneous model configurations, limiting their ability to exploit the distinct strengths of differently post-trained models. To address this, we introduce Team-of-Thoughts, a novel MAS architecture that leverages the complementary capabilities of heterogeneous agents via an orchestrator-tool paradigm. Our framework introduces two key mechanisms to optimize performance: (1) an orchestrator calibration scheme that identifies models with superior coordination capabilities, and (2) a self-assessment protocol where tool agents profile their own domain expertise to account for variations in post-training skills. During inference, the orchestrator dynamically activates the most suitable tool agents based on these proficiency profiles. Experiments on five reasoning and code generation benchmarks show that Team-of-Thoughts delivers consistently superior task performance. Notably, on AIME24 and LiveCodeBench, our approach achieves accuracies of 96.67% and 72.53%, respectively, substantially outperforming homogeneous role-play baselines, which score 80% and 65.93%.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16485v1",
        "pdf": "https://arxiv.org/pdf/2602.16485v1"
      },
      "arxiv_id": "2602.16485v1",
      "comment": "8 pages",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16481v1",
      "title": "Leveraging Large Language Models for Causal Discovery: a Constraint-based, Argumentation-driven Approach",
      "authors": [
        "Zihao Li",
        "Fabrizio Russo"
      ],
      "abstract": "Causal discovery seeks to uncover causal relations from data, typically represented as causal graphs, and is essential for predicting the effects of interventions. While expert knowledge is required to construct principled causal graphs, many statistical methods have been proposed to leverage observational data with varying formal guarantees. Causal Assumption-based Argumentation (ABA) is a framework that uses symbolic reasoning to ensure correspondence between input constraints and output graphs, while offering a principled way to combine data and expertise. We explore the use of large language models (LLMs) as imperfect experts for Causal ABA, eliciting semantic structural priors from variable names and descriptions and integrating them with conditional-independence evidence. Experiments on standard benchmarks and semantically grounded synthetic graphs demonstrate state-of-the-art performance, and we additionally introduce an evaluation protocol to mitigate memorisation bias when assessing LLMs for causal discovery.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16481v1",
        "pdf": "https://arxiv.org/pdf/2602.16481v1"
      },
      "arxiv_id": "2602.16481v1",
      "comment": "26 pages, including appendix",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16476v1",
      "title": "Learning Preference from Observed Rankings",
      "authors": [
        "Yu-Chang Chen",
        "Chen Chian Fuh",
        "Shang En Tsai"
      ],
      "abstract": "Estimating consumer preferences is central to many problems in economics and marketing. This paper develops a flexible framework for learning individual preferences from partial ranking information by interpreting observed rankings as collections of pairwise comparisons with logistic choice probabilities. We model latent utility as the sum of interpretable product attributes, item fixed effects, and a low-rank user-item factor structure, enabling both interpretability and information sharing across consumers and items. We further correct for selection in which comparisons are observed: a comparison is recorded only if both items enter the consumer's consideration set, inducing exposure bias toward frequently encountered items. We model pair observability as the product of item-level observability propensities and estimate these propensities with a logistic model for the marginal probability that an item is observable. Preference parameters are then estimated by maximizing an inverse-probability-weighted (IPW), ridge-regularized log-likelihood that reweights observed comparisons toward a target comparison population. To scale computation, we propose a stochastic gradient descent (SGD) algorithm based on inverse-probability resampling, which draws comparisons in proportion to their IPW weights. In an application to transaction data from an online wine retailer, the method improves out-of-sample recommendation performance relative to a popularity-based benchmark, with particularly strong gains in predicting purchases of previously unconsumed products.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16476v1",
        "pdf": "https://arxiv.org/pdf/2602.16476v1"
      },
      "arxiv_id": "2602.16476v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16473v1",
      "title": "Synthesis and Verification of Transformer Programs",
      "authors": [
        "Hongjian Jiang",
        "Matthew Hague",
        "Philipp Rümmer",
        "Anthony Widjaja Lin"
      ],
      "abstract": "C-RASP is a simple programming language that was recently shown to capture concepts expressible by transformers. In this paper, we develop new algorithmic techniques for automatically verifying C-RASPs. To this end, we establish a connection to the verification of synchronous dataflow programs in Lustre, which enables us to exploit state-of-the-art model checkers utilizing highly optimized SMT-solvers. Our second contribution addresses learning a C-RASP program in the first place. To this end, we provide a new algorithm for learning a C-RASP from examples using local search. We demonstrate efficacy of our implementation for benchmarks of C-RASPs in the literature, in particular in connection to the following applications: (1) transformer program optimization, and (2) constrained learning of transformer programs (based on a partial specification).",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.LG",
        "cs.FL",
        "cs.LO"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16473v1",
        "pdf": "https://arxiv.org/pdf/2602.16473v1"
      },
      "arxiv_id": "2602.16473v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16468v1",
      "title": "HPMixer: Hierarchical Patching for Multivariate Time Series Forecasting",
      "authors": [
        "Jung Min Choi",
        "Vijaya Krishna Yalavarthi",
        "Lars Schmidt-Thieme"
      ],
      "abstract": "In long-term multivariate time series forecasting, effectively capturing both periodic patterns and residual dynamics is essential. To address this within standard deep learning benchmark settings, we propose the Hierarchical Patching Mixer (HPMixer), which models periodicity and residuals in a decoupled yet complementary manner. The periodic component utilizes a learnable cycle module [7] enhanced with a nonlinear channel-wise MLP for greater expressiveness. The residual component is processed through a Learnable Stationary Wavelet Transform (LSWT) to extract stable, shift-invariant frequency-domain representations. Subsequently, a channel-mixing encoder models explicit inter-channel dependencies, while a two-level non-overlapping hierarchical patching mechanism captures coarse- and fine-scale residual variations. By integrating decoupled periodicity modeling with structured, multi-scale residual learning, HPMixer provides an effective framework. Extensive experiments on standard multivariate benchmarks demonstrate that HPMixer achieves competitive or state-of-the-art performance compared to recent baselines.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16468v1",
        "pdf": "https://arxiv.org/pdf/2602.16468v1"
      },
      "arxiv_id": "2602.16468v1",
      "comment": "18 pages, 5 figures, 5 tables, PAKDD 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16467v1",
      "title": "IndicEval: A Bilingual Indian Educational Evaluation Framework for Large Language Models",
      "authors": [
        "Saurabh Bharti",
        "Gaurav Azad",
        "Abhinaw Jagtap",
        "Nachiket Tapas"
      ],
      "abstract": "The rapid advancement of large language models (LLMs) necessitates evaluation frameworks that reflect real-world academic rigor and multilingual complexity. This paper introduces IndicEval, a scalable benchmarking platform designed to assess LLM performance using authentic high-stakes examination questions from UPSC, JEE, and NEET across STEM and humanities domains in both English and Hindi. Unlike synthetic benchmarks, IndicEval grounds evaluation in real examination standards, enabling realistic measurement of reasoning, domain knowledge, and bilingual adaptability. The framework automates assessment using Zero-Shot, Few-Shot, and Chain-of-Thought (CoT) prompting strategies and supports modular integration of new models and languages. Experiments conducted on Gemini 2.0 Flash, GPT-4, Claude, and LLaMA 3-70B reveal three major findings. First, CoT prompting consistently improves reasoning accuracy, with substantial gains across subjects and languages. Second, significant cross-model performance disparities persist, particularly in high-complexity examinations. Third, multilingual degradation remains a critical challenge, with marked accuracy drops in Hindi compared to English, especially under Zero-Shot conditions. These results highlight persistent gaps in bilingual reasoning and domain transfer. Overall, IndicEval provides a practice-oriented, extensible foundation for rigorous, equitable evaluation of LLMs in multilingual educational settings and offers actionable insights for improving reasoning robustness and language adaptability.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16467v1",
        "pdf": "https://arxiv.org/pdf/2602.16467v1"
      },
      "arxiv_id": "2602.16467v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16456v1",
      "title": "Beyond SGD, Without SVD: Proximal Subspace Iteration LoRA with Diagonal Fractional K-FAC",
      "authors": [
        "Abdulla Jasem Almansoori",
        "Maria Ivanova",
        "Andrey Veprikov",
        "Aleksandr Beznosikov",
        "Samuel Horváth",
        "Martin Takáč"
      ],
      "abstract": "Low-Rank Adaptation (LoRA) fine-tunes large models by learning low-rank updates on top of frozen weights, dramatically reducing trainable parameters and memory. In this work, we address the gap between training with full steps with low-rank projections (SVDLoRA) and LoRA fine-tuning. We propose LoRSum, a memory-efficient subroutine that closes this gap for gradient descent by casting LoRA optimization as a proximal sub-problem and solving it efficiently with alternating least squares updates, which we prove to be an implicit block power method. We recover several recently proposed preconditioning methods for LoRA as special cases, and show that LoRSum can also be used for updating a low-rank momentum. In order to address full steps with preconditioned gradient descent, we propose a scaled variant of LoRSum that uses structured metrics such as K-FAC and Shampoo, and we show that storing the diagonal of these metrics still allows them to perform well while remaining memory-efficient. Experiments on a synthetic task, CIFAR-100, and language-model fine-tuning on GLUE, SQuAD v2, and WikiText-103, show that our method can match or improve LoRA baselines given modest compute overhead, while avoiding full-matrix SVD projections and retaining LoRA-style parameter efficiency.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16456v1",
        "pdf": "https://arxiv.org/pdf/2602.16456v1"
      },
      "arxiv_id": "2602.16456v1",
      "comment": "20 pages, 5 figures, 4 tables",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16455v1",
      "title": "Visual Self-Refine: A Pixel-Guided Paradigm for Accurate Chart Parsing",
      "authors": [
        "Jinsong Li",
        "Xiaoyi Dong",
        "Yuhang Zang",
        "Yuhang Cao",
        "Jiaqi Wang",
        "Dahua Lin"
      ],
      "abstract": "While Large Vision-Language Models (LVLMs) have demonstrated remarkable capabilities for reasoning and self-correction at the textual level, these strengths provide minimal benefits for complex tasks centered on visual perception, such as Chart Parsing. Existing models often struggle with visually dense charts, leading to errors like data omission, misalignment, and hallucination. Inspired by the human strategy of using a finger as a ``visual anchor'' to ensure accuracy when reading complex charts, we propose a new paradigm named Visual Self-Refine (VSR). The core idea of VSR is to enable a model to generate pixel-level localization outputs, visualize them, and then feed these visualizations back to itself, allowing it to intuitively inspect and correct its own potential visual perception errors. We instantiate the VSR paradigm in the domain of Chart Parsing by proposing ChartVSR. This model decomposes the parsing process into two stages: a Refine Stage, where it iteratively uses visual feedback to ensure the accuracy of all data points' Pixel-level Localizations, and a Decode Stage, where it uses these verified localizations as precise visual anchors to parse the final structured data. To address the limitations of existing benchmarks, we also construct ChartP-Bench, a new and highly challenging benchmark for chart parsing. Our work also highlights VSR as a general-purpose visual feedback mechanism, offering a promising new direction for enhancing accuracy on a wide range of vision-centric tasks.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16455v1",
        "pdf": "https://arxiv.org/pdf/2602.16455v1"
      },
      "arxiv_id": "2602.16455v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16449v1",
      "title": "GICDM: Mitigating Hubness for Reliable Distance-Based Generative Model Evaluation",
      "authors": [
        "Nicolas Salvy",
        "Hugues Talbot",
        "Bertrand Thirion"
      ],
      "abstract": "Generative model evaluation commonly relies on high-dimensional embedding spaces to compute distances between samples. We show that dataset representations in these spaces are affected by the hubness phenomenon, which distorts nearest neighbor relationships and biases distance-based metrics. Building on the classical Iterative Contextual Dissimilarity Measure (ICDM), we introduce Generative ICDM (GICDM), a method to correct neighborhood estimation for both real and generated data. We introduce a multi-scale extension to improve empirical behavior. Extensive experiments on synthetic and real benchmarks demonstrate that GICDM resolves hubness-induced failures, restores reliable metric behavior, and improves alignment with human judgment.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16449v1",
        "pdf": "https://arxiv.org/pdf/2602.16449v1"
      },
      "arxiv_id": "2602.16449v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16444v1",
      "title": "RoboGene: Boosting VLA Pre-training via Diversity-Driven Agentic Framework for Real-World Task Generation",
      "authors": [
        "Yixue Zhang",
        "Kun Wu",
        "Zhi Gao",
        "Zhen Zhao",
        "Pei Ren",
        "Zhiyuan Xu",
        "Fei Liao",
        "Xinhua Wang",
        "Shichao Fan",
        "Di Wu",
        "Qiuxuan Feng",
        "Meng Li",
        "Zhengping Che",
        "Chang Liu",
        "Jian Tang"
      ],
      "abstract": "The pursuit of general-purpose robotic manipulation is hindered by the scarcity of diverse, real-world interaction data. Unlike data collection from web in vision or language, robotic data collection is an active process incurring prohibitive physical costs. Consequently, automated task curation to maximize data value remains a critical yet under-explored challenge. Existing manual methods are unscalable and biased toward common tasks, while off-the-shelf foundation models often hallucinate physically infeasible instructions. To address this, we introduce RoboGene, an agentic framework designed to automate the generation of diverse, physically plausible manipulation tasks across single-arm, dual-arm, and mobile robots. RoboGene integrates three core components: diversity-driven sampling for broad task coverage, self-reflection mechanisms to enforce physical constraints, and human-in-the-loop refinement for continuous improvement. We conduct extensive quantitative analysis and large-scale real-world experiments, collecting datasets of 18k trajectories and introducing novel metrics to assess task quality, feasibility, and diversity. Results demonstrate that RoboGene significantly outperforms state-of-the-art foundation models (e.g., GPT-4o, Gemini 2.5 Pro). Furthermore, real-world experiments show that VLA models pre-trained with RoboGene achieve higher success rates and superior generalization, underscoring the importance of high-quality task generation. Our project is available at https://robogene-boost-vla.github.io.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16444v1",
        "pdf": "https://arxiv.org/pdf/2602.16444v1"
      },
      "arxiv_id": "2602.16444v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16442v1",
      "title": "Hardware-accelerated graph neural networks: an alternative approach for neuromorphic event-based audio classification and keyword spotting on SoC FPGA",
      "authors": [
        "Kamil Jeziorek",
        "Piotr Wzorek",
        "Krzysztof Blachut",
        "Hiroshi Nakano",
        "Manon Dampfhoffer",
        "Thomas Mesquida",
        "Hiroaki Nishi",
        "Thomas Dalgaty",
        "Tomasz Kryjak"
      ],
      "abstract": "As the volume of data recorded by embedded edge sensors increases, particularly from neuromorphic devices producing discrete event streams, there is a growing need for hardware-aware neural architectures that enable efficient, low-latency, and energy-conscious local processing. We present an FPGA implementation of event-graph neural networks for audio processing. We utilise an artificial cochlea that converts time-series signals into sparse event data, reducing memory and computation costs. Our architecture was implemented on a SoC FPGA and evaluated on two open-source datasets. For classification task, our baseline floating-point model achieves 92.7% accuracy on SHD dataset - only 2.4% below the state of the art - while requiring over 10x and 67x fewer parameters. On SSC, our models achieve 66.9-71.0% accuracy. Compared to FPGA-based spiking neural networks, our quantised model reaches 92.3% accuracy, outperforming them by up to 19.3% while reducing resource usage and latency. For SSC, we report the first hardware-accelerated evaluation. We further demonstrate the first end-to-end FPGA implementation of event-audio keyword spotting, combining graph convolutional layers with recurrent sequence modelling. The system achieves up to 95% word-end detection accuracy, with only 10.53 microsecond latency and 1.18 W power consumption, establishing a strong benchmark for energy-efficient event-driven KWS.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16442v1",
        "pdf": "https://arxiv.org/pdf/2602.16442v1"
      },
      "arxiv_id": "2602.16442v1",
      "comment": "Under revision in TRETS Journal",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16438v1",
      "title": "Intra-Fairness Dynamics: The Bias Spillover Effect in Targeted LLM Alignment",
      "authors": [
        "Eva Paraschou",
        "Line Harder Clemmensen",
        "Sneha Das"
      ],
      "abstract": "Conventional large language model (LLM) fairness alignment largely focuses on mitigating bias along single sensitive attributes, overlooking fairness as an inherently multidimensional and context-specific value. This approach risks creating systems that achieve narrow fairness metrics while exacerbating disparities along untargeted attributes, a phenomenon known as bias spillover. While extensively studied in machine learning, bias spillover remains critically underexplored in LLM alignment. In this work, we investigate how targeted gender alignment affects fairness across nine sensitive attributes in three state-of-the-art LLMs (Mistral 7B, Llama 3.1 8B, Qwen 2.5 7B). Using Direct Preference Optimization and the BBQ benchmark, we evaluate fairness under ambiguous and disambiguous contexts. Our findings reveal noticeable bias spillover: while aggregate results show improvements, context-aware analysis exposes significant degradations in ambiguous contexts, particularly for physical appearance ($p< 0.001$ across all models), sexual orientation, and disability status. We demonstrate that improving fairness along one attribute can inadvertently worsen disparities in others under uncertainty, highlighting the necessity of context-aware, multi-attribute fairness evaluation frameworks.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16438v1",
        "pdf": "https://arxiv.org/pdf/2602.16438v1"
      },
      "arxiv_id": "2602.16438v1",
      "comment": "Submitted to the BiAlign CHI Workshop 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16436v1",
      "title": "Learning with Locally Private Examples by Inverse Weierstrass Private Stochastic Gradient Descent",
      "authors": [
        "Jean Dufraiche",
        "Paul Mangold",
        "Michaël Perrot",
        "Marc Tommasi"
      ],
      "abstract": "Releasing data once and for all under noninteractive Local Differential Privacy (LDP) enables complete data reusability, but the resulting noise may create bias in subsequent analyses. In this work, we leverage the Weierstrass transform to characterize this bias in binary classification. We prove that inverting this transform leads to a bias-correction method to compute unbiased estimates of nonlinear functions on examples released under LDP. We then build a novel stochastic gradient descent algorithm called Inverse Weierstrass Private SGD (IWP-SGD). It converges to the true population risk minimizer at a rate of $\\mathcal{O}(1/n)$, with $n$ the number of examples. We empirically validate IWP-SGD on binary classification tasks using synthetic and real-world datasets.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.LG",
        "cs.CR",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16436v1",
        "pdf": "https://arxiv.org/pdf/2602.16436v1"
      },
      "arxiv_id": "2602.16436v1",
      "comment": "30 pages, 8 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16435v1",
      "title": "Causally-Guided Automated Feature Engineering with Multi-Agent Reinforcement Learning",
      "authors": [
        "Arun Vignesh Malarkkan",
        "Wangyang Ying",
        "Yanjie Fu"
      ],
      "abstract": "Automated feature engineering (AFE) enables AI systems to autonomously construct high-utility representations from raw tabular data. However, existing AFE methods rely on statistical heuristics, yielding brittle features that fail under distribution shift. We introduce CAFE, a framework that reformulates AFE as a causally-guided sequential decision process, bridging causal discovery with reinforcement learning-driven feature construction. Phase I learns a sparse directed acyclic graph over features and the target to obtain soft causal priors, grouping features as direct, indirect, or other based on their causal influence with respect to the target. Phase II uses a cascading multi-agent deep Q-learning architecture to select causal groups and transformation operators, with hierarchical reward shaping and causal group-level exploration strategies that favor causally plausible transformations while controlling feature complexity. Across 15 public benchmarks (classification with macro-F1; regression with inverse relative absolute error), CAFE achieves up to 7% improvement over strong AFE baselines, reduces episodes-to-convergence, and delivers competitive time-to-target. Under controlled covariate shifts, CAFE reduces performance drop by ~4x relative to a non-causal multi-agent baseline, and produces more compact feature sets with more stable post-hoc attributions. These findings underscore that causal structure, used as a soft inductive prior rather than a rigid constraint, can substantially improve the robustness and efficiency of automated feature engineering.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16435v1",
        "pdf": "https://arxiv.org/pdf/2602.16435v1"
      },
      "arxiv_id": "2602.16435v1",
      "comment": "11 Pages, References and Appendix",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16430v1",
      "title": "Designing Production-Scale OCR for India: Multilingual and Domain-Specific Systems",
      "authors": [
        "Ali Faraz",
        "Raja Kolla",
        "Ashish Kulkarni",
        "Shubham Agarwal"
      ],
      "abstract": "Designing Optical Character Recognition (OCR) systems for India requires balancing linguistic diversity, document heterogeneity, and deployment constraints. In this paper, we study two training strategies for building multilingual OCR systems with Vision-Language Models through the Chitrapathak series. We first follow a popular multimodal approach, pairing a generic vision encoder with a strong multilingual language model and training the system end-to-end for OCR. Alternatively, we explore fine-tuning an existing OCR model, despite not being trained for the target languages. Through extensive evaluation on multilingual Indic OCR benchmarks and deployment-oriented metrics, we find that the second strategy consistently achieves better accuracy-latency trade-offs. Chitrapathak-2 achieves 3-6x speedup over its predecessor with being state-of-the-art (SOTA) in Telugu (6.69 char ANLS) and second best in the rest. In addition, we present Parichay, an independent OCR model series designed specifically for 9 Indian government documents to extract structured key fields, achieving 89.8% Exact Match score with a faster inference. Together, these systems achieve SOTA performance and provide practical guidance for building production-scale OCR pipelines in the Indian context.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16430v1",
        "pdf": "https://arxiv.org/pdf/2602.16430v1"
      },
      "arxiv_id": "2602.16430v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16424v1",
      "title": "Verifiable Semantics for Agent-to-Agent Communication",
      "authors": [
        "Philipp Schoenegger",
        "Matt Carlson",
        "Chris Schneider",
        "Chris Daly"
      ],
      "abstract": "Multiagent AI systems require consistent communication, but we lack methods to verify that agents share the same understanding of the terms used. Natural language is interpretable but vulnerable to semantic drift, while learned protocols are efficient but opaque. We propose a certification protocol based on the stimulus-meaning model, where agents are tested on shared observable events and terms are certified if empirical disagreement falls below a statistical threshold. In this protocol, agents restricting their reasoning to certified terms (\"core-guarded reasoning\") achieve provably bounded disagreement. We also outline mechanisms for detecting drift (recertification) and recovering shared vocabulary (renegotiation). In simulations with varying degrees of semantic divergence, core-guarding reduces disagreement by 72-96%. In a validation with fine-tuned language models, disagreement is reduced by 51%. Our framework provides a first step towards verifiable agent-to-agent communication.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16424v1",
        "pdf": "https://arxiv.org/pdf/2602.16424v1"
      },
      "arxiv_id": "2602.16424v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16422v1",
      "title": "Automated Histopathology Report Generation via Pyramidal Feature Extraction and the UNI Foundation Model",
      "authors": [
        "Ahmet Halici",
        "Ece Tugba Cebeci",
        "Musa Balci",
        "Mustafa Cini",
        "Serkan Sokmen"
      ],
      "abstract": "Generating diagnostic text from histopathology whole slide images (WSIs) is challenging due to the gigapixel scale of the input and the requirement for precise, domain specific language. We propose a hierarchical vision language framework that combines a frozen pathology foundation model with a Transformer decoder for report generation. To make WSI processing tractable, we perform multi resolution pyramidal patch selection (downsampling factors 2^3 to 2^6) and remove background and artifacts using Laplacian variance and HSV based criteria. Patch features are extracted with the UNI Vision Transformer and projected to a 6 layer Transformer decoder that generates diagnostic text via cross attention. To better represent biomedical terminology, we tokenize the output using BioGPT. Finally, we add a retrieval based verification step that compares generated reports with a reference corpus using Sentence BERT embeddings; if a high similarity match is found, the generated report is replaced with the retrieved ground truth reference to improve reliability.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16422v1",
        "pdf": "https://arxiv.org/pdf/2602.16422v1"
      },
      "arxiv_id": "2602.16422v1",
      "comment": "9 pages. Equal contribution: Ahmet Halici, Ece Tugba Cebeci, Musa Balci",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16412v1",
      "title": "ReMoRa: Multimodal Large Language Model based on Refined Motion Representation for Long-Video Understanding",
      "authors": [
        "Daichi Yashima",
        "Shuhei Kurita",
        "Yusuke Oda",
        "Komei Sugiura"
      ],
      "abstract": "While multimodal large language models (MLLMs) have shown remarkable success across a wide range of tasks, long-form video understanding remains a significant challenge. In this study, we focus on video understanding by MLLMs. This task is challenging because processing a full stream of RGB frames is computationally intractable and highly redundant, as self-attention have quadratic complexity with sequence length. In this paper, we propose ReMoRa, a video MLLM that processes videos by operating directly on their compressed representations. A sparse set of RGB keyframes is retained for appearance, while temporal dynamics are encoded as a motion representation, removing the need for sequential RGB frames. These motion representations act as a compact proxy for optical flow, capturing temporal dynamics without full frame decoding. To refine the noise and low fidelity of block-based motions, we introduce a module to denoise and generate a fine-grained motion representation. Furthermore, our model compresses these features in a way that scales linearly with sequence length. We demonstrate the effectiveness of ReMoRa through extensive experiments across a comprehensive suite of long-video understanding benchmarks. ReMoRa outperformed baseline methods on multiple challenging benchmarks, including LongVideoBench, NExT-QA, and MLVU.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16412v1",
        "pdf": "https://arxiv.org/pdf/2602.16412v1"
      },
      "arxiv_id": "2602.16412v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16400v1",
      "title": "Easy Data Unlearning Bench",
      "authors": [
        "Roy Rinberg",
        "Pol Puigdemont",
        "Martin Pawelczyk",
        "Volkan Cevher"
      ],
      "abstract": "Evaluating machine unlearning methods remains technically challenging, with recent benchmarks requiring complex setups and significant engineering overhead. We introduce a unified and extensible benchmarking suite that simplifies the evaluation of unlearning algorithms using the KLoM (KL divergence of Margins) metric. Our framework provides precomputed model ensembles, oracle outputs, and streamlined infrastructure for running evaluations out of the box. By standardizing setup and metrics, it enables reproducible, scalable, and fair comparison across unlearning methods. We aim for this benchmark to serve as a practical foundation for accelerating research and promoting best practices in machine unlearning. Our code and data are publicly available.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16400v1",
        "pdf": "https://arxiv.org/pdf/2602.16400v1"
      },
      "arxiv_id": "2602.16400v1",
      "comment": "ICML 2025 Workshop on Machine Unlearning for Generative AI",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16399v1",
      "title": "Multi-Channel Replay Speech Detection using Acoustic Maps",
      "authors": [
        "Michael Neri",
        "Tuomas Virtanen"
      ],
      "abstract": "Replay attacks remain a critical vulnerability for automatic speaker verification systems, particularly in real-time voice assistant applications. In this work, we propose acoustic maps as a novel spatial feature representation for replay speech detection from multi-channel recordings. Derived from classical beamforming over discrete azimuth and elevation grids, acoustic maps encode directional energy distributions that reflect physical differences between human speech radiation and loudspeaker-based replay. A lightweight convolutional neural network is designed to operate on this representation, achieving competitive performance on the ReMASC dataset with approximately 6k trainable parameters. Experimental results show that acoustic maps provide a compact and physically interpretable feature space for replay attack detection across different devices and acoustic environments.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "eess.AS",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16399v1",
        "pdf": "https://arxiv.org/pdf/2602.16399v1"
      },
      "arxiv_id": "2602.16399v1",
      "comment": "Submitted to EUSIPCO 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16385v1",
      "title": "Parameter-Free Adaptive Multi-Scale Channel-Spatial Attention Aggregation framework for 3D Indoor Semantic Scene Completion Toward Assisting Visually Impaired",
      "authors": [
        "Qi He",
        "XiangXiang Wang",
        "Jingtao Zhang",
        "Yongbin Yu",
        "Hongxiang Chu",
        "Manping Fan",
        "JingYe Cai",
        "Zhenglin Yang"
      ],
      "abstract": "In indoor assistive perception for visually impaired users, 3D Semantic Scene Completion (SSC) is expected to provide structurally coherent and semantically consistent occupancy under strictly monocular vision for safety-critical scene understanding. However, existing monocular SSC approaches often lack explicit modeling of voxel-feature reliability and regulated cross-scale information propagation during 2D-3D projection and multi-scale fusion, making them vulnerable to projection diffusion and feature entanglement and thus limiting structural stability.To address these challenges, this paper presents an Adaptive Multi-scale Attention Aggregation (AMAA) framework built upon the MonoScene pipeline. Rather than introducing a heavier backbone, AMAA focuses on reliability-oriented feature regulation within a monocular SSC framework. Specifically, lifted voxel features are jointly calibrated in semantic and spatial dimensions through parallel channel-spatial attention aggregation, while multi-scale encoder-decoder fusion is stabilized via a hierarchical adaptive feature-gating strategy that regulates information injection across scales.Experiments on the NYUv2 benchmark demonstrate consistent improvements over MonoScene without significantly increasing system complexity: AMAA achieves 27.25% SSC mIoU (+0.31) and 43.10% SC IoU (+0.59). In addition, system-level deployment on an NVIDIA Jetson platform verifies that the complete AMAA framework can be executed stably on embedded hardware. Overall, AMAA improves monocular SSC quality and provides a reliable and deployable perception framework for indoor assistive systems targeting visually impaired users.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16385v1",
        "pdf": "https://arxiv.org/pdf/2602.16385v1"
      },
      "arxiv_id": "2602.16385v1",
      "comment": "17 pages, 9 figures, 5 tables",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16375v1",
      "title": "Variable-Length Semantic IDs for Recommender Systems",
      "authors": [
        "Kirill Khrylchenko"
      ],
      "abstract": "Generative models are increasingly used in recommender systems, both for modeling user behavior as event sequences and for integrating large language models into recommendation pipelines. A key challenge in this setting is the extremely large cardinality of item spaces, which makes training generative models difficult and introduces a vocabulary gap between natural language and item identifiers. Semantic identifiers (semantic IDs), which represent items as sequences of low-cardinality tokens, have recently emerged as an effective solution to this problem.\n  However, existing approaches generate semantic identifiers of fixed length, assigning the same description length to all items. This is inefficient, misaligned with natural language, and ignores the highly skewed frequency structure of real-world catalogs, where popular items and rare long-tail items exhibit fundamentally different information requirements. In parallel, the emergent communication literature studies how agents develop discrete communication protocols, often producing variable-length messages in which frequent concepts receive shorter descriptions. Despite the conceptual similarity, these ideas have not been systematically adopted in recommender systems.\n  In this work, we bridge recommender systems and emergent communication by introducing variable-length semantic identifiers for recommendation. We propose a discrete variational autoencoder with Gumbel-Softmax reparameterization that learns item representations of adaptive length under a principled probabilistic framework, avoiding the instability of REINFORCE-based training and the fixed-length constraints of prior semantic ID methods.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.IR",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16375v1",
        "pdf": "https://arxiv.org/pdf/2602.16375v1"
      },
      "arxiv_id": "2602.16375v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16372v1",
      "title": "AI-Driven Structure Refinement of X-ray Diffraction",
      "authors": [
        "Bin Cao",
        "Qian Zhang",
        "Zhenjie Feng",
        "Taolue Zhang",
        "Jiaqiang Huang",
        "Lu-Tao Weng",
        "Tong-Yi Zhang"
      ],
      "abstract": "Artificial intelligence can rapidly propose candidate phases and structures from X-ray diffraction (XRD), but these hypotheses often fail in downstream refinement because peak intensities cannot be stably assigned under severe overlap and diffraction consistency is enforced only weakly. Here we introduce WPEM, a physics-constrained whole-pattern decomposition and refinement workflow that turns Bragg's law into an explicit constraint within a batch expectation--maximization framework. WPEM models the full profile as a probabilistic mixture density and iteratively infers component-resolved intensities while keeping peak centres Bragg-consistent, producing a continuous, physically admissible intensity representation that remains stable in heavily overlapped regions and in the presence of mixed radiation or multiple phases. We benchmark WPEM on standard reference patterns (\\ce{PbSO4} and \\ce{Tb2BaCoO5}), where it yields lower $R_{\\mathrm{p}}$/$R_{\\mathrm{wp}}$ than widely used packages (FullProf and TOPAS) under matched refinement conditions. We further demonstrate generality across realistic experimental scenarios, including phase-resolved decomposition of a multiphase Ti--15Nb thin film, quantitative recovery of \\ce{NaCl}--\\ce{Li2CO3} mixture compositions, separation of crystalline peaks from amorphous halos in semicrystalline polymers, high-throughput operando lattice tracking in layered cathodes, automated refinement of a compositionally disordered Ru--Mn oxide solid solution (CCDC 2530452), and quantitative phase-resolved deciphering of an ancient Egyptian make-up sample from synchrotron powder XRD. By providing Bragg-consistent, uncertainty-aware intensity partitioning as a refinement-ready interface, WPEM closes the gap between AI-generated hypotheses and diffraction-admissible structure refinement on challenging XRD data.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16372v1",
        "pdf": "https://arxiv.org/pdf/2602.16372v1"
      },
      "arxiv_id": "2602.16372v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16365v1",
      "title": "Markerless 6D Pose Estimation and Position-Based Visual Servoing for Endoscopic Continuum Manipulators",
      "authors": [
        "Junhyun Park",
        "Chunggil An",
        "Myeongbo Park",
        "Ihsan Ullah",
        "Sihyeong Park",
        "Minho Hwang"
      ],
      "abstract": "Continuum manipulators in flexible endoscopic surgical systems offer high dexterity for minimally invasive procedures; however, accurate pose estimation and closed-loop control remain challenging due to hysteresis, compliance, and limited distal sensing. Vision-based approaches reduce hardware complexity but are often constrained by limited geometric observability and high computational overhead, restricting real-time closed-loop applicability. This paper presents a unified framework for markerless stereo 6D pose estimation and position-based visual servoing of continuum manipulators. A photo-realistic simulation pipeline enables large-scale automatic training with pixel-accurate annotations. A stereo-aware multi-feature fusion network jointly exploits segmentation masks, keypoints, heatmaps, and bounding boxes to enhance geometric observability. To enforce geometric consistency without iterative optimization, a feed-forward rendering-based refinement module predicts residual pose corrections in a single pass. A self-supervised sim-to-real adaptation strategy further improves real-world performance using unlabeled data. Extensive real-world validation achieves a mean translation error of 0.83 mm and a mean rotation error of 2.76° across 1,000 samples. Markerless closed-loop visual servoing driven by the estimated pose attains accurate trajectory tracking with a mean translation error of 2.07 mm and a mean rotation error of 7.41°, corresponding to 85% and 59% reductions compared to open-loop control, together with high repeatability in repeated point-reaching tasks. To the best of our knowledge, this work presents the first fully markerless pose-estimation-driven position-based visual servoing framework for continuum manipulators, enabling precise closed-loop control without physical markers or embedded sensing.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.RO",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16365v1",
        "pdf": "https://arxiv.org/pdf/2602.16365v1"
      },
      "arxiv_id": "2602.16365v1",
      "comment": "20 pages, 13 figures, 7 tables",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16363v1",
      "title": "Improved Bounds for Reward-Agnostic and Reward-Free Exploration",
      "authors": [
        "Oran Ridel",
        "Alon Cohen"
      ],
      "abstract": "We study reward-free and reward-agnostic exploration in episodic finite-horizon Markov decision processes (MDPs), where an agent explores an unknown environment without observing external rewards. Reward-free exploration aims to enable $ε$-optimal policies for any reward revealed after exploration, while reward-agnostic exploration targets $ε$-optimality for rewards drawn from a small finite class. In the reward-agnostic setting, Li, Yan, Chen, and Fan achieve minimax sample complexity, but only for restrictively small accuracy parameter $ε$. We propose a new algorithm that significantly relaxes the requirement on $ε$. Our approach is novel and of technical interest by itself. Our algorithm employs an online learning procedure with carefully designed rewards to construct an exploration policy, which is used to gather data sufficient for accurate dynamics estimation and subsequent computation of an $ε$-optimal policy once the reward is revealed. Finally, we establish a tight lower bound for reward-free exploration, closing the gap between known upper and lower bounds.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16363v1",
        "pdf": "https://arxiv.org/pdf/2602.16363v1"
      },
      "arxiv_id": "2602.16363v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16357v1",
      "title": "Optical Inversion and Spectral Unmixing of Spectroscopic Photoacoustic Images with Physics-Informed Neural Networks",
      "authors": [
        "Sarkis Ter Martirosyan",
        "Xinyue Huang",
        "David Qin",
        "Anthony Yu",
        "Stanislav Emelianov"
      ],
      "abstract": "Accurate estimation of the relative concentrations of chromophores in a spectroscopic photoacoustic (sPA) image can reveal immense structural, functional, and molecular information about physiological processes. However, due to nonlinearities and ill-posedness inherent to sPA imaging, concentration estimation is intractable. The Spectroscopic Photoacoustic Optical Inversion Autoencoder (SPOI-AE) aims to address the sPA optical inversion and spectral unmixing problems without assuming linearity. Herein, SPOI-AE was trained and tested on \\textit{in vivo} mouse lymph node sPA images with unknown ground truth chromophore concentrations. SPOI-AE better reconstructs input sPA pixels than conventional algorithms while providing biologically coherent estimates for optical parameters, chromophore concentrations, and the percent oxygen saturation of tissue. SPOI-AE's unmixing accuracy was validated using a simulated mouse lymph node phantom ground truth.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.LG",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16357v1",
        "pdf": "https://arxiv.org/pdf/2602.16357v1"
      },
      "arxiv_id": "2602.16357v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16356v1",
      "title": "Articulated 3D Scene Graphs for Open-World Mobile Manipulation",
      "authors": [
        "Martin Büchner",
        "Adrian Röfer",
        "Tim Engelbracht",
        "Tim Welschehold",
        "Zuria Bauer",
        "Hermann Blum",
        "Marc Pollefeys",
        "Abhinav Valada"
      ],
      "abstract": "Semantics has enabled 3D scene understanding and affordance-driven object interaction. However, robots operating in real-world environments face a critical limitation: they cannot anticipate how objects move. Long-horizon mobile manipulation requires closing the gap between semantics, geometry, and kinematics. In this work, we present MoMa-SG, a novel framework for building semantic-kinematic 3D scene graphs of articulated scenes containing a myriad of interactable objects. Given RGB-D sequences containing multiple object articulations, we temporally segment object interactions and infer object motion using occlusion-robust point tracking. We then lift point trajectories into 3D and estimate articulation models using a novel unified twist estimation formulation that robustly estimates revolute and prismatic joint parameters in a single optimization pass. Next, we associate objects with estimated articulations and detect contained objects by reasoning over parent-child relations at identified opening states. We also introduce the novel Arti4D-Semantic dataset, which uniquely combines hierarchical object semantics including parent-child relation labels with object axis annotations across 62 in-the-wild RGB-D sequences containing 600 object interactions and three distinct observation paradigms. We extensively evaluate the performance of MoMa-SG on two datasets and ablate key design choices of our approach. In addition, real-world experiments on both a quadruped and a mobile manipulator demonstrate that our semantic-kinematic scene graphs enable robust manipulation of articulated objects in everyday home environments. We provide code and data at: https://momasg.cs.uni-freiburg.de.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16356v1",
        "pdf": "https://arxiv.org/pdf/2602.16356v1"
      },
      "arxiv_id": "2602.16356v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16352v1",
      "title": "Machine Learning in Epidemiology",
      "authors": [
        "Marvin N. Wright",
        "Lukas Burk",
        "Pegah Golchian",
        "Jan Kapar",
        "Niklas Koenen",
        "Sophie Hanna Langbein"
      ],
      "abstract": "In the age of digital epidemiology, epidemiologists are faced by an increasing amount of data of growing complexity and dimensionality. Machine learning is a set of powerful tools that can help to analyze such enormous amounts of data. This chapter lays the methodological foundations for successfully applying machine learning in epidemiology. It covers the principles of supervised and unsupervised learning and discusses the most important machine learning methods. Strategies for model evaluation and hyperparameter optimization are developed and interpretable machine learning is introduced. All these theoretical parts are accompanied by code examples in R, where an example dataset on heart disease is used throughout the chapter.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "stat.ML",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16352v1",
        "pdf": "https://arxiv.org/pdf/2602.16352v1"
      },
      "arxiv_id": "2602.16352v1",
      "comment": "",
      "journal_ref": "In: Ahrens, W., Pigeot, I. (Eds.) Handbook of Epidemiology. Springer, New York (2025)",
      "has_code": false
    },
    {
      "id": "2602.16349v1",
      "title": "SCAR: Satellite Imagery-Based Calibration for Aerial Recordings",
      "authors": [
        "Henry Hölzemann",
        "Michael Schleiss"
      ],
      "abstract": "We introduce SCAR, a method for long-term auto-calibration refinement of aerial visual-inertial systems that exploits georeferenced satellite imagery as a persistent global reference. SCAR estimates both intrinsic and extrinsic parameters by aligning aerial images with 2D--3D correspondences derived from publicly available orthophotos and elevation models. In contrast to existing approaches that rely on dedicated calibration maneuvers or manually surveyed ground control points, our method leverages external geospatial data to detect and correct calibration degradation under field deployment conditions. We evaluate our approach on six large-scale aerial campaigns conducted over two years under diverse seasonal and environmental conditions. Across all sequences, SCAR consistently outperforms established baselines (Kalibr, COLMAP, VINS-Mono), reducing median reprojection error by a large margin, and translating these calibration gains into substantially lower visual localization rotation errors and higher pose accuracy. These results demonstrate that SCAR provides accurate, robust, and reproducible calibration over long-term aerial operations without the need for manual intervention.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16349v1",
        "pdf": "https://arxiv.org/pdf/2602.16349v1"
      },
      "arxiv_id": "2602.16349v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16346v1",
      "title": "Helpful to a Fault: Measuring Illicit Assistance in Multi-Turn, Multilingual LLM Agents",
      "authors": [
        "Nivya Talokar",
        "Ayush K Tarun",
        "Murari Mandal",
        "Maksym Andriushchenko",
        "Antoine Bosselut"
      ],
      "abstract": "LLM-based agents execute real-world workflows via tools and memory. These affordances enable ill-intended adversaries to also use these agents to carry out complex misuse scenarios. Existing agent misuse benchmarks largely test single-prompt instructions, leaving a gap in measuring how agents end up helping with harmful or illegal tasks over multiple turns. We introduce STING (Sequential Testing of Illicit N-step Goal execution), an automated red-teaming framework that constructs a step-by-step illicit plan grounded in a benign persona and iteratively probes a target agent with adaptive follow-ups, using judge agents to track phase completion. We further introduce an analysis framework that models multi-turn red-teaming as a time-to-first-jailbreak random variable, enabling analysis tools like discovery curves, hazard-ratio attribution by attack language, and a new metric: Restricted Mean Jailbreak Discovery. Across AgentHarm scenarios, STING yields substantially higher illicit-task completion than single-turn prompting and chat-oriented multi-turn baselines adapted to tool-using agents. In multilingual evaluations across six non-English settings, we find that attack success and illicit-task completion do not consistently increase in lower-resource languages, diverging from common chatbot findings. Overall, STING provides a practical way to evaluate and stress-test agent misuse in realistic deployment settings, where interactions are inherently multi-turn and often multilingual.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16346v1",
        "pdf": "https://arxiv.org/pdf/2602.16346v1"
      },
      "arxiv_id": "2602.16346v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2602.16343v1",
      "title": "How to Label Resynthesized Audio: The Dual Role of Neural Audio Codecs in Audio Deepfake Detection",
      "authors": [
        "Yixuan Xiao",
        "Florian Lux",
        "Alejandro Pérez-González-de-Martos",
        "Ngoc Thang Vu"
      ],
      "abstract": "Since Text-to-Speech systems typically don't produce waveforms directly, recent spoof detection studies use resynthesized waveforms from vocoders and neural audio codecs to simulate an attacker. Unlike vocoders, which are specifically designed for speech synthesis, neural audio codecs were originally developed for compressing audio for storage and transmission. However, their ability to discretize speech also sparked interest in language-modeling-based speech synthesis. Owing to this dual functionality, codec resynthesized data may be labeled as either bonafide or spoof. So far, very little research has addressed this issue. In this study, we present a challenging extension of the ASVspoof 5 dataset constructed for this purpose. We examine how different labeling choices affect detection performance and provide insights into labeling strategies.",
      "published": "2026-02-18",
      "updated": "2026-02-18",
      "categories": [
        "cs.SD",
        "cs.LG"
      ],
      "primary_category": "cs.SD",
      "links": {
        "paper": "http://arxiv.org/abs/2602.16343v1",
        "pdf": "https://arxiv.org/pdf/2602.16343v1"
      },
      "arxiv_id": "2602.16343v1",
      "comment": "Accepted to ICASSP 2026",
      "journal_ref": "",
      "has_code": false
    }
  ]
}