{
  "fetched_at": "2026-01-06T00:26:55.244918",
  "total_papers": 100,
  "papers": [
    {
      "id": "2601.00796v1",
      "title": "AdaGaR: Adaptive Gabor Representation for Dynamic Scene Reconstruction",
      "authors": [
        "Jiewen Chan",
        "Zhenjun Zhao",
        "Yu-Lun Liu"
      ],
      "abstract": "Reconstructing dynamic 3D scenes from monocular videos requires simultaneously capturing high-frequency appearance details and temporally continuous motion. Existing methods using single Gaussian primitives are limited by their low-pass filtering nature, while standard Gabor functions introduce energy instability. Moreover, lack of temporal continuity constraints often leads to motion artifacts during interpolation. We propose AdaGaR, a unified framework addressing both frequency adaptivity and temporal continuity in explicit dynamic scene modeling. We introduce Adaptive Gabor Representation, extending Gaussians through learnable frequency weights and adaptive energy compensation to balance detail capture and stability. For temporal continuity, we employ Cubic Hermite Splines with Temporal Curvature Regularization to ensure smooth motion evolution. An Adaptive Initialization mechanism combining depth estimation, point tracking, and foreground masks establishes stable point cloud distributions in early training. Experiments on Tap-Vid DAVIS demonstrate state-of-the-art performance (PSNR 35.49, SSIM 0.9433, LPIPS 0.0723) and strong generalization across frame interpolation, depth consistency, video editing, and stereo view synthesis. Project page: https://jiewenchan.github.io/AdaGaR/",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00796v1",
        "pdf": "https://arxiv.org/pdf/2601.00796v1"
      },
      "arxiv_id": "2601.00796v1",
      "comment": "Project page: https://jiewenchan.github.io/AdaGaR/",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2601.00794v1",
      "title": "Two Deep Learning Approaches for Automated Segmentation of Left Ventricle in Cine Cardiac MRI",
      "authors": [
        "Wenhui Chu",
        "Nikolaos V. Tsekos"
      ],
      "abstract": "Left ventricle (LV) segmentation is critical for clinical quantification and diagnosis of cardiac images. In this work, we propose two novel deep learning architectures called LNU-Net and IBU-Net for left ventricle segmentation from short-axis cine MRI images. LNU-Net is derived from layer normalization (LN) U-Net architecture, while IBU-Net is derived from the instance-batch normalized (IB) U-Net for medical image segmentation. The architectures of LNU-Net and IBU-Net have a down-sampling path for feature extraction and an up-sampling path for precise localization. We use the original U-Net as the basic segmentation approach and compared it with our proposed architectures. Both LNU-Net and IBU-Net have left ventricle segmentation methods: LNU-Net applies layer normalization in each convolutional block, while IBU-Net incorporates instance and batch normalization together in the first convolutional block and passes its result to the next layer. Our method incorporates affine transformations and elastic deformations for image data processing. Our dataset that contains 805 MRI images regarding the left ventricle from 45 patients is used for evaluation. We experimentally evaluate the results of the proposed approaches outperforming the dice coefficient and the average perpendicular distance than other state-of-the-art approaches.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00794v1",
        "pdf": "https://arxiv.org/pdf/2601.00794v1"
      },
      "arxiv_id": "2601.00794v1",
      "comment": "7 pages, 5 figures, published in ICBBB 2022",
      "journal_ref": "2022 12th International Conference on Bioscience, Biochemistry and Bioinformatics (ICBBB '22), January 7-10, 2022, Tokyo, Japan",
      "has_code": false
    },
    {
      "id": "2601.00791v1",
      "title": "Geometry of Reason: Spectral Signatures of Valid Mathematical Reasoning",
      "authors": [
        "Valentin Noël"
      ],
      "abstract": "We present a training-free method for detecting valid mathematical reasoning in large language models through spectral analysis of attention patterns. By treating attention matrices as adjacency matrices of dynamic graphs over tokens, we extract four interpretable spectral diagnostics, the Fiedler value (algebraic connectivity), high-frequency energy ratio (HFER), graph signal smoothness, and spectral entropy, that exhibit statistically significant differences between valid and invalid mathematical proofs. Experiments across seven transformer models from four independent architectural families (Meta Llama, Alibaba Qwen, Microsoft Phi, and Mistral AI) demonstrate that this spectral signature produces effect sizes up to Cohen's $d = 3.30$ ($p < 10^{-116}$), enabling 85.0--95.6\\% classification accuracy under rigorous evaluation, with calibrated thresholds reaching 93--95\\% on the full dataset. The method requires no training data, fine-tuning, or learned classifiers: a single threshold on a spectral metric suffices for high accuracy. Through systematic label correction, we discover that the spectral method detects logical coherence rather than compiler acceptance, identifying mathematically valid proofs that formal verifiers reject due to technical failures. We further identify an architectural dependency: Mistral-7B's Sliding Window Attention shifts the discriminative signal from HFER to late-layer Smoothness ($d = 2.09$, $p_{\\text{MW}} = 1.16 \\times 10^{-48}$), revealing that attention mechanism design affects which spectral features capture reasoning validity. These findings establish spectral graph analysis as a principled framework for reasoning verification with immediate applications to hallucination detection and AI safety monitoring.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.LO"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00791v1",
        "pdf": "https://arxiv.org/pdf/2601.00791v1"
      },
      "arxiv_id": "2601.00791v1",
      "comment": "58 pages, 19 figures, Under Review",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00789v1",
      "title": "Fusion-SSAT: Unleashing the Potential of Self-supervised Auxiliary Task by Feature Fusion for Generalized Deepfake Detection",
      "authors": [
        "Shukesh Reddy",
        "Srijan Das",
        "Abhijit Das"
      ],
      "abstract": "In this work, we attempted to unleash the potential of self-supervised learning as an auxiliary task that can optimise the primary task of generalised deepfake detection. To explore this, we examined different combinations of the training schemes for these tasks that can be most effective. Our findings reveal that fusing the feature representation from self-supervised auxiliary tasks is a powerful feature representation for the problem at hand. Such a representation can leverage the ultimate potential and bring in a unique representation of both the self-supervised and primary tasks, achieving better performance for the primary task. We experimented on a large set of datasets, which includes DF40, FaceForensics++, Celeb-DF, DFD, FaceShifter, UADFV, and our results showed better generalizability on cross-dataset evaluation when compared with current state-of-the-art detectors.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00789v1",
        "pdf": "https://arxiv.org/pdf/2601.00789v1"
      },
      "arxiv_id": "2601.00789v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00785v1",
      "title": "FedHypeVAE: Federated Learning with Hypernetwork Generated Conditional VAEs for Differentially Private Embedding Sharing",
      "authors": [
        "Sunny Gupta",
        "Amit Sethi"
      ],
      "abstract": "Federated data sharing promises utility without centralizing raw data, yet existing embedding-level generators struggle under non-IID client heterogeneity and provide limited formal protection against gradient leakage. We propose FedHypeVAE, a differentially private, hypernetwork-driven framework for synthesizing embedding-level data across decentralized clients. Building on a conditional VAE backbone, we replace the single global decoder and fixed latent prior with client-aware decoders and class-conditional priors generated by a shared hypernetwork from private, trainable client codes. This bi-level design personalizes the generative layerrather than the downstream modelwhile decoupling local data from communicated parameters. The shared hypernetwork is optimized under differential privacy, ensuring that only noise-perturbed, clipped gradients are aggregated across clients. A local MMD alignment between real and synthetic embeddings and a Lipschitz regularizer on hypernetwork outputs further enhance stability and distributional coherence under non-IID conditions. After training, a neutral meta-code enables domain agnostic synthesis, while mixtures of meta-codes provide controllable multi-domain coverage. FedHypeVAE unifies personalization, privacy, and distribution alignment at the generator level, establishing a principled foundation for privacy-preserving data synthesis in federated settings. Code: github.com/sunnyinAI/FedHypeVAE",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00785v1",
        "pdf": "https://arxiv.org/pdf/2601.00785v1"
      },
      "arxiv_id": "2601.00785v1",
      "comment": "10 pages, 1 figures, Accepted at AAI'26",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00781v1",
      "title": "Categorical Reparameterization with Denoising Diffusion models",
      "authors": [
        "Samson Gourevitch",
        "Alain Durmus",
        "Eric Moulines",
        "Jimmy Olsson",
        "Yazid Janati"
      ],
      "abstract": "Gradient-based optimization with categorical variables typically relies on score-function estimators, which are unbiased but noisy, or on continuous relaxations that replace the discrete distribution with a smooth surrogate admitting a pathwise (reparameterized) gradient, at the cost of optimizing a biased, temperature-dependent objective. In this paper, we extend this family of relaxations by introducing a diffusion-based soft reparameterization for categorical distributions. For these distributions, the denoiser under a Gaussian noising process admits a closed form and can be computed efficiently, yielding a training-free diffusion sampler through which we can backpropagate. Our experiments show that the proposed reparameterization trick yields competitive or improved optimization performance on various benchmarks.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00781v1",
        "pdf": "https://arxiv.org/pdf/2601.00781v1"
      },
      "arxiv_id": "2601.00781v1",
      "comment": "working paper",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00777v1",
      "title": "Investigating the Viability of Employing Multi-modal Large Language Models in the Context of Audio Deepfake Detection",
      "authors": [
        "Akanksha Chuchra",
        "Shukesh Reddy",
        "Sudeepta Mishra",
        "Abhijit Das",
        "Abhinav Dhall"
      ],
      "abstract": "While Vision-Language Models (VLMs) and Multimodal Large Language Models (MLLMs) have shown strong generalisation in detecting image and video deepfakes, their use for audio deepfake detection remains largely unexplored. In this work, we aim to explore the potential of MLLMs for audio deepfake detection. Combining audio inputs with a range of text prompts as queries to find out the viability of MLLMs to learn robust representations across modalities for audio deepfake detection. Therefore, we attempt to explore text-aware and context-rich, question-answer based prompts with binary decisions. We hypothesise that such a feature-guided reasoning will help in facilitating deeper multimodal understanding and enable robust feature learning for audio deepfake detection. We evaluate the performance of two MLLMs, Qwen2-Audio-7B-Instruct and SALMONN, in two evaluation modes: (a) zero-shot and (b) fine-tuned. Our experiments demonstrate that combining audio with a multi-prompt approach could be a viable way forward for audio deepfake detection. Our experiments show that the models perform poorly without task-specific training and struggle to generalise to out-of-domain data. However, they achieve good performance on in-domain data with minimal supervision, indicating promising potential for audio deepfake detection.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.SD",
        "cs.CV"
      ],
      "primary_category": "cs.SD",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00777v1",
        "pdf": "https://arxiv.org/pdf/2601.00777v1"
      },
      "arxiv_id": "2601.00777v1",
      "comment": "Accepted at IJCB 2025",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00770v1",
      "title": "LLM Agents for Combinatorial Efficient Frontiers: Investment Portfolio Optimization",
      "authors": [
        "Simon Paquette-Greenbaum",
        "Jiangbo Yu"
      ],
      "abstract": "Investment portfolio optimization is a task conducted in all major financial institutions. The Cardinality Constrained Mean-Variance Portfolio Optimization (CCPO) problem formulation is ubiquitous for portfolio optimization. The challenge of this type of portfolio optimization, a mixed-integer quadratic programming (MIQP) problem, arises from the intractability of solutions from exact solvers, where heuristic algorithms are used to find approximate portfolio solutions. CCPO entails many laborious and complex workflows and also requires extensive effort pertaining to heuristic algorithm development, where the combination of pooled heuristic solutions results in improved efficient frontiers. Hence, common approaches are to develop many heuristic algorithms. Agentic frameworks emerge as a promising candidate for many problems within combinatorial optimization, as they have been shown to be equally efficient with regard to automating large workflows and have been shown to be excellent in terms of algorithm development, sometimes surpassing human-level performance. This study implements a novel agentic framework for the CCPO and explores several concrete architectures. In benchmark problems, the implemented agentic framework matches state-of-the-art algorithms. Furthermore, complex workflows and algorithm development efforts are alleviated, while in the worst case, lower but acceptable error is reported.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.CE",
        "cs.AI",
        "econ.GN"
      ],
      "primary_category": "cs.CE",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00770v1",
        "pdf": "https://arxiv.org/pdf/2601.00770v1"
      },
      "arxiv_id": "2601.00770v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00759v1",
      "title": "Unified Primitive Proxies for Structured Shape Completion",
      "authors": [
        "Zhaiyu Chen",
        "Yuqing Wang",
        "Xiao Xiang Zhu"
      ],
      "abstract": "Structured shape completion recovers missing geometry as primitives rather than as unstructured points, which enables primitive-based surface reconstruction. Instead of following the prevailing cascade, we rethink how primitives and points should interact, and find it more effective to decode primitives in a dedicated pathway that attends to shared shape features. Following this principle, we present UniCo, which in a single feed-forward pass predicts a set of primitives with complete geometry, semantics, and inlier membership. To drive this unified representation, we introduce primitive proxies, learnable queries that are contextualized to produce assembly-ready outputs. To ensure consistent optimization, our training strategy couples primitives and points with online target updates. Across synthetic and real-world benchmarks with four independent assembly solvers, UniCo consistently outperforms recent baselines, lowering Chamfer distance by up to 50% and improving normal consistency by up to 7%. These results establish an attractive recipe for structured 3D understanding from incomplete data. Project page: https://unico-completion.github.io.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00759v1",
        "pdf": "https://arxiv.org/pdf/2601.00759v1"
      },
      "arxiv_id": "2601.00759v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00756v1",
      "title": "Memory Bank Compression for Continual Adaptation of Large Language Models",
      "authors": [
        "Thomas Katraouras",
        "Dimitrios Rafailidis"
      ],
      "abstract": "Large Language Models (LLMs) have become a mainstay for many everyday applications. However, as data evolve their knowledge quickly becomes outdated. Continual learning aims to update LLMs with new information without erasing previously acquired knowledge. Although methods such as full fine-tuning can incorporate new data, they are computationally expensive and prone to catastrophic forgetting, where prior knowledge is overwritten. Memory-augmented approaches address this by equipping LLMs with a memory bank, that is an external memory module which stores information for future use. However, these methods face a critical limitation, in particular, the memory bank constantly grows in the real-world scenario when large-scale data streams arrive. In this paper, we propose MBC, a model that compresses the memory bank through a codebook optimization strategy during online adaptation learning. To ensure stable learning, we also introduce an online resetting mechanism that prevents codebook collapse. In addition, we employ Key-Value Low-Rank Adaptation in the attention layers of the LLM, enabling efficient utilization of the compressed memory representations. Experiments with benchmark question-answering datasets demonstrate that MBC reduces the memory bank size to 0.3% when compared against the most competitive baseline, while maintaining high retention accuracy during online adaptation learning. Our code is publicly available at https://github.com/Thomkat/MBC.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00756v1",
        "pdf": "https://arxiv.org/pdf/2601.00756v1"
      },
      "arxiv_id": "2601.00756v1",
      "comment": "Accepted to the 41st ACM/SIGAPP Symposium on Applied Computing (SAC '26)",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00748v1",
      "title": "A Machine Learning Framework for Off Ball Defensive Role and Performance Evaluation in Football",
      "authors": [
        "Sean Groom",
        "Shuo Wang",
        "Francisco Belo",
        "Axl Rice",
        "Liam Anderson"
      ],
      "abstract": "Evaluating off-ball defensive performance in football is challenging, as traditional metrics do not capture the nuanced coordinated movements that limit opponent action selection and success probabilities. Although widely used possession value models excel at appraising on-ball actions, their application to defense remains limited. Existing counterfactual methods, such as ghosting models, help extend these analyses but often rely on simulating \"average\" behavior that lacks tactical context. To address this, we introduce a covariate-dependent Hidden Markov Model (CDHMM) tailored to corner kicks, a highly structured aspect of football games. Our label-free model infers time-resolved man-marking and zonal assignments directly from player tracking data. We leverage these assignments to propose a novel framework for defensive credit attribution and a role-conditioned ghosting method for counterfactual analysis of off-ball defensive performance. We show how these contributions provide a interpretable evaluation of defensive contributions against context-aware baselines.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00748v1",
        "pdf": "https://arxiv.org/pdf/2601.00748v1"
      },
      "arxiv_id": "2601.00748v1",
      "comment": "40 pages, 16 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00747v1",
      "title": "The Reasoning-Creativity Trade-off: Toward Creativity-Driven Problem Solving",
      "authors": [
        "Max Ruiz Luyten",
        "Mihaela van der Schaar"
      ],
      "abstract": "State-of-the-art large language model (LLM) pipelines rely on bootstrapped reasoning loops: sampling diverse chains of thought and reinforcing the highest-scoring ones, mainly optimizing correctness. We analyze how this design choice is sensitive to the collapse of the model's distribution over reasoning paths, slashing semantic entropy and undermining creative problem-solving. To analyze this failure, we introduce Distributional Creative Reasoning (DCR), a unified variational objective that casts training as gradient flow through probability measures on solution traces. STaR, GRPO, and DPO, as well as entropy bonuses, and other methods, all constitute special cases of the same loss. The framework delivers three core results: (i) the diversity decay theorem, describing how correctness-based objectives lead to distinct modes of diversity decay for STaR, GRPO, and DPO; (ii) designs that ensure convergence to a stable and diverse policy, effectively preventing collapse; and (iii) simple, actionable recipes to achieve this in practice. DCR thus offers the first principled recipe for LLMs that remain both correct and creative.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00747v1",
        "pdf": "https://arxiv.org/pdf/2601.00747v1"
      },
      "arxiv_id": "2601.00747v1",
      "comment": "56 pages, 9 figures, submitted to Twenty-Ninth Annual Conference on Artificial Intelligence and Statistics",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00743v1",
      "title": "An Agentic Framework for Neuro-Symbolic Programming",
      "authors": [
        "Aliakbar Nafar",
        "Chetan Chigurupati",
        "Danial Kamali",
        "Hamid Karimian",
        "Parisa Kordjamshidi"
      ],
      "abstract": "Integrating symbolic constraints into deep learning models could make them more robust, interpretable, and data-efficient. Still, it remains a time-consuming and challenging task. Existing frameworks like DomiKnowS help this integration by providing a high-level declarative programming interface, but they still assume the user is proficient with the library's specific syntax. We propose AgenticDomiKnowS (ADS) to eliminate this dependency. ADS translates free-form task descriptions into a complete DomiKnowS program using an agentic workflow that creates and tests each DomiKnowS component separately. The workflow supports optional human-in-the-loop intervention, enabling users familiar with DomiKnowS to refine intermediate outputs. We show how ADS enables experienced DomiKnowS users and non-users to rapidly construct neuro-symbolic programs, reducing development time from hours to 10-15 minutes.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00743v1",
        "pdf": "https://arxiv.org/pdf/2601.00743v1"
      },
      "arxiv_id": "2601.00743v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00737v1",
      "title": "Stochastic Actor-Critic: Mitigating Overestimation via Temporal Aleatoric Uncertainty",
      "authors": [
        "Uğurcan Özalp"
      ],
      "abstract": "Off-policy actor-critic methods in reinforcement learning train a critic with temporal-difference updates and use it as a learning signal for the policy (actor). This design typically achieves higher sample efficiency than purely on-policy methods. However, critic networks tend to overestimate value estimates systematically. This is often addressed by introducing a pessimistic bias based on uncertainty estimates. Current methods employ ensembling to quantify the critic's epistemic uncertainty-uncertainty due to limited data and model ambiguity-to scale pessimistic updates. In this work, we propose a new algorithm called Stochastic Actor-Critic (STAC) that incorporates temporal (one-step) aleatoric uncertainty-uncertainty arising from stochastic transitions, rewards, and policy-induced variability in Bellman targets-to scale pessimistic bias in temporal-difference updates, rather than relying on epistemic uncertainty. STAC uses a single distributional critic network to model the temporal return uncertainty, and applies dropout to both the critic and actor networks for regularization. Our results show that pessimism based on a distributional critic alone suffices to mitigate overestimation, and naturally leads to risk-averse behavior in stochastic environments. Introducing dropout further improves training stability and performance by means of regularization. With this design, STAC achieves improved computational efficiency using a single distributional critic network.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00737v1",
        "pdf": "https://arxiv.org/pdf/2601.00737v1"
      },
      "arxiv_id": "2601.00737v1",
      "comment": "19 pages",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00736v1",
      "title": "Exploring the Performance of Large Language Models on Subjective Span Identification Tasks",
      "authors": [
        "Alphaeus Dmonte",
        "Roland Oruche",
        "Tharindu Ranasinghe",
        "Marcos Zampieri",
        "Prasad Calyam"
      ],
      "abstract": "Identifying relevant text spans is important for several downstream tasks in NLP, as it contributes to model explainability. While most span identification approaches rely on relatively smaller pre-trained language models like BERT, a few recent approaches have leveraged the latest generation of Large Language Models (LLMs) for the task. Current work has focused on explicit span identification like Named Entity Recognition (NER), while more subjective span identification with LLMs in tasks like Aspect-based Sentiment Analysis (ABSA) has been underexplored. In this paper, we fill this important gap by presenting an evaluation of the performance of various LLMs on text span identification in three popular tasks, namely sentiment analysis, offensive language identification, and claim verification. We explore several LLM strategies like instruction tuning, in-context learning, and chain of thought. Our results indicate underlying relationships within text aid LLMs in identifying precise text spans.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00736v1",
        "pdf": "https://arxiv.org/pdf/2601.00736v1"
      },
      "arxiv_id": "2601.00736v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00730v1",
      "title": "Grading Handwritten Engineering Exams with Multimodal Large Language Models",
      "authors": [
        "Janez Perš",
        "Jon Muhovič",
        "Andrej Košir",
        "Boštjan Murovec"
      ],
      "abstract": "Handwritten STEM exams capture open-ended reasoning and diagrams, but manual grading is slow and difficult to scale. We present an end-to-end workflow for grading scanned handwritten engineering quizzes with multimodal large language models (LLMs) that preserves the standard exam process (A4 paper, unconstrained student handwriting). The lecturer provides only a handwritten reference solution (100%) and a short set of grading rules; the reference is converted into a text-only summary that conditions grading without exposing the reference scan. Reliability is achieved through a multi-stage design with a format/presence check to prevent grading blank answers, an ensemble of independent graders, supervisor aggregation, and rigid templates with deterministic validation to produce auditable, machine-parseable reports. We evaluate the frozen pipeline in a clean-room protocol on a held-out real course quiz in Slovenian, including hand-drawn circuit schematics. With state-of-the-art backends (GPT-5.2 and Gemini-3 Pro), the full pipeline achieves $\\approx$8-point mean absolute difference to lecturer grades with low bias and an estimated manual-review trigger rate of $\\approx$17% at $D_{\\max}=40$. Ablations show that trivial prompting and removing the reference solution substantially degrade accuracy and introduce systematic over-grading, confirming that structured prompting and reference grounding are essential.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00730v1",
        "pdf": "https://arxiv.org/pdf/2601.00730v1"
      },
      "arxiv_id": "2601.00730v1",
      "comment": "10 pages, 5 figures, 2 tables. Supplementary material available at https://lmi.fe.uni-lj.si/en/janez-pers-2/supplementary-material/",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00728v1",
      "title": "Precision Autotuning for Linear Solvers via Contextual Bandit-Based RL",
      "authors": [
        "Erin Carson",
        "Xinye Chen"
      ],
      "abstract": "We propose a reinforcement learning (RL) framework for adaptive precision tuning of linear solvers, and can be extended to general algorithms. The framework is formulated as a contextual bandit problem and solved using incremental action-value estimation with a discretized state space to select optimal precision configurations for computational steps, balancing precision and computational efficiency. To verify its effectiveness, we apply the framework to iterative refinement for solving linear systems $Ax = b$. In this application, our approach dynamically chooses precisions based on calculated features from the system. In detail, a Q-table maps discretized features (e.g., approximate condition number and matrix norm)to actions (chosen precision configurations for specific steps), optimized via an epsilon-greedy strategy to maximize a multi-objective reward balancing accuracy and computational cost. Empirical results demonstrate effective precision selection, reducing computational cost while maintaining accuracy comparable to double-precision baselines. The framework generalizes to diverse out-of-sample data and offers insight into utilizing RL precision selection for other numerical algorithms, advancing mixed-precision numerical methods in scientific computing. To the best of our knowledge, this is the first work on precision autotuning with RL and verified on unseen datasets.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.LG",
        "math.NA"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00728v1",
        "pdf": "https://arxiv.org/pdf/2601.00728v1"
      },
      "arxiv_id": "2601.00728v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00725v1",
      "title": "Multi-Level Feature Fusion for Continual Learning in Visual Quality Inspection",
      "authors": [
        "Johannes C. Bauer",
        "Paul Geng",
        "Stephan Trattnig",
        "Petr Dokládal",
        "Rüdiger Daub"
      ],
      "abstract": "Deep neural networks show great potential for automating various visual quality inspection tasks in manufacturing. However, their applicability is limited in more volatile scenarios, such as remanufacturing, where the inspected products and defect patterns often change. In such settings, deployed models require frequent adaptation to novel conditions, effectively posing a continual learning problem. To enable quick adaptation, the necessary training processes must be computationally efficient while still avoiding effects like catastrophic forgetting. This work presents a multi-level feature fusion (MLFF) approach that aims to improve both aspects simultaneously by utilizing representations from different depths of a pretrained network. We show that our approach is able to match the performance of end-to-end training for different quality inspection problems while using significantly less trainable parameters. Furthermore, it reduces catastrophic forgetting and improves generalization robustness to new product types or defects.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00725v1",
        "pdf": "https://arxiv.org/pdf/2601.00725v1"
      },
      "arxiv_id": "2601.00725v1",
      "comment": "Accepted at the 2025 IEEE 13th International Conference on Control, Mechatronics and Automation (ICCMA)",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00716v1",
      "title": "Detecting Performance Degradation under Data Shift in Pathology Vision-Language Model",
      "authors": [
        "Hao Guan",
        "Li Zhou"
      ],
      "abstract": "Vision-Language Models have demonstrated strong potential in medical image analysis and disease diagnosis. However, after deployment, their performance may deteriorate when the input data distribution shifts from that observed during development. Detecting such performance degradation is essential for clinical reliability, yet remains challenging for large pre-trained VLMs operating without labeled data. In this study, we investigate performance degradation detection under data shift in a state-of-the-art pathology VLM. We examine both input-level data shift and output-level prediction behavior to understand their respective roles in monitoring model reliability. To facilitate systematic analysis of input data shift, we develop DomainSAT, a lightweight toolbox with a graphical interface that integrates representative shift detection algorithms and enables intuitive exploration of data shift. Our analysis shows that while input data shift detection is effective at identifying distributional changes and providing early diagnostic signals, it does not always correspond to actual performance degradation. Motivated by this observation, we further study output-based monitoring and introduce a label-free, confidence-based degradation indicator that directly captures changes in model prediction confidence. We find that this indicator exhibits a close relationship with performance degradation and serves as an effective complement to input shift detection. Experiments on a large-scale pathology dataset for tumor classification demonstrate that combining input data shift detection and output confidence-based indicators enables more reliable detection and interpretation of performance degradation in VLMs under data shift. These findings provide a practical and complementary framework for monitoring the reliability of foundation models in digital pathology.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00716v1",
        "pdf": "https://arxiv.org/pdf/2601.00716v1"
      },
      "arxiv_id": "2601.00716v1",
      "comment": "8 pages, 6 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00714v1",
      "title": "KDPhys: An Attention Guided 3D to 2D Knowledge Distillation for Real-time Video-Based Physiological Measurement",
      "authors": [
        "Nicky Nirlipta Sahoo",
        "VS Sachidanand",
        "Matcha Naga Gayathri",
        "Balamurali Murugesan",
        "Keerthi Ram",
        "Jayaraj Joseph",
        "Mohanasankar Sivaprakasam"
      ],
      "abstract": "Camera-based physiological monitoring, such as remote photoplethysmography (rPPG), captures subtle variations in skin optical properties caused by pulsatile blood volume changes using standard digital camera sensors. The demand for real-time, non-contact physiological measurement has increased significantly, particularly during the SARS-CoV-2 pandemic, to support telehealth and remote health monitoring applications. In this work, we propose an attention-based knowledge distillation (KD) framework, termed KDPhys, for extracting rPPG signals from facial video sequences. The proposed method distills global temporal representations from a 3D convolutional neural network (CNN) teacher model to a lightweight 2D CNN student model through effective 3D-to-2D feature distillation. To the best of our knowledge, this is the first application of knowledge distillation in the rPPG domain. Furthermore, we introduce a Distortion Loss incorporating Shape and Time (DILATE), which jointly accounts for both morphological and temporal characteristics of rPPG signals. Extensive qualitative and quantitative evaluations are conducted on three benchmark datasets. The proposed model achieves a significant reduction in computational complexity, using only half the parameters of existing methods while operating 56.67% faster. With just 0.23M parameters, it achieves an 18.15% reduction in Mean Absolute Error (MAE) compared to state-of-the-art approaches, attaining an average MAE of 1.78 bpm across all datasets. Additional experiments under diverse environmental conditions and activity scenarios further demonstrate the robustness and adaptability of the proposed approach.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "eess.IV"
      ],
      "primary_category": "eess.IV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00714v1",
        "pdf": "https://arxiv.org/pdf/2601.00714v1"
      },
      "arxiv_id": "2601.00714v1",
      "comment": "This paper has been published in Biomedical Signal Processing and Control",
      "journal_ref": "Biomed. Signal Process. Control, vol. 107, art. no. 107797, 2025",
      "has_code": false
    },
    {
      "id": "2601.00703v1",
      "title": "Efficient Deep Demosaicing with Spatially Downsampled Isotropic Networks",
      "authors": [
        "Cory Fan",
        "Wenchao Zhang"
      ],
      "abstract": "In digital imaging, image demosaicing is a crucial first step which recovers the RGB information from a color filter array (CFA). Oftentimes, deep learning is utilized to perform image demosaicing. Given that most modern digital imaging applications occur on mobile platforms, applying deep learning to demosaicing requires lightweight and efficient networks. Isotropic networks, also known as residual-in-residual networks, have been often employed for image demosaicing and joint-demosaicing-and-denoising (JDD). Most demosaicing isotropic networks avoid spatial downsampling entirely, and thus are often prohibitively expensive computationally for mobile applications. Contrary to previous isotropic network designs, this paper claims that spatial downsampling to a signficant degree can improve the efficiency and performance of isotropic networks. To validate this claim, we design simple fully convolutional networks with and without downsampling using a mathematical architecture design technique adapted from DeepMAD, and find that downsampling improves empirical performance. Additionally, empirical testing of the downsampled variant, JD3Net, of our fully convolutional networks reveals strong empirical performance on a variety of image demosaicing and JDD tasks.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00703v1",
        "pdf": "https://arxiv.org/pdf/2601.00703v1"
      },
      "arxiv_id": "2601.00703v1",
      "comment": "9 pages, 5 figures. To be published at WVAQ Workshop at WACV",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00702v1",
      "title": "DefVINS: Visual-Inertial Odometry for Deformable Scenes",
      "authors": [
        "Samuel Cerezo",
        "Javier Civera"
      ],
      "abstract": "Deformable scenes violate the rigidity assumptions underpinning classical visual-inertial odometry (VIO), often leading to over-fitting to local non-rigid motion or severe drift when deformation dominates visual parallax. We introduce DefVINS, a visual-inertial odometry framework that explicitly separates a rigid, IMU-anchored state from a non--rigid warp represented by an embedded deformation graph. The system is initialized using a standard VIO procedure that fixes gravity, velocity, and IMU biases, after which non-rigid degrees of freedom are activated progressively as the estimation becomes well conditioned. An observability analysis is included to characterize how inertial measurements constrain the rigid motion and render otherwise unobservable modes identifiable in the presence of deformation. This analysis motivates the use of IMU anchoring and informs a conditioning-based activation strategy that prevents ill-posed updates under poor excitation. Ablation studies demonstrate the benefits of combining inertial constraints with observability-aware deformation activation, resulting in improved robustness under non-rigid environments.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.RO",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00702v1",
        "pdf": "https://arxiv.org/pdf/2601.00702v1"
      },
      "arxiv_id": "2601.00702v1",
      "comment": "4 figures, 3 tables. Submitted to RA-L",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00698v1",
      "title": "BSAT: B-Spline Adaptive Tokenizer for Long-Term Time Series Forecasting",
      "authors": [
        "Maximilian Reinwardt",
        "Michael Eichelbeck",
        "Matthias Althoff"
      ],
      "abstract": "Long-term time series forecasting using transformers is hampered by the quadratic complexity of self-attention and the rigidity of uniform patching, which may be misaligned with the data's semantic structure. In this paper, we introduce the \\textit{B-Spline Adaptive Tokenizer (BSAT)}, a novel, parameter-free method that adaptively segments a time series by fitting it with B-splines. BSAT algorithmically places tokens in high-curvature regions and represents each variable-length basis function as a fixed-size token, composed of its coefficient and position. Further, we propose a hybrid positional encoding that combines a additive learnable positional encoding with Rotary Positional Embedding featuring a layer-wise learnable base: L-RoPE. This allows each layer to attend to different temporal dependencies. Our experiments on several public benchmarks show that our model is competitive with strong performance at high compression rates. This makes it particularly well-suited for use cases with strong memory constraints.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00698v1",
        "pdf": "https://arxiv.org/pdf/2601.00698v1"
      },
      "arxiv_id": "2601.00698v1",
      "comment": "20 pages, 7 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00696v1",
      "title": "Bayesian Inverse Games with High-Dimensional Multi-Modal Observations",
      "authors": [
        "Yash Jain",
        "Xinjie Liu",
        "Lasse Peters",
        "David Fridovich-Keil",
        "Ufuk Topcu"
      ],
      "abstract": "Many multi-agent interaction scenarios can be naturally modeled as noncooperative games, where each agent's decisions depend on others' future actions. However, deploying game-theoretic planners for autonomous decision-making requires a specification of all agents' objectives. To circumvent this practical difficulty, recent work develops maximum likelihood techniques for solving inverse games that can identify unknown agent objectives from interaction data. Unfortunately, these methods only infer point estimates and do not quantify estimator uncertainty; correspondingly, downstream planning decisions can overconfidently commit to unsafe actions. We present an approximate Bayesian inference approach for solving the inverse game problem, which can incorporate observation data from multiple modalities and be used to generate samples from the Bayesian posterior over the hidden agent objectives given limited sensor observations in real time. Concretely, the proposed Bayesian inverse game framework trains a structured variational autoencoder with an embedded differentiable Nash game solver on interaction datasets and does not require labels of agents' true objectives. Extensive experiments show that our framework successfully learns prior and posterior distributions, improves inference quality over maximum likelihood estimation-based inverse game approaches, and enables safer downstream decision-making without sacrificing efficiency. When trajectory information is uninformative or unavailable, multimodal inference further reduces uncertainty by exploiting additional observation modalities.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.LG",
        "cs.GT",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00696v1",
        "pdf": "https://arxiv.org/pdf/2601.00696v1"
      },
      "arxiv_id": "2601.00696v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00694v1",
      "title": "A Vision-and-Knowledge Enhanced Large Language Model for Generalizable Pedestrian Crossing Behavior Inference",
      "authors": [
        "Qingwen Pu",
        "Kun Xie",
        "Hong Yang",
        "Guocong Zhai"
      ],
      "abstract": "Existing paradigms for inferring pedestrian crossing behavior, ranging from statistical models to supervised learning methods, demonstrate limited generalizability and perform inadequately on new sites. Recent advances in Large Language Models (LLMs) offer a shift from numerical pattern fitting to semantic, context-aware behavioral reasoning, yet existing LLM applications lack domain-specific adaptation and visual context. This study introduces Pedestrian Crossing LLM (PedX-LLM), a vision-and-knowledge enhanced framework designed to transform pedestrian crossing inference from site-specific pattern recognition to generalizable behavioral reasoning. By integrating LLaVA-extracted visual features with textual data and transportation domain knowledge, PedX-LLM fine-tunes a LLaMA-2-7B foundation model via Low-Rank Adaptation (LoRA) to infer crossing decisions. PedX-LLM achieves 82.0% balanced accuracy, outperforming the best statistical and supervised learning methods. Results demonstrate that the vision-augmented module contributes a 2.9% performance gain by capturing the built environment and integrating domain knowledge yields an additional 4.1% improvement. To evaluate generalizability across unseen environments, cross-site validation was conducted using site-based partitioning. The zero-shot PedX-LLM configuration achieves 66.9% balanced accuracy on five unseen test sites, outperforming the baseline data-driven methods by at least 18 percentage points. Incorporating just five validation examples via few-shot learning to PedX-LLM further elevates the balanced accuracy to 72.2%. PedX-LLM demonstrates strong generalizability to unseen scenarios, confirming that vision-and-knowledge-enhanced reasoning enables the model to mimic human-like decision logic and overcome the limitations of purely data-driven methods.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00694v1",
        "pdf": "https://arxiv.org/pdf/2601.00694v1"
      },
      "arxiv_id": "2601.00694v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00693v1",
      "title": "ARISE: Adaptive Reinforcement Integrated with Swarm Exploration",
      "authors": [
        "Rajiv Chaitanya M",
        "D R Ramesh Babu"
      ],
      "abstract": "Effective exploration remains a key challenge in RL, especially with non-stationary rewards or high-dimensional policies. We introduce ARISE, a lightweight framework that enhances reinforcement learning by augmenting standard policy-gradient methods with a compact swarm-based exploration layer. ARISE blends policy actions with particle-driven proposals, where each particle represents a candidate policy trajectory sampled in the action space, and modulates exploration adaptively using reward-variance cues. While easy benchmarks exhibit only slight improvements (e.g., +0.7% on CartPole-v1), ARISE yields substantial gains on more challenging tasks, including +46% on LunarLander-v3 and +22% on Hopper-v4, while preserving stability on Walker2d and Ant. Under non-stationary reward shifts, ARISE provides marked robustness advantages, outperforming PPO by +75 points on CartPole and improving LunarLander accordingly. Ablation studies confirm that both the swarm component and the adaptive mechanism contribute to the performance. Overall, ARISE offers a simple, architecture-agnostic route to more exploratory and resilient RL agents without altering core algorithmic structures.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.LG",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00693v1",
        "pdf": "https://arxiv.org/pdf/2601.00693v1"
      },
      "arxiv_id": "2601.00693v1",
      "comment": "12 pages. Accepted for presentation at WCSC 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00691v1",
      "title": "TeleDoCTR: Domain-Specific and Contextual Troubleshooting for Telecommunications",
      "authors": [
        "Mohamed Trabelsi",
        "Huseyin Uzunalioglu"
      ],
      "abstract": "Ticket troubleshooting refers to the process of analyzing and resolving problems that are reported through a ticketing system. In large organizations offering a wide range of services, this task is highly complex due to the diversity of submitted tickets and the need for specialized domain knowledge. In particular, troubleshooting in telecommunications (telecom) is a very time-consuming task as it requires experts to interpret ticket content, consult documentation, and search historical records to identify appropriate resolutions. This human-intensive approach not only delays issue resolution but also hinders overall operational efficiency. To enhance the effectiveness and efficiency of ticket troubleshooting in telecom, we propose TeleDoCTR, a novel telecom-related, domain-specific, and contextual troubleshooting system tailored for end-to-end ticket resolution in telecom. TeleDoCTR integrates both domain-specific ranking and generative models to automate key steps of the troubleshooting workflow which are: routing tickets to the appropriate expert team responsible for resolving the ticket (classification task), retrieving contextually and semantically similar historical tickets (retrieval task), and generating a detailed fault analysis report outlining the issue, root cause, and potential solutions (generation task). We evaluate TeleDoCTR on a real-world dataset from a telecom infrastructure and demonstrate that it achieves superior performance over existing state-of-the-art methods, significantly enhancing the accuracy and efficiency of the troubleshooting process.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.LG",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00691v1",
        "pdf": "https://arxiv.org/pdf/2601.00691v1"
      },
      "arxiv_id": "2601.00691v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00689v1",
      "title": "Cost Optimization in Production Line Using Genetic Algorithm",
      "authors": [
        "Alireza Rezaee"
      ],
      "abstract": "This paper presents a genetic algorithm (GA) approach to cost-optimal task scheduling in a production line. The system consists of a set of serial processing tasks, each with a given duration, unit execution cost, and precedence constraints, which must be assigned to an unlimited number of stations subject to a per-station duration bound. The objective is to minimize the total production cost, modeled as a station-wise function of task costs and the duration bound, while strictly satisfying all prerequisite and capacity constraints. Two chromosome encoding strategies are investigated: a station-based representation implemented using the JGAP library with SuperGene validity checks, and a task-based representation in which genes encode station assignments directly. For each encoding, standard GA operators (crossover, mutation, selection, and replacement) are adapted to preserve feasibility and drive the population toward lower-cost schedules. Experimental results on three classes of precedence structures-tightly coupled, loosely coupled, and uncoupled-demonstrate that the task-based encoding yields smoother convergence and more reliable cost minimization than the station-based encoding, particularly when the number of valid schedules is large. The study highlights the advantages of GA over gradient-based and analytical methods for combinatorial scheduling problems, especially in the presence of complex constraints and non-differentiable cost landscapes.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.NE",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00689v1",
        "pdf": "https://arxiv.org/pdf/2601.00689v1"
      },
      "arxiv_id": "2601.00689v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00679v1",
      "title": "QSLM: A Performance- and Memory-aware Quantization Framework with Tiered Search Strategy for Spike-driven Language Models",
      "authors": [
        "Rachmad Vidya Wicaksana Putra",
        "Pasindu Wickramasinghe",
        "Muhammad Shafique"
      ],
      "abstract": "Large Language Models (LLMs) have been emerging as prominent AI models for solving many natural language tasks due to their high performance (e.g., accuracy) and capabilities in generating high-quality responses to the given inputs. However, their large computational cost, huge memory footprints, and high processing power/energy make it challenging for their embedded deployments. Amid several tinyLLMs, recent works have proposed spike-driven language models (SLMs) for significantly reducing the processing power/energy of LLMs. However, their memory footprints still remain too large for low-cost and resource-constrained embedded devices. Manual quantization approach may effectively compress SLM memory footprints, but it requires a huge design time and compute power to find the quantization setting for each network, hence making this approach not-scalable for handling different networks, performance requirements, and memory budgets. To bridge this gap, we propose QSLM, a novel framework that performs automated quantization for compressing pre-trained SLMs, while meeting the performance and memory constraints. To achieve this, QSLM first identifies the hierarchy of the given network architecture and the sensitivity of network layers under quantization, then employs a tiered quantization strategy (e.g., global-, block-, and module-level quantization) while leveraging a multi-objective performance-and-memory trade-off function to select the final quantization setting. Experimental results indicate that our QSLM reduces memory footprint by up to 86.5%, reduces power consumption by up to 20%, maintains high performance across different tasks (i.e., by up to 84.4% accuracy of sentiment classification on the SST-2 dataset and perplexity score of 23.2 for text generation on the WikiText-2 dataset) close to the original non-quantized model while meeting the performance and memory constraints.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00679v1",
        "pdf": "https://arxiv.org/pdf/2601.00679v1"
      },
      "arxiv_id": "2601.00679v1",
      "comment": "Accepted at the Design, Automation and Test in Europe Conference (DATE) 2025 on April 20th-22nd, 2025 in Verona, Italy",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00678v1",
      "title": "Pixel-to-4D: Camera-Controlled Image-to-Video Generation with Dynamic 3D Gaussians",
      "authors": [
        "Melonie de Almeida",
        "Daniela Ivanova",
        "Tong Shi",
        "John H. Williamson",
        "Paul Henderson"
      ],
      "abstract": "Humans excel at forecasting the future dynamics of a scene given just a single image. Video generation models that can mimic this ability are an essential component for intelligent systems. Recent approaches have improved temporal coherence and 3D consistency in single-image-conditioned video generation. However, these methods often lack robust user controllability, such as modifying the camera path, limiting their applicability in real-world applications. Most existing camera-controlled image-to-video models struggle with accurately modeling camera motion, maintaining temporal consistency, and preserving geometric integrity. Leveraging explicit intermediate 3D representations offers a promising solution by enabling coherent video generation aligned with a given camera trajectory. Although these methods often use 3D point clouds to render scenes and introduce object motion in a later stage, this two-step process still falls short in achieving full temporal consistency, despite allowing precise control over camera movement. We propose a novel framework that constructs a 3D Gaussian scene representation and samples plausible object motion, given a single image in a single forward pass. This enables fast, camera-guided video generation without the need for iterative denoising to inject object motion into render frames. Extensive experiments on the KITTI, Waymo, RealEstate10K and DL3DV-10K datasets demonstrate that our method achieves state-of-the-art video quality and inference efficiency. The project page is available at https://melonienimasha.github.io/Pixel-to-4D-Website.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00678v1",
        "pdf": "https://arxiv.org/pdf/2601.00678v1"
      },
      "arxiv_id": "2601.00678v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00677v1",
      "title": "IRPO: Scaling the Bradley-Terry Model via Reinforcement Learning",
      "authors": [
        "Haonan Song",
        "Qingchen Xie",
        "Huan Zhu",
        "Feng Xiao",
        "Luxi Xing",
        "Fuzhen Li",
        "Liu Kang",
        "Feng Jiang",
        "Zhiyong Zheng",
        "Fan Yang"
      ],
      "abstract": "Generative Reward Models (GRMs) have attracted considerable research interest in reward modeling due to their interpretability, inference-time scalability, and potential for refinement through reinforcement learning (RL). However, widely used pairwise GRMs create a computational bottleneck when integrated with RL algorithms such as Group Relative Policy Optimization (GRPO). This bottleneck arises from two factors: (i) the O(n^2) time complexity of pairwise comparisons required to obtain relative scores, and (ii) the computational overhead of repeated sampling or additional chain-of-thought (CoT) reasoning to improve performance. To address the first factor, we propose Intergroup Relative Preference Optimization (IRPO), a novel RL framework that incorporates the well-established Bradley-Terry model into GRPO. By generating a pointwise score for each response, IRPO enables efficient evaluation of arbitrarily many candidates during RL training while preserving interpretability and fine-grained reward signals. Experimental results demonstrate that IRPO achieves state-of-the-art (SOTA) performance among pointwise GRMs across multiple benchmarks, with performance comparable to that of current leading pairwise GRMs. Furthermore, we show that IRPO significantly outperforms pairwise GRMs in post-training evaluations.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00677v1",
        "pdf": "https://arxiv.org/pdf/2601.00677v1"
      },
      "arxiv_id": "2601.00677v1",
      "comment": "14 pages, 4 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00672v1",
      "title": "Sparse FEONet: A Low-Cost, Memory-Efficient Operator Network via Finite-Element Local Sparsity for Parametric PDEs",
      "authors": [
        "Seungchan Ko",
        "Jiyeon Kim",
        "Dongwook Shin"
      ],
      "abstract": "In this paper, we study the finite element operator network (FEONet), an operator-learning method for parametric problems, originally introduced in J. Y. Lee, S. Ko, and Y. Hong, Finite Element Operator Network for Solving Elliptic-Type Parametric PDEs, SIAM J. Sci. Comput., 47(2), C501-C528, 2025. FEONet realizes the parameter-to-solution map on a finite element space and admits a training procedure that does not require training data, while exhibiting high accuracy and robustness across a broad class of problems. However, its computational cost increases and accuracy may deteriorate as the number of elements grows, posing notable challenges for large-scale problems. In this paper, we propose a new sparse network architecture motivated by the structure of the finite elements to address this issue. Throughout extensive numerical experiments, we show that the proposed sparse network achieves substantial improvements in computational cost and efficiency while maintaining comparable accuracy. We also establish theoretical results demonstrating that the sparse architecture can approximate the target operator effectively and provide a stability analysis ensuring reliable training and prediction.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "math.NA",
        "cs.LG"
      ],
      "primary_category": "math.NA",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00672v1",
        "pdf": "https://arxiv.org/pdf/2601.00672v1"
      },
      "arxiv_id": "2601.00672v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00671v1",
      "title": "Fast-weight Product Key Memory",
      "authors": [
        "Tianyu Zhao",
        "Llion Jones"
      ],
      "abstract": "Sequence modeling layers in modern language models typically face a trade-off between storage capacity and computational efficiency. While Softmax attention offers unbounded storage at prohibitive quadratic costs, linear variants provide efficiency but suffer from limited, fixed-size storage. We propose Fast-weight Product Key Memory (FwPKM), a novel architecture that resolves this tension by transforming the sparse Product Key Memory (PKM) from a static module into a dynamic, \"fast-weight\" episodic memory. Unlike PKM, FwPKM updates its parameters dynamically at both training and inference time via local chunk-level gradient descent, allowing the model to rapidly memorize and retrieve new key-value pairs from input sequences. Experiments reveal that FwPKM functions as an effective episodic memory that complements the semantic memory of standard modules, yielding significant perplexity reductions on long-context datasets. Notably, in Needle in a Haystack evaluations, FwPKM generalizes to 128K-token contexts despite being trained on only 4K-token sequences.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00671v1",
        "pdf": "https://arxiv.org/pdf/2601.00671v1"
      },
      "arxiv_id": "2601.00671v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00669v1",
      "title": "Physics-Guided Dual-Domain Plug-and-Play ADMM for Low-Dose CT Reconstruction",
      "authors": [
        "Sayantan Dutta",
        "Sudhanya Chatterjee",
        "Ashwini Galande",
        "K. S. Shriram",
        "Bipul Das"
      ],
      "abstract": "Ultra-low-dose CT (ULDCT) imaging can greatly reduce patient radiation exposure, but the resulting scans suffer from severe structured and random noise that degrades image quality. To address this challenge, we propose a novel Plug-and-Play model-based iterative reconstruction framework (PnP-MBIR) that integrates a deep convolutional denoiser trained in a 2-stage self-supervised Noise-to-Noise (N2N) scheme. The method alternates between enforcing sinogram-domain data fidelity and applying the learned image-domain denoiser within an optimization, enabling artifact suppression while maintaining anatomical structure. The 2-stage protocol enables fully self-supervised training from noisy data, followed by high-dose fine-tuning, ensuring the denoiser's robustness in the ultra-low-dose regime. Our method enables high-quality reconstructions at $\\sim$70--80\\% lower dose levels, while maintaining diagnostic fidelity comparable to standard full-dose scans. Quantitative evaluations using Gray-Level Co-occurrence Matrix (GLCM) features -- including contrast, homogeneity, entropy, and correlation -- confirm that the proposed method yields superior texture consistency and detail preservation over standalone deep learning and supervised PnP baselines. Qualitative and quantitative results on both simulated and clinical datasets demonstrate that our framework effectively reduces streaks and structured artifacts while preserving subtle tissue contrast, making it a promising tool for ULDCT reconstruction.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "eess.IV"
      ],
      "primary_category": "eess.IV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00669v1",
        "pdf": "https://arxiv.org/pdf/2601.00669v1"
      },
      "arxiv_id": "2601.00669v1",
      "comment": "19 pages, 5 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00668v1",
      "title": "Three factor delay learning rules for spiking neural networks",
      "authors": [
        "Luke Vassallo",
        "Nima Taherinejad"
      ],
      "abstract": "Spiking Neural Networks (SNNs) are dynamical systems that operate on spatiotemporal data, yet their learnable parameters are often limited to synaptic weights, contributing little to temporal pattern recognition. Learnable parameters that delay spike times can improve classification performance in temporal tasks, but existing methods rely on large networks and offline learning, making them unsuitable for real-time operation in resource-constrained environments. In this paper, we introduce synaptic and axonal delays to leaky integrate and fire (LIF)-based feedforward and recurrent SNNs, and propose three-factor learning rules to simultaneously learn delay parameters online. We employ a smooth Gaussian surrogate to approximate spike derivatives exclusively for the eligibility trace calculation, and together with a top-down error signal determine parameter updates. Our experiments show that incorporating delays improves accuracy by up to 20% over a weights-only baseline, and for networks with similar parameter counts, jointly learning weights and delays yields up to 14% higher accuracy. On the SHD speech recognition dataset, our method achieves similar accuracy to offline backpropagation-based approaches. Compared to state-of-the-art methods, it reduces model size by 6.6x and inference latency by 67%, with only a 2.4% drop in classification accuracy. Our findings benefit the design of power and area-constrained neuromorphic processors by enabling on-device learning and lowering memory requirements.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.NE",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00668v1",
        "pdf": "https://arxiv.org/pdf/2601.00668v1"
      },
      "arxiv_id": "2601.00668v1",
      "comment": "7 pages, 5 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00664v1",
      "title": "Avatar Forcing: Real-Time Interactive Head Avatar Generation for Natural Conversation",
      "authors": [
        "Taekyung Ki",
        "Sangwon Jang",
        "Jaehyeong Jo",
        "Jaehong Yoon",
        "Sung Ju Hwang"
      ],
      "abstract": "Talking head generation creates lifelike avatars from static portraits for virtual communication and content creation. However, current models do not yet convey the feeling of truly interactive communication, often generating one-way responses that lack emotional engagement. We identify two key challenges toward truly interactive avatars: generating motion in real-time under causal constraints and learning expressive, vibrant reactions without additional labeled data. To address these challenges, we propose Avatar Forcing, a new framework for interactive head avatar generation that models real-time user-avatar interactions through diffusion forcing. This design allows the avatar to process real-time multimodal inputs, including the user's audio and motion, with low latency for instant reactions to both verbal and non-verbal cues such as speech, nods, and laughter. Furthermore, we introduce a direct preference optimization method that leverages synthetic losing samples constructed by dropping user conditions, enabling label-free learning of expressive interaction. Experimental results demonstrate that our framework enables real-time interaction with low latency (approximately 500ms), achieving 6.8X speedup compared to the baseline, and produces reactive and expressive avatar motion, which is preferred over 80% against the baseline.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.HC",
        "cs.MM"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00664v1",
        "pdf": "https://arxiv.org/pdf/2601.00664v1"
      },
      "arxiv_id": "2601.00664v1",
      "comment": "Project page: https://taekyungki.github.io/AvatarForcing/",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2601.00659v1",
      "title": "CRoPS: A Training-Free Hallucination Mitigation Framework for Vision-Language Models",
      "authors": [
        "Neeraj Anand",
        "Samyak Jha",
        "Udbhav Bamba",
        "Rahul Rahaman"
      ],
      "abstract": "Despite the rapid success of Large Vision-Language Models (LVLMs), a persistent challenge is their tendency to generate hallucinated content, undermining reliability in real-world use. Existing training-free methods address hallucinations but face two limitations: (i) they rely on narrow assumptions about hallucination sources, and (ii) their effectiveness declines toward the end of generation, where hallucinations are most likely to occur. A common strategy is to build hallucinated models by completely or partially removing visual tokens and contrasting them with the original model. Yet, this alone proves insufficient, since visual information still propagates into generated text. Building on this insight, we propose a novel hallucinated model that captures hallucination effects by selectively removing key text tokens. We further introduce Generalized Contrastive Decoding, which integrates multiple hallucinated models to represent diverse hallucination sources. Together, these ideas form CRoPS, a training-free hallucination mitigation framework that improves CHAIR scores by 20% and achieves consistent gains across six benchmarks and three LVLM families, outperforming state-of-the-art training-free methods.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00659v1",
        "pdf": "https://arxiv.org/pdf/2601.00659v1"
      },
      "arxiv_id": "2601.00659v1",
      "comment": "Accepted at TMLR 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00658v1",
      "title": "Reconstructing Building Height from Spaceborne TomoSAR Point Clouds Using a Dual-Topology Network",
      "authors": [
        "Zhaiyu Chen",
        "Yuanyuan Wang",
        "Yilei Shi",
        "Xiao Xiang Zhu"
      ],
      "abstract": "Reliable building height estimation is essential for various urban applications. Spaceborne SAR tomography (TomoSAR) provides weather-independent, side-looking observations that capture facade-level structure, offering a promising alternative to conventional optical methods. However, TomoSAR point clouds often suffer from noise, anisotropic point distributions, and data voids on incoherent surfaces, all of which hinder accurate height reconstruction. To address these challenges, we introduce a learning-based framework for converting raw TomoSAR points into high-resolution building height maps. Our dual-topology network alternates between a point branch that models irregular scatterer features and a grid branch that enforces spatial consistency. By jointly processing these representations, the network denoises the input points and inpaints missing regions to produce continuous height estimates. To our knowledge, this is the first proof of concept for large-scale urban height mapping directly from TomoSAR point clouds. Extensive experiments on data from Munich and Berlin validate the effectiveness of our approach. Moreover, we demonstrate that our framework can be extended to incorporate optical satellite imagery, further enhancing reconstruction quality. The source code is available at https://github.com/zhu-xlab/tomosar2height.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00658v1",
        "pdf": "https://arxiv.org/pdf/2601.00658v1"
      },
      "arxiv_id": "2601.00658v1",
      "comment": "Accepted for publication in IEEE Transactions on Geoscience and Remote Sensing",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00655v1",
      "title": "Interpretability-Guided Bi-objective Optimization: Aligning Accuracy and Explainability",
      "authors": [
        "Kasra Fouladi",
        "Hamta Rahmani"
      ],
      "abstract": "This paper introduces Interpretability-Guided Bi-objective Optimization (IGBO), a framework that trains interpretable models by incorporating structured domain knowledge via a bi-objective formulation. IGBO encodes feature importance hierarchies as a Directed Acyclic Graph (DAG) and uses Temporal Integrated Gradients (TIG) to measure feature importance. To address the Out-of-Distribution (OOD) problem in TIG computation, we propose an Optimal Path Oracle that learns data-manifold-aware integration paths. Theoretical analysis proves convergence properties and robustness to mini-batch noise, while empirical results on time-series data demonstrate IGBO's effectiveness in enforcing DAG constraints with minimal accuracy loss, outperforming standard regularization baselines.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00655v1",
        "pdf": "https://arxiv.org/pdf/2601.00655v1"
      },
      "arxiv_id": "2601.00655v1",
      "comment": "10 pages",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00645v1",
      "title": "Quality Detection of Stored Potatoes via Transfer Learning: A CNN and Vision Transformer Approach",
      "authors": [
        "Shrikant Kapse",
        "Priyankkumar Dhrangdhariya",
        "Priya Kedia",
        "Manasi Patwardhan",
        "Shankar Kausley",
        "Soumyadipta Maiti",
        "Beena Rai",
        "Shirish Karande"
      ],
      "abstract": "Image-based deep learning provides a non-invasive, scalable solution for monitoring potato quality during storage, addressing key challenges such as sprout detection, weight loss estimation, and shelf-life prediction. In this study, images and corresponding weight data were collected over a 200-day period under controlled temperature and humidity conditions. Leveraging powerful pre-trained architectures of ResNet, VGG, DenseNet, and Vision Transformer (ViT), we designed two specialized models: (1) a high-precision binary classifier for sprout detection, and (2) an advanced multi-class predictor to estimate weight loss and forecast remaining shelf-life with remarkable accuracy. DenseNet achieved exceptional performance, with 98.03% accuracy in sprout detection. Shelf-life prediction models performed best with coarse class divisions (2-5 classes), achieving over 89.83% accuracy, while accuracy declined for finer divisions (6-8 classes) due to subtle visual differences and limited data per class. These findings demonstrate the feasibility of integrating image-based models into automated sorting and inventory systems, enabling early identification of sprouted potatoes and dynamic categorization based on storage stage. Practical implications include improved inventory management, differential pricing strategies, and reduced food waste across supply chains. While predicting exact shelf-life intervals remains challenging, focusing on broader class divisions ensures robust performance. Future research should aim to develop generalized models trained on diverse potato varieties and storage conditions to enhance adaptability and scalability. Overall, this approach offers a cost-effective, non-destructive method for quality assessment, supporting efficiency and sustainability in potato storage and distribution.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00645v1",
        "pdf": "https://arxiv.org/pdf/2601.00645v1"
      },
      "arxiv_id": "2601.00645v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00626v1",
      "title": "HyperPriv-EPN: Hypergraph Learning with Privileged Knowledge for Ependymoma Prognosis",
      "authors": [
        "Shuren Gabriel Yu",
        "Sikang Ren",
        "Yongji Tian"
      ],
      "abstract": "Preoperative prognosis of Ependymoma is critical for treatment planning but challenging due to the lack of semantic insights in MRI compared to post-operative surgical reports. Existing multimodal methods fail to leverage this privileged text data when it is unavailable during inference. To bridge this gap, we propose HyperPriv-EPN, a hypergraph-based Learning Using Privileged Information (LUPI) framework. We introduce a Severed Graph Strategy, utilizing a shared encoder to process both a Teacher graph (enriched with privileged post-surgery information) and a Student graph (restricted to pre-operation data). Through dual-stream distillation, the Student learns to hallucinate semantic community structures from visual features alone. Validated on a multi-center cohort of 311 patients, HyperPriv-EPN achieves state-of-the-art diagnostic accuracy and survival stratification. This effectively transfers expert knowledge to the preoperative setting, unlocking the value of historical post-operative data to guide the diagnosis of new patients without requiring text at inference.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00626v1",
        "pdf": "https://arxiv.org/pdf/2601.00626v1"
      },
      "arxiv_id": "2601.00626v1",
      "comment": "6 pages, 2 figures, 2 tables",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00625v1",
      "title": "RePose: A Real-Time 3D Human Pose Estimation and Biomechanical Analysis Framework for Rehabilitation",
      "authors": [
        "Junxiao Xue",
        "Pavel Smirnov",
        "Ziao Li",
        "Yunyun Shi",
        "Shi Chen",
        "Xinyi Yin",
        "Xiaohan Yue",
        "Lei Wang",
        "Yiduo Wang",
        "Feng Lin",
        "Yijia Chen",
        "Xiao Ma",
        "Xiaoran Yan",
        "Qing Zhang",
        "Fengjian Xue",
        "Xuecheng Wu"
      ],
      "abstract": "We propose a real-time 3D human pose estimation and motion analysis method termed RePose for rehabilitation training. It is capable of real-time monitoring and evaluation of patients'motion during rehabilitation, providing immediate feedback and guidance to assist patients in executing rehabilitation exercises correctly. Firstly, we introduce a unified pipeline for end-to-end real-time human pose estimation and motion analysis using RGB video input from multiple cameras which can be applied to the field of rehabilitation training. The pipeline can help to monitor and correct patients'actions, thus aiding them in regaining muscle strength and motor functions. Secondly, we propose a fast tracking method for medical rehabilitation scenarios with multiple-person interference, which requires less than 1ms for tracking for a single frame. Additionally, we modify SmoothNet for real-time posture estimation, effectively reducing pose estimation errors and restoring the patient's true motion state, making it visually smoother. Finally, we use Unity platform for real-time monitoring and evaluation of patients' motion during rehabilitation, and to display the muscle stress conditions to assist patients with their rehabilitation training.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00625v1",
        "pdf": "https://arxiv.org/pdf/2601.00625v1"
      },
      "arxiv_id": "2601.00625v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00624v1",
      "title": "Do Chatbot LLMs Talk Too Much? The YapBench Benchmark",
      "authors": [
        "Vadim Borisov",
        "Michael Gröger",
        "Mina Mikhael",
        "Richard H. Schreiber"
      ],
      "abstract": "Large Language Models (LLMs) such as ChatGPT, Claude, and Gemini increasingly act as general-purpose copilots, yet they often respond with unnecessary length on simple requests, adding redundant explanations, hedging, or boilerplate that increases cognitive load and inflates token-based inference cost. Prior work suggests that preference-based post-training and LLM-judged evaluations can induce systematic length bias, where longer answers are rewarded even at comparable quality.\n  We introduce YapBench, a lightweight benchmark for quantifying user-visible over-generation on brevity-ideal prompts. Each item consists of a single-turn prompt, a curated minimal-sufficient baseline answer, and a category label. Our primary metric, YapScore, measures excess response length beyond the baseline in characters, enabling comparisons across models without relying on any specific tokenizer. We summarize model performance via the YapIndex, a uniformly weighted average of category-level median YapScores.\n  YapBench contains over three hundred English prompts spanning three common brevity-ideal settings: (A) minimal or ambiguous inputs where the ideal behavior is a short clarification, (B) closed-form factual questions with short stable answers, and (C) one-line coding tasks where a single command or snippet suffices. Evaluating 76 assistant LLMs, we observe an order-of-magnitude spread in median excess length and distinct category-specific failure modes, including vacuum-filling on ambiguous inputs and explanation or formatting overhead on one-line technical requests. We release the benchmark and maintain a live leaderboard for tracking verbosity behavior over time.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00624v1",
        "pdf": "https://arxiv.org/pdf/2601.00624v1"
      },
      "arxiv_id": "2601.00624v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00623v1",
      "title": "DA-DPO: Cost-efficient Difficulty-aware Preference Optimization for Reducing MLLM Hallucinations",
      "authors": [
        "Longtian Qiu",
        "Shan Ning",
        "Chuyu Zhang",
        "Jiaxuan Sun",
        "Xuming He"
      ],
      "abstract": "Direct Preference Optimization (DPO) has shown strong potential for mitigating hallucinations in Multimodal Large Language Models (MLLMs). However, existing multimodal DPO approaches often suffer from overfitting due to the difficulty imbalance in preference data. Our analysis shows that MLLMs tend to overemphasize easily distinguishable preference pairs, which hinders fine-grained hallucination suppression and degrades overall performance. To address this issue, we propose Difficulty-Aware Direct Preference Optimization (DA-DPO), a cost-effective framework designed to balance the learning process. DA-DPO consists of two main components: (1) Difficulty Estimation leverages pre-trained vision--language models with complementary generative and contrastive objectives, whose outputs are integrated via a distribution-aware voting strategy to produce robust difficulty scores without additional training; and (2) Difficulty-Aware Training reweights preference pairs based on their estimated difficulty, down-weighting easy samples while emphasizing harder ones to alleviate overfitting. This framework enables more effective preference optimization by prioritizing challenging examples, without requiring new data or extra fine-tuning stages. Extensive experiments demonstrate that DA-DPO consistently improves multimodal preference optimization, yielding stronger robustness to hallucinations and better generalization across standard benchmarks, while remaining computationally efficient. The project page is available at https://artanic30.github.io/project_pages/DA-DPO/.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00623v1",
        "pdf": "https://arxiv.org/pdf/2601.00623v1"
      },
      "arxiv_id": "2601.00623v1",
      "comment": "Accepted by TMLR",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00617v1",
      "title": "Noise-Robust Tiny Object Localization with Flows",
      "authors": [
        "Huixin Sun",
        "Linlin Yang",
        "Ronyu Chen",
        "Kerui Gu",
        "Baochang Zhang",
        "Angela Yao",
        "Xianbin Cao"
      ],
      "abstract": "Despite significant advances in generic object detection, a persistent performance gap remains for tiny objects compared to normal-scale objects. We demonstrate that tiny objects are highly sensitive to annotation noise, where optimizing strict localization objectives risks noise overfitting. To address this, we propose Tiny Object Localization with Flows (TOLF), a noise-robust localization framework leveraging normalizing flows for flexible error modeling and uncertainty-guided optimization. Our method captures complex, non-Gaussian prediction distributions through flow-based error modeling, enabling robust learning under noisy supervision. An uncertainty-aware gradient modulation mechanism further suppresses learning from high-uncertainty, noise-prone samples, mitigating overfitting while stabilizing training. Extensive experiments across three datasets validate our approach's effectiveness. Especially, TOLF boosts the DINO baseline by 1.2% AP on the AI-TOD dataset.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00617v1",
        "pdf": "https://arxiv.org/pdf/2601.00617v1"
      },
      "arxiv_id": "2601.00617v1",
      "comment": "11 pages, 5 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00611v1",
      "title": "Stronger Approximation Guarantees for Non-Monotone γ-Weakly DR-Submodular Maximization",
      "authors": [
        "Hareshkumar Jadav",
        "Ranveer Singh",
        "Vaneet Aggarwal"
      ],
      "abstract": "Maximizing submodular objectives under constraints is a fundamental problem in machine learning and optimization. We study the maximization of a nonnegative, non-monotone $γ$-weakly DR-submodular function over a down-closed convex body. Our main result is an approximation algorithm whose guarantee depends smoothly on $γ$; in particular, when $γ=1$ (the DR-submodular case) our bound recovers the $0.401$ approximation factor, while for $γ<1$ the guarantee degrades gracefully and, it improves upon previously reported bounds for $γ$-weakly DR-submodular maximization under the same constraints. Our approach combines a Frank-Wolfe-guided continuous-greedy framework with a $γ$-aware double-greedy step, yielding a simple yet effective procedure for handling non-monotonicity. This results in state-of-the-art guarantees for non-monotone $γ$-weakly DR-submodular maximization over down-closed convex bodies.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CC",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00611v1",
        "pdf": "https://arxiv.org/pdf/2601.00611v1"
      },
      "arxiv_id": "2601.00611v1",
      "comment": "Extended version of paper accepted in AAMAS 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00607v1",
      "title": "Traffic-Aware Optimal Taxi Placement Using Graph Neural Network-Based Reinforcement Learning",
      "authors": [
        "Sonia Khetarpaul",
        "P Y Sharan"
      ],
      "abstract": "In the context of smart city transportation, efficient matching of taxi supply with passenger demand requires real-time integration of urban traffic network data and mobility patterns. Conventional taxi hotspot prediction models often rely solely on historical demand, overlooking dynamic influences such as traffic congestion, road incidents, and public events. This paper presents a traffic-aware, graph-based reinforcement learning (RL) framework for optimal taxi placement in metropolitan environments. The urban road network is modeled as a graph where intersections represent nodes, road segments serve as edges, and node attributes capture historical demand, event proximity, and real-time congestion scores obtained from live traffic APIs. Graph Neural Network (GNN) embeddings are employed to encode spatial-temporal dependencies within the traffic network, which are then used by a Q-learning agent to recommend optimal taxi hotspots. The reward mechanism jointly optimizes passenger waiting time, driver travel distance, and congestion avoidance. Experiments on a simulated Delhi taxi dataset, generated using real geospatial boundaries and historic ride-hailing request patterns, demonstrate that the proposed model reduced passenger waiting time by about 56% and reduced travel distance by 38% compared to baseline stochastic selection. The proposed approach is adaptable to multi-modal transport systems and can be integrated into smart city platforms for real-time urban mobility optimization.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00607v1",
        "pdf": "https://arxiv.org/pdf/2601.00607v1"
      },
      "arxiv_id": "2601.00607v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00604v1",
      "title": "Cycling Race Time Prediction: A Personalized Machine Learning Approach Using Route Topology and Training Load",
      "authors": [
        "Francisco Aguilera Moreno"
      ],
      "abstract": "Predicting cycling duration for a given route is essential for training planning and event preparation. Existing solutions rely on physics-based models that require extensive parameterization, including aerodynamic drag coefficients and real-time wind forecasts, parameters impractical for most amateur cyclists. This work presents a machine learning approach that predicts ride duration using route topology features combined with the athlete's current fitness state derived from training load metrics. The model learns athlete-specific performance patterns from historical data, substituting complex physical measurements with historical performance proxies. We evaluate the approach using a single-athlete dataset (N=96 rides) in an N-of-1 study design. After rigorous feature engineering to eliminate data leakage, we find that Lasso regression with Topology + Fitness features achieves MAE=6.60 minutes and R2=0.922. Notably, integrating fitness metrics (CTL, ATL) reduces error by 14% compared to topology alone (MAE=7.66 min), demonstrating that physiological state meaningfully constrains performance even in self-paced efforts. Progressive checkpoint predictions enable dynamic race planning as route difficulty becomes apparent.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00604v1",
        "pdf": "https://arxiv.org/pdf/2601.00604v1"
      },
      "arxiv_id": "2601.00604v1",
      "comment": "14 pages, 22 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00598v1",
      "title": "Modality Dominance-Aware Optimization for Embodied RGB-Infrared Perception",
      "authors": [
        "Xianhui Liu",
        "Siqi Jiang",
        "Yi Xie",
        "Yuqing Lin",
        "Siao Liu"
      ],
      "abstract": "RGB-Infrared (RGB-IR) multimodal perception is fundamental to embodied multimedia systems operating in complex physical environments. Although recent cross-modal fusion methods have advanced RGB-IR detection, the optimization dynamics caused by asymmetric modality characteristics remain underexplored. In practice, disparities in information density and feature quality introduce persistent optimization bias, leading training to overemphasize a dominant modality and hindering effective fusion. To quantify this phenomenon, we propose the Modality Dominance Index (MDI), which measures modality dominance by jointly modeling feature entropy and gradient contribution. Based on MDI, we develop a Modality Dominance-Aware Cross-modal Learning (MDACL) framework that regulates cross-modal optimization. MDACL incorporates Hierarchical Cross-modal Guidance (HCG) to enhance feature alignment and Adversarial Equilibrium Regularization (AER) to balance optimization dynamics during fusion. Extensive experiments on three RGB-IR benchmarks demonstrate that MDACL effectively mitigates optimization bias and achieves SOTA performance.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00598v1",
        "pdf": "https://arxiv.org/pdf/2601.00598v1"
      },
      "arxiv_id": "2601.00598v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00590v1",
      "title": "SafeMo: Linguistically Grounded Unlearning for Trustworthy Text-to-Motion Generation",
      "authors": [
        "Yiling Wang",
        "Zeyu Zhang",
        "Yiran Wang",
        "Hao Tang"
      ],
      "abstract": "Text-to-motion (T2M) generation with diffusion backbones achieves strong realism and alignment. Safety concerns in T2M methods have been raised in recent years; existing methods replace discrete VQ-VAE codebook entries to steer the model away from unsafe behaviors. However, discrete codebook replacement-based methods have two critical flaws: firstly, replacing codebook entries which are reused by benign prompts leads to drifts on everyday tasks, degrading the model's benign performance; secondly, discrete token-based methods introduce quantization and smoothness loss, resulting in artifacts and jerky transitions. Moreover, existing text-to-motion datasets naturally contain unsafe intents and corresponding motions, making them unsuitable for safety-driven machine learning. To address these challenges, we propose SafeMo, a trustworthy motion generative framework integrating Minimal Motion Unlearning (MMU), a two-stage machine unlearning strategy, enabling safe human motion generation in continuous space, preserving continuous kinematics without codebook loss and delivering strong safety-utility trade-offs compared to current baselines. Additionally, we present the first safe text-to-motion dataset SafeMoVAE-29K integrating rewritten safe text prompts and continuous refined motion for trustworthy human motion unlearning. Built upon DiP, SafeMo efficiently generates safe human motions with natural transitions. Experiments demonstrate effective unlearning performance of SafeMo by showing strengthened forgetting on unsafe prompts, reaching 2.5x and 14.4x higher forget-set FID on HumanML3D and Motion-X respectively, compared to the previous SOTA human motion unlearning method LCR, with benign performance on safe prompts being better or comparable. Code: https://github.com/AIGeeksGroup/SafeMo. Website: https://aigeeksgroup.github.io/SafeMo.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00590v1",
        "pdf": "https://arxiv.org/pdf/2601.00590v1"
      },
      "arxiv_id": "2601.00590v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00584v1",
      "title": "GranAlign: Granularity-Aware Alignment Framework for Zero-Shot Video Moment Retrieval",
      "authors": [
        "Mingyu Jeon",
        "Sunjae Yoon",
        "Jonghee Kim",
        "Junyeoung Kim"
      ],
      "abstract": "Zero-shot video moment retrieval (ZVMR) is the task of localizing a temporal moment within an untrimmed video using a natural language query without relying on task-specific training data. The primary challenge in this setting lies in the mismatch in semantic granularity between textual queries and visual content. Previous studies in ZVMR have attempted to achieve alignment by leveraging high-quality pre-trained knowledge that represents video and language in a joint space. However, these approaches failed to balance the semantic granularity between the pre-trained knowledge provided by each modality for a given scene. As a result, despite the high quality of each modality's representations, the mismatch in granularity led to inaccurate retrieval. In this paper, we propose a training-free framework, called Granularity-Aware Alignment (GranAlign), that bridges this gap between coarse and fine semantic representations. Our approach introduces two complementary techniques: granularity-based query rewriting to generate varied semantic granularities, and query-aware caption generation to embed query intent into video content. By pairing multi-level queries with both query-agnostic and query-aware captions, we effectively resolve semantic mismatches. As a result, our method sets a new state-of-the-art across all three major benchmarks (QVHighlights, Charades-STA, ActivityNet-Captions), with a notable 3.23% mAP@avg improvement on the challenging QVHighlights dataset.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00584v1",
        "pdf": "https://arxiv.org/pdf/2601.00584v1"
      },
      "arxiv_id": "2601.00584v1",
      "comment": "Accepted to AAAI 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00583v1",
      "title": "HFedMoE: Resource-aware Heterogeneous Federated Learning with Mixture-of-Experts",
      "authors": [
        "Zihan Fang",
        "Zheng Lin",
        "Senkang Hu",
        "Yanan Ma",
        "Yihang Tao",
        "Yiqin Deng",
        "Xianhao Chen",
        "Yuguang Fang"
      ],
      "abstract": "While federated learning (FL) enables fine-tuning of large language models (LLMs) without compromising data privacy, the substantial size of an LLM renders on-device training impractical for resource-constrained clients, such as mobile devices. Thus, Mixture-of-Experts (MoE) models have emerged as a computation-efficient solution, which activates only a sparse subset of experts during model training to reduce computing burden without sacrificing performance. Though integrating MoE into FL fine-tuning holds significant potential, it still encounters three key challenges: i) selecting appropriate experts for clients remains challenging due to the lack of a reliable metric to measure each expert's impact on local fine-tuning performance, ii) the heterogeneous computing resources across clients severely hinder MoE-based LLM fine-tuning, as dynamic expert activations across diverse input samples can overwhelm resource-constrained devices, and iii) client-specific expert subsets and routing preference undermine global aggregation, where misaligned expert updates and inconsistent gating networks in troduce destructive interference. To address these challenges, we propose HFedMoE, a heterogeneous MoE-based FL fine-tuning framework that customizes a subset of experts to each client for computation-efficient LLM fine-tuning. Specifically, HFedMoE identifies the expert importance based on its contributions to fine-tuning performance, and then adaptively selects a subset of experts from an information bottleneck perspective to align with each client' s computing budget. A sparsity-aware model aggregation strategy is also designed to aggregate the actively fine-tuned experts and gating parameters with importance weighted contributions. Extensive experiments demonstrate that HFedMoE outperforms state-of-the-art benchmarks in training accuracy and convergence speed.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00583v1",
        "pdf": "https://arxiv.org/pdf/2601.00583v1"
      },
      "arxiv_id": "2601.00583v1",
      "comment": "14 pages, 16 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00581v1",
      "title": "AceFF: A State-of-the-Art Machine Learning Potential for Small Molecules",
      "authors": [
        "Stephen E. Farr",
        "Stefan Doerr",
        "Antonio Mirarchi",
        "Francesc Sabanes Zariquiey",
        "Gianni De Fabritiis"
      ],
      "abstract": "We introduce AceFF, a pre-trained machine learning interatomic potential (MLIP) optimized for small molecule drug discovery. While MLIPs have emerged as efficient alternatives to Density Functional Theory (DFT), generalizability across diverse chemical spaces remains difficult. AceFF addresses this via a refined TensorNet2 architecture trained on a comprehensive dataset of drug-like compounds. This approach yields a force field that balances high-throughput inference speed with DFT-level accuracy. AceFF fully supports the essential medicinal chemistry elements (H, B, C, N, O, F, Si, P, S, Cl, Br, I) and is explicitly trained to handle charged states. Validation against rigorous benchmarks, including complex torsional energy scans, molecular dynamics trajectories, batched minimizations, and forces and anergy accuracy demonstrates that AceFF establishes a new state-of-the-art for organic molecules. The AceFF-2 model weights and inference code are available at https://huggingface.co/Acellera/AceFF-2.0.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "physics.chem-ph",
        "cs.LG"
      ],
      "primary_category": "physics.chem-ph",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00581v1",
        "pdf": "https://arxiv.org/pdf/2601.00581v1"
      },
      "arxiv_id": "2601.00581v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00580v1",
      "title": "Priority-Aware Multi-Robot Coverage Path Planning",
      "authors": [
        "Kanghoon Lee",
        "Hyeonjun Kim",
        "Jiachen Li",
        "Jinkyoo Park"
      ],
      "abstract": "Multi-robot systems are widely used for coverage tasks that require efficient coordination across large environments. In Multi-Robot Coverage Path Planning (MCPP), the objective is typically to minimize the makespan by generating non-overlapping paths for full-area coverage. However, most existing methods assume uniform importance across regions, limiting their effectiveness in scenarios where some zones require faster attention. We introduce the Priority-Aware MCPP (PA-MCPP) problem, where a subset of the environment is designated as prioritized zones with associated weights. The goal is to minimize, in lexicographic order, the total priority-weighted latency of zone coverage and the overall makespan. To address this, we propose a scalable two-phase framework combining (1) greedy zone assignment with local search, spanning-tree-based path planning, and (2) Steiner-tree-guided residual coverage. Experiments across diverse scenarios demonstrate that our method significantly reduces priority-weighted latency compared to standard MCPP baselines, while maintaining competitive makespan. Sensitivity analyses further show that the method scales well with the number of robots and that zone coverage behavior can be effectively controlled by adjusting priority weights.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00580v1",
        "pdf": "https://arxiv.org/pdf/2601.00580v1"
      },
      "arxiv_id": "2601.00580v1",
      "comment": "IEEE Robotics and Automation Letters, 8 pages, 10 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00578v1",
      "title": "Learning to be Reproducible: Custom Loss Design for Robust Neural Networks",
      "authors": [
        "Waqas Ahmed",
        "Sheeba Samuel",
        "Kevin Coakley",
        "Birgitta Koenig-Ries",
        "Odd Erik Gundersen"
      ],
      "abstract": "To enhance the reproducibility and reliability of deep learning models, we address a critical gap in current training methodologies: the lack of mechanisms that ensure consistent and robust performance across runs. Our empirical analysis reveals that even under controlled initialization and training conditions, the accuracy of the model can exhibit significant variability. To address this issue, we propose a Custom Loss Function (CLF) that reduces the sensitivity of training outcomes to stochastic factors such as weight initialization and data shuffling. By fine-tuning its parameters, CLF explicitly balances predictive accuracy with training stability, leading to more consistent and reliable model performance. Extensive experiments across diverse architectures for both image classification and time series forecasting demonstrate that our approach significantly improves training robustness without sacrificing predictive performance. These results establish CLF as an effective and efficient strategy for developing more stable, reliable and trustworthy neural networks.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00578v1",
        "pdf": "https://arxiv.org/pdf/2601.00578v1"
      },
      "arxiv_id": "2601.00578v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00577v1",
      "title": "Adversarial Samples Are Not Created Equal",
      "authors": [
        "Jennifer Crawford",
        "Amol Khanna",
        "Fred Lu",
        "Amy R. Wagoner",
        "Stella Biderman",
        "Andre T. Nguyen",
        "Edward Raff"
      ],
      "abstract": "Over the past decade, numerous theories have been proposed to explain the widespread vulnerability of deep neural networks to adversarial evasion attacks. Among these, the theory of non-robust features proposed by Ilyas et al. has been widely accepted, showing that brittle but predictive features of the data distribution can be directly exploited by attackers. However, this theory overlooks adversarial samples that do not directly utilize these features. In this work, we advocate that these two kinds of samples - those which use use brittle but predictive features and those that do not - comprise two types of adversarial weaknesses and should be differentiated when evaluating adversarial robustness. For this purpose, we propose an ensemble-based metric to measure the manipulation of non-robust features by adversarial perturbations and use this metric to analyze the makeup of adversarial samples generated by attackers. This new perspective also allows us to re-examine multiple phenomena, including the impact of sharpness-aware minimization on adversarial robustness and the robustness gap observed between adversarially training and standard training on robust datasets.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00577v1",
        "pdf": "https://arxiv.org/pdf/2601.00577v1"
      },
      "arxiv_id": "2601.00577v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00567v1",
      "title": "Improving Scientific Document Retrieval with Academic Concept Index",
      "authors": [
        "Jeyun Lee",
        "Junhyoung Lee",
        "Wonbin Kweon",
        "Bowen Jin",
        "Yu Zhang",
        "Susik Yoon",
        "Dongha Lee",
        "Hwanjo Yu",
        "Jiawei Han",
        "Seongku Kang"
      ],
      "abstract": "Adapting general-domain retrievers to scientific domains is challenging due to the scarcity of large-scale domain-specific relevance annotations and the substantial mismatch in vocabulary and information needs. Recent approaches address these issues through two independent directions that leverage large language models (LLMs): (1) generating synthetic queries for fine-tuning, and (2) generating auxiliary contexts to support relevance matching. However, both directions overlook the diverse academic concepts embedded within scientific documents, often producing redundant or conceptually narrow queries and contexts. To address this limitation, we introduce an academic concept index, which extracts key concepts from papers and organizes them guided by an academic taxonomy. This structured index serves as a foundation for improving both directions. First, we enhance the synthetic query generation with concept coverage-based generation (CCQGen), which adaptively conditions LLMs on uncovered concepts to generate complementary queries with broader concept coverage. Second, we strengthen the context augmentation with concept-focused auxiliary contexts (CCExpand), which leverages a set of document snippets that serve as concise responses to the concept-aware CCQGen queries. Extensive experiments show that incorporating the academic concept index into both query generation and context augmentation leads to higher-quality queries, better conceptual alignment, and improved retrieval performance.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00567v1",
        "pdf": "https://arxiv.org/pdf/2601.00567v1"
      },
      "arxiv_id": "2601.00567v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00562v1",
      "title": "A Cascaded Information Interaction Network for Precise Image Segmentation",
      "authors": [
        "Hewen Xiao",
        "Jie Mei",
        "Guangfu Ma",
        "Weiren Wu"
      ],
      "abstract": "Visual perception plays a pivotal role in enabling autonomous behavior, offering a cost-effective and efficient alternative to complex multi-sensor systems. However, robust segmentation remains a challenge in complex scenarios. To address this, this paper proposes a cascaded convolutional neural network integrated with a novel Global Information Guidance Module. This module is designed to effectively fuse low-level texture details with high-level semantic features across multiple layers, thereby overcoming the inherent limitations of single-scale feature extraction. This architectural innovation significantly enhances segmentation accuracy, particularly in visually cluttered or blurred environments where traditional methods often fail. Experimental evaluations on benchmark image segmentation datasets demonstrate that the proposed framework achieves superior precision, outperforming existing state-of-the-art methods. The results highlight the effectiveness of the approach and its promising potential for deployment in practical robotic applications.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00562v1",
        "pdf": "https://arxiv.org/pdf/2601.00562v1"
      },
      "arxiv_id": "2601.00562v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00561v1",
      "title": "AEGIS: Exploring the Limit of World Knowledge Capabilities for Unified Mulitmodal Models",
      "authors": [
        "Jintao Lin",
        "Bowen Dong",
        "Weikang Shi",
        "Chenyang Lei",
        "Suiyun Zhang",
        "Rui Liu",
        "Xihui Liu"
      ],
      "abstract": "The capability of Unified Multimodal Models (UMMs) to apply world knowledge across diverse tasks remains a critical, unresolved challenge. Existing benchmarks fall short, offering only siloed, single-task evaluations with limited diagnostic power. To bridge this gap, we propose AEGIS (\\emph{i.e.}, \\textbf{A}ssessing \\textbf{E}diting, \\textbf{G}eneration, \\textbf{I}nterpretation-Understanding for \\textbf{S}uper-intelligence), a comprehensive multi-task benchmark covering visual understanding, generation, editing, and interleaved generation. AEGIS comprises 1,050 challenging, manually-annotated questions spanning 21 topics (including STEM, humanities, daily life, etc.) and 6 reasoning types. To concretely evaluate the performance of UMMs in world knowledge scope without ambiguous metrics, we further propose Deterministic Checklist-based Evaluation (DCE), a protocol that replaces ambiguous prompt-based scoring with atomic ``Y/N'' judgments, to enhance evaluation reliability. Our extensive experiments reveal that most UMMs exhibit severe world knowledge deficits and that performance degrades significantly with complex reasoning. Additionally, simple plug-in reasoning modules can partially mitigate these vulnerabilities, highlighting a promising direction for future research. These results highlight the importance of world-knowledge-based reasoning as a critical frontier for UMMs.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00561v1",
        "pdf": "https://arxiv.org/pdf/2601.00561v1"
      },
      "arxiv_id": "2601.00561v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00559v1",
      "title": "Cracking IoT Security: Can LLMs Outsmart Static Analysis Tools?",
      "authors": [
        "Jason Quantrill",
        "Noura Khajehnouri",
        "Zihan Guo",
        "Manar H. Alalfi"
      ],
      "abstract": "Smart home IoT platforms such as openHAB rely on Trigger Action Condition (TAC) rules to automate device behavior, but the interplay among these rules can give rise to interaction threats, unintended or unsafe behaviors emerging from implicit dependencies, conflicting triggers, or overlapping conditions. Identifying these threats requires semantic understanding and structural reasoning that traditionally depend on symbolic, constraint-driven static analysis. This work presents the first comprehensive evaluation of Large Language Models (LLMs) across a multi-category interaction threat taxonomy, assessing their performance on both the original openHAB (oHC/IoTB) dataset and a structurally challenging Mutation dataset designed to test robustness under rule transformations. We benchmark Llama 3.1 8B, Llama 70B, GPT-4o, Gemini-2.5-Pro, and DeepSeek-R1 across zero-, one-, and two-shot settings, comparing their results against oHIT's manually validated ground truth. Our findings show that while LLMs exhibit promising semantic understanding, particularly on action- and condition-related threats, their accuracy degrades significantly for threats requiring cross-rule structural reasoning, especially under mutated rule forms. Model performance varies widely across threat categories and prompt settings, with no model providing consistent reliability. In contrast, the symbolic reasoning baseline maintains stable detection across both datasets, unaffected by rule rewrites or structural perturbations. These results underscore that LLMs alone are not yet dependable for safety critical interaction-threat detection in IoT environments. We discuss the implications for tool design and highlight the potential of hybrid architectures that combine symbolic analysis with LLM-based semantic interpretation to reduce false positives while maintaining structural rigor.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00559v1",
        "pdf": "https://arxiv.org/pdf/2601.00559v1"
      },
      "arxiv_id": "2601.00559v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00554v1",
      "title": "Entropy Production in Machine Learning Under Fokker-Planck Probability Flow",
      "authors": [
        "Lennon Shikhman"
      ],
      "abstract": "Machine learning models deployed in nonstationary environments experience performance degradation due to data drift. While many drift detection heuristics exist, most lack a principled dynamical interpretation and provide limited guidance on how retraining frequency should be balanced against operational cost. In this work, we propose an entropy--based retraining framework grounded in nonequilibrium stochastic dynamics. Modeling deployment--time data drift as probability flow governed by a Fokker--Planck equation, we quantify model--data mismatch using a time--evolving Kullback--Leibler divergence. We show that the time derivative of this mismatch admits an entropy--balance decomposition featuring a nonnegative entropy production term driven by probability currents. This interpretation motivates entropy--triggered retraining as a label--free intervention strategy that responds to accumulated mismatch rather than delayed performance collapse. In a controlled nonstationary classification experiment, entropy--triggered retraining achieves predictive performance comparable to high--frequency retraining while reducing retraining events by an order of magnitude relative to daily and label--based policies.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00554v1",
        "pdf": "https://arxiv.org/pdf/2601.00554v1"
      },
      "arxiv_id": "2601.00554v1",
      "comment": "10 pages, 3 figures. Submitted for journal review",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00553v1",
      "title": "A Comprehensive Dataset for Human vs. AI Generated Image Detection",
      "authors": [
        "Rajarshi Roy",
        "Nasrin Imanpour",
        "Ashhar Aziz",
        "Shashwat Bajpai",
        "Gurpreet Singh",
        "Shwetangshu Biswas",
        "Kapil Wanaskar",
        "Parth Patwa",
        "Subhankar Ghosh",
        "Shreyas Dixit",
        "Nilesh Ranjan Pal",
        "Vipula Rawte",
        "Ritvik Garimella",
        "Gaytri Jena",
        "Vasu Sharma",
        "Vinija Jain",
        "Aman Chadha",
        "Aishwarya Naresh Reganti",
        "Amitava Das"
      ],
      "abstract": "Multimodal generative AI systems like Stable Diffusion, DALL-E, and MidJourney have fundamentally changed how synthetic images are created. These tools drive innovation but also enable the spread of misleading content, false information, and manipulated media. As generated images become harder to distinguish from photographs, detecting them has become an urgent priority. To combat this challenge, We release MS COCOAI, a novel dataset for AI generated image detection consisting of 96000 real and synthetic datapoints, built using the MS COCO dataset. To generate synthetic images, we use five generators: Stable Diffusion 3, Stable Diffusion 2.1, SDXL, DALL-E 3, and MidJourney v6. Based on the dataset, we propose two tasks: (1) classifying images as real or generated, and (2) identifying which model produced a given synthetic image. The dataset is available at https://huggingface.co/datasets/Rajarshi-Roy-research/Defactify_Image_Dataset.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00553v1",
        "pdf": "https://arxiv.org/pdf/2601.00553v1"
      },
      "arxiv_id": "2601.00553v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00551v1",
      "title": "SingBAG Pro: Accelerating point cloud-based iterative reconstruction for 3D photoacoustic imaging under arbitrary array",
      "authors": [
        "Shuang Li",
        "Yibing Wang",
        "Jian Gao",
        "Chulhong Kim",
        "Seongwook Choi",
        "Yu Zhang",
        "Qian Chen",
        "Yao Yao",
        "Changhui Li"
      ],
      "abstract": "High-quality three-dimensional (3D) photoacoustic imaging (PAI) is gaining increasing attention in clinical applications. To address the challenges of limited space and high costs, irregular geometric transducer arrays that conform to specific imaging regions are promising for achieving high-quality 3D PAI with fewer transducers. However, traditional iterative reconstruction algorithms struggle with irregular array configurations, suffering from high computational complexity, substantial memory requirements, and lengthy reconstruction times. In this work, we introduce SlingBAG Pro, an advanced reconstruction algorithm based on the point cloud iteration concept of the Sliding ball adaptive growth (SlingBAG) method, while extending its compatibility to arbitrary array geometries. SlingBAG Pro maintains high reconstruction quality, reduces the number of required transducers, and employs a hierarchical optimization strategy that combines zero-gradient filtering with progressively increased temporal sampling rates during iteration. This strategy rapidly removes redundant spatial point clouds, accelerates convergence, and significantly shortens overall reconstruction time. Compared to the original SlingBAG algorithm, SlingBAG Pro achieves up to a 2.2-fold speed improvement in point cloud-based 3D PA reconstruction under irregular array geometries. The proposed method is validated through both simulation and in vivo mouse experiments, and the source code is publicly available at https://github.com/JaegerCQ/SlingBAG_Pro.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00551v1",
        "pdf": "https://arxiv.org/pdf/2601.00551v1"
      },
      "arxiv_id": "2601.00551v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00549v1",
      "title": "CoCo-Fed: A Unified Framework for Memory- and Communication-Efficient Federated Learning at the Wireless Edge",
      "authors": [
        "Zhiheng Guo",
        "Zhaoyang Liu",
        "Zihan Cen",
        "Chenyuan Feng",
        "Xinghua Sun",
        "Xiang Chen",
        "Tony Q. S. Quek",
        "Xijun Wang"
      ],
      "abstract": "The deployment of large-scale neural networks within the Open Radio Access Network (O-RAN) architecture is pivotal for enabling native edge intelligence. However, this paradigm faces two critical bottlenecks: the prohibitive memory footprint required for local training on resource-constrained gNBs, and the saturation of bandwidth-limited backhaul links during the global aggregation of high-dimensional model updates. To address these challenges, we propose CoCo-Fed, a novel Compression and Combination-based Federated learning framework that unifies local memory efficiency and global communication reduction. Locally, CoCo-Fed breaks the memory wall by performing a double-dimension down-projection of gradients, adapting the optimizer to operate on low-rank structures without introducing additional inference parameters/latency. Globally, we introduce a transmission protocol based on orthogonal subspace superposition, where layer-wise updates are projected and superimposed into a single consolidated matrix per gNB, drastically reducing the backhaul traffic. Beyond empirical designs, we establish a rigorous theoretical foundation, proving the convergence of CoCo-Fed even under unsupervised learning conditions suitable for wireless sensing tasks. Extensive simulations on an angle-of-arrival estimation task demonstrate that CoCo-Fed significantly outperforms state-of-the-art baselines in both memory and communication efficiency while maintaining robust convergence under non-IID settings.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.IT",
        "cs.AI"
      ],
      "primary_category": "cs.IT",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00549v1",
        "pdf": "https://arxiv.org/pdf/2601.00549v1"
      },
      "arxiv_id": "2601.00549v1",
      "comment": "7 pages, 3 figures, 1 algorithm",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00543v1",
      "title": "ECR: Manifold-Guided Semantic Cues for Compact Language Models",
      "authors": [
        "Chung-Wei Victor Yuan"
      ],
      "abstract": "Compact models often lose the structure of their embedding space. The issue shows up when the capacity is tight or the data spans several languages. Such collapse makes it difficult for downstream tasks to build on the resulting representation. Existing compression methods focus on aligning model outputs at a superficial level but fail to preserve the underlying manifold structure. This mismatch often leads to semantic drift in the compact model, causing both task behavior and linguistic properties to deviate from the reference model.\n  To address those issues, we provide a new framework called Embedding Consistency Regulation (ECR). This framework first derives a set of semantic anchors from teacher embeddings (computed once offline). Then, the compact model learns to maintain consistent geometry around these anchors, without relying on matching logits or internal features. ECR adds only a small projection step at inference, without altering the decoding architecture or its runtime behavior.\n  In experiments on a 100K multilingual corpus, ECR consistently stabilizes training and preserves semantic structure across tasks and languages. It also produces a more compact and task-aligned representation space, enabling low-capacity models to learn cleaner manifolds than conventional baselines. ECR works without teacher outputs and is compatible with, but independent of, distillation. Taken together, our results show that ECR helps compact models better follow task requirements and makes them easier to deploy under strict efficiency or privacy limits.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00543v1",
        "pdf": "https://arxiv.org/pdf/2601.00543v1"
      },
      "arxiv_id": "2601.00543v1",
      "comment": "Preprint 13pages, 6 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00542v1",
      "title": "DynaDrag: Dynamic Drag-Style Image Editing by Motion Prediction",
      "authors": [
        "Jiacheng Sui",
        "Yujie Zhou",
        "Li Niu"
      ],
      "abstract": "To achieve pixel-level image manipulation, drag-style image editing which edits images using points or trajectories as conditions is attracting widespread attention. Most previous methods follow move-and-track framework, in which miss tracking and ambiguous tracking are unavoidable challenging issues. Other methods under different frameworks suffer from various problems like the huge gap between source image and target edited image as well as unreasonable intermediate point which can lead to low editability. To avoid these problems, we propose DynaDrag, the first dragging method under predict-and-move framework. In DynaDrag, Motion Prediction and Motion Supervision are performed iteratively. In each iteration, Motion Prediction first predicts where the handle points should move, and then Motion Supervision drags them accordingly. We also propose to dynamically adjust the valid handle points to further improve the performance. Experiments on face and human datasets showcase the superiority over previous works.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00542v1",
        "pdf": "https://arxiv.org/pdf/2601.00542v1"
      },
      "arxiv_id": "2601.00542v1",
      "comment": "9 pages, 6 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00538v1",
      "title": "Parametrized Sharing for Multi-Agent Hybrid DRL for Multiple Multi-Functional RISs-Aided Downlink NOMA Networks",
      "authors": [
        "Chi-Te Kuo",
        "Li-Hsiang Shen",
        "Jyun-Jhe Huang"
      ],
      "abstract": "Multi-functional reconfigurable intelligent surface (MF-RIS) is conceived to address the communication efficiency thanks to its extended signal coverage from its active RIS capability and self-sustainability from energy harvesting (EH). We investigate the architecture of multi-MF-RISs to assist non-orthogonal multiple access (NOMA) downlink networks. We formulate an energy efficiency (EE) maximization problem by optimizing power allocation, transmit beamforming and MF-RIS configurations of amplitudes, phase-shifts and EH ratios, as well as the position of MF-RISs, while satisfying constraints of available power, user rate requirements, and self-sustainability property. We design a parametrized sharing scheme for multi-agent hybrid deep reinforcement learning (PMHRL), where the multi-agent proximal policy optimization (PPO) and deep-Q network (DQN) handle continuous and discrete variables, respectively. The simulation results have demonstrated that proposed PMHRL has the highest EE compared to other benchmarks, including cases without parametrized sharing, pure PPO and DQN. Moreover, the proposed multi-MF-RISs-aided downlink NOMA achieves the highest EE compared to scenarios of no-EH/amplification, traditional RISs, and deployment without RISs/MF-RISs under different multiple access.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00538v1",
        "pdf": "https://arxiv.org/pdf/2601.00538v1"
      },
      "arxiv_id": "2601.00538v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00537v1",
      "title": "Boosting Segment Anything Model to Generalize Visually Non-Salient Scenarios",
      "authors": [
        "Guangqian Guo",
        "Pengfei Chen",
        "Yong Guo",
        "Huafeng Chen",
        "Boqiang Zhang",
        "Shan Gao"
      ],
      "abstract": "Segment Anything Model (SAM), known for its remarkable zero-shot segmentation capabilities, has garnered significant attention in the community. Nevertheless, its performance is challenged when dealing with what we refer to as visually non-salient scenarios, where there is low contrast between the foreground and background. In these cases, existing methods often cannot capture accurate contours and fail to produce promising segmentation results. In this paper, we propose Visually Non-Salient SAM (VNS-SAM), aiming to enhance SAM's perception of visually non-salient scenarios while preserving its original zero-shot generalizability. We achieve this by effectively exploiting SAM's low-level features through two designs: Mask-Edge Token Interactive decoder and Non-Salient Feature Mining module. These designs help the SAM decoder gain a deeper understanding of non-salient characteristics with only marginal parameter increments and computational requirements. The additional parameters of VNS-SAM can be optimized within 4 hours, demonstrating its feasibility and practicality. In terms of data, we established VNS-SEG, a unified dataset for various VNS scenarios, with more than 35K images, in contrast to previous single-task adaptations. It is designed to make the model learn more robust VNS features and comprehensively benchmark the model's segmentation performance and generalizability on VNS scenarios. Extensive experiments across various VNS segmentation tasks demonstrate the superior performance of VNS-SAM, particularly under zero-shot settings, highlighting its potential for broad real-world applications. Codes and datasets are publicly available at https://guangqian-guo.github.io/VNS-SAM.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00537v1",
        "pdf": "https://arxiv.org/pdf/2601.00537v1"
      },
      "arxiv_id": "2601.00537v1",
      "comment": "Accepted by IEEE TIP",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00535v1",
      "title": "FreeText: Training-Free Text Rendering in Diffusion Transformers via Attention Localization and Spectral Glyph Injection",
      "authors": [
        "Ruiqiang Zhang",
        "Hengyi Wang",
        "Chang Liu",
        "Guanjie Wang",
        "Zehua Ma",
        "Weiming Zhang"
      ],
      "abstract": "Large-scale text-to-image (T2I) diffusion models excel at open-domain synthesis but still struggle with precise text rendering, especially for multi-line layouts, dense typography, and long-tailed scripts such as Chinese. Prior solutions typically require costly retraining or rigid external layout constraints, which can degrade aesthetics and limit flexibility. We propose \\textbf{FreeText}, a training-free, plug-and-play framework that improves text rendering by exploiting intrinsic mechanisms of \\emph{Diffusion Transformer (DiT)} models. \\textbf{FreeText} decomposes the problem into \\emph{where to write} and \\emph{what to write}. For \\emph{where to write}, we localize writing regions by reading token-wise spatial attribution from endogenous image-to-text attention, using sink-like tokens as stable spatial anchors and topology-aware refinement to produce high-confidence masks. For \\emph{what to write}, we introduce Spectral-Modulated Glyph Injection (SGMI), which injects a noise-aligned glyph prior with frequency-domain band-pass modulation to strengthen glyph structure and suppress semantic leakage (rendering the concept instead of the word). Extensive experiments on Qwen-Image, FLUX.1-dev, and SD3 variants across longText-Benchmark, CVTG, and our CLT-Bench show consistent gains in text readability while largely preserving semantic alignment and aesthetic quality, with modest inference overhead.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00535v1",
        "pdf": "https://arxiv.org/pdf/2601.00535v1"
      },
      "arxiv_id": "2601.00535v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00533v1",
      "title": "All-in-One Video Restoration under Smoothly Evolving Unknown Weather Degradations",
      "authors": [
        "Wenrui Li",
        "Hongtao Chen",
        "Yao Xiao",
        "Wangmeng Zuo",
        "Jiantao Zhou",
        "Yonghong Tian",
        "Xiaopeng Fan"
      ],
      "abstract": "All-in-one image restoration aims to recover clean images from diverse unknown degradations using a single model. But extending this task to videos faces unique challenges. Existing approaches primarily focus on frame-wise degradation variation, overlooking the temporal continuity that naturally exists in real-world degradation processes. In practice, degradation types and intensities evolve smoothly over time, and multiple degradations may coexist or transition gradually. In this paper, we introduce the Smoothly Evolving Unknown Degradations (SEUD) scenario, where both the active degradation set and degradation intensity change continuously over time. To support this scenario, we design a flexible synthesis pipeline that generates temporally coherent videos with single, compound, and evolving degradations. To address the challenges in the SEUD scenario, we propose an all-in-One Recurrent Conditional and Adaptive prompting Network (ORCANet). First, a Coarse Intensity Estimation Dehazing (CIED) module estimates haze intensity using physical priors and provides coarse dehazed features as initialization. Second, a Flow Prompt Generation (FPG) module extracts degradation features. FPG generates both static prompts that capture segment-level degradation types and dynamic prompts that adapt to frame-level intensity variations. Furthermore, a label-aware supervision mechanism improves the discriminability of static prompt representations under different degradations. Extensive experiments show that ORCANet achieves superior restoration quality, temporal consistency, and robustness over image and video-based baselines. Code is available at https://github.com/Friskknight/ORCANet-SEUD.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00533v1",
        "pdf": "https://arxiv.org/pdf/2601.00533v1"
      },
      "arxiv_id": "2601.00533v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00527v1",
      "title": "Cloud-Native Generative AI for Automated Planogram Synthesis: A Diffusion Model Approach for Multi-Store Retail Optimization",
      "authors": [
        "Ravi Teja Pagidoju",
        "Shriya Agarwal"
      ],
      "abstract": "Planogram creation is a significant challenge for retail, requiring an average of 30 hours per complex layout. This paper introduces a cloud-native architecture using diffusion models to automatically generate store-specific planograms. Unlike conventional optimization methods that reorganize existing layouts, our system learns from successful shelf arrangements across multiple retail locations to create new planogram configurations. The architecture combines cloud-based model training via AWS with edge deployment for real-time inference. The diffusion model integrates retail-specific constraints through a modified loss function. Simulation-based analysis demonstrates the system reduces planogram design time by 98.3% (from 30 to 0.5 hours) while achieving 94.4% constraint satisfaction. Economic analysis reveals a 97.5% reduction in creation expenses with a 4.4-month break-even period. The cloud-native architecture scales linearly, supporting up to 10,000 concurrent store requests. This work demonstrates the viability of generative AI for automated retail space optimization.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00527v1",
        "pdf": "https://arxiv.org/pdf/2601.00527v1"
      },
      "arxiv_id": "2601.00527v1",
      "comment": "International Conference on Software Engineering and Data Engineering : Springer Nature",
      "journal_ref": "Proceedings of the International Conference on Software Engineering and Data Engineering, Springer Communications in Computer and Information Science, vol. 2720, pp. 152-165, 2025",
      "has_code": false
    },
    {
      "id": "2601.00526v1",
      "title": "Federated Customization of Large Models: Approaches, Experiments, and Insights",
      "authors": [
        "Yuchuan Ye",
        "Ming Ding",
        "Youjia Chen",
        "Peng Cheng",
        "Dusit Niyato"
      ],
      "abstract": "In this article, we explore federated customization of large models and highlight the key challenges it poses within the federated learning framework. We review several popular large model customization techniques, including full fine-tuning, efficient fine-tuning, prompt engineering, prefix-tuning, knowledge distillation, and retrieval-augmented generation. Then, we discuss how these techniques can be implemented within the federated learning framework. Moreover, we conduct experiments on federated prefix-tuning, which, to the best of our knowledge, is the first trial to apply prefix-tuning in the federated learning setting. The conducted experiments validate its feasibility with performance close to centralized approaches. Further comparison with three other federated customization methods demonstrated its competitive performance, satisfactory efficiency, and consistent robustness.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.LG",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00526v1",
        "pdf": "https://arxiv.org/pdf/2601.00526v1"
      },
      "arxiv_id": "2601.00526v1",
      "comment": "8 pages, 1 figure",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00525v1",
      "title": "Optimizing LSTM Neural Networks for Resource-Constrained Retail Sales Forecasting: A Model Compression Study",
      "authors": [
        "Ravi Teja Pagidoju"
      ],
      "abstract": "Standard LSTM(Long Short-Term Memory) neural networks provide accurate predictions for sales data in the retail industry, but require a lot of computing power. It can be challenging especially for mid to small retail industries. This paper examines LSTM model compression by gradually reducing the number of hidden units from 128 to 16. We used the Kaggle Store Item Demand Forecasting dataset, which has 913,000 daily sales records from 10 stores and 50 items, to look at the trade-off between model size and how accurate the predictions are. Experiments show that lowering the number of hidden LSTM units to 64 maintains the same level of accuracy while also improving it. The mean absolute percentage error (MAPE) ranges from 23.6% for the full 128-unit model to 12.4% for the 64-unit model. The optimized model is 73% smaller (from 280KB to 76KB) and 47% more accurate. These results show that larger models do not always achieve better results.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00525v1",
        "pdf": "https://arxiv.org/pdf/2601.00525v1"
      },
      "arxiv_id": "2601.00525v1",
      "comment": "Accepted to IEEE ICUIS 2025 (International Conference on Ubiquitous and Intelligent Systems). 5 pages, 3 figures, 1 table",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00521v1",
      "title": "Probability-Aware Parking Selection",
      "authors": [
        "Cameron Hickert",
        "Sirui Li",
        "Zhengbing He",
        "Cathy Wu"
      ],
      "abstract": "Current parking navigation systems often underestimate total travel time by failing to account for the time spent searching for a parking space, which significantly affects user experience, mode choice, congestion, and emissions. To address this issue, this paper introduces the probability-aware parking selection problem, which aims to direct drivers to the best parking location rather than straight to their destination. An adaptable dynamic programming framework is proposed for decision-making based on probabilistic information about parking availability at the parking lot level. Closed-form analysis determines when it is optimal to target a specific parking lot or explore alternatives, as well as the expected time cost. Sensitivity analysis and three illustrative cases are examined, demonstrating the model's ability to account for the dynamic nature of parking availability. Acknowledging the financial costs of permanent sensing infrastructure, the paper provides analytical and empirical assessments of errors incurred when leveraging stochastic observations to estimate parking availability. Experiments with real-world data from the US city of Seattle indicate this approach's viability, with mean absolute error decreasing from 7% to below 2% as observation frequency grows. In data-based simulations, probability-aware strategies demonstrate time savings up to 66% relative to probability-unaware baselines, yet still take up to 123% longer than direct-to-destination estimates.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "eess.SY",
        "cs.AI",
        "stat.AP"
      ],
      "primary_category": "eess.SY",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00521v1",
        "pdf": "https://arxiv.org/pdf/2601.00521v1"
      },
      "arxiv_id": "2601.00521v1",
      "comment": "10 pages, 6 figures, 3 tables. To be published in IEEE Transactions on Intelligent Transportation Systems",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00519v1",
      "title": "A Sparse-Attention Deep Learning Model Integrating Heterogeneous Multimodal Features for Parkinson's Disease Severity Profiling",
      "authors": [
        "Dristi Datta",
        "Tanmoy Debnath",
        "Minh Chau",
        "Manoranjan Paul",
        "Gourab Adhikary",
        "Md Geaur Rahman"
      ],
      "abstract": "Characterising the heterogeneous presentation of Parkinson's disease (PD) requires integrating biological and clinical markers within a unified predictive framework. While multimodal data provide complementary information, many existing computational models struggle with interpretability, class imbalance, or effective fusion of high-dimensional imaging and tabular clinical features. To address these limitations, we propose the Class-Weighted Sparse-Attention Fusion Network (SAFN), an interpretable deep learning framework for robust multimodal profiling. SAFN integrates MRI cortical thickness, MRI volumetric measures, clinical assessments, and demographic variables using modality-specific encoders and a symmetric cross-attention mechanism that captures nonlinear interactions between imaging and clinical representations. A sparsity-constrained attention-gating fusion layer dynamically prioritises informative modalities, while a class-balanced focal loss (beta = 0.999, gamma = 1.5) mitigates dataset imbalance without synthetic oversampling. Evaluated on 703 participants (570 PD, 133 healthy controls) from the Parkinson's Progression Markers Initiative using subject-wise five-fold cross-validation, SAFN achieves an accuracy of 0.98 plus or minus 0.02 and a PR-AUC of 1.00 plus or minus 0.00, outperforming established machine learning and deep learning baselines. Interpretability analysis shows a clinically coherent decision process, with approximately 60 percent of predictive weight assigned to clinical assessments, consistent with Movement Disorder Society diagnostic principles. SAFN provides a reproducible and transparent multimodal modelling paradigm for computational profiling of neurodegenerative disease.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00519v1",
        "pdf": "https://arxiv.org/pdf/2601.00519v1"
      },
      "arxiv_id": "2601.00519v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00517v1",
      "title": "Generative Conditional Missing Imputation Networks",
      "authors": [
        "George Sun",
        "Yi-Hui Zhou"
      ],
      "abstract": "In this study, we introduce a sophisticated generative conditional strategy designed to impute missing values within datasets, an area of considerable importance in statistical analysis. Specifically, we initially elucidate the theoretical underpinnings of the Generative Conditional Missing Imputation Networks (GCMI), demonstrating its robust properties in the context of the Missing Completely at Random (MCAR) and the Missing at Random (MAR) mechanisms. Subsequently, we enhance the robustness and accuracy of GCMI by integrating a multiple imputation framework using a chained equations approach. This innovation serves to bolster model stability and improve imputation performance significantly. Finally, through a series of meticulous simulations and empirical assessments utilizing benchmark datasets, we establish the superior efficacy of our proposed methods when juxtaposed with other leading imputation techniques currently available. This comprehensive evaluation not only underscores the practicality of GCMI but also affirms its potential as a leading-edge tool in the field of statistical data analysis.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00517v1",
        "pdf": "https://arxiv.org/pdf/2601.00517v1"
      },
      "arxiv_id": "2601.00517v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00516v1",
      "title": "Trajectory Guard -- A Lightweight, Sequence-Aware Model for Real-Time Anomaly Detection in Agentic AI",
      "authors": [
        "Laksh Advani"
      ],
      "abstract": "Autonomous LLM agents generate multi-step action plans that can fail due to contextual misalignment or structural incoherence. Existing anomaly detection methods are ill-suited for this challenge: mean-pooling embeddings dilutes anomalous steps, while contrastive-only approaches ignore sequential structure. Standard unsupervised methods on pre-trained embeddings achieve F1-scores no higher than 0.69. We introduce Trajectory Guard, a Siamese Recurrent Autoencoder with a hybrid loss function that jointly learns task-trajectory alignment via contrastive learning and sequential validity via reconstruction. This dual objective enables unified detection of both \"wrong plan for this task\" and \"malformed plan structure.\" On benchmarks spanning synthetic perturbations and real-world failures from security audits (RAS-Eval) and multi-agent systems (Who\\&When), we achieve F1-scores of 0.88-0.94 on balanced sets and recall of 0.86-0.92 on imbalanced external benchmarks. At 32 ms inference latency, our approach runs 17-27$\\times$ faster than LLM Judge baselines, enabling real-time safety verification in production deployments.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00516v1",
        "pdf": "https://arxiv.org/pdf/2601.00516v1"
      },
      "arxiv_id": "2601.00516v1",
      "comment": "Accepted to AAAI Trustagent 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00514v1",
      "title": "The Illusion of Insight in Reasoning Models",
      "authors": [
        "Liv G. d'Aliberti",
        "Manoel Horta Ribeiro"
      ],
      "abstract": "Do reasoning models have \"Aha!\" moments? Prior work suggests that models like DeepSeek-R1-Zero undergo sudden mid-trace realizations that lead to accurate outputs, implying an intrinsic capacity for self-correction. Yet, it remains unclear whether such intrinsic shifts in reasoning strategy actually improve performance. Here, we study mid-reasoning shifts and instrument training runs to detect them. Our analysis spans 1M+ reasoning traces, hundreds of training checkpoints, three reasoning domains, and multiple decoding temperatures and model architectures. We find that reasoning shifts are rare, do not become more frequent with training, and seldom improve accuracy, indicating that they do not correspond to prior perceptions of model insight. However, their effect varies with model uncertainty. Building on this finding, we show that artificially triggering extrinsic shifts under high entropy reliably improves accuracy. Our results show that mid-reasoning shifts are symptoms of unstable inference behavior rather than an intrinsic mechanism for self-correction.",
      "published": "2026-01-02",
      "updated": "2026-01-02",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00514v1",
        "pdf": "https://arxiv.org/pdf/2601.00514v1"
      },
      "arxiv_id": "2601.00514v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00513v1",
      "title": "When Small Models Are Right for Wrong Reasons: Process Verification for Trustworthy Agents",
      "authors": [
        "Laksh Advani"
      ],
      "abstract": "Deploying small language models (7-9B parameters) as autonomous agents requires trust in their reasoning, not just their outputs. We reveal a critical reliability crisis: 50-69\\% of correct answers from these models contain fundamentally flawed reasoning -- a ``Right-for-Wrong-Reasons'' phenomenon invisible to standard accuracy metrics. Through analysis of 10,734 reasoning traces across three models and diverse tasks, we introduce the Reasoning Integrity Score (RIS), a process-based metric validated with substantial inter-rater agreement ($κ=0.657$). Conventional practices are challenged by our findings: while retrieval-augmented generation (RAG) significantly improves reasoning integrity (Cohen's $d=0.23$--$0.93$), meta-cognitive interventions like self-critique often harm performance ($d=-0.14$ to $-0.33$) in small models on the evaluated tasks. Mechanistic analysis reveals RAG succeeds by grounding calculations in external evidence, reducing errors by 7.6\\%, while meta-cognition amplifies confusion without sufficient model capacity. To enable deployment, verification capabilities are distilled into a neural classifier achieving 0.86 F1-score with 100$\\times$ speedup. These results underscore the necessity of process-based verification for trustworthy agents: accuracy alone is dangerously insufficient when models can be right for entirely wrong reasons.",
      "published": "2026-01-01",
      "updated": "2026-01-01",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00513v1",
        "pdf": "https://arxiv.org/pdf/2601.00513v1"
      },
      "arxiv_id": "2601.00513v1",
      "comment": "Accepted to Trustagent workshop AAAI 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00509v1",
      "title": "Improving LLM-Assisted Secure Code Generation through Retrieval-Augmented-Generation and Multi-Tool Feedback",
      "authors": [
        "Vidyut Sriram",
        "Sawan Pandita",
        "Achintya Lakshmanan",
        "Aneesh Shamraj",
        "Suman Saha"
      ],
      "abstract": "Large Language Models (LLMs) can generate code but often introduce security vulnerabilities, logical inconsistencies, and compilation errors. Prior work demonstrates that LLMs benefit substantially from structured feedback, static analysis, retrieval augmentation, and execution-based refinement. We propose a retrieval-augmented, multi-tool repair workflow in which a single code-generating LLM iteratively refines its outputs using compiler diagnostics, CodeQL security scanning, and KLEE symbolic execution. A lightweight embedding model is used for semantic retrieval of previously successful repairs, providing security-focused examples that guide generation. Evaluated on a combined dataset of 3,242 programs generated by DeepSeek-Coder-1.3B and CodeLlama-7B, the system demonstrates significant improvements in robustness. For DeepSeek, security vulnerabilities were reduced by 96%. For the larger CodeLlama model, the critical security defect rate was decreased from 58.55% to 22.19%, highlighting the efficacy of tool-assisted self-repair even on \"stubborn\" models.",
      "published": "2026-01-01",
      "updated": "2026-01-01",
      "categories": [
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00509v1",
        "pdf": "https://arxiv.org/pdf/2601.00509v1"
      },
      "arxiv_id": "2601.00509v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00504v1",
      "title": "MotionPhysics: Learnable Motion Distillation for Text-Guided Simulation",
      "authors": [
        "Miaowei Wang",
        "Jakub Zadrożny",
        "Oisin Mac Aodha",
        "Amir Vaxman"
      ],
      "abstract": "Accurately simulating existing 3D objects and a wide variety of materials often demands expert knowledge and time-consuming physical parameter tuning to achieve the desired dynamic behavior. We introduce MotionPhysics, an end-to-end differentiable framework that infers plausible physical parameters from a user-provided natural language prompt for a chosen 3D scene of interest, removing the need for guidance from ground-truth trajectories or annotated videos. Our approach first utilizes a multimodal large language model to estimate material parameter values, which are constrained to lie within plausible ranges. We further propose a learnable motion distillation loss that extracts robust motion priors from pretrained video diffusion models while minimizing appearance and geometry inductive biases to guide the simulation. We evaluate MotionPhysics across more than thirty scenarios, including real-world, human-designed, and AI-generated 3D objects, spanning a wide range of materials such as elastic solids, metals, foams, sand, and both Newtonian and non-Newtonian fluids. We demonstrate that MotionPhysics produces visually realistic dynamic simulations guided by natural language, surpassing the state of the art while automatically determining physically plausible parameters. The code and project page are available at: https://wangmiaowei.github.io/MotionPhysics.github.io/.",
      "published": "2026-01-01",
      "updated": "2026-01-01",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00504v1",
        "pdf": "https://arxiv.org/pdf/2601.00504v1"
      },
      "arxiv_id": "2601.00504v1",
      "comment": "AAAI2026 Accepted",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00503v1",
      "title": "Interpretable Machine Learning for Quantum-Informed Property Predictions in Artificial Sensing Materials",
      "authors": [
        "Li Chen",
        "Leonardo Medrano Sandonas",
        "Shirong Huang",
        "Alexander Croy",
        "Gianaurelio Cuniberti"
      ],
      "abstract": "Digital sensing faces challenges in developing sustainable methods to extend the applicability of customized e-noses to complex body odor volatilome (BOV). To address this challenge, we developed MORE-ML, a computational framework that integrates quantum-mechanical (QM) property data of e-nose molecular building blocks with machine learning (ML) methods to predict sensing-relevant properties. Within this framework, we expanded our previous dataset, MORE-Q, to MORE-QX by sampling a larger conformational space of interactions between BOV molecules and mucin-derived receptors. This dataset provides extensive electronic binding features (BFs) computed upon BOV adsorption. Analysis of MORE-QX property space revealed weak correlations between QM properties of building blocks and resulting BFs. Leveraging this observation, we defined electronic descriptors of building blocks as inputs for tree-based ML models to predict BFs. Benchmarking showed CatBoost models outperform alternatives, especially in transferability to unseen compounds. Explainable AI methods further highlighted which QM properties most influence BF predictions. Collectively, MORE-ML combines QM insights with ML to provide mechanistic understanding and rational design principles for molecular receptors in BOV sensing. This approach establishes a foundation for advancing artificial sensing materials capable of analyzing complex odor mixtures, bridging the gap between molecular-level computations and practical e-nose applications.",
      "published": "2026-01-01",
      "updated": "2026-01-01",
      "categories": [
        "physics.chem-ph",
        "cs.LG"
      ],
      "primary_category": "physics.chem-ph",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00503v1",
        "pdf": "https://arxiv.org/pdf/2601.00503v1"
      },
      "arxiv_id": "2601.00503v1",
      "comment": "18 pages, 6 figures, 1 table",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00501v1",
      "title": "CPPO: Contrastive Perception for Vision Language Policy Optimization",
      "authors": [
        "Ahmad Rezaei",
        "Mohsen Gholami",
        "Saeed Ranjbar Alvar",
        "Kevin Cannons",
        "Mohammad Asiful Hossain",
        "Zhou Weimin",
        "Shunbo Zhou",
        "Yong Zhang",
        "Mohammad Akbari"
      ],
      "abstract": "We introduce CPPO, a Contrastive Perception Policy Optimization method for finetuning vision-language models (VLMs). While reinforcement learning (RL) has advanced reasoning in language models, extending it to multimodal reasoning requires improving both the perception and reasoning aspects. Prior works tackle this challenge mainly with explicit perception rewards, but disentangling perception tokens from reasoning tokens is difficult, requiring extra LLMs, ground-truth data, forced separation of perception from reasoning by policy model, or applying rewards indiscriminately to all output tokens. CPPO addresses this problem by detecting perception tokens via entropy shifts in the model outputs under perturbed input images. CPPO then extends the RL objective function with a Contrastive Perception Loss (CPL) that enforces consistency under information-preserving perturbations and sensitivity under information-removing ones. Experiments show that CPPO surpasses previous perception-rewarding methods, while avoiding extra models, making training more efficient and scalable.",
      "published": "2026-01-01",
      "updated": "2026-01-01",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00501v1",
        "pdf": "https://arxiv.org/pdf/2601.00501v1"
      },
      "arxiv_id": "2601.00501v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00488v1",
      "title": "Noise-Aware Named Entity Recognition for Historical VET Documents",
      "authors": [
        "Alexander M. Esser",
        "Jens Dörpinghaus"
      ],
      "abstract": "This paper addresses Named Entity Recognition (NER) in the domain of Vocational Education and Training (VET), focusing on historical, digitized documents that suffer from OCR-induced noise. We propose a robust NER approach leveraging Noise-Aware Training (NAT) with synthetically injected OCR errors, transfer learning, and multi-stage fine-tuning. Three complementary strategies, training on noisy, clean, and artificial data, are systematically compared. Our method is one of the first to recognize multiple entity types in VET documents. It is applied to German documents but transferable to arbitrary languages. Experimental results demonstrate that domain-specific and noise-aware fine-tuning substantially increases robustness and accuracy under noisy conditions. We provide publicly available code for reproducible noise-aware NER in domain-specific contexts.",
      "published": "2026-01-01",
      "updated": "2026-01-01",
      "categories": [
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00488v1",
        "pdf": "https://arxiv.org/pdf/2601.00488v1"
      },
      "arxiv_id": "2601.00488v1",
      "comment": "This is an extended, non-peer-reviewed version of the paper presented at VISAPP 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00482v1",
      "title": "Multi-Agent Coordinated Rename Refactoring",
      "authors": [
        "Abhiram Bellur",
        "Mohammed Raihan Ullah",
        "Fraol Batole",
        "Mohit Kansara",
        "Masaharu Morimoto",
        "Kai Ishikawa",
        "Haifeng Chen",
        "Yaroslav Zharov",
        "Timofey Bryksin",
        "Tien N. Nguyen",
        "Hridesh Rajan",
        "Danny Dig"
      ],
      "abstract": "The primary value of AI agents in software development lies in their ability to extend the developer's capacity for reasoning and action, not to supplant human involvement. To showcase how to use agents working in tandem with developers, we designed a novel approach for carrying out coordinated renaming. Coordinated renaming, where a single rename refactoring triggers refactorings in multiple, related identifiers, is a frequent yet challenging task. Developers must manually propagate these rename refactorings across numerous files and contexts, a process that is both tedious and highly error-prone. State-of-the-art heuristic-based approaches produce an overwhelming number of false positives, while vanilla Large Language Models (LLMs) provide incomplete suggestions due to their limited context and inability to interact with refactoring tools. This leaves developers with incomplete refactorings or burdens them with filtering too many false positives. Coordinated renaming is exactly the kind of repetitive task that agents can significantly reduce the developers' burden while keeping them in the driver's seat.\n  We designed, implemented, and evaluated the first multi-agent framework that automates coordinated renaming. It operates on a key insight: a developer's initial refactoring is a clue to infer the scope of related refactorings. Our Scope Inference Agent first transforms this clue into an explicit, natural-language Declared Scope. The Planned Execution Agent then uses this as a strict plan to identify program elements that should undergo refactoring and safely executes the changes by invoking the IDE's own trusted refactoring APIs. Finally, the Replication Agent uses it to guide the project-wide search. We first conducted a formative study on the practice of coordinated renaming in 609K commits in 100 open-source projects and surveyed 205 developers ...",
      "published": "2026-01-01",
      "updated": "2026-01-01",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00482v1",
        "pdf": "https://arxiv.org/pdf/2601.00482v1"
      },
      "arxiv_id": "2601.00482v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00481v1",
      "title": "MAESTRO: Multi-Agent Evaluation Suite for Testing, Reliability, and Observability",
      "authors": [
        "Tie Ma",
        "Yixi Chen",
        "Vaastav Anand",
        "Alessandro Cornacchia",
        "Amândio R. Faustino",
        "Guanheng Liu",
        "Shan Zhang",
        "Hongbin Luo",
        "Suhaib A. Fahmy",
        "Zafar A. Qazi",
        "Marco Canini"
      ],
      "abstract": "We present MAESTRO, an evaluation suite for the testing, reliability, and observability of LLM-based MAS. MAESTRO standardizes MAS configuration and execution through a unified interface, supports integrating both native and third-party MAS via a repository of examples and lightweight adapters, and exports framework-agnostic execution traces together with system-level signals (e.g., latency, cost, and failures). We instantiate MAESTRO with 12 representative MAS spanning popular agentic frameworks and interaction patterns, and conduct controlled experiments across repeated runs, backend models, and tool configurations. Our case studies show that MAS executions can be structurally stable yet temporally variable, leading to substantial run-to-run variance in performance and reliability. We further find that MAS architecture is the dominant driver of resource profiles, reproducibility, and cost-latency-accuracy trade-off, often outweighing changes in backend models or tool settings. Overall, MAESTRO enables systematic evaluation and provides empirical guidance for designing and optimizing agentic systems.",
      "published": "2026-01-01",
      "updated": "2026-01-01",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00481v1",
        "pdf": "https://arxiv.org/pdf/2601.00481v1"
      },
      "arxiv_id": "2601.00481v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00475v1",
      "title": "Progressive Ideation using an Agentic AI Framework for Human-AI Co-Creation",
      "authors": [
        "Sankar B",
        "Srinidhi Ranjini Girish",
        "Aadya Bharti",
        "Dibakar Sen"
      ],
      "abstract": "The generation of truly novel and diverse ideas is important for contemporary engineering design, yet it remains a significant cognitive challenge for novice designers. Current 'single-spurt' AI systems exacerbate this challenge by producing a high volume of semantically clustered ideas. We propose MIDAS (Meta-cognitive Ideation through Distributed Agentic AI System), a novel framework that replaces the single-AI paradigm with a distributed 'team' of specialized AI agents designed to emulate the human meta-cognitive ideation workflow. This agentic system progressively refines ideas and assesses each one for both global novelty (against existing solutions) and local novelty (against previously generated ideas). MIDAS, therefore, demonstrates a viable and progressive paradigm for true human-AI co-creation, elevating the human designer from a passive filterer to a participatory, active, collaborative partner.",
      "published": "2026-01-01",
      "updated": "2026-01-01",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00475v1",
        "pdf": "https://arxiv.org/pdf/2601.00475v1"
      },
      "arxiv_id": "2601.00475v1",
      "comment": "21 pages, 11 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00473v1",
      "title": "Neural Chains and Discrete Dynamical Systems",
      "authors": [
        "Sauro Succi",
        "Abhisek Ganguly",
        "Santosh Ansumali"
      ],
      "abstract": "We inspect the analogy between machine-learning (ML) applications based on the transformer architecture without self-attention, {\\it neural chains} hereafter, and discrete dynamical systems associated with discretised versions of neural integral and partial differential equations (NIE, PDE). A comparative analysis of the numerical solution of the (viscid and inviscid) Burgers and Eikonal equations via standard numerical discretization (also cast in terms of neural chains) and via PINN's learning is presented and commented on. It is found that standard numerical discretization and PINN learning provide two different paths to acquire essentially the same knowledge about the dynamics of the system. PINN learning proceeds through random matrices which bear no direct relation to the highly structured matrices associated with finite-difference (FD) procedures. Random matrices leading to acceptable solutions are far more numerous than the unique tridiagonal form in matrix space, which explains why the PINN search typically lands on the random ensemble. The price is a much larger number of parameters, causing lack of physical transparency (explainability) as well as large training costs with no counterpart in the FD procedure. However, our results refer to one-dimensional dynamic problems, hence they don't rule out the possibility that PINNs and ML in general, may offer better strategies for high-dimensional problems.",
      "published": "2026-01-01",
      "updated": "2026-01-01",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00473v1",
        "pdf": "https://arxiv.org/pdf/2601.00473v1"
      },
      "arxiv_id": "2601.00473v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00461v1",
      "title": "Laplacian Kernelized Bandit",
      "authors": [
        "Shuang Wu",
        "Arash A. Amini"
      ],
      "abstract": "We study multi-user contextual bandits where users are related by a graph and their reward functions exhibit both non-linear behavior and graph homophily. We introduce a principled joint penalty for the collection of user reward functions $\\{f_u\\}$, combining a graph smoothness term based on RKHS distances with an individual roughness penalty. Our central contribution is proving that this penalty is equivalent to the squared norm within a single, unified \\emph{multi-user RKHS}. We explicitly derive its reproducing kernel, which elegantly fuses the graph Laplacian with the base arm kernel. This unification allows us to reframe the problem as learning a single ''lifted'' function, enabling the design of principled algorithms, \\texttt{LK-GP-UCB} and \\texttt{LK-GP-TS}, that leverage Gaussian Process posteriors over this new kernel for exploration. We provide high-probability regret bounds that scale with an \\emph{effective dimension} of the multi-user kernel, replacing dependencies on user count or ambient dimension. Empirically, our methods outperform strong linear and non-graph-aware baselines in non-linear settings and remain competitive even when the true rewards are linear. Our work delivers a unified, theoretically grounded, and practical framework that bridges Laplacian regularization with kernelized bandits for structured exploration.",
      "published": "2026-01-01",
      "updated": "2026-01-01",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00461v1",
        "pdf": "https://arxiv.org/pdf/2601.00461v1"
      },
      "arxiv_id": "2601.00461v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00459v1",
      "title": "Detecting Spike Wave Discharges (SWD) using 1-dimensional Residual UNet",
      "authors": [
        "Saurav Sengupta",
        "Scott Kilianski",
        "Suchetha Sharma",
        "Sakina Lashkeri",
        "Ashley McHugh",
        "Mark Beenhakker",
        "Donald E. Brown"
      ],
      "abstract": "The manual labeling of events in electroencephalography (EEG) records is time-consuming. This is especially true when EEG recordings are taken continuously over weeks to months. Therefore, a method to automatically label pertinent EEG events reduces the manual workload. Spike wave discharges (SWD), which are the electrographic hallmark of absence seizures, are EEG events that are often labeled manually. While some previous studies have utilized machine learning to automatically segment and classify EEG signals like SWDs, they can be improved. Here we compare the performance of 14 machine learning classifiers on our own manually annotated dataset of 961 hours of EEG recordings from C3H/HeJ mice, including 22,637 labeled SWDs. We find that a 1D UNet performs best for labeling SWDs in this dataset. We also improve the 1D UNet by augmenting our training data and determine that scaling showed the greatest benefit of all augmentation procedures applied. We then compare the 1D UNet with data augmentation, AugUNet1D, against a recently published time- and frequency-based algorithmic approach called \"Twin Peaks\". AugUNet1D showed superior performance and detected events with more similar features to the SWDs labeled manually. AugUNet1D, pretrained on our manually annotated data or untrained, is made public for others users.",
      "published": "2026-01-01",
      "updated": "2026-01-01",
      "categories": [
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00459v1",
        "pdf": "https://arxiv.org/pdf/2601.00459v1"
      },
      "arxiv_id": "2601.00459v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00457v1",
      "title": "Geometric Regularization in Mixture-of-Experts: The Disconnect Between Weights and Activations",
      "authors": [
        "Hyunjun Kim"
      ],
      "abstract": "Mixture-of-Experts (MoE) models achieve efficiency through sparse activation, but the role of geometric regularization in expert specialization remains unclear. We apply orthogonality loss to enforce expert diversity and find it fails on multiple fronts: it does not reduce weight-space overlap (MSO actually increases by up to 114%), activation-space overlap remains high (~0.6) regardless of regularization, and effects on performance are inconsistent -- marginal improvement on WikiText-103 (-0.9%), slight degradation on TinyStories (+0.9%), and highly variable results on PTB (std > 1.0). Our analysis across 7 regularization strengths reveals no significant correlation (r = -0.293, p = 0.523) between weight and activation orthogonality. These findings demonstrate that weight-space regularization neither achieves its geometric goal nor reliably improves performance, making it unsuitable for MoE diversity.",
      "published": "2026-01-01",
      "updated": "2026-01-01",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00457v1",
        "pdf": "https://arxiv.org/pdf/2601.00457v1"
      },
      "arxiv_id": "2601.00457v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00455v1",
      "title": "Deep Networks Learn Deep Hierarchical Models",
      "authors": [
        "Amit Daniely"
      ],
      "abstract": "We consider supervised learning with $n$ labels and show that layerwise SGD on residual networks can efficiently learn a class of hierarchical models. This model class assumes the existence of an (unknown) label hierarchy $L_1 \\subseteq L_2 \\subseteq \\dots \\subseteq L_r = [n]$, where labels in $L_1$ are simple functions of the input, while for $i > 1$, labels in $L_i$ are simple functions of simpler labels.\n  Our class surpasses models that were previously shown to be learnable by deep learning algorithms, in the sense that it reaches the depth limit of efficient learnability. That is, there are models in this class that require polynomial depth to express, whereas previous models can be computed by log-depth circuits.\n  Furthermore, we suggest that learnability of such hierarchical models might eventually form a basis for understanding deep learning. Beyond their natural fit for domains where deep learning excels, we argue that the mere existence of human ``teachers\" supports the hypothesis that hierarchical structures are inherently available. By providing granular labels, teachers effectively reveal ``hints'' or ``snippets'' of the internal algorithms used by the brain. We formalize this intuition, showing that in a simplified model where a teacher is partially aware of their internal logic, a hierarchical structure emerges that facilitates efficient learnability.",
      "published": "2026-01-01",
      "updated": "2026-01-01",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00455v1",
        "pdf": "https://arxiv.org/pdf/2601.00455v1"
      },
      "arxiv_id": "2601.00455v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00454v1",
      "title": "Defensive M2S: Training Guardrail Models on Compressed Multi-turn Conversations",
      "authors": [
        "Hyunjun Kim"
      ],
      "abstract": "Guardrail models are essential for ensuring the safety of Large Language Model (LLM) deployments, but processing full multi-turn conversation histories incurs significant computational cost. We propose Defensive M2S, a training paradigm that fine-tunes guardrail models on Multi-turn to Single-turn (M2S) compressed conversations rather than complete dialogue histories. We provide a formal complexity analysis showing that M2S reduces training cost from $O(n^2)$ to $O(n)$ for $n$-turn conversations. Empirically, on our training dataset (779 samples, avg. 10.6 turns), M2S requires only 169K tokens compared to 15.7M tokens for the multi-turn baseline -- a 93$\\times$ reduction. We evaluate Defensive M2S across three guardrail model families (LlamaGuard, Nemotron, Qwen3Guard) and three compression templates (hyphenize, numberize, pythonize) on SafeDialBench, a comprehensive multi-turn jailbreak benchmark. Our best configuration, Qwen3Guard with hyphenize compression, achieves 93.8% attack detection recall while reducing inference tokens by 94.6% (from 3,231 to 173 tokens per conversation). This represents a 38.9 percentage point improvement over the baseline while dramatically reducing both training and inference costs. Our findings demonstrate that M2S compression can serve as an effective efficiency technique for guardrail deployment, enabling scalable safety screening of long multi-turn conversations.",
      "published": "2026-01-01",
      "updated": "2026-01-01",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00454v1",
        "pdf": "https://arxiv.org/pdf/2601.00454v1"
      },
      "arxiv_id": "2601.00454v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00452v1",
      "title": "Imitation from Observations with Trajectory-Level Generative Embeddings",
      "authors": [
        "Yongtao Qu",
        "Shangzhe Li",
        "Weitong Zhang"
      ],
      "abstract": "We consider the offline imitation learning from observations (LfO) where the expert demonstrations are scarce and the available offline suboptimal data are far from the expert behavior. Many existing distribution-matching approaches struggle in this regime because they impose strict support constraints and rely on brittle one-step models, making it hard to extract useful signal from imperfect data. To tackle this challenge, we propose TGE, a trajectory-level generative embedding for offline LfO that constructs a dense, smooth surrogate reward by estimating expert state density in the latent space of a temporal diffusion model trained on offline trajectory data. By leveraging the smooth geometry of the learned diffusion embedding, TGE captures long-horizon temporal dynamics and effectively bridges the gap between disjoint supports, ensuring a robust learning signal even when offline data is distributionally distinct from the expert. Empirically, the proposed approach consistently matches or outperforms prior offline LfO methods across a range of D4RL locomotion and manipulation benchmarks.",
      "published": "2026-01-01",
      "updated": "2026-01-01",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00452v1",
        "pdf": "https://arxiv.org/pdf/2601.00452v1"
      },
      "arxiv_id": "2601.00452v1",
      "comment": "24 pages, 6 figures, 7 tables",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00451v1",
      "title": "Controllable Concept Bottleneck Models",
      "authors": [
        "Hongbin Lin",
        "Chenyang Ren",
        "Juangui Xu",
        "Zhengyu Hu",
        "Cheng-Long Wang",
        "Yao Shu",
        "Hui Xiong",
        "Jingfeng Zhang",
        "Di Wang",
        "Lijie Hu"
      ],
      "abstract": "Concept Bottleneck Models (CBMs) have garnered much attention for their ability to elucidate the prediction process through a human-understandable concept layer. However, most previous studies focused on static scenarios where the data and concepts are assumed to be fixed and clean. In real-world applications, deployed models require continuous maintenance: we often need to remove erroneous or sensitive data (unlearning), correct mislabeled concepts, or incorporate newly acquired samples (incremental learning) to adapt to evolving environments. Thus, deriving efficient editable CBMs without retraining from scratch remains a significant challenge, particularly in large-scale applications. To address these challenges, we propose Controllable Concept Bottleneck Models (CCBMs). Specifically, CCBMs support three granularities of model editing: concept-label-level, concept-level, and data-level, the latter of which encompasses both data removal and data addition. CCBMs enjoy mathematically rigorous closed-form approximations derived from influence functions that obviate the need for retraining. Experimental results demonstrate the efficiency and adaptability of our CCBMs, affirming their practical value in enabling dynamic and trustworthy CBMs.",
      "published": "2026-01-01",
      "updated": "2026-01-01",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00451v1",
        "pdf": "https://arxiv.org/pdf/2601.00451v1"
      },
      "arxiv_id": "2601.00451v1",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2405.15476",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00448v1",
      "title": "Language as Mathematical Structure: Examining Semantic Field Theory Against Language Games",
      "authors": [
        "Dimitris Vartziotis"
      ],
      "abstract": "Large language models (LLMs) offer a new empirical setting in which long-standing theories of linguistic meaning can be examined. This paper contrasts two broad approaches: social constructivist accounts associated with language games, and a mathematically oriented framework we call Semantic Field Theory. Building on earlier work by the author, we formalize the notions of lexical fields (Lexfelder) and linguistic fields (Lingofelder) as interacting structures in a continuous semantic space. We then analyze how core properties of transformer architectures-such as distributed representations, attention mechanisms, and geometric regularities in embedding spaces-relate to these concepts. We argue that the success of LLMs in capturing semantic regularities supports the view that language exhibits an underlying mathematical structure, while their persistent limitations in pragmatic reasoning and context sensitivity are consistent with the importance of social grounding emphasized in philosophical accounts of language use. On this basis, we suggest that mathematical structure and language games can be understood as complementary rather than competing perspectives. The resulting framework clarifies the scope and limits of purely statistical models of language and motivates new directions for theoretically informed AI architectures.",
      "published": "2026-01-01",
      "updated": "2026-01-01",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00448v1",
        "pdf": "https://arxiv.org/pdf/2601.00448v1"
      },
      "arxiv_id": "2601.00448v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00446v1",
      "title": "A Comparative Study of Adaptation Strategies for Time Series Foundation Models in Anomaly Detection",
      "authors": [
        "Miseon Park",
        "Kijung Yoon"
      ],
      "abstract": "Time series anomaly detection is essential for the reliable operation of complex systems, but most existing methods require extensive task-specific training. We explore whether time series foundation models (TSFMs), pretrained on large heterogeneous data, can serve as universal backbones for anomaly detection. Through systematic experiments across multiple benchmarks, we compare zero-shot inference, full model adaptation, and parameter-efficient fine-tuning (PEFT) strategies. Our results demonstrate that TSFMs outperform task-specific baselines, achieving notable gains in AUC-PR and VUS-PR, particularly under severe class imbalance. Moreover, PEFT methods such as LoRA, OFT, and HRA not only reduce computational cost but also match or surpass full fine-tuning in most cases, indicating that TSFMs can be efficiently adapted for anomaly detection, even when pretrained for forecasting. These findings position TSFMs as promising general-purpose models for scalable and efficient time series anomaly detection.",
      "published": "2026-01-01",
      "updated": "2026-01-01",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00446v1",
        "pdf": "https://arxiv.org/pdf/2601.00446v1"
      },
      "arxiv_id": "2601.00446v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00428v1",
      "title": "A Comparative Analysis of Interpretable Machine Learning Methods",
      "authors": [
        "Mattia Billa",
        "Giovanni Orlandi",
        "Veronica Guidetti",
        "Federica Mandreoli"
      ],
      "abstract": "In recent years, Machine Learning (ML) has seen widespread adoption across a broad range of sectors, including high-stakes domains such as healthcare, finance, and law. This growing reliance has raised increasing concerns regarding model interpretability and accountability, particularly as legal and regulatory frameworks place tighter constraints on using black-box models in critical applications. Although interpretable ML has attracted substantial attention, systematic evaluations of inherently interpretable models, especially for tabular data, remain relatively scarce and often focus primarily on aggregated performance outcomes.\n  To address this gap, we present a large-scale comparative evaluation of 16 inherently interpretable methods, ranging from classical linear models and decision trees to more recent approaches such as Explainable Boosting Machines (EBMs), Symbolic Regression (SR), and Generalized Optimal Sparse Decision Trees (GOSDT). Our study spans 216 real-world tabular datasets and goes beyond aggregate rankings by stratifying performance according to structural dataset characteristics, including dimensionality, sample size, linearity, and class imbalance. In addition, we assess training time and robustness under controlled distributional shifts. Our results reveal clear performance hierarchies, especially for regression tasks, where EBMs consistently achieve strong predictive accuracy. At the same time, we show that performance is highly context-dependent: SR and Interpretable Generalized Additive Neural Networks (IGANNs) perform particularly well in non-linear regimes, while GOSDT models exhibit pronounced sensitivity to class imbalance. Overall, these findings provide practical guidance for practitioners seeking a balance between interpretability and predictive performance, and contribute to a deeper empirical understanding of interpretable modeling for tabular data.",
      "published": "2026-01-01",
      "updated": "2026-01-01",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00428v1",
        "pdf": "https://arxiv.org/pdf/2601.00428v1"
      },
      "arxiv_id": "2601.00428v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00426v1",
      "title": "RMAAT: Astrocyte-Inspired Memory Compression and Replay for Efficient Long-Context Transformers",
      "authors": [
        "Md Zesun Ahmed Mia",
        "Malyaban Bal",
        "Abhronil Sengupta"
      ],
      "abstract": "The quadratic complexity of self-attention mechanism presents a significant impediment to applying Transformer models to long sequences. This work explores computational principles derived from astrocytes-glial cells critical for biological memory and synaptic modulation-as a complementary approach to conventional architectural modifications for efficient self-attention. We introduce the Recurrent Memory Augmented Astromorphic Transformer (RMAAT), an architecture integrating abstracted astrocyte functionalities. RMAAT employs a recurrent, segment-based processing strategy where persistent memory tokens propagate contextual information. An adaptive compression mechanism, governed by a novel retention factor derived from simulated astrocyte long-term plasticity (LTP), modulates these tokens. Attention within segments utilizes an efficient, linear-complexity mechanism inspired by astrocyte short-term plasticity (STP). Training is performed using Astrocytic Memory Replay Backpropagation (AMRB), a novel algorithm designed for memory efficiency in recurrent networks. Evaluations on the Long Range Arena (LRA) benchmark demonstrate RMAAT's competitive accuracy and substantial improvements in computational and memory efficiency, indicating the potential of incorporating astrocyte-inspired dynamics into scalable sequence models.",
      "published": "2026-01-01",
      "updated": "2026-01-01",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00426v1",
        "pdf": "https://arxiv.org/pdf/2601.00426v1"
      },
      "arxiv_id": "2601.00426v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.00423v1",
      "title": "E-GRPO: High Entropy Steps Drive Effective Reinforcement Learning for Flow Models",
      "authors": [
        "Shengjun Zhang",
        "Zhang Zhang",
        "Chensheng Dai",
        "Yueqi Duan"
      ],
      "abstract": "Recent reinforcement learning has enhanced the flow matching models on human preference alignment. While stochastic sampling enables the exploration of denoising directions, existing methods which optimize over multiple denoising steps suffer from sparse and ambiguous reward signals. We observe that the high entropy steps enable more efficient and effective exploration while the low entropy steps result in undistinguished roll-outs. To this end, we propose E-GRPO, an entropy aware Group Relative Policy Optimization to increase the entropy of SDE sampling steps. Since the integration of stochastic differential equations suffer from ambiguous reward signals due to stochasticity from multiple steps, we specifically merge consecutive low entropy steps to formulate one high entropy step for SDE sampling, while applying ODE sampling on other steps. Building upon this, we introduce multi-step group normalized advantage, which computes group-relative advantages within samples sharing the same consolidated SDE denoising step. Experimental results on different reward settings have demonstrated the effectiveness of our methods.",
      "published": "2026-01-01",
      "updated": "2026-01-01",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.00423v1",
        "pdf": "https://arxiv.org/pdf/2601.00423v1"
      },
      "arxiv_id": "2601.00423v1",
      "comment": "Code: https://github.com/shengjun-zhang/VisualGRPO",
      "journal_ref": "",
      "has_code": true
    }
  ]
}