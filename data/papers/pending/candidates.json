{
  "fetched_at": "2026-01-28T00:28:13.936916",
  "total_papers": 100,
  "papers": [
    {
      "id": "2601.18796v1",
      "title": "ctELM: Decoding and Manipulating Embeddings of Clinical Trials with Embedding Language Models",
      "authors": [
        "Brian Ondov",
        "Chia-Hsuan Chang",
        "Yujia Zhou",
        "Mauro Giuffrè",
        "Hua Xu"
      ],
      "abstract": "Text embeddings have become an essential part of a variety of language applications. However, methods for interpreting, exploring and reversing embedding spaces are limited, reducing transparency and precluding potentially valuable generative use cases. In this work, we align Large Language Models to embeddings of clinical trials using the recently reported Embedding Language Model (ELM) method. We develop an open-source, domain-agnostic ELM architecture and training framework, design training tasks for clinical trials, and introduce an expert-validated synthetic dataset. We then train a series of ELMs exploring the impact of tasks and training regimes. Our final model, ctELM, can accurately describe and compare unseen clinical trials from embeddings alone and produce plausible clinical trials from novel vectors. We further show that generated trial abstracts are responsive to moving embeddings along concept vectors for age and sex of study subjects. Our public ELM implementation and experimental results will aid the alignment of Large Language Models to embedding spaces in the biomedical domain and beyond.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18796v1",
        "pdf": "https://arxiv.org/pdf/2601.18796v1"
      },
      "arxiv_id": "2601.18796v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18795v1",
      "title": "Reuse your FLOPs: Scaling RL on Hard Problems by Conditioning on Very Off-Policy Prefixes",
      "authors": [
        "Amrith Setlur",
        "Zijian Wang",
        "Andrew Cohen",
        "Paria Rashidinejad",
        "Sang Michael Xie"
      ],
      "abstract": "Typical reinforcement learning (RL) methods for LLM reasoning waste compute on hard problems, where correct on-policy traces are rare, policy gradients vanish, and learning stalls. To bootstrap more efficient RL, we consider reusing old sampling FLOPs (from prior inference or RL training) in the form of off-policy traces. Standard off-policy methods supervise against off-policy data, causing instabilities during RL optimization. We introduce PrefixRL, where we condition on the prefix of successful off-policy traces and run on-policy RL to complete them, side-stepping off-policy instabilities. PrefixRL boosts the learning signal on hard problems by modulating the difficulty of the problem through the off-policy prefix length. We prove that the PrefixRL objective is not only consistent with the standard RL objective but also more sample efficient. Empirically, we discover back-generalization: training only on prefixed problems generalizes to out-of-distribution unprefixed performance, with learned strategies often differing from those in the prefix. In our experiments, we source the off-policy traces by rejection sampling with the base model, creating a self-improvement loop. On hard reasoning problems, PrefixRL reaches the same training reward 2x faster than the strongest baseline (SFT on off-policy data then RL), even after accounting for the compute spent on the initial rejection sampling, and increases the final reward by 3x. The gains transfer to held-out benchmarks, and PrefixRL is still effective when off-policy traces are derived from a different model family, validating its flexibility in practical settings.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18795v1",
        "pdf": "https://arxiv.org/pdf/2601.18795v1"
      },
      "arxiv_id": "2601.18795v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18792v1",
      "title": "MEGnifying Emotion: Sentiment Analysis from Annotated Brain Data",
      "authors": [
        "Brian Liu",
        "Oiwi Parker Jones"
      ],
      "abstract": "Decoding emotion from brain activity could unlock a deeper understanding of the human experience. While a number of existing datasets align brain data with speech and with speech transcripts, no datasets have annotated brain data with sentiment. To bridge this gap, we explore the use of pre-trained Text-to-Sentiment models to annotate non invasive brain recordings, acquired using magnetoencephalography (MEG), while participants listened to audiobooks. Having annotated the text, we employ force-alignment of the text and audio to align our sentiment labels with the brain recordings. It is straightforward then to train Brainto-Sentiment models on these data. Experimental results show an improvement in balanced accuracy for Brain-to-Sentiment compared to baseline, supporting the proposed approach as a proof-of-concept for leveraging existing MEG datasets and learning to decode sentiment directly from the brain.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.HC",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18792v1",
        "pdf": "https://arxiv.org/pdf/2601.18792v1"
      },
      "arxiv_id": "2601.18792v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18791v1",
      "title": "Subword-Based Comparative Linguistics across 242 Languages Using Wikipedia Glottosets",
      "authors": [
        "Iaroslav Chelombitko",
        "Mika Hämäläinen",
        "Aleksey Komissarov"
      ],
      "abstract": "We present a large-scale comparative study of 242 Latin and Cyrillic-script languages using subword-based methodologies. By constructing 'glottosets' from Wikipedia lexicons, we introduce a framework for simultaneous cross-linguistic comparison via Byte-Pair Encoding (BPE). Our approach utilizes rank-based subword vectors to analyze vocabulary overlap, lexical divergence, and language similarity at scale. Evaluations demonstrate that BPE segmentation aligns with morpheme boundaries 95% better than random baseline across 15 languages (F1 = 0.34 vs 0.15). BPE vocabulary similarity correlates significantly with genetic language relatedness (Mantel r = 0.329, p < 0.001), with Romance languages forming the tightest cluster (mean distance 0.51) and cross-family pairs showing clear separation (0.82). Analysis of 26,939 cross-linguistic homographs reveals that 48.7% receive different segmentations across related languages, with variation correlating to phylogenetic distance. Our results provide quantitative macro-linguistic insights into lexical patterns across typologically diverse languages within a unified analytical framework.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18791v1",
        "pdf": "https://arxiv.org/pdf/2601.18791v1"
      },
      "arxiv_id": "2601.18791v1",
      "comment": "15 pages, 4 figues, 4 tables",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18788v1",
      "title": "Unsupervised Text Segmentation via Kernel Change-Point Detection on Sentence Embeddings",
      "authors": [
        "Mumin Jia",
        "Jairo Diaz-Rodriguez"
      ],
      "abstract": "Unsupervised text segmentation is crucial because boundary labels are expensive, subjective, and often fail to transfer across domains and granularity choices. We propose Embed-KCPD, a training-free method that represents sentences as embedding vectors and estimates boundaries by minimizing a penalized KCPD objective. Beyond the algorithmic instantiation, we develop, to our knowledge, the first dependence-aware theory for KCPD under $m$-dependent sequences, a finite-memory abstraction of short-range dependence common in language. We prove an oracle inequality for the population penalized risk and a localization guarantee showing that each true change point is recovered within a window that is small relative to segment length. To connect theory to practice, we introduce an LLM-based simulation framework that generates synthetic documents with controlled finite-memory dependence and known boundaries, validating the predicted scaling behavior. Across standard segmentation benchmarks, Embed-KCPD often outperforms strong unsupervised baselines. A case study on Taylor Swift's tweets illustrates that Embed-KCPD combines strong theoretical guarantees, simulated reliability, and practical effectiveness for text segmentation.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.CL",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18788v1",
        "pdf": "https://arxiv.org/pdf/2601.18788v1"
      },
      "arxiv_id": "2601.18788v1",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2510.03437. substantial text overlap with arXiv:2510.03437. substantial text overlap with arXiv:2510.03437. substantial text overlap with arXiv:2510.03437",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18785v1",
      "title": "Design Techniques for LLM-Powered Interactive Storytelling: A Case Study of the Dramamancer System",
      "authors": [
        "Tiffany Wang",
        "Yuqian Sun",
        "Yi Wang",
        "Melissa Roemmele",
        "John Joon Young Chung",
        "Max Kreminski"
      ],
      "abstract": "The rise of Large Language Models (LLMs) has enabled a new paradigm for bridging authorial intent and player agency in interactive narrative. We consider this paradigm through the example of Dramamancer, a system that uses an LLM to transform author-created story schemas into player-driven playthroughs. This extended abstract outlines some design techniques and evaluation considerations associated with this system.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18785v1",
        "pdf": "https://arxiv.org/pdf/2601.18785v1"
      },
      "arxiv_id": "2601.18785v1",
      "comment": "Extended abstract presented at the 2025 Wordplay Workshop at EMNLP",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18783v1",
      "title": "Multi-Objective Reinforcement Learning for Efficient Tactical Decision Making for Trucks in Highway Traffic",
      "authors": [
        "Deepthi Pathare",
        "Leo Laine",
        "Morteza Haghir Chehreghani"
      ],
      "abstract": "Balancing safety, efficiency, and operational costs in highway driving poses a challenging decision-making problem for heavy-duty vehicles. A central difficulty is that conventional scalar reward formulations, obtained by aggregating these competing objectives, often obscure the structure of their trade-offs. We present a Proximal Policy Optimization based multi-objective reinforcement learning framework that learns a continuous set of policies explicitly representing these trade-offs and evaluates it on a scalable simulation platform for tactical decision making in trucks. The proposed approach learns a continuous set of Pareto-optimal policies that capture the trade-offs among three conflicting objectives: safety, quantified in terms of collisions and successful completion; energy efficiency and time efficiency, quantified using energy cost and driver cost, respectively. The resulting Pareto frontier is smooth and interpretable, enabling flexibility in choosing driving behavior along different conflicting objectives. This framework allows seamless transitions between different driving policies without retraining, yielding a robust and adaptive decision-making strategy for autonomous trucking applications.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18783v1",
        "pdf": "https://arxiv.org/pdf/2601.18783v1"
      },
      "arxiv_id": "2601.18783v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18782v1",
      "title": "Low-Bit Quantization of Bandlimited Graph Signals via Iterative Methods",
      "authors": [
        "Felix Krahmer",
        "He Lyu",
        "Rayan Saab",
        "Jinna Qian",
        "Anna Veselovska",
        "Rongrong Wang"
      ],
      "abstract": "We study the quantization of real-valued bandlimited signals on graphs, focusing on low-bit representations. We propose iterative noise-shaping algorithms for quantization, including sampling approaches with and without vertex replacement. The methods leverage the spectral properties of the graph Laplacian and exploit graph incoherence to achieve high-fidelity approximations. Theoretical guarantees are provided for the random sampling method, and extensive numerical experiments on synthetic and real-world graphs illustrate the efficiency and robustness of the proposed schemes.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "eess.SP",
        "eess.IV",
        "math.GR",
        "math.NA",
        "math.OC"
      ],
      "primary_category": "eess.SP",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18782v1",
        "pdf": "https://arxiv.org/pdf/2601.18782v1"
      },
      "arxiv_id": "2601.18782v1",
      "comment": "17 pages, 5 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18779v1",
      "title": "POPE: Learning to Reason on Hard Problems via Privileged On-Policy Exploration",
      "authors": [
        "Yuxiao Qu",
        "Amrith Setlur",
        "Virginia Smith",
        "Ruslan Salakhutdinov",
        "Aviral Kumar"
      ],
      "abstract": "Reinforcement learning (RL) has improved the reasoning abilities of large language models (LLMs), yet state-of-the-art methods still fail to learn on many training problems. On hard problems, on-policy RL rarely explores even a single correct rollout, yielding zero reward and no learning signal for driving improvement. We find that natural solutions to remedy this exploration problem from classical RL, such as entropy bonuses, more permissive clipping of the importance ratio, or direct optimization of pass@k objectives, do not resolve this issue and often destabilize optimization without improving solvability. A natural alternative is to leverage transfer from easier problems. However, we show that mixing easy and hard problems during RL training is counterproductive due to ray interference, where optimization focuses on already-solvable problems in a way that actively inhibits progress on harder ones. To address this challenge, we introduce Privileged On-Policy Exploration (POPE), an approach that leverages human- or other oracle solutions as privileged information to guide exploration on hard problems, unlike methods that use oracle solutions as training targets (e.g., off-policy RL methods or warmstarting from SFT). POPE augments hard problems with prefixes of oracle solutions, enabling RL to obtain non-zero rewards during guided rollouts. Crucially, the resulting behaviors transfer back to the original, unguided problems through a synergy between instruction-following and reasoning. Empirically, POPE expands the set of solvable problems and substantially improves performance on challenging reasoning benchmarks.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18779v1",
        "pdf": "https://arxiv.org/pdf/2601.18779v1"
      },
      "arxiv_id": "2601.18779v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18778v1",
      "title": "Teaching Models to Teach Themselves: Reasoning at the Edge of Learnability",
      "authors": [
        "Shobhita Sundaram",
        "John Quan",
        "Ariel Kwiatkowski",
        "Kartik Ahuja",
        "Yann Ollivier",
        "Julia Kempe"
      ],
      "abstract": "Can a model learn to escape its own learning plateau? Reinforcement learning methods for finetuning large reasoning models stall on datasets with low initial success rates, and thus little training signal. We investigate a fundamental question: Can a pretrained LLM leverage latent knowledge to generate an automated curriculum for problems it cannot solve? To explore this, we design SOAR: A self-improvement framework designed to surface these pedagogical signals through meta-RL. A teacher copy of the model proposes synthetic problems for a student copy, and is rewarded with its improvement on a small subset of hard problems. Critically, SOAR grounds the curriculum in measured student progress rather than intrinsic proxy rewards. Our study on the hardest subsets of mathematical benchmarks (0/128 success) reveals three core findings. First, we show that it is possible to realize bi-level meta-RL that unlocks learning under sparse, binary rewards by sharpening a latent capacity of pretrained models to generate useful stepping stones. Second, grounded rewards outperform intrinsic reward schemes used in prior LLM self-play, reliably avoiding the instability and diversity collapse modes they typically exhibit. Third, analyzing the generated questions reveals that structural quality and well-posedness are more critical for learning progress than solution correctness. Our results suggest that the ability to generate useful stepping stones does not require the preexisting ability to actually solve the hard problems, paving a principled path to escape reasoning plateaus without additional curated data.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18778v1",
        "pdf": "https://arxiv.org/pdf/2601.18778v1"
      },
      "arxiv_id": "2601.18778v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18777v1",
      "title": "PRECISE: Reducing the Bias of LLM Evaluations Using Prediction-Powered Ranking Estimation",
      "authors": [
        "Abhishek Divekar",
        "Anirban Majumder"
      ],
      "abstract": "Evaluating the quality of search, ranking and RAG systems traditionally requires a significant number of human relevance annotations. In recent times, several deployed systems have explored the usage of Large Language Models (LLMs) as automated judges for this task while their inherent biases prevent direct use for metric estimation. We present a statistical framework extending Prediction-Powered Inference (PPI) that combines minimal human annotations with LLM judgments to produce reliable estimates of metrics which require sub-instance annotations. Our method requires as few as 100 human-annotated queries and 10,000 unlabeled examples, reducing annotation requirements significantly compared to traditional approaches. We formulate our proposed framework (PRECISE) for inference of relevance uplift for an LLM-based query reformulation application, extending PPI to sub-instance annotations at the query-document level. By reformulating the metric-integration space, we reduced the computational complexity from O(2^|C|) to O(2^K), where |C| represents corpus size (in order of millions). Detailed experiments across prominent retrieval datasets demonstrate that our method reduces the variance of estimates for the business-critical Precision@K metric, while effectively correcting for LLM bias in low-resource settings.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18777v1",
        "pdf": "https://arxiv.org/pdf/2601.18777v1"
      },
      "arxiv_id": "2601.18777v1",
      "comment": "Accepted at AAAI 2026 - Innovative Applications of AI (IAAI-26)",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18771v1",
      "title": "Dep-Search: Learning Dependency-Aware Reasoning Traces with Persistent Memory",
      "authors": [
        "Yanming Liu",
        "Xinyue Peng",
        "Zixuan Yan",
        "Yanxin Shen",
        "Wenjie Xu",
        "Yuefeng Huang",
        "Xinyi Wang",
        "Jiannan Cao",
        "Jianwei Yin",
        "Xuhong Zhang"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable capabilities in complex reasoning tasks, particularly when augmented with search mechanisms that enable systematic exploration of external knowledge bases. The field has evolved from traditional retrieval-augmented generation (RAG) frameworks to more sophisticated search-based frameworks that orchestrate multi-step reasoning through explicit search strategies. However, existing search frameworks still rely heavily on implicit natural language reasoning to determine search strategies and how to leverage retrieved information across reasoning steps. This reliance on implicit reasoning creates fundamental challenges for managing dependencies between sub-questions, efficiently reusing previously retrieved knowledge, and learning optimal search strategies through reinforcement learning. To address these limitations, we propose Dep-Search, a dependency-aware search framework that advances beyond existing search frameworks by integrating structured reasoning, retrieval, and persistent memory through GRPO. Dep-Search introduces explicit control mechanisms that enable the model to decompose questions with dependency relationships, retrieve information when needed, access previously stored knowledge from memory, and summarize long reasoning contexts into reusable memory entries. Through extensive experiments on seven diverse question answering datasets, we demonstrate that Dep-Search significantly enhances LLMs' ability to tackle complex multi-hop reasoning tasks, achieving substantial improvements over strong baselines across different model scales.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18771v1",
        "pdf": "https://arxiv.org/pdf/2601.18771v1"
      },
      "arxiv_id": "2601.18771v1",
      "comment": "Dep-Search 1st version",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18766v1",
      "title": "Learning to Discover: A Generalized Framework for Raga Identification without Forgetting",
      "authors": [
        "Parampreet Singh",
        "Somya Kumar",
        "Chaitanya Shailendra Nitawe",
        "Vipul Arora"
      ],
      "abstract": "Raga identification in Indian Art Music (IAM) remains challenging due to the presence of numerous rarely performed Ragas that are not represented in available training datasets. Traditional classification models struggle in this setting, as they assume a closed set of known categories and therefore fail to recognise or meaningfully group previously unseen Ragas. Recent works have tried categorizing unseen Ragas, but they run into a problem of catastrophic forgetting, where the knowledge of previously seen Ragas is diminished. To address this problem, we adopt a unified learning framework that leverages both labeled and unlabeled audio, enabling the model to discover coherent categories corresponding to the unseen Ragas, while retaining the knowledge of previously known ones. We test our model on benchmark Raga Identification datasets and demonstrate its performance in categorizing previously seen, unseen, and all Raga classes. The proposed approach surpasses the previous NCD-based pipeline even in discovering the unseen Raga categories, offering new insights into representation learning for IAM tasks.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "eess.AS",
        "cs.LG"
      ],
      "primary_category": "eess.AS",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18766v1",
        "pdf": "https://arxiv.org/pdf/2601.18766v1"
      },
      "arxiv_id": "2601.18766v1",
      "comment": "Accepted at NCC 2026 conference",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18760v1",
      "title": "Beyond Preferences: Learning Alignment Principles Grounded in Human Reasons and Values",
      "authors": [
        "Henry Bell",
        "Lara Neubauer da Costa Schertel",
        "Bochu Ding",
        "Brandon Fain"
      ],
      "abstract": "A crucial consideration when developing and deploying Large Language Models (LLMs) is the human values to which these models are aligned. In the constitutional framework of alignment models are aligned to a set of principles (the constitution) specified in natural language. However, it is unclear how to fairly determine this constitution with widespread stakeholder input. In this work we propose Grounded Constitutional AI (GCAI), a unified framework for generating constitutions of principles that are representative of both users' general expectations toward AI (general principles) and their interaction-time preferences (contextual principles). We extend the Inverse Constitutional AI (ICAI) approach to generate contextual principles from human preference annotation data by leveraging human-provided \\textit{reasons} for their preferences. We supplement these contextual principles with general principles surfaced from user statements of \\textit{values} regarding AI. We show that a constitution generated by GCAI is preferred by humans over one generated through ICAI both personally, and for widespread use in governing AI behavior. Additionally participants consider the GCAI constitution to be more morally grounded, coherent, and pluralistic.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18760v1",
        "pdf": "https://arxiv.org/pdf/2601.18760v1"
      },
      "arxiv_id": "2601.18760v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18754v1",
      "title": "$α^3$-SecBench: A Large-Scale Evaluation Suite of Security, Resilience, and Trust for LLM-based UAV Agents over 6G Networks",
      "authors": [
        "Mohamed Amine Ferrag",
        "Abderrahmane Lakas",
        "Merouane Debbah"
      ],
      "abstract": "Autonomous unmanned aerial vehicle (UAV) systems are increasingly deployed in safety-critical, networked environments where they must operate reliably in the presence of malicious adversaries. While recent benchmarks have evaluated large language model (LLM)-based UAV agents in reasoning, navigation, and efficiency, systematic assessment of security, resilience, and trust under adversarial conditions remains largely unexplored, particularly in emerging 6G-enabled settings.\n  We introduce $α^{3}$-SecBench, the first large-scale evaluation suite for assessing the security-aware autonomy of LLM-based UAV agents under realistic adversarial interference. Building on multi-turn conversational UAV missions from $α^{3}$-Bench, the framework augments benign episodes with 20,000 validated security overlay attack scenarios targeting seven autonomy layers, including sensing, perception, planning, control, communication, edge/cloud infrastructure, and LLM reasoning. $α^{3}$-SecBench evaluates agents across three orthogonal dimensions: security (attack detection and vulnerability attribution), resilience (safe degradation behavior), and trust (policy-compliant tool usage).\n  We evaluate 23 state-of-the-art LLMs from major industrial providers and leading AI labs using thousands of adversarially augmented UAV episodes sampled from a corpus of 113,475 missions spanning 175 threat types. While many models reliably detect anomalous behavior, effective mitigation, vulnerability attribution, and trustworthy control actions remain inconsistent. Normalized overall scores range from 12.9% to 57.1%, highlighting a significant gap between anomaly detection and security-aware autonomous decision-making. We release $α^{3}$-SecBench on GitHub: https://github.com/maferrag/AlphaSecBench",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18754v1",
        "pdf": "https://arxiv.org/pdf/2601.18754v1"
      },
      "arxiv_id": "2601.18754v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18753v1",
      "title": "HalluGuard: Demystifying Data-Driven and Reasoning-Driven Hallucinations in LLMs",
      "authors": [
        "Xinyue Zeng",
        "Junhong Lin",
        "Yujun Yan",
        "Feng Guo",
        "Liang Shi",
        "Jun Wu",
        "Dawei Zhou"
      ],
      "abstract": "The reliability of Large Language Models (LLMs) in high-stakes domains such as healthcare, law, and scientific discovery is often compromised by hallucinations. These failures typically stem from two sources: data-driven hallucinations and reasoning-driven hallucinations. However, existing detection methods usually address only one source and rely on task-specific heuristics, limiting their generalization to complex scenarios. To overcome these limitations, we introduce the Hallucination Risk Bound, a unified theoretical framework that formally decomposes hallucination risk into data-driven and reasoning-driven components, linked respectively to training-time mismatches and inference-time instabilities. This provides a principled foundation for analyzing how hallucinations emerge and evolve. Building on this foundation, we introduce HalluGuard, an NTK-based score that leverages the induced geometry and captured representations of the NTK to jointly identify data-driven and reasoning-driven hallucinations. We evaluate HalluGuard on 10 diverse benchmarks, 11 competitive baselines, and 9 popular LLM backbones, consistently achieving state-of-the-art performance in detecting diverse forms of LLM hallucinations.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18753v1",
        "pdf": "https://arxiv.org/pdf/2601.18753v1"
      },
      "arxiv_id": "2601.18753v1",
      "comment": "Have been accepted by ICLR'26",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18751v1",
      "title": "Trust, Don't Trust, or Flip: Robust Preference-Based Reinforcement Learning with Multi-Expert Feedback",
      "authors": [
        "Seyed Amir Hosseini",
        "Maryam Abdolali",
        "Amirhosein Tavakkoli",
        "Fardin Ayar",
        "Ehsan Javanmardi",
        "Manabu Tsukada",
        "Mahdi Javanmardi"
      ],
      "abstract": "Preference-based reinforcement learning (PBRL) offers a promising alternative to explicit reward engineering by learning from pairwise trajectory comparisons. However, real-world preference data often comes from heterogeneous annotators with varying reliability; some accurate, some noisy, and some systematically adversarial. Existing PBRL methods either treat all feedback equally or attempt to filter out unreliable sources, but both approaches fail when faced with adversarial annotators who systematically provide incorrect preferences. We introduce TriTrust-PBRL (TTP), a unified framework that jointly learns a shared reward model and expert-specific trust parameters from multi-expert preference feedback. The key insight is that trust parameters naturally evolve during gradient-based optimization to be positive (trust), near zero (ignore), or negative (flip), enabling the model to automatically invert adversarial preferences and recover useful signal rather than merely discarding corrupted feedback. We provide theoretical analysis establishing identifiability guarantees and detailed gradient analysis that explains how expert separation emerges naturally during training without explicit supervision. Empirically, we evaluate TTP on four diverse domains spanning manipulation tasks (MetaWorld) and locomotion (DM Control) under various corruption scenarios. TTP achieves state-of-the-art robustness, maintaining near-oracle performance under adversarial corruption while standard PBRL methods fail catastrophically. Notably, TTP outperforms existing baselines by successfully learning from mixed expert pools containing both reliable and adversarial annotators, all while requiring no expert features beyond identification indices and integrating seamlessly with existing PBRL pipelines.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18751v1",
        "pdf": "https://arxiv.org/pdf/2601.18751v1"
      },
      "arxiv_id": "2601.18751v1",
      "comment": "Equal contribution: Seyed Amir Hosseini and Maryam Abdolali. Corresponding author: Maryam Abdolali (maryam.abdolali@kntu.ac.ir)",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18747v1",
      "title": "Capturing P: On the Expressive Power and Efficient Evaluation of Boolean Retrieval",
      "authors": [
        "Amir Aavani"
      ],
      "abstract": "Modern information retrieval is transitioning from simple document filtering to complex, neuro-symbolic reasoning workflows. However, current retrieval architectures face a fundamental efficiency dilemma when handling the rigorous logical and arithmetic constraints required by this new paradigm. Standard iterator-based engines (Document-at-a-Time) do not natively support complex, nested logic graphs; forcing them to execute such queries typically results in intractable runtime performance. Conversely, naive recursive approaches (Term-at-a-Time), while capable of supporting these structures, suffer from prohibitive memory consumption when enforcing broad logical exclusions.\n  In this paper, we propose that a retrieval engine must be capable of ``Capturing $\\mathbf{P}$'' -- evaluating any polynomial-time property directly over its index in a computationally efficient manner. We define a formal Retrieval Language ($\\mathcal{L}_R$) based on Directed Acyclic Graphs (DAGs) and prove it precisely captures the complexity class $\\mathbf{P}$. We introduce \\texttt{ComputePN}, a novel evaluation algorithm that makes $\\mathcal{L}_R$ tractable. By combining native DAG traversal with a memory-efficient ``Positive-Negative'' response mechanism, \\texttt{ComputePN} ensures the efficient evaluation of any query in $\\mathcal{L}_R$. This work establishes the theoretical foundation for turning the search index into a general-purpose computational engine.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CC",
        "cs.CL",
        "cs.DB"
      ],
      "primary_category": "cs.IR",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18747v1",
        "pdf": "https://arxiv.org/pdf/2601.18747v1"
      },
      "arxiv_id": "2601.18747v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18744v1",
      "title": "TSRBench: A Comprehensive Multi-task Multi-modal Time Series Reasoning Benchmark for Generalist Models",
      "authors": [
        "Fangxu Yu",
        "Xingang Guo",
        "Lingzhi Yuan",
        "Haoqiang Kang",
        "Hongyu Zhao",
        "Lianhui Qin",
        "Furong Huang",
        "Bin Hu",
        "Tianyi Zhou"
      ],
      "abstract": "Time series data is ubiquitous in real-world scenarios and crucial for critical applications ranging from energy management to traffic control. Consequently, the ability to reason over time series is a fundamental skill for generalist models to solve practical problems. However, this dimension is notably absent from existing benchmarks of generalist models. To bridge this gap, we introduce TSRBench, a comprehensive multi-modal benchmark designed to stress-test the full spectrum of time series reasoning capabilities. TSRBench features: i) a diverse set of 4125 problems from 14 domains, and is categorized into 4 major dimensions: Perception, Reasoning, Prediction, and Decision-Making. ii) 15 tasks from the 4 dimensions evaluating essential reasoning capabilities (e.g., numerical reasoning). Through extensive experiments, we evaluated over 30 leading proprietary and open-source LLMs, VLMs, and TSLLMs within TSRBench. Our findings reveal that: i) scaling laws hold for perception and reasoning but break down for prediction; ii) strong reasoning does not guarantee accurate context-aware forecasting, indicating a decoupling between semantic understanding and numerical prediction; and iii) despite the complementary nature of textual and visual represenations of time series as inputs, current multimodal models fail to effectively fuse them for reciprocal performance gains. TSRBench provides a standardized evaluation platform that not only highlights existing challenges but also offers valuable insights to advance generalist models. Our code and dataset are available at https://tsrbench.github.io/.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18744v1",
        "pdf": "https://arxiv.org/pdf/2601.18744v1"
      },
      "arxiv_id": "2601.18744v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18739v1",
      "title": "SeNeDiF-OOD: Semantic Nested Dichotomy Fusion for Out-of-Distribution Detection Methodology in Open-World Classification. A Case Study on Monument Style Classification",
      "authors": [
        "Ignacio Antequera-Sánchez",
        "Juan Luis Suárez-Díaz",
        "Rosana Montes",
        "Francisco Herrera"
      ],
      "abstract": "Out-of-distribution (OOD) detection is a fundamental requirement for the reliable deployment of artificial intelligence applications in open-world environments. However, addressing the heterogeneous nature of OOD data, ranging from low-level corruption to semantic shifts, remains a complex challenge that single-stage detectors often fail to resolve. To address this issue, we propose SeNeDiF-OOD, a novel methodology based on Semantic Nested Dichotomy Fusion. This framework decomposes the detection task into a hierarchical structure of binary fusion nodes, where each layer is designed to integrate decision boundaries aligned with specific levels of semantic abstraction. To validate the proposed framework, we present a comprehensive case study using MonuMAI, a real-world architectural style recognition system exposed to an open environment. This application faces a diverse range of inputs, including non-monument images, unknown architectural styles, and adversarial attacks, making it an ideal testbed for our proposal. Through extensive experimental evaluation in this domain, results demonstrate that our hierarchical fusion methodology significantly outperforms traditional baselines, effectively filtering these diverse OOD categories while preserving in-distribution performance.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18739v1",
        "pdf": "https://arxiv.org/pdf/2601.18739v1"
      },
      "arxiv_id": "2601.18739v1",
      "comment": "28 pages",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18736v1",
      "title": "Benchmarking Machine Learning Models for IoT Malware Detection under Data Scarcity and Drift",
      "authors": [
        "Jake Lyon",
        "Ehsan Saeedizade",
        "Shamik Sengupta"
      ],
      "abstract": "The rapid expansion of the Internet of Things (IoT) in domains such as smart cities, transportation, and industrial systems has heightened the urgency of addressing their security vulnerabilities. IoT devices often operate under limited computational resources, lack robust physical safeguards, and are deployed in heterogeneous and dynamic networks, making them prime targets for cyberattacks and malware applications. Machine learning (ML) offers a promising approach to automated malware detection and classification, but practical deployment requires models that are both effective and lightweight. The goal of this study is to investigate the effectiveness of four supervised learning models (Random Forest, LightGBM, Logistic Regression, and a Multi-Layer Perceptron) for malware detection and classification using the IoT-23 dataset. We evaluate model performance in both binary and multiclass classification tasks, assess sensitivity to training data volume, and analyze temporal robustness to simulate deployment in evolving threat landscapes. Our results show that tree-based models achieve high accuracy and generalization, even with limited training data, while performance deteriorates over time as malware diversity increases. These findings underscore the importance of adaptive, resource-efficient ML models for securing IoT systems in real-world environments.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.LG",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18736v1",
        "pdf": "https://arxiv.org/pdf/2601.18736v1"
      },
      "arxiv_id": "2601.18736v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18735v1",
      "title": "Why Keep Your Doubts to Yourself? Trading Visual Uncertainties in Multi-Agent Bandit Systems",
      "authors": [
        "Jusheng Zhang",
        "Yijia Fan",
        "Kaitong Cai",
        "Jing Yang",
        "Jiawei Yao",
        "Jian Wang",
        "Guanlong Qu",
        "Ziliang Chen",
        "Keze Wang"
      ],
      "abstract": "Vision-Language Models (VLMs) enable powerful multi-agent systems, but scaling them is economically unsustainable: coordinating heterogeneous agents under information asymmetry often spirals costs. Existing paradigms, such as Mixture-of-Agents and knowledge-based routers, rely on heuristic proxies that ignore costs and collapse uncertainty structure, leading to provably suboptimal coordination. We introduce Agora, a framework that reframes coordination as a decentralized market for uncertainty. Agora formalizes epistemic uncertainty into a structured, tradable asset (perceptual, semantic, inferential), and enforces profitability-driven trading among agents based on rational economic rules. A market-aware broker, extending Thompson Sampling, initiates collaboration and guides the system toward cost-efficient equilibria. Experiments on five multimodal benchmarks (MMMU, MMBench, MathVision, InfoVQA, CC-OCR) show that Agora outperforms strong VLMs and heuristic multi-agent strategies, e.g., achieving +8.5% accuracy over the best baseline on MMMU while reducing cost by over 3x. These results establish market-based coordination as a principled and scalable paradigm for building economically viable multi-agent visual intelligence systems.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18735v1",
        "pdf": "https://arxiv.org/pdf/2601.18735v1"
      },
      "arxiv_id": "2601.18735v1",
      "comment": "Accepted to ICLR 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18734v1",
      "title": "Self-Distilled Reasoner: On-Policy Self-Distillation for Large Language Models",
      "authors": [
        "Siyan Zhao",
        "Zhihui Xie",
        "Mengchen Liu",
        "Jing Huang",
        "Guan Pang",
        "Feiyu Chen",
        "Aditya Grover"
      ],
      "abstract": "Knowledge distillation improves large language model (LLM) reasoning by compressing the knowledge of a teacher LLM to train smaller LLMs. On-policy distillation advances this approach by having the student sample its own trajectories while a teacher LLM provides dense token-level supervision, addressing the distribution mismatch between training and inference in off-policy distillation methods. However, on-policy distillation typically requires a separate, often larger, teacher LLM and does not explicitly leverage ground-truth solutions available in reasoning datasets. Inspired by the intuition that a sufficiently capable LLM can rationalize external privileged reasoning traces and teach its weaker self (i.e., the version without access to privileged information), we introduce On-Policy Self-Distillation (OPSD), a framework where a single model acts as both teacher and student by conditioning on different contexts. The teacher policy conditions on privileged information (e.g., verified reasoning traces) while the student policy sees only the question; training minimizes the per-token divergence between these distributions over the student's own rollouts. We demonstrate the efficacy of our method on multiple mathematical reasoning benchmarks, achieving 4-8x token efficiency compared to reinforcement learning methods such as GRPO and superior performance over off-policy distillation methods.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18734v1",
        "pdf": "https://arxiv.org/pdf/2601.18734v1"
      },
      "arxiv_id": "2601.18734v1",
      "comment": "13 pages",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18733v1",
      "title": "Advances and Innovations in the Multi-Agent Robotic System (MARS) Challenge",
      "authors": [
        "Li Kang",
        "Heng Zhou",
        "Xiufeng Song",
        "Rui Li",
        "Bruno N. Y. Chen",
        "Ziye Wang",
        "Ximeng Meng",
        "Stone Tao",
        "Yiran Qin",
        "Xiaohong Liu",
        "Ruimao Zhang",
        "Lei Bai",
        "Yilun Du",
        "Hao Su",
        "Philip Torr",
        "Zhenfei Yin",
        "Ruihao Gong",
        "Yejun Zeng",
        "Fengjun Zhong",
        "Shenghao Jin",
        "Jinyang Guo",
        "Xianglong Liu",
        "Xiaojun Jia",
        "Tianqi Shan",
        "Wenqi Ren",
        "Simeng Qin",
        "Jialing Yang",
        "Xiaoyu Ma",
        "Tianxing Chen",
        "Zixuan Li",
        "Zijian Cai",
        "Yan Qin",
        "Yusen Qin",
        "Qiangyu Chen",
        "Kaixuan Wang",
        "Zhaoming Han",
        "Yao Mu",
        "Ping Luo",
        "Yuanqi Yao",
        "Haoming Song",
        "Jan-Nico Zaech",
        "Fabien Despinoy",
        "Danda Pani Paudel",
        "Luc Van Gool"
      ],
      "abstract": "Recent advancements in multimodal large language models and vision-languageaction models have significantly driven progress in Embodied AI. As the field transitions toward more complex task scenarios, multi-agent system frameworks are becoming essential for achieving scalable, efficient, and collaborative solutions. This shift is fueled by three primary factors: increasing agent capabilities, enhancing system efficiency through task delegation, and enabling advanced human-agent interactions. To address the challenges posed by multi-agent collaboration, we propose the Multi-Agent Robotic System (MARS) Challenge, held at the NeurIPS 2025 Workshop on SpaVLE. The competition focuses on two critical areas: planning and control, where participants explore multi-agent embodied planning using vision-language models (VLMs) to coordinate tasks and policy execution to perform robotic manipulation in dynamic environments. By evaluating solutions submitted by participants, the challenge provides valuable insights into the design and coordination of embodied multi-agent systems, contributing to the future development of advanced collaborative AI systems.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18733v1",
        "pdf": "https://arxiv.org/pdf/2601.18733v1"
      },
      "arxiv_id": "2601.18733v1",
      "comment": "MARS Challenge @ NeurIPS 2025 Workshop on Space in Vision, Language, and Embodied AI. Challenge page: https://mars-eai.github.io/MARS-Challenge-Webpage/",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2601.18732v1",
      "title": "Optimal Use of Preferences in Artificial Intelligence Algorithms",
      "authors": [
        "Joshua S. Gans"
      ],
      "abstract": "Machine learning systems embed preferences either in training losses or through post-processing of calibrated predictions. Applying information design methods from Strack and Yang (2024), this paper provides decision problem agnostic conditions under which separation training preference free and applying preferences ex post is optimal. Unlike prior work that requires specifying downstream objectives, the welfare results here apply uniformly across decision problems. The key primitive is a diminishing-value-of-information condition: relative to a fixed (normalised) preference-free loss, preference embedding makes informativeness less valuable at the margin, inducing a mean-preserving contraction of learned posteriors. Because the value of information is convex in beliefs, preference-free training weakly dominates for any expected utility decision problem. This provides theoretical foundations for modular AI pipelines that learn calibrated probabilities and implement asymmetric costs through downstream decision rules. However, separation requires users to implement optimal decision rules. When cognitive constraints bind, as documented in human AI decision-making, preference embedding can dominate by automating threshold computation. These results provide design guidance: preserve optionality through post-processing when objectives may shift; embed preferences when decision-stage frictions dominate.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "econ.TH",
        "cs.AI"
      ],
      "primary_category": "econ.TH",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18732v1",
        "pdf": "https://arxiv.org/pdf/2601.18732v1"
      },
      "arxiv_id": "2601.18732v1",
      "comment": "54 pages, 2 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18731v1",
      "title": "One Adapts to Any: Meta Reward Modeling for Personalized LLM Alignment",
      "authors": [
        "Hongru Cai",
        "Yongqi Li",
        "Tiezheng Yu",
        "Fengbin Zhu",
        "Wenjie Wang",
        "Fuli Feng",
        "Wenjie Li"
      ],
      "abstract": "Alignment of Large Language Models (LLMs) aims to align outputs with human preferences, and personalized alignment further adapts models to individual users. This relies on personalized reward models that capture user-specific preferences and automatically provide individualized feedback. However, developing these models faces two critical challenges: the scarcity of feedback from individual users and the need for efficient adaptation to unseen users. We argue that addressing these constraints requires a paradigm shift from fitting data to learn user preferences to learn the process of preference adaptation. To realize this, we propose Meta Reward Modeling (MRM), which reformulates personalized reward modeling as a meta-learning problem. Specifically, we represent each user's reward model as a weighted combination of base reward functions, and optimize the initialization of these weights using a Model-Agnostic Meta-Learning (MAML)-style framework to support fast adaptation under limited feedback. To ensure robustness, we introduce the Robust Personalization Objective (RPO), which places greater emphasis on hard-to-learn users during meta optimization. Extensive experiments on personalized preference datasets validate that MRM enhances few-shot personalization, improves user robustness, and consistently outperforms baselines.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18731v1",
        "pdf": "https://arxiv.org/pdf/2601.18731v1"
      },
      "arxiv_id": "2601.18731v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18730v1",
      "title": "Reflect: Transparent Principle-Guided Reasoning for Constitutional Alignment at Scale",
      "authors": [
        "Henry Bell",
        "Caroline Zhang",
        "Mohammed Mobasserul Haque",
        "Dhaval Potdar",
        "Samia Zaman",
        "Brandon Fain"
      ],
      "abstract": "The constitutional framework of alignment aims to align large language models (LLMs) with value-laden principles written in natural language (such as to avoid using biased language). Prior work has focused on parameter fine-tuning techniques, such as reinforcement learning from human feedback (RLHF), to instill these principles. However, these approaches are computationally demanding, require careful engineering and tuning, and often require difficult-to-obtain human annotation data. We propose \\textsc{reflect}, an inference-time framework for constitutional alignment that does not require any training or data, providing a plug-and-play approach for aligning an instruction-tuned model to a set of principles. \\textsc{reflect} operates entirely in-context, combining a (i) constitution-conditioned base response with post-generation (ii) self-evaluation, (iii)(a) self-critique, and (iii)(b) final revision. \\textsc{reflect}'s technique of explicit in-context reasoning over principles during post-generation outperforms standard few-shot prompting and provides transparent reasoning traces. Our results demonstrate that \\textsc{reflect} significantly improves LLM conformance to diverse and complex principles, including principles quite distinct from those emphasized in the model's original parameter fine-tuning, without sacrificing factual reasoning. \\textsc{reflect} is particularly effective at reducing the rate of rare but significant violations of principles, thereby improving safety and robustness in the tail end of the distribution of generations. Finally, we show that \\textsc{reflect} naturally generates useful training data for traditional parameter fine-tuning techniques, allowing for efficient scaling and the reduction of inference-time computational overhead in long-term deployment scenarios.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18730v1",
        "pdf": "https://arxiv.org/pdf/2601.18730v1"
      },
      "arxiv_id": "2601.18730v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18728v1",
      "title": "Riemannian AmbientFlow: Towards Simultaneous Manifold Learning and Generative Modeling from Corrupted Data",
      "authors": [
        "Willem Diepeveen",
        "Oscar Leong"
      ],
      "abstract": "Modern generative modeling methods have demonstrated strong performance in learning complex data distributions from clean samples. In many scientific and imaging applications, however, clean samples are unavailable, and only noisy or linearly corrupted measurements can be observed. Moreover, latent structures, such as manifold geometries, present in the data are important to extract for further downstream scientific analysis. In this work, we introduce Riemannian AmbientFlow, a framework for simultaneously learning a probabilistic generative model and the underlying, nonlinear data manifold directly from corrupted observations. Building on the variational inference framework of AmbientFlow, our approach incorporates data-driven Riemannian geometry induced by normalizing flows, enabling the extraction of manifold structure through pullback metrics and Riemannian Autoencoders. We establish theoretical guarantees showing that, under appropriate geometric regularization and measurement conditions, the learned model recovers the underlying data distribution up to a controllable error and yields a smooth, bi-Lipschitz manifold parametrization. We further show that the resulting smooth decoder can serve as a principled generative prior for inverse problems with recovery guarantees. We empirically validate our approach on low-dimensional synthetic manifolds and on MNIST.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.LG",
        "math.DG",
        "math.OC",
        "math.ST"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18728v1",
        "pdf": "https://arxiv.org/pdf/2601.18728v1"
      },
      "arxiv_id": "2601.18728v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18724v1",
      "title": "HalluCitation Matters: Revealing the Impact of Hallucinated References with 300 Hallucinated Papers in ACL Conferences",
      "authors": [
        "Yusuke Sakai",
        "Hidetaka Kamigaito",
        "Taro Watanabe"
      ],
      "abstract": "Recently, we have often observed hallucinated citations or references that do not correspond to any existing work in papers under review, preprints, or published papers. Such hallucinated citations pose a serious concern to scientific reliability. When they appear in accepted papers, they may also negatively affect the credibility of conferences. In this study, we refer to hallucinated citations as \"HalluCitation\" and systematically investigate their prevalence and impact. We analyze all papers published at ACL, NAACL, and EMNLP in 2024 and 2025, including main conference, Findings, and workshop papers. Our analysis reveals that nearly 300 papers contain at least one HalluCitation, most of which were published in 2025. Notably, half of these papers were identified at EMNLP 2025, the most recent conference, indicating that this issue is rapidly increasing. Moreover, more than 100 such papers were accepted as main conference and Findings papers at EMNLP 2025, affecting the credibility.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DL"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18724v1",
        "pdf": "https://arxiv.org/pdf/2601.18724v1"
      },
      "arxiv_id": "2601.18724v1",
      "comment": "Work In Progress",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18722v1",
      "title": "Gained in Translation: Privileged Pairwise Judges Enhance Multilingual Reasoning",
      "authors": [
        "Lintang Sutawika",
        "Gokul Swamy",
        "Zhiwei Steven Wu",
        "Graham Neubig"
      ],
      "abstract": "When asked a question in a language less seen in its training data, current reasoning large language models (RLMs) often exhibit dramatically lower performance than when asked the same question in English. In response, we introduce \\texttt{SP3F} (Self-Play with Privileged Pairwise Feedback), a two-stage framework for enhancing multilingual reasoning without \\textit{any} data in the target language(s). First, we supervise fine-tune (SFT) on translated versions of English question-answer pairs to raise base model correctness. Second, we perform RL with feedback from a pairwise judge in a self-play fashion, with the judge receiving the English reference response as \\textit{privileged information}. Thus, even when none of the model's responses are completely correct, the privileged pairwise judge can still tell which response is better. End-to-end, \\texttt{SP3F} greatly improves base model performance, even outperforming fully post-trained models on multiple math and non-math tasks with less than\n  of the training data across the single-language, multilingual, and generalization to unseen language settings.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18722v1",
        "pdf": "https://arxiv.org/pdf/2601.18722v1"
      },
      "arxiv_id": "2601.18722v1",
      "comment": "Code available at https://github.com/lintangsutawika/SP3F",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2601.18716v1",
      "title": "Conditioned Generative Modeling of Molecular Glues: A Realistic AI Approach for Synthesizable Drug-like Molecules",
      "authors": [
        "Naeyma N. Islam",
        "Thomas R. Caulfield"
      ],
      "abstract": "Alzheimer's disease (AD) is marked by the pathological accumulation of amyloid beta-42 (Abeta-42), contributing to synaptic dysfunction and neurodegeneration. While extracellular amyloid plaques are well-studied, increasing evidence highlights intracellular Abeta-42 as an early and toxic driver of disease progression. In this study, we present a novel, AI-assisted drug design approach to promote targeted degradation of Abeta-42 via the ubiquitin-proteasome system (UPS), using E3 ligase-directed molecular glues. We systematically evaluated the ternary complex formation potential of Abeta-42 with three E3 ligases: CRBN, VHL, and MDM2, through structure-based modeling, ADMET screening, and docking. We then developed a Ligase-Conditioned Junction Tree Variational Autoencoder (LC-JT-VAE) to generate ligase-specific small molecules, incorporating protein sequence embeddings and torsional angle-aware molecular graphs. Our results demonstrate that this generative model can produce chemically valid, novel, and target-specific molecular glues capable of facilitating Abeta-42 degradation. This integrated approach offers a promising framework for designing UPS-targeted therapies for neurodegenerative diseases.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18716v1",
        "pdf": "https://arxiv.org/pdf/2601.18716v1"
      },
      "arxiv_id": "2601.18716v1",
      "comment": "30 pages, 8 figures",
      "journal_ref": "Biomolecules 2025, 15, 849",
      "has_code": false
    },
    {
      "id": "2601.18714v1",
      "title": "Low Cost, High Efficiency: LiDAR Place Recognition in Vineyards with Matryoshka Representation Learning",
      "authors": [
        "Judith Vilella-Cantos",
        "Mauro Martini",
        "Marcello Chiaberge",
        "Mónica Ballesta",
        "David Valiente"
      ],
      "abstract": "Localization in agricultural environments is challenging due to their unstructured nature and lack of distinctive landmarks. Although agricultural settings have been studied in the context of object classification and segmentation, the place recognition task for mobile robots is not trivial in the current state of the art. In this study, we propose MinkUNeXt-VINE, a lightweight, deep-learning-based method that surpasses state-of-the-art methods in vineyard environments thanks to its pre-processing and Matryoshka Representation Learning multi-loss approach. Our method prioritizes enhanced performance with low-cost, sparse LiDAR inputs and lower-dimensionality outputs to ensure high efficiency in real-time scenarios. Additionally, we present a comprehensive ablation study of the results on various evaluation cases and two extensive long-term vineyard datasets employing different LiDAR sensors. The results demonstrate the efficiency of the trade-off output produced by this approach, as well as its robust performance on low-cost and low-resolution input data. The code is publicly available for reproduction.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18714v1",
        "pdf": "https://arxiv.org/pdf/2601.18714v1"
      },
      "arxiv_id": "2601.18714v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18713v1",
      "title": "Point transformer for protein structural heterogeneity analysis using CryoEM",
      "authors": [
        "Muyuan Chen",
        "Muchen Li",
        "Renjie Liao"
      ],
      "abstract": "Structural dynamics of macromolecules is critical to their structural-function relationship. Cryogenic electron microscopy (CryoEM) provides snapshots of vitrified protein at different compositional and conformational states, and the structural heterogeneity of proteins can be characterized through computational analysis of the images. For protein systems with multiple degrees of freedom, it is still challenging to disentangle and interpret the different modes of dynamics. Here, by implementing Point Transformer, a self-attention network designed for point cloud analysis, we are able to improve the performance of heterogeneity analysis on CryoEM data, and characterize the dynamics of highly complex protein systems in a more human-interpretable way.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "q-bio.QM",
        "cs.AI"
      ],
      "primary_category": "q-bio.QM",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18713v1",
        "pdf": "https://arxiv.org/pdf/2601.18713v1"
      },
      "arxiv_id": "2601.18713v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18710v1",
      "title": "Analyzing Images of Blood Cells with Quantum Machine Learning Methods: Equilibrium Propagation and Variational Quantum Circuits to Detect Acute Myeloid Leukemia",
      "authors": [
        "A. Bano",
        "L. Liebovitch"
      ],
      "abstract": "This paper presents a feasibility study demonstrating that quantum machine learning (QML) algorithms achieve competitive performance on real-world medical imaging despite operating under severe constraints. We evaluate Equilibrium Propagation (EP), an energy-based learning method that does not use backpropagation (incompatible with quantum systems due to state-collapsing measurements) and Variational Quantum Circuits (VQCs) for automated detection of Acute Myeloid Leukemia (AML) from blood cell microscopy images using binary classification (2 classes: AML vs. Healthy).\n  Key Result: Using limited subsets (50-250 samples per class) of the AML-Cytomorphology dataset (18,365 expert-annotated images), quantum methods achieve performance only 12-15% below classical CNNs despite reduced image resolution (64x64 pixels), engineered features (20D), and classical simulation via Qiskit. EP reaches 86.4% accuracy (only 12% below CNN) without backpropagation, while the 4-qubit VQC attains 83.0% accuracy with consistent data efficiency: VQC maintains stable 83% performance with only 50 samples per class, whereas CNN requires 250 samples (5x more data) to reach 98%. These results establish reproducible baselines for QML in healthcare, validating NISQ-era feasibility.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.ET",
        "cs.LG",
        "quant-ph"
      ],
      "primary_category": "cs.ET",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18710v1",
        "pdf": "https://arxiv.org/pdf/2601.18710v1"
      },
      "arxiv_id": "2601.18710v1",
      "comment": "5 pages, 1 figure, 2 tables",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18707v1",
      "title": "SMART: Scalable Mesh-free Aerodynamic Simulations from Raw Geometries using a Transformer-based Surrogate Model",
      "authors": [
        "Jan Hagnberger",
        "Mathias Niepert"
      ],
      "abstract": "Machine learning-based surrogate models have emerged as more efficient alternatives to numerical solvers for physical simulations over complex geometries, such as car bodies. Many existing models incorporate the simulation mesh as an additional input, thereby reducing prediction errors. However, generating a simulation mesh for new geometries is computationally costly. In contrast, mesh-free methods, which do not rely on the simulation mesh, typically incur higher errors. Motivated by these considerations, we introduce SMART, a neural surrogate model that predicts physical quantities at arbitrary query locations using only a point-cloud representation of the geometry, without requiring access to the simulation mesh. The geometry and simulation parameters are encoded into a shared latent space that captures both structural and parametric characteristics of the physical field. A physics decoder then attends to the encoder's intermediate latent representations to map spatial queries to physical quantities. Through this cross-layer interaction, the model jointly updates latent geometric features and the evolving physical field. Extensive experiments show that SMART is competitive with and often outperforms existing methods that rely on the simulation mesh as input, demonstrating its capabilities for industry-level simulations.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18707v1",
        "pdf": "https://arxiv.org/pdf/2601.18707v1"
      },
      "arxiv_id": "2601.18707v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18706v1",
      "title": "Health-SCORE: Towards Scalable Rubrics for Improving Health-LLMs",
      "authors": [
        "Zhichao Yang",
        "Sepehr Janghorbani",
        "Dongxu Zhang",
        "Jun Han",
        "Qian Qian",
        "Andrew Ressler",
        "Gregory D. Lyng",
        "Sanjit Singh Batra",
        "Robert E. Tillman"
      ],
      "abstract": "Rubrics are essential for evaluating open-ended LLM responses, especially in safety-critical domains such as healthcare. However, creating high-quality and domain-specific rubrics typically requires significant human expertise time and development cost, making rubric-based evaluation and training difficult to scale. In this work, we introduce Health-SCORE, a generalizable and scalable rubric-based training and evaluation framework that substantially reduces rubric development costs without sacrificing performance. We show that Health-SCORE provides two practical benefits beyond standalone evaluation: it can be used as a structured reward signal to guide reinforcement learning with safety-aware supervision, and it can be incorporated directly into prompts to improve response quality through in-context learning. Across open-ended healthcare tasks, Health-SCORE achieves evaluation quality comparable to human-created rubrics while significantly lowering development effort, making rubric-based evaluation and training more scalable.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18706v1",
        "pdf": "https://arxiv.org/pdf/2601.18706v1"
      },
      "arxiv_id": "2601.18706v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18704v1",
      "title": "Data-Driven Qubit Characterization and Optimal Control using Deep Learning",
      "authors": [
        "Paul Surrey",
        "Julian D. Teske",
        "Tobias Hangleiter",
        "Hendrik Bluhm",
        "Pascal Cerfontaine"
      ],
      "abstract": "Quantum computing requires the optimization of control pulses to achieve high-fidelity quantum gates. We propose a machine learning-based protocol to address the challenges of evaluating gradients and modeling complex system dynamics. By training a recurrent neural network (RNN) to predict qubit behavior, our approach enables efficient gradient-based pulse optimization without the need for a detailed system model. First, we sample qubit dynamics using random control pulses with weak prior assumptions. We then train the RNN on the system's observed responses, and use the trained model to optimize high-fidelity control pulses. We demonstrate the effectiveness of this approach through simulations on a single $ST_0$ qubit.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "quant-ph",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18704v1",
        "pdf": "https://arxiv.org/pdf/2601.18704v1"
      },
      "arxiv_id": "2601.18704v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18702v1",
      "title": "From Fuzzy to Exact: The Halo Architecture for Infinite-Depth Reasoning via Rational Arithmetic",
      "authors": [
        "Hansheng Ren"
      ],
      "abstract": "Current paradigms in Deep Learning prioritize computational throughput over numerical precision, relying on the assumption that intelligence emerges from statistical correlation at scale. In this paper, we challenge this orthodoxy. We propose the Exactness Hypothesis: that General Intelligence (AGI), specifically high-order causal inference, requires a computational substrate capable of Arbitrary Precision Arithmetic. We argue that the \"hallucinations\" and logical incoherence seen in current Large Language Models (LLMs) are artifacts of IEEE 754 floating-point approximation errors accumulating over deep compositional functions. To mitigate this, we introduce the Halo Architecture, a paradigm shift to Rational Arithmetic ($\\mathbb{Q}$) supported by a novel Exact Inference Unit (EIU). Empirical validation on the Huginn-0125 prototype demonstrates that while 600B-parameter scale BF16 baselines collapse in chaotic systems, Halo maintains zero numerical divergence indefinitely. This work establishes exact arithmetic as a prerequisite for reducing logical uncertainty in System 2 AGI.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18702v1",
        "pdf": "https://arxiv.org/pdf/2601.18702v1"
      },
      "arxiv_id": "2601.18702v1",
      "comment": "8 pages, 6 figures. Submitted to UAI 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18700v1",
      "title": "TEA-Bench: A Systematic Benchmarking of Tool-enhanced Emotional Support Dialogue Agent",
      "authors": [
        "Xingyu Sui",
        "Yanyan Zhao",
        "Yulin Hu",
        "Jiahe Guo",
        "Weixiang Zhao",
        "Bing Qin"
      ],
      "abstract": "Emotional Support Conversation requires not only affective expression but also grounded instrumental support to provide trustworthy guidance. However, existing ESC systems and benchmarks largely focus on affective support in text-only settings, overlooking how external tools can enable factual grounding and reduce hallucination in multi-turn emotional support. We introduce TEA-Bench, the first interactive benchmark for evaluating tool-augmented agents in ESC, featuring realistic emotional scenarios, an MCP-style tool environment, and process-level metrics that jointly assess the quality and factual grounding of emotional support. Experiments on nine LLMs show that tool augmentation generally improves emotional support quality and reduces hallucination, but the gains are strongly capacity-dependent: stronger models use tools more selectively and effectively, while weaker models benefit only marginally. We further release TEA-Dialog, a dataset of tool-enhanced ESC dialogues, and find that supervised fine-tuning improves in-distribution support but generalizes poorly. Our results underscore the importance of tool use in building reliable emotional support agents.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18700v1",
        "pdf": "https://arxiv.org/pdf/2601.18700v1"
      },
      "arxiv_id": "2601.18700v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18699v1",
      "title": "Mechanistic Analysis of Catastrophic Forgetting in Large Language Models During Continual Fine-tuning",
      "authors": [
        "Olaf Yunus Laitinen Imanov"
      ],
      "abstract": "Large language models exhibit remarkable performance across diverse tasks through pre-training and fine-tuning paradigms. However, continual fine-tuning on sequential tasks induces catastrophic forgetting, where newly acquired knowledge interferes with previously learned capabilities. Despite widespread observations of this phenomenon, the mechanistic understanding remains limited. Here, we present a comprehensive mechanistic analysis of catastrophic forgetting in transformer-based LLMs during sequential fine-tuning. Through systematic experiments across multiple model scales (109B to 400B total parameters) and task sequences, we identify three primary mechanisms driving forgetting: gradient interference in attention weights, representational drift in intermediate layers, and loss landscape flattening. We demonstrate that forgetting severity correlates strongly with task similarity (Pearson r = 0.87) and gradient alignment metrics. Our analysis reveals that approximately 15 to 23 percent of attention heads undergo severe disruption during fine-tuning, with lower layers showing greater susceptibility. These findings establish mechanistic foundations for developing targeted mitigation strategies in continual learning systems.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18699v1",
        "pdf": "https://arxiv.org/pdf/2601.18699v1"
      },
      "arxiv_id": "2601.18699v1",
      "comment": "16 pages, 16 figures (6 main + 10 supplementary)",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18698v1",
      "title": "Are Video Generation Models Geographically Fair? An Attraction-Centric Evaluation of Global Visual Knowledge",
      "authors": [
        "Xiao Liu",
        "Jiawei Zhang"
      ],
      "abstract": "Recent advances in text-to-video generation have produced visually compelling results, yet it remains unclear whether these models encode geographically equitable visual knowledge. In this work, we investigate the geo-equity and geographically grounded visual knowledge of text-to-video models through an attraction-centric evaluation. We introduce Geo-Attraction Landmark Probing (GAP), a systematic framework for assessing how faithfully models synthesize tourist attractions from diverse regions, and construct GEOATTRACTION-500, a benchmark of 500 globally distributed attractions spanning varied regions and popularity levels. GAP integrates complementary metrics that disentangle overall video quality from attraction-specific knowledge, including global structural alignment, fine-grained keypoint-based alignment, and vision-language model judgments, all validated against human evaluation. Applying GAP to the state-of-the-art text-to-video model Sora 2, we find that, contrary to common assumptions of strong geographic bias, the model exhibits a relatively uniform level of geographically grounded visual knowledge across regions, development levels, and cultural groupings, with only weak dependence on attraction popularity. These results suggest that current text-to-video models express global visual knowledge more evenly than expected, highlighting both their promise for globally deployed applications and the need for continued evaluation as such systems evolve.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18698v1",
        "pdf": "https://arxiv.org/pdf/2601.18698v1"
      },
      "arxiv_id": "2601.18698v1",
      "comment": "Work in progress",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18696v1",
      "title": "Explainability Methods for Hardware Trojan Detection: A Systematic Comparison",
      "authors": [
        "Paul Whitten",
        "Francis Wolff",
        "Chris Papachristou"
      ],
      "abstract": "Hardware trojan detection requires accurate identification and interpretable explanations for security engineers to validate and act on results. This work compares three explainability categories for gate-level trojan detection on the Trust-Hub benchmark: (1) domain-aware property-based analysis of 31 circuit-specific features from gate fanin patterns, flip-flop distances, and I/O connectivity; (2) case-based reasoning using k-nearest neighbors for precedent-based explanations; and (3) model-agnostic feature attribution (LIME, SHAP, gradient).\n  Results show different advantages per approach. Property-based analysis provides explanations through circuit concepts like \"high fanin complexity near outputs indicates potential triggers.\" Case-based reasoning achieves 97.4% correspondence between predictions and training exemplars, offering justifications grounded in precedent. LIME and SHAP provide feature attributions with strong inter-method correlation (r=0.94, p<0.001) but lack circuit-level context for validation.\n  XGBoost classification achieves 46.15% precision and 52.17% recall on 11,392 test samples, a 9-fold precision improvement over prior work (Hasegawa et al.: 5.13%) while reducing false positive rates from 5.6% to 0.25%. Gradient-based attribution runs 481 times faster than SHAP but provides similar domain-opaque insights.\n  This work demonstrates that property-based and case-based approaches offer domain alignment and precedent-based interpretability compared to generic feature rankings, with implications for XAI deployment where practitioners must validate ML predictions.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18696v1",
        "pdf": "https://arxiv.org/pdf/2601.18696v1"
      },
      "arxiv_id": "2601.18696v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18694v1",
      "title": "Neural Multi-Speaker Voice Cloning for Nepali in Low-Resource Settings",
      "authors": [
        "Aayush M. Shrestha",
        "Aditya Bajracharya",
        "Projan Shakya",
        "Dinesh B. Kshatri"
      ],
      "abstract": "This research presents a few-shot voice cloning system for Nepali speakers, designed to synthesize speech in a specific speaker's voice from Devanagari text using minimal data. Voice cloning in Nepali remains largely unexplored due to its low-resource nature. To address this, we constructed separate datasets: untranscribed audio for training a speaker encoder and paired text-audio data for training a Tacotron2-based synthesizer. The speaker encoder, optimized with Generative End2End loss, generates embeddings that capture the speaker's vocal identity, validated through Uniform Manifold Approximation and Projection (UMAP) for dimension reduction visualizations. These embeddings are fused with Tacotron2's text embeddings to produce mel-spectrograms, which are then converted into audio using a WaveRNN vocoder. Audio data were collected from various sources, including self-recordings, and underwent thorough preprocessing for quality and alignment. Training was performed using mel and gate loss functions under multiple hyperparameter settings. The system effectively clones speaker characteristics even for unseen voices, demonstrating the feasibility of few-shot voice cloning for the Nepali language and establishing a foundation for personalized speech synthesis in low-resource scenarios.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.SD",
        "cs.AI"
      ],
      "primary_category": "cs.SD",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18694v1",
        "pdf": "https://arxiv.org/pdf/2601.18694v1"
      },
      "arxiv_id": "2601.18694v1",
      "comment": "16 pages with appendix included",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18692v1",
      "title": "A Pragmatic VLA Foundation Model",
      "authors": [
        "Wei Wu",
        "Fan Lu",
        "Yunnan Wang",
        "Shuai Yang",
        "Shi Liu",
        "Fangjing Wang",
        "Qian Zhu",
        "He Sun",
        "Yong Wang",
        "Shuailei Ma",
        "Yiyu Ren",
        "Kejia Zhang",
        "Hui Yu",
        "Jingmei Zhao",
        "Shuai Zhou",
        "Zhenqi Qiu",
        "Houlong Xiong",
        "Ziyu Wang",
        "Zechen Wang",
        "Ran Cheng",
        "Yong-Lu Li",
        "Yongtao Huang",
        "Xing Zhu",
        "Yujun Shen",
        "Kecheng Zheng"
      ],
      "abstract": "Offering great potential in robotic manipulation, a capable Vision-Language-Action (VLA) foundation model is expected to faithfully generalize across tasks and platforms while ensuring cost efficiency (e.g., data and GPU hours required for adaptation). To this end, we develop LingBot-VLA with around 20,000 hours of real-world data from 9 popular dual-arm robot configurations. Through a systematic assessment on 3 robotic platforms, each completing 100 tasks with 130 post-training episodes per task, our model achieves clear superiority over competitors, showcasing its strong performance and broad generalizability. We have also built an efficient codebase, which delivers a throughput of 261 samples per second per GPU with an 8-GPU training setup, representing a 1.5~2.8$\\times$ (depending on the relied VLM base model) speedup over existing VLA-oriented codebases. The above features ensure that our model is well-suited for real-world deployment. To advance the field of robot learning, we provide open access to the code, base model, and benchmark data, with a focus on enabling more challenging tasks and promoting sound evaluation standards.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.RO",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18692v1",
        "pdf": "https://arxiv.org/pdf/2601.18692v1"
      },
      "arxiv_id": "2601.18692v1",
      "comment": "Project Webpage: https://technology.robbyant.com/lingbot-vla/, Code: https://github.com/Robbyant/lingbot-vla/",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2601.18685v1",
      "title": "LLAMA LIMA: A Living Meta-Analysis on the Effects of Generative AI on Learning Mathematics",
      "authors": [
        "Anselm Strohmaier",
        "Samira Bödefeld",
        "Frank Reinhold"
      ],
      "abstract": "The capabilities of generative AI in mathematics education are rapidly evolving, posing significant challenges for research to keep pace. Research syntheses remain scarce and risk being outdated by the time of publication. To address this issue, we present a Living Meta-Analysis (LIMA) on the effects of generative AI-based interventions for learning mathematics. Following PRISMA-LSR guidelines, we continuously update the literature base, apply a Bayesian multilevel meta-regression model to account for cumulative data, and publish updated versions on a preprint server at regular intervals. This paper reports results from the first version, including 15 studies. The analyses indicate a small positive effect (g = 0.31) with a wide credible interval [0.06, 0.58], reflecting the still limited evidence base.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "math.HO",
        "cs.LG"
      ],
      "primary_category": "math.HO",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18685v1",
        "pdf": "https://arxiv.org/pdf/2601.18685v1"
      },
      "arxiv_id": "2601.18685v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18683v1",
      "title": "Learned harmonic mean estimation of the marginal likelihood for multimodal posteriors with flow matching",
      "authors": [
        "Alicja Polanska",
        "Jason D. McEwen"
      ],
      "abstract": "The marginal likelihood, or Bayesian evidence, is a crucial quantity for Bayesian model comparison but its computation can be challenging for complex models, even in parameters space of moderate dimension. The learned harmonic mean estimator has been shown to provide accurate and robust estimates of the marginal likelihood simply using posterior samples. It is agnostic to the sampling strategy, meaning that the samples can be obtained using any method. This enables marginal likelihood calculation and model comparison with whatever sampling is most suitable for the task. However, the internal density estimators considered previously for the learned harmonic mean can struggle with highly multimodal posteriors. In this work we introduce flow matching-based continuous normalizing flows as a powerful architecture for the internal density estimation of the learned harmonic mean. We demonstrate the ability to handle challenging multimodal posteriors, including an example in 20 parameter dimensions, showcasing the method's ability to handle complex posteriors without the need for fine-tuning or heuristic modifications to the base distribution.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "stat.ME",
        "astro-ph.IM",
        "cs.LG"
      ],
      "primary_category": "stat.ME",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18683v1",
        "pdf": "https://arxiv.org/pdf/2601.18683v1"
      },
      "arxiv_id": "2601.18683v1",
      "comment": "Submitted to 44th International Workshop on Bayesian Inference and Maximum Entropy Methods in Science and Engineering",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18681v1",
      "title": "ART for Diffusion Sampling: A Reinforcement Learning Approach to Timestep Schedule",
      "authors": [
        "Yilie Huang",
        "Wenpin Tang",
        "Xunyu Zhou"
      ],
      "abstract": "We consider time discretization for score-based diffusion models to generate samples from a learned reverse-time dynamic on a finite grid. Uniform and hand-crafted grids can be suboptimal given a budget on the number of time steps. We introduce Adaptive Reparameterized Time (ART) that controls the clock speed of a reparameterized time variable, leading to a time change and uneven timesteps along the sampling trajectory while preserving the terminal time. The objective is to minimize the aggregate error arising from the discretized Euler scheme. We derive a randomized control companion, ART-RL, and formulate time change as a continuous-time reinforcement learning (RL) problem with Gaussian policies. We then prove that solving ART-RL recovers the optimal ART schedule, which in turn enables practical actor--critic updates to learn the latter in a data-driven way. Empirically, based on the official EDM pipeline, ART-RL improves Fréchet Inception Distance on CIFAR-10 over a wide range of budgets and transfers to AFHQv2, FFHQ, and ImageNet without the need of retraining.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SY",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18681v1",
        "pdf": "https://arxiv.org/pdf/2601.18681v1"
      },
      "arxiv_id": "2601.18681v1",
      "comment": "17 pages, 7 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18678v1",
      "title": "Counterfactual Explanations on Robust Perceptual Geodesics",
      "authors": [
        "Eslam Zaher",
        "Maciej Trzaskowski",
        "Quan Nguyen",
        "Fred Roosta"
      ],
      "abstract": "Latent-space optimization methods for counterfactual explanations - framed as minimal semantic perturbations that change model predictions - inherit the ambiguity of Wachter et al.'s objective: the choice of distance metric dictates whether perturbations are meaningful or adversarial. Existing approaches adopt flat or misaligned geometries, leading to off-manifold artifacts, semantic drift, or adversarial collapse. We introduce Perceptual Counterfactual Geodesics (PCG), a method that constructs counterfactuals by tracing geodesics under a perceptually Riemannian metric induced from robust vision features. This geometry aligns with human perception and penalizes brittle directions, enabling smooth, on-manifold, semantically valid transitions. Experiments on three vision datasets show that PCG outperforms baselines and reveals failure modes hidden under standard metrics.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.LG",
        "cs.CV",
        "cs.HC",
        "math.DG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18678v1",
        "pdf": "https://arxiv.org/pdf/2601.18678v1"
      },
      "arxiv_id": "2601.18678v1",
      "comment": "Accepted at ICLR 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18677v1",
      "title": "Out-of-Distribution Radar Detection with Complex VAEs: Theory, Whitening, and ANMF Fusion",
      "authors": [
        "Yadang Alexis Rouzoumka",
        "Jean Pinsolle",
        "Eugénie Terreaux",
        "Christèle Morisseau",
        "Jean-Philippe Ovarlez",
        "Chengfang Ren"
      ],
      "abstract": "We investigate the detection of weak complex-valued signals immersed in non-Gaussian, range-varying interference, with emphasis on maritime radar scenarios. The proposed methodology exploits a Complex-valued Variational AutoEncoder (CVAE) trained exclusively on clutter-plus-noise to perform Out-Of-Distribution detection. By operating directly on in-phase / quadrature samples, the CVAE preserves phase and Doppler structure and is assessed in two configurations: (i) using unprocessed range profiles and (ii) after local whitening, where per-range covariance estimates are obtained from neighboring profiles. Using extensive simulations together with real sea-clutter data from the CSIR maritime dataset, we benchmark performance against classical and adaptive detectors (MF, NMF, AMF-SCM, ANMF-SCM, ANMF-Tyler). In both configurations, the CVAE yields a higher detection probability Pd at matched false-alarm rate Pfa, with the most notable improvements observed under whitening. We further integrate the CVAE with the ANMF through a weighted log-p fusion rule at the decision level, attaining enhanced robustness in strongly non-Gaussian clutter and enabling empirically calibrated Pfa control under H0. Overall, the results demonstrate that statistical normalization combined with complex-valued generative modeling substantively improves detection in realistic sea-clutter conditions, and that the fused CVAE-ANMF scheme constitutes a competitive alternative to established model-based detectors.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18677v1",
        "pdf": "https://arxiv.org/pdf/2601.18677v1"
      },
      "arxiv_id": "2601.18677v1",
      "comment": "13 pages, 12 figures, submitted to IEEE Transactions on Signal Processing",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18676v1",
      "title": "Quasi Monte Carlo methods enable extremely low-dimensional deep generative models",
      "authors": [
        "Miles Martinez",
        "Alex H. Williams"
      ],
      "abstract": "This paper introduces quasi-Monte Carlo latent variable models (QLVMs): a class of deep generative models that are specialized for finding extremely low-dimensional and interpretable embeddings of high-dimensional datasets. Unlike standard approaches, which rely on a learned encoder and variational lower bounds, QLVMs directly approximate the marginal likelihood by randomized quasi-Monte Carlo integration. While this brute force approach has drawbacks in higher-dimensional spaces, we find that it excels in fitting one, two, and three dimensional deep latent variable models. Empirical results on a range of datasets show that QLVMs consistently outperform conventional variational autoencoders (VAEs) and importance weighted autoencoders (IWAEs) with matched latent dimensionality. The resulting embeddings enable transparent visualization and post hoc analyses such as nonparametric density estimation, clustering, and geodesic path computation, which are nontrivial to validate in higher-dimensional spaces. While our approach is compute-intensive and struggles to generate fine-scale details in complex datasets, it offers a compelling solution for applications prioritizing interpretability and latent space analysis.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18676v1",
        "pdf": "https://arxiv.org/pdf/2601.18676v1"
      },
      "arxiv_id": "2601.18676v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18675v1",
      "title": "Learning temporal embeddings from electronic health records of chronic kidney disease patients",
      "authors": [
        "Aditya Kumar",
        "Mario A. Cypko",
        "Oliver Amft"
      ],
      "abstract": "We investigate whether temporal embedding models trained on longitudinal electronic health records can learn clinically meaningful representations without compromising predictive performance, and how architectural choices affect embedding quality. Model-guided medicine requires representations that capture disease dynamics while remaining transparent and task agnostic, whereas most clinical prediction models are optimised for a single task. Representation learning facilitates learning embeddings that generalise across downstream tasks, and recurrent architectures are well-suited for modelling temporal structure in observational clinical data. Using the MIMIC-IV dataset, we study patients with chronic kidney disease (CKD) and compare three recurrent architectures: a vanilla LSTM, an attention-augmented LSTM, and a time-aware LSTM (T-LSTM). All models are trained both as embedding models and as direct end-to-end predictors. Embedding quality is evaluated via CKD stage clustering and in-ICU mortality prediction. The T-LSTM produces more structured embeddings, achieving a lower Davies-Bouldin Index (DBI = 9.91) and higher CKD stage classification accuracy (0.74) than the vanilla LSTM (DBI = 15.85, accuracy = 0.63) and attention-augmented LSTM (DBI = 20.72, accuracy = 0.67). For in-ICU mortality prediction, embedding models consistently outperform end-to-end predictors, improving accuracy from 0.72-0.75 to 0.82-0.83, which indicates that learning embeddings as an intermediate step is more effective than direct end-to-end learning.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18675v1",
        "pdf": "https://arxiv.org/pdf/2601.18675v1"
      },
      "arxiv_id": "2601.18675v1",
      "comment": "7 pages, 3 figures, 3 tables. The paper has been submitted to IEEE EMBC 2026 and copyright might be transferred without notice",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18672v1",
      "title": "A Dynamic Framework for Grid Adaptation in Kolmogorov-Arnold Networks",
      "authors": [
        "Spyros Rigas",
        "Thanasis Papaioannou",
        "Panagiotis Trakadas",
        "Georgios Alexandridis"
      ],
      "abstract": "Kolmogorov-Arnold Networks (KANs) have recently demonstrated promising potential in scientific machine learning, partly due to their capacity for grid adaptation during training. However, existing adaptation strategies rely solely on input data density, failing to account for the geometric complexity of the target function or metrics calculated during network training. In this work, we propose a generalized framework that treats knot allocation as a density estimation task governed by Importance Density Functions (IDFs), allowing training dynamics to determine grid resolution. We introduce a curvature-based adaptation strategy and evaluate it across synthetic function fitting, regression on a subset of the Feynman dataset and different instances of the Helmholtz PDE, demonstrating that it significantly outperforms the standard input-based baseline. Specifically, our method yields average relative error reductions of 25.3% on synthetic functions, 9.4% on the Feynman dataset, and 23.3% on the PDE benchmark. Statistical significance is confirmed via Wilcoxon signed-rank tests, establishing curvature-based adaptation as a robust and computationally efficient alternative for KAN training.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18672v1",
        "pdf": "https://arxiv.org/pdf/2601.18672v1"
      },
      "arxiv_id": "2601.18672v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18670v1",
      "title": "COMETS: Coordinated Multi-Destination Video Transmission with In-Network Rate Adaptation",
      "authors": [
        "Yulong Zhang",
        "Ying Cui",
        "Zili Meng",
        "Abhishek Kumar",
        "Dirk Kutscher"
      ],
      "abstract": "Large-scale video streaming events attract millions of simultaneous viewers, stressing existing delivery infrastructures. Client-driven adaptation reacts slowly to shared congestion, while server-based coordination introduces scalability bottlenecks and single points of failure. We present COMETS, a coordinated multi-destination video transmission framework that leverages information-centric networking principles such as request aggregation and in-network state awareness to enable scalable, fair, and adaptive rate control. COMETS introduces a novel range-interest protocol and distributed in-network decision process that aligns video quality across receiver groups while minimizing redundant transmissions. To achieve this, we develop a lightweight distributed optimization framework that guides per-hop quality adaptation without centralized control. Extensive emulation shows that COMETS consistently improves bandwidth utilization, fairness, and user-perceived quality of experience over DASH, MoQ, and ICN baselines, particularly under high concurrency. The results highlight COMETS as a practical, deployable approach for next-generation scalable video delivery.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.NI",
        "cs.MM",
        "eess.IV"
      ],
      "primary_category": "cs.NI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18670v1",
        "pdf": "https://arxiv.org/pdf/2601.18670v1"
      },
      "arxiv_id": "2601.18670v1",
      "comment": "Accepted to appear in IEEE Transactions on Multimedia (2026)",
      "journal_ref": "IEEE Transactions on Multimedia, 2026",
      "has_code": false
    },
    {
      "id": "2601.18663v1",
      "title": "Uniform Computability of PAC Learning",
      "authors": [
        "Vasco Brattka",
        "Guillaume Chirache"
      ],
      "abstract": "We study uniform computability properties of PAC learning using Weihrauch complexity. We focus on closed concept classes, which are either represented by positive, by negative or by full information. Among other results, we prove that proper PAC learning from positive information is equivalent to the limit operation on Baire space, whereas improper PAC learning from positive information is closely related to Weak Kőnig's Lemma and even equivalent to it, when we have some negative information about the admissible hypotheses. If arbitrary hypotheses are allowed, then improper PAC learning from positive information is still in a finitary DNC range, which implies that it is non-deterministically computable, but does not allow for probabilistic algorithms. These results can also be seen as a classification of the degree of constructivity of the Fundamental Theorem of Statistical Learning. All the aforementioned results hold if an upper bound of the VC dimension is provided as an additional input information. We also study the question of how these results are affected if the VC dimension is not given, but only promised to be finite or if concept classes are represented by negative or full information. Finally, we also classify the complexity of the VC dimension operation itself, which is a problem that is of independent interest. For positive or full information it turns out to be equivalent to the binary sorting problem, for negative information it is equivalent to the jump of sorting. This classification allows also conclusions regarding the Borel complexity of PAC learnability.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "math.LO",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "math.LO",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18663v1",
        "pdf": "https://arxiv.org/pdf/2601.18663v1"
      },
      "arxiv_id": "2601.18663v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18650v1",
      "title": "FaLW: A Forgetting-aware Loss Reweighting for Long-tailed Unlearning",
      "authors": [
        "Liheng Yu",
        "Zhe Zhao",
        "Yuxuan Wang",
        "Pengkun Wang",
        "Binwu Wang",
        "Yang Wang"
      ],
      "abstract": "Machine unlearning, which aims to efficiently remove the influence of specific data from trained models, is crucial for upholding data privacy regulations like the ``right to be forgotten\". However, existing research predominantly evaluates unlearning methods on relatively balanced forget sets. This overlooks a common real-world scenario where data to be forgotten, such as a user's activity records, follows a long-tailed distribution. Our work is the first to investigate this critical research gap. We find that in such long-tailed settings, existing methods suffer from two key issues: \\textit{Heterogeneous Unlearning Deviation} and \\textit{Skewed Unlearning Deviation}. To address these challenges, we propose FaLW, a plug-and-play, instance-wise dynamic loss reweighting method. FaLW innovatively assesses the unlearning state of each sample by comparing its predictive probability to the distribution of unseen data from the same class. Based on this, it uses a forgetting-aware reweighting scheme, modulated by a balancing factor, to adaptively adjust the unlearning intensity for each sample. Extensive experiments demonstrate that FaLW achieves superior performance. Code is available at \\textbf{Supplementary Material}.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18650v1",
        "pdf": "https://arxiv.org/pdf/2601.18650v1"
      },
      "arxiv_id": "2601.18650v1",
      "comment": "camera-ready for iclr2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18642v1",
      "title": "FadeMem: Biologically-Inspired Forgetting for Efficient Agent Memory",
      "authors": [
        "Lei Wei",
        "Xu Dong",
        "Xiao Peng",
        "Niantao Xie",
        "Bin Wang"
      ],
      "abstract": "Large language models deployed as autonomous agents face critical memory limitations, lacking selective forgetting mechanisms that lead to either catastrophic forgetting at context boundaries or information overload within them. While human memory naturally balances retention and forgetting through adaptive decay processes, current AI systems employ binary retention strategies that preserve everything or lose it entirely. We propose FadeMem, a biologically-inspired agent memory architecture that incorporates active forgetting mechanisms mirroring human cognitive efficiency. FadeMem implements differential decay rates across a dual-layer memory hierarchy, where retention is governed by adaptive exponential decay functions modulated by semantic relevance, access frequency, and temporal patterns. Through LLM-guided conflict resolution and intelligent memory fusion, our system consolidates related information while allowing irrelevant details to fade. Experiments on Multi-Session Chat, LoCoMo, and LTI-Bench demonstrate superior multi-hop reasoning and retrieval with 45\\% storage reduction, validating the effectiveness of biologically-inspired forgetting in agent memory systems.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18642v1",
        "pdf": "https://arxiv.org/pdf/2601.18642v1"
      },
      "arxiv_id": "2601.18642v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18641v1",
      "title": "Unheard in the Digital Age: Rethinking AI Bias and Speech Diversity",
      "authors": [
        "Onyedikachi Hope Amaechi-Okorie",
        "Branislav Radeljic"
      ],
      "abstract": "Speech remains one of the most visible yet overlooked vectors of inclusion and exclusion in contemporary society. While fluency is often equated with credibility and competence, individuals with atypical speech patterns are routinely marginalized. Given the current state of the debate, this article focuses on the structural biases that shape perceptions of atypical speech and are now being encoded into artificial intelligence. Automated speech recognition (ASR) systems and voice interfaces, trained predominantly on standardized speech, routinely fail to recognize or respond to diverse voices, compounding digital exclusion. As AI technologies increasingly mediate access to opportunity, the study calls for inclusive technological design, anti-bias training to minimize the impact of discriminatory algorithmic decisions, and enforceable policy reform that explicitly recognize speech diversity as a matter of equity, not merely accessibility. Drawing on interdisciplinary research, the article advocates for a cultural and institutional shift in how we value voice, urging co-created solutions that elevate the rights, representation, and realities of atypical speakers in the digital age. Ultimately, the article reframes speech inclusion as a matter of equity (not accommodation) and advocates for co-created AI systems that reflect the full spectrum of human voices.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18641v1",
        "pdf": "https://arxiv.org/pdf/2601.18641v1"
      },
      "arxiv_id": "2601.18641v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18640v1",
      "title": "TwinPurify: Purifying gene expression data to reveal tumor-intrinsic transcriptional programs via self-supervised learning",
      "authors": [
        "Zhiwei Zheng",
        "Kevin Bryson"
      ],
      "abstract": "Advances in single-cell and spatial transcriptomic technologies have transformed tumor ecosystem profiling at cellular resolution. However, large scale studies on patient cohorts continue to rely on bulk transcriptomic data, where variation in tumor purity obscures tumor-intrinsic transcriptional signals and constrains downstream discovery. Many deconvolution methods report strong performance on synthetic bulk mixtures but fail to generalize to real patient cohorts because of unmodeled biological and technical variation.\n  Here, we introduce TwinPurify, a representation learning framework that adapts the Barlow Twins self-supervised objective, representing a fundamental departure from the deconvolution paradigm. Rather than resolving the bulk mixture into discrete cell-type fractions, TwinPurify instead learns continuous, high-dimensional tumor embeddings by leveraging adjacent-normal profiles within the same cohort as \"background\" guidance, enabling the disentanglement of tumor-specific signals without relying on any external reference.\n  Benchmarked against multiple large cancer cohorts across RNA-seq and microarray platforms, TwinPurify outperforms conventional representation learning baselines like auto-encoders in recovering tumor-intrinsic and immune signals. The purified embeddings improve molecular subtype and grade classification, enhance survival model concordance, and uncover biologically meaningful pathway activities compared to raw bulk profiles. By providing a transferable framework for decontaminating bulk transcriptomics, TwinPurify extends the utility of existing clinical datasets for molecular discovery.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.LG",
        "q-bio.MN"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18640v1",
        "pdf": "https://arxiv.org/pdf/2601.18640v1"
      },
      "arxiv_id": "2601.18640v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18638v1",
      "title": "Physics-Informed Uncertainty Enables Reliable AI-driven Design",
      "authors": [
        "Tingkai Xue",
        "Chin Chun Ooi",
        "Yang Jiang",
        "Luu Trung Pham Duong",
        "Pao-Hsiung Chiu",
        "Weijiang Zhao",
        "Nagarajan Raghavan",
        "My Ha Dao"
      ],
      "abstract": "Inverse design is a central goal in much of science and engineering, including frequency-selective surfaces (FSS) that are critical to microelectronics for telecommunications and optical metamaterials. Traditional surrogate-assisted optimization methods using deep learning can accelerate the design process but do not usually incorporate uncertainty quantification, leading to poorer optimization performance due to erroneous predictions in data-sparse regions. Here, we introduce and validate a fundamentally different paradigm of Physics-Informed Uncertainty, where the degree to which a model's prediction violates fundamental physical laws serves as a computationally-cheap and effective proxy for predictive uncertainty. By integrating physics-informed uncertainty into a multi-fidelity uncertainty-aware optimization workflow to design complex frequency-selective surfaces within the 20 - 30 GHz range, we increase the success rate of finding performant solutions from less than 10% to over 50%, while simultaneously reducing computational cost by an order of magnitude compared to the sole use of a high-fidelity solver. These results highlight the necessity of incorporating uncertainty quantification in machine-learning-driven inverse design for high-dimensional problems, and establish physics-informed uncertainty as a viable alternative to quantifying uncertainty in surrogate models for physical systems, thereby setting the stage for autonomous scientific discovery systems that can efficiently and robustly explore and evaluate candidate designs.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.LG",
        "physics.comp-ph"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18638v1",
        "pdf": "https://arxiv.org/pdf/2601.18638v1"
      },
      "arxiv_id": "2601.18638v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18637v1",
      "title": "Universality of Many-body Projected Ensemble for Learning Quantum Data Distribution",
      "authors": [
        "Quoc Hoan Tran",
        "Koki Chinzei",
        "Yasuhiro Endo",
        "Hirotaka Oshima"
      ],
      "abstract": "Generating quantum data by learning the underlying quantum distribution poses challenges in both theoretical and practical scenarios, yet it is a critical task for understanding quantum systems. A fundamental question in quantum machine learning (QML) is the universality of approximation: whether a parameterized QML model can approximate any quantum distribution. We address this question by proving a universality theorem for the Many-body Projected Ensemble (MPE) framework, a method for quantum state design that uses a single many-body wave function to prepare random states. This demonstrates that MPE can approximate any distribution of pure states within a 1-Wasserstein distance error. This theorem provides a rigorous guarantee of universal expressivity, addressing key theoretical gaps in QML. For practicality, we propose an Incremental MPE variant with layer-wise training to improve the trainability. Numerical experiments on clustered quantum states and quantum chemistry datasets validate MPE's efficacy in learning complex quantum data distributions.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "quant-ph",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "quant-ph",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18637v1",
        "pdf": "https://arxiv.org/pdf/2601.18637v1"
      },
      "arxiv_id": "2601.18637v1",
      "comment": "21 pages, 6 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18633v1",
      "title": "Splat-Portrait: Generalizing Talking Heads with Gaussian Splatting",
      "authors": [
        "Tong Shi",
        "Melonie de Almeida",
        "Daniela Ivanova",
        "Nicolas Pugeault",
        "Paul Henderson"
      ],
      "abstract": "Talking Head Generation aims at synthesizing natural-looking talking videos from speech and a single portrait image. Previous 3D talking head generation methods have relied on domain-specific heuristics such as warping-based facial motion representation priors to animate talking motions, yet still produce inaccurate 3D avatar reconstructions, thus undermining the realism of generated animations. We introduce Splat-Portrait, a Gaussian-splatting-based method that addresses the challenges of 3D head reconstruction and lip motion synthesis. Our approach automatically learns to disentangle a single portrait image into a static 3D reconstruction represented as static Gaussian Splatting, and a predicted whole-image 2D background. It then generates natural lip motion conditioned on input audio, without any motion driven priors. Training is driven purely by 2D reconstruction and score-distillation losses, without 3D supervision nor landmarks. Experimental results demonstrate that Splat-Portrait exhibits superior performance on talking head generation and novel view synthesis, achieving better visual quality compared to previous works. Our project code and supplementary documents are public available at https://github.com/stonewalking/Splat-portrait.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18633v1",
        "pdf": "https://arxiv.org/pdf/2601.18633v1"
      },
      "arxiv_id": "2601.18633v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18631v1",
      "title": "AdaReasoner: Dynamic Tool Orchestration for Iterative Visual Reasoning",
      "authors": [
        "Mingyang Song",
        "Haoyu Sun",
        "Jiawei Gu",
        "Linjie Li",
        "Luxin Xu",
        "Ranjay Krishna",
        "Yu Cheng"
      ],
      "abstract": "When humans face problems beyond their immediate capabilities, they rely on tools, providing a promising paradigm for improving visual reasoning in multimodal large language models (MLLMs). Effective reasoning, therefore, hinges on knowing which tools to use, when to invoke them, and how to compose them over multiple steps, even when faced with new tools or new tasks. We introduce \\textbf{AdaReasoner}, a family of multimodal models that learn tool use as a general reasoning skill rather than as tool-specific or explicitly supervised behavior. AdaReasoner is enabled by (i) a scalable data curation pipeline exposing models to long-horizon, multi-step tool interactions; (ii) Tool-GRPO, a reinforcement learning algorithm that optimizes tool selection and sequencing based on end-task success; and (iii) an adaptive learning mechanism that dynamically regulates tool usage. Together, these components allow models to infer tool utility from task context and intermediate outcomes, enabling coordination of multiple tools and generalization to unseen tools. Empirically, AdaReasoner exhibits strong tool-adaptive and generalization behaviors: it autonomously adopts beneficial tools, suppresses irrelevant ones, and adjusts tool usage frequency based on task demands, despite never being explicitly trained to do so. These capabilities translate into state-of-the-art performance across challenging benchmarks, improving the 7B base model by +24.9\\% on average and surpassing strong proprietary systems such as GPT-5 on multiple tasks, including VSP and Jigsaw.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18631v1",
        "pdf": "https://arxiv.org/pdf/2601.18631v1"
      },
      "arxiv_id": "2601.18631v1",
      "comment": "28 pages, 10 figures and 13 tables",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18630v1",
      "title": "Assessing the Quality of Mental Health Support in LLM Responses through Multi-Attribute Human Evaluation",
      "authors": [
        "Abeer Badawi",
        "Md Tahmid Rahman Laskar",
        "Elahe Rahimi",
        "Sheri Grach",
        "Lindsay Bertrand",
        "Lames Danok",
        "Frank Rudzicz",
        "Jimmy Huang",
        "Elham Dolatabadi"
      ],
      "abstract": "The escalating global mental health crisis, marked by persistent treatment gaps, availability, and a shortage of qualified therapists, positions Large Language Models (LLMs) as a promising avenue for scalable support. While LLMs offer potential for accessible emotional assistance, their reliability, therapeutic relevance, and alignment with human standards remain challenging to address. This paper introduces a human-grounded evaluation methodology designed to assess LLM generated responses in therapeutic dialogue. Our approach involved curating a dataset of 500 mental health conversations from datasets with real-world scenario questions and evaluating the responses generated by nine diverse LLMs, including closed source and open source models. More specifically, these responses were evaluated by two psychiatric trained experts, who independently rated each on a 5 point Likert scale across a comprehensive 6 attribute rubric. This rubric captures Cognitive Support and Affective Resonance, providing a multidimensional perspective on therapeutic quality. Our analysis reveals that LLMs provide strong cognitive reliability by producing safe, coherent, and clinically appropriate information, but they demonstrate unstable affective alignment. Although closed source models (e.g., GPT-4o) offer balanced therapeutic responses, open source models show greater variability and emotional flatness. We reveal a persistent cognitive-affective gap and highlight the need for failure aware, clinically grounded evaluation frameworks that prioritize relational sensitivity alongside informational accuracy in mental health oriented LLMs. We advocate for balanced evaluation protocols with human in the loop that center on therapeutic sensitivity and provide a framework to guide the responsible design and clinical oversight of mental health oriented conversational AI.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18630v1",
        "pdf": "https://arxiv.org/pdf/2601.18630v1"
      },
      "arxiv_id": "2601.18630v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18626v1",
      "title": "Rank-1 Approximation of Inverse Fisher for Natural Policy Gradients in Deep Reinforcement Learning",
      "authors": [
        "Yingxiao Huo",
        "Satya Prakash Dash",
        "Radu Stoican",
        "Samuel Kaski",
        "Mingfei Sun"
      ],
      "abstract": "Natural gradients have long been studied in deep reinforcement learning due to their fast convergence properties and covariant weight updates. However, computing natural gradients requires inversion of the Fisher Information Matrix (FIM) at each iteration, which is computationally prohibitive in nature. In this paper, we present an efficient and scalable natural policy optimization technique that leverages a rank-1 approximation to full inverse-FIM. We theoretically show that under certain conditions, a rank-1 approximation to inverse-FIM converges faster than policy gradients and, under some conditions, enjoys the same sample complexity as stochastic policy gradient methods. We benchmark our method on a diverse set of environments and show that it achieves superior performance to standard actor-critic and trust-region baselines.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18626v1",
        "pdf": "https://arxiv.org/pdf/2601.18626v1"
      },
      "arxiv_id": "2601.18626v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18625v1",
      "title": "CONQUER: Context-Aware Representation with Query Enhancement for Text-Based Person Search",
      "authors": [
        "Zequn Xie"
      ],
      "abstract": "Text-Based Person Search (TBPS) aims to retrieve pedestrian images from large galleries using natural language descriptions. This task, essential for public safety applications, is hindered by cross-modal discrepancies and ambiguous user queries. We introduce CONQUER, a two-stage framework designed to address these challenges by enhancing cross-modal alignment during training and adaptively refining queries at inference. During training, CONQUER employs multi-granularity encoding, complementary pair mining, and context-guided optimal matching based on Optimal Transport to learn robust embeddings. At inference, a plug-and-play query enhancement module refines vague or incomplete queries via anchor selection and attribute-driven enrichment, without requiring retraining of the backbone. Extensive experiments on CUHK-PEDES, ICFG-PEDES, and RSTPReid demonstrate that CONQUER consistently outperforms strong baselines in both Rank-1 accuracy and mAP, yielding notable improvements in cross-domain and incomplete-query scenarios. These results highlight CONQUER as a practical and effective solution for real-world TBPS deployment. Source code is available at https://github.com/zqxie77/CONQUER.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18625v1",
        "pdf": "https://arxiv.org/pdf/2601.18625v1"
      },
      "arxiv_id": "2601.18625v1",
      "comment": "Accepted by ICASSP 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18623v1",
      "title": "Adaptive Domain Shift in Diffusion Models for Cross-Modality Image Translation",
      "authors": [
        "Zihao Wang",
        "Yuzhou Chen",
        "Shaogang Ren"
      ],
      "abstract": "Cross-modal image translation remains brittle and inefficient. Standard diffusion approaches often rely on a single, global linear transfer between domains. We find that this shortcut forces the sampler to traverse off-manifold, high-cost regions, inflating the correction burden and inviting semantic drift. We refer to this shared failure mode as fixed-schedule domain transfer. In this paper, we embed domain-shift dynamics directly into the generative process. Our model predicts a spatially varying mixing field at every reverse step and injects an explicit, target-consistent restoration term into the drift. This in-step guidance keeps large updates on-manifold and shifts the model's role from global alignment to local residual correction. We provide a continuous-time formulation with an exact solution form and derive a practical first-order sampler that preserves marginal consistency. Empirically, across translation tasks in medical imaging, remote sensing, and electroluminescence semantic mapping, our framework improves structural fidelity and semantic consistency while converging in fewer denoising steps.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18623v1",
        "pdf": "https://arxiv.org/pdf/2601.18623v1"
      },
      "arxiv_id": "2601.18623v1",
      "comment": "Paper accepted as a conference paper at ICLR 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18620v1",
      "title": "CASSANDRA: Programmatic and Probabilistic Learning and Inference for Stochastic World Modeling",
      "authors": [
        "Panagiotis Lymperopoulos",
        "Abhiramon Rajasekharan",
        "Ian Berlot-Attwell",
        "Stéphane Aroca-Ouellette",
        "Kaheer Suleman"
      ],
      "abstract": "Building world models is essential for planning in real-world domains such as businesses. Since such domains have rich semantics, we can leverage world knowledge to effectively model complex action effects and causal relationships from limited data. In this work, we propose CASSANDRA, a neurosymbolic world modeling approach that leverages an LLM as a knowledge prior to construct lightweight transition models for planning. CASSANDRA integrates two components: (1) LLM-synthesized code to model deterministic features, and (2) LLM-guided structure learning of a probabilistic graphical model to capture causal relationships among stochastic variables. We evaluate CASSANDRA in (i) a small-scale coffee-shop simulator and (ii) a complex theme park business simulator, where we demonstrate significant improvements in transition prediction and planning over baselines.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18620v1",
        "pdf": "https://arxiv.org/pdf/2601.18620v1"
      },
      "arxiv_id": "2601.18620v1",
      "comment": "28 pages, 2 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18619v1",
      "title": "Scale-Aware Self-Supervised Learning for Segmentation of Small and Sparse Structures",
      "authors": [
        "Jorge Quesada",
        "Ghassan AlRegib"
      ],
      "abstract": "Self-supervised learning (SSL) has emerged as a powerful strategy for representation learning under limited annotation regimes, yet its effectiveness remains highly sensitive to many factors, especially the nature of the target task. In segmentation, existing pipelines are typically tuned to large, homogeneous regions, but their performance drops when objects are small, sparse, or locally irregular. In this work, we propose a scale-aware SSL adaptation that integrates small-window cropping into the augmentation pipeline, zooming in on fine-scale structures during pretraining. We evaluate this approach across two domains with markedly different data modalities: seismic imaging, where the goal is to segment sparse faults, and neuroimaging, where the task is to delineate small cellular structures. In both settings, our method yields consistent improvements over standard and state-of-the-art baselines under label constraints, improving accuracy by up to 13% for fault segmentation and 5% for cell delineation. In contrast, large-scale features such as seismic facies or tissue regions see little benefit, underscoring that the value of SSL depends critically on the scale of the target objects. Our findings highlight the need to align SSL design with object size and sparsity, offering a general principle for buil ding more effective representation learning pipelines across scientific imaging domains.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18619v1",
        "pdf": "https://arxiv.org/pdf/2601.18619v1"
      },
      "arxiv_id": "2601.18619v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18617v1",
      "title": "Emergence of Phonemic, Syntactic, and Semantic Representations in Artificial Neural Networks",
      "authors": [
        "Pierre Orhan",
        "Pablo Diego-Simón",
        "Emmnanuel Chemla",
        "Yair Lakretz",
        "Yves Boubenec",
        "Jean-Rémi King"
      ],
      "abstract": "During language acquisition, children successively learn to categorize phonemes, identify words, and combine them with syntax to form new meaning. While the development of this behavior is well characterized, we still lack a unifying computational framework to explain its underlying neural representations. Here, we investigate whether and when phonemic, lexical, and syntactic representations emerge in the activations of artificial neural networks during their training. Our results show that both speech- and text-based models follow a sequence of learning stages: during training, their neural activations successively build subspaces, where the geometry of the neural activations represents phonemic, lexical, and syntactic structure. While this developmental trajectory qualitatively relates to children's, it is quantitatively different: These algorithms indeed require two to four orders of magnitude more data for these neural representations to emerge. Together, these results show conditions under which major stages of language acquisition spontaneously emerge, and hence delineate a promising path to understand the computations underpinning language acquisition.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18617v1",
        "pdf": "https://arxiv.org/pdf/2601.18617v1"
      },
      "arxiv_id": "2601.18617v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18615v1",
      "title": "Geometry-Free Conditional Diffusion Modeling for Solving the Inverse Electrocardiography Problem",
      "authors": [
        "Ramiro Valdes Jara",
        "Adam Meyers"
      ],
      "abstract": "This paper proposes a data-driven model for solving the inverse problem of electrocardiography, the mathematical problem that forms the basis of electrocardiographic imaging (ECGI). We present a conditional diffusion framework that learns a probabilistic mapping from noisy body surface signals to heart surface electric potentials. The proposed approach leverages the generative nature of diffusion models to capture the non-unique and underdetermined nature of the ECGI inverse problem, enabling probabilistic sampling of multiple reconstructions rather than a single deterministic estimate. Unlike traditional methods, the proposed framework is geometry-free and purely data-driven, alleviating the need for patient-specific mesh construction. We evaluate the method on a real ECGI dataset and compare it against strong deterministic baselines, including a convolutional neural network, long short-term memory network, and transformer-based model. The results demonstrate that the proposed diffusion approach achieves improved reconstruction accuracy, highlighting the potential of diffusion models as a robust tool for noninvasive cardiac electrophysiology imaging.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18615v1",
        "pdf": "https://arxiv.org/pdf/2601.18615v1"
      },
      "arxiv_id": "2601.18615v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18612v1",
      "title": "Multimodal Privacy-Preserving Entity Resolution with Fully Homomorphic Encryption",
      "authors": [
        "Susim Roy",
        "Nalini Ratha"
      ],
      "abstract": "The canonical challenge of entity resolution within high-compliance sectors, where secure identity reconciliation is frequently confounded by significant data heterogeneity, including syntactic variations in personal identifiers, is a longstanding and complex problem. To this end, we introduce a novel multimodal framework operating with the voluminous data sets typical of government and financial institutions. Specifically, our methodology is designed to address the tripartite challenge of data volume, matching fidelity, and privacy. Consequently, the underlying plaintext of personally identifiable information remains computationally inaccessible throughout the matching lifecycle, empowering institutions to rigorously satisfy stringent regulatory mandates with cryptographic assurances of client confidentiality while achieving a demonstrably low equal error rate and maintaining computational tractability at scale.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.CR",
        "cs.CV"
      ],
      "primary_category": "cs.CR",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18612v1",
        "pdf": "https://arxiv.org/pdf/2601.18612v1"
      },
      "arxiv_id": "2601.18612v1",
      "comment": "5 pages, 3 figures, IEEE ICASSP'26",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18608v1",
      "title": "PolySHAP: Extending KernelSHAP with Interaction-Informed Polynomial Regression",
      "authors": [
        "Fabian Fumagalli",
        "R. Teal Witter",
        "Christopher Musco"
      ],
      "abstract": "Shapley values have emerged as a central game-theoretic tool in explainable AI (XAI). However, computing Shapley values exactly requires $2^d$ game evaluations for a model with $d$ features. Lundberg and Lee's KernelSHAP algorithm has emerged as a leading method for avoiding this exponential cost. KernelSHAP approximates Shapley values by approximating the game as a linear function, which is fit using a small number of game evaluations for random feature subsets.\n  In this work, we extend KernelSHAP by approximating the game via higher degree polynomials, which capture non-linear interactions between features. Our resulting PolySHAP method yields empirically better Shapley value estimates for various benchmark datasets, and we prove that these estimates are consistent.\n  Moreover, we connect our approach to paired sampling (antithetic sampling), a ubiquitous modification to KernelSHAP that improves empirical accuracy. We prove that paired sampling outputs exactly the same Shapley value approximations as second-order PolySHAP, without ever fitting a degree 2 polynomial. To the best of our knowledge, this finding provides the first strong theoretical justification for the excellent practical performance of the paired sampling heuristic.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18608v1",
        "pdf": "https://arxiv.org/pdf/2601.18608v1"
      },
      "arxiv_id": "2601.18608v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18604v1",
      "title": "LaCoGSEA: Unsupervised deep learning for pathway analysis via latent correlation",
      "authors": [
        "Zhiwei Zheng",
        "Kevin Bryson"
      ],
      "abstract": "Motivation: Pathway enrichment analysis is widely used to interpret gene expression data. Standard approaches, such as GSEA, rely on predefined phenotypic labels and pairwise comparisons, which limits their applicability in unsupervised settings. Existing unsupervised extensions, including single-sample methods, provide pathway-level summaries but primarily capture linear relationships and do not explicitly model gene-pathway associations. More recently, deep learning models have been explored to capture non-linear transcriptomic structure. However, their interpretation has typically relied on generic explainable AI (XAI) techniques designed for feature-level attribution. As these methods are not designed for pathway-level interpretation in unsupervised transcriptomic analyses, their effectiveness in this setting remains limited.\n  Results: To bridge this gap, we introduce LaCoGSEA (Latent Correlation GSEA), an unsupervised framework that integrates deep representation learning with robust pathway statistics. LaCoGSEA employs an autoencoder to capture non-linear manifolds and proposes a global gene-latent correlation metric as a proxy for differential expression, generating dense gene rankings without prior labels. We demonstrate that LaCoGSEA offers three key advantages: (i) it achieves improved clustering performance in distinguishing cancer subtypes compared to existing unsupervised baselines; (ii) it recovers a broader range of biologically meaningful pathways at higher ranks compared with linear dimensionality reduction and gradient-based XAI methods; and (iii) it maintains high robustness and consistency across varying experimental protocols and dataset sizes. Overall, LaCoGSEA provides state-of-the-art performance in unsupervised pathway enrichment analysis.\n  Availability and implementation: https://github.com/willyzzz/LaCoGSEA",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.LG",
        "q-bio.GN"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18604v1",
        "pdf": "https://arxiv.org/pdf/2601.18604v1"
      },
      "arxiv_id": "2601.18604v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18597v1",
      "title": "EFSI-DETR: Efficient Frequency-Semantic Integration for Real-Time Small Object Detection in UAV Imagery",
      "authors": [
        "Yu Xia",
        "Chang Liu",
        "Tianqi Xiang",
        "Zhigang Tu"
      ],
      "abstract": "Real-time small object detection in Unmanned Aerial Vehicle (UAV) imagery remains challenging due to limited feature representation and ineffective multi-scale fusion. Existing methods underutilize frequency information and rely on static convolutional operations, which constrain the capacity to obtain rich feature representations and hinder the effective exploitation of deep semantic features. To address these issues, we propose EFSI-DETR, a novel detection framework that integrates efficient semantic feature enhancement with dynamic frequency-spatial guidance. EFSI-DETR comprises two main components: (1) a Dynamic Frequency-Spatial Unified Synergy Network (DyFusNet) that jointly exploits frequency and spatial cues for robust multi-scale feature fusion, (2) an Efficient Semantic Feature Concentrator (ESFC) that enables deep semantic extraction with minimal computational cost. Furthermore, a Fine-grained Feature Retention (FFR) strategy is adopted to incorporate spatially rich shallow features during fusion to preserve fine-grained details, crucial for small object detection in UAV imagery. Extensive experiments on VisDrone and CODrone benchmarks demonstrate that our EFSI-DETR achieves the state-of-the-art performance with real-time efficiency, yielding improvement of \\textbf{1.6}\\% and \\textbf{5.8}\\% in AP and AP$_{s}$ on VisDrone, while obtaining \\textbf{188} FPS inference speed on a single RTX 4090 GPU.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18597v1",
        "pdf": "https://arxiv.org/pdf/2601.18597v1"
      },
      "arxiv_id": "2601.18597v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18595v1",
      "title": "A Balanced Neuro-Symbolic Approach for Commonsense Abductive Logic",
      "authors": [
        "Joseph Cotnareanu",
        "Didier Chetelat",
        "Yingxue Zhang",
        "Mark Coates"
      ],
      "abstract": "Although Large Language Models (LLMs) have demonstrated impressive formal reasoning abilities, they often break down when problems require complex proof planning. One promising approach for improving LLM reasoning abilities involves translating problems into formal logic and using a logic solver. Although off-the-shelf logic solvers are in principle substantially more efficient than LLMs at logical reasoning, they assume that all relevant facts are provided in a question and are unable to deal with missing commonsense relations. In this work, we propose a novel method that uses feedback from the logic solver to augment a logic problem with commonsense relations provided by the LLM, in an iterative manner. This involves a search procedure through potential commonsense assumptions to maximize the chance of finding useful facts while keeping cost tractable. On a collection of pure-logical reasoning datasets, from which some commonsense information has been removed, our method consistently achieves considerable improvements over existing techniques, demonstrating the value in balancing neural and symbolic elements when working in human contexts.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18595v1",
        "pdf": "https://arxiv.org/pdf/2601.18595v1"
      },
      "arxiv_id": "2601.18595v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18589v1",
      "title": "AGSP-DSA: An Adaptive Graph Signal Processing Framework for Robust Multimodal Fusion with Dynamic Semantic Alignment",
      "authors": [
        "KV Karthikeya",
        "Ashok Kumar Das",
        "Shantanu Pal",
        "Vivekananda Bhat K",
        "Arun Sekar Rajasekaran"
      ],
      "abstract": "In this paper, we introduce an Adaptive Graph Signal Processing with Dynamic Semantic Alignment (AGSP DSA) framework to perform robust multimodal data fusion over heterogeneous sources, including text, audio, and images. The requested approach uses a dual-graph construction to learn both intra-modal and inter-modal relations, spectral graph filtering to boost the informative signals, and effective node embedding with Multi-scale Graph Convolutional Networks (GCNs). Semantic aware attention mechanism: each modality may dynamically contribute to the context with respect to contextual relevance. The experimental outcomes on three benchmark datasets, including CMU-MOSEI, AVE, and MM-IMDB, show that AGSP-DSA performs as the state of the art. More precisely, it achieves 95.3% accuracy, 0.936 F1-score, and 0.924 mAP on CMU-MOSEI, improving MM-GNN by 2.6 percent in accuracy. It gets 93.4% accuracy and 0.911 F1-score on AVE and 91.8% accuracy and 0.886 F1-score on MM-IMDB, which demonstrate good generalization and robustness in the missing modality setting. These findings verify the efficiency of AGSP-DSA in promoting multimodal learning in sentiment analysis, event recognition and multimedia classification.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18589v1",
        "pdf": "https://arxiv.org/pdf/2601.18589v1"
      },
      "arxiv_id": "2601.18589v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18588v1",
      "title": "Stability as a Liability:Systematic Breakdown of Linguistic Structure in LLMs",
      "authors": [
        "Xianzhe Meng",
        "Qiangsheng Zeng",
        "Ling Luo",
        "Qinghan Yang",
        "Jiarui Hao",
        "Wenbo Wu",
        "Qinyu Wang",
        "Rui Yin",
        "Lin Qi",
        "Renzhi Lu"
      ],
      "abstract": "Training stability is typically regarded as a prerequisite for reliable optimization in large language models. In this work, we analyze how stabilizing training dynamics affects the induced generation distribution. We show that under standard maximum likelihood training, stable parameter trajectories lead stationary solutions to approximately minimize the forward KL divergence to the empirical distribution, while implicitly reducing generative entropy. As a consequence, the learned model can concentrate probability mass on a limited subset of empirical modes, exhibiting systematic degeneration despite smooth loss convergence. We empirically validate this effect using a controlled feedback-based training framework that stabilizes internal generation statistics, observing consistent low-entropy outputs and repetitive behavior across architectures and random seeds. It indicates that optimization stability and generative expressivity are not inherently aligned, and that stability alone is an insufficient indicator of generative quality.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18588v1",
        "pdf": "https://arxiv.org/pdf/2601.18588v1"
      },
      "arxiv_id": "2601.18588v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18586v1",
      "title": "Learning long term climate-resilient transport adaptation pathways under direct and indirect flood impacts using reinforcement learning",
      "authors": [
        "Miguel Costa",
        "Arthur Vandervoort",
        "Carolin Schmidt",
        "Morten W. Petersen",
        "Martin Drews",
        "Karyn Morrissey",
        "Francisco C. Pereira"
      ],
      "abstract": "Climate change is expected to intensify rainfall and other hazards, increasing disruptions in urban transportation systems. Designing effective adaptation strategies is challenging due to the long-term, sequential nature of infrastructure investments, deep uncertainty, and complex cross-sector interactions. We propose a generic decision-support framework that couples an integrated assessment model (IAM) with reinforcement learning (RL) to learn adaptive, multi-decade investment pathways under uncertainty. The framework combines long-term climate projections (e.g., IPCC scenario pathways) with models that map projected extreme-weather drivers (e.g. rain) into hazard likelihoods (e.g. flooding), propagate hazards into urban infrastructure impacts (e.g. transport disruption), and value direct and indirect consequences for service performance and societal costs. Embedded in a reinforcement-learning loop, it learns adaptive climate adaptation policies that trade off investment and maintenance expenditures against avoided impacts. In collaboration with Copenhagen Municipality, we demonstrate the approach on pluvial flooding in the inner city for the horizon of 2024 to 2100. The learned strategies yield coordinated spatial-temporal pathways and improved robustness relative to conventional optimization baselines, namely inaction and random action, illustrating the framework's transferability to other hazards and cities.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18586v1",
        "pdf": "https://arxiv.org/pdf/2601.18586v1"
      },
      "arxiv_id": "2601.18586v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18585v1",
      "title": "GimmBO: Interactive Generative Image Model Merging via Bayesian Optimization",
      "authors": [
        "Chenxi Liu",
        "Selena Ling",
        "Alec Jacobson"
      ],
      "abstract": "Fine-tuning-based adaptation is widely used to customize diffusion-based image generation, leading to large collections of community-created adapters that capture diverse subjects and styles. Adapters derived from the same base model can be merged with weights, enabling the synthesis of new visual results within a vast and continuous design space. To explore this space, current workflows rely on manual slider-based tuning, an approach that scales poorly and makes weight selection difficult, even when the candidate set is limited to 20-30 adapters. We propose GimmBO to support interactive exploration of adapter merging for image generation through Preferential Bayesian Optimization (PBO). Motivated by observations from real-world usage, including sparsity and constrained weight ranges, we introduce a two-stage BO backend that improves sampling efficiency and convergence in high-dimensional spaces. We evaluate our approach with simulated users and a user study, demonstrating improved convergence, high success rates, and consistent gains over BO and line-search baselines, and further show the flexibility of the framework through several extensions.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.CV",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18585v1",
        "pdf": "https://arxiv.org/pdf/2601.18585v1"
      },
      "arxiv_id": "2601.18585v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18583v1",
      "title": "Uncooled Poisson Bolometer for High-Speed Event-Based Long-wave Thermal Imaging",
      "authors": [
        "Mohamed A. Mousa",
        "Leif Bauer",
        "Utkarsh Singh",
        "Ziyi Yang",
        "Angshuman Deka",
        "Zubin Jacob"
      ],
      "abstract": "Event-based vision provides high-speed, energy-efficient sensing for applications such as autonomous navigation and motion tracking. However, implementing this technology in the long-wave infrared remains a significant challenge. Traditional infrared sensors are hindered by slow thermal response times or the heavy power requirements of cryogenic cooling. Here, we introduce the first event-based infrared detector operating in a Poisson-counting regime. This is realized with a spintronic Poisson bolometer capable of broadband detection from 0.8-14$μ\\text{m}$. In this regime, infrared signals are detected through statistically resolvable changes in stochastic switching events. This approach enables room-temperature operation with high timing resolution. Our device achieves a maximum event rate of 1,250 Hz, surpassing the temporal resolution of conventional uncooled microbolometers by a factor of 4. Power consumption is kept low at 0.2$μ$W per pixel. This work establishes an operating principle for infrared sensing and demonstrates a pathway toward high-speed, energy-efficient, event-driven thermal imaging.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "physics.optics",
        "eess.IV",
        "physics.app-ph"
      ],
      "primary_category": "physics.optics",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18583v1",
        "pdf": "https://arxiv.org/pdf/2601.18583v1"
      },
      "arxiv_id": "2601.18583v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18580v1",
      "title": "K-Myriad: Jump-starting reinforcement learning with unsupervised parallel agents",
      "authors": [
        "Vincenzo De Paola",
        "Mirco Mutti",
        "Riccardo Zamboni",
        "Marcello Restelli"
      ],
      "abstract": "Parallelization in Reinforcement Learning is typically employed to speed up the training of a single policy, where multiple workers collect experience from an identical sampling distribution. This common design limits the potential of parallelization by neglecting the advantages of diverse exploration strategies. We propose K-Myriad, a scalable and unsupervised method that maximizes the collective state entropy induced by a population of parallel policies. By cultivating a portfolio of specialized exploration strategies, K-Myriad provides a robust initialization for Reinforcement Learning, leading to both higher training efficiency and the discovery of heterogeneous solutions. Experiments on high-dimensional continuous control tasks, with large-scale parallelization, demonstrate that K-Myriad can learn a broad set of distinct policies, highlighting its effectiveness for collective exploration and paving the way towards novel parallelization strategies.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18580v1",
        "pdf": "https://arxiv.org/pdf/2601.18580v1"
      },
      "arxiv_id": "2601.18580v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18579v1",
      "title": "FastInsight: Fast and Insightful Retrieval via Fusion Operators for Graph RAG",
      "authors": [
        "Seonho An",
        "Chaejeong Hyun",
        "Min-Soo Kim"
      ],
      "abstract": "Existing Graph RAG methods aiming for insightful retrieval on corpus graphs typically rely on time-intensive processes that interleave Large Language Model (LLM) reasoning. To enable time-efficient insightful retrieval, we propose FastInsight. We first introduce a graph retrieval taxonomy that categorizes existing methods into three fundamental operations: vector search, graph search, and model-based search. Through this taxonomy, we identify two critical limitations in current approaches: the topology-blindness of model-based search and the semantics-blindness of graph search. FastInsight overcomes these limitations by interleaving two novel fusion operators: the Graph-based Reranker (GRanker), which functions as a graph model-based search, and Semantic-Topological eXpansion (STeX), which operates as a vector-graph search. Extensive experiments on broad retrieval and generation datasets demonstrate that FastInsight significantly improves both retrieval accuracy and generation quality compared to state-of-the-art baselines, achieving a substantial Pareto improvement in the trade-off between effectiveness and efficiency.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18579v1",
        "pdf": "https://arxiv.org/pdf/2601.18579v1"
      },
      "arxiv_id": "2601.18579v1",
      "comment": "under review",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18577v1",
      "title": "Self-Refining Video Sampling",
      "authors": [
        "Sangwon Jang",
        "Taekyung Ki",
        "Jaehyeong Jo",
        "Saining Xie",
        "Jaehong Yoon",
        "Sung Ju Hwang"
      ],
      "abstract": "Modern video generators still struggle with complex physical dynamics, often falling short of physical realism. Existing approaches address this using external verifiers or additional training on augmented data, which is computationally expensive and still limited in capturing fine-grained motion. In this work, we present self-refining video sampling, a simple method that uses a pre-trained video generator trained on large-scale datasets as its own self-refiner. By interpreting the generator as a denoising autoencoder, we enable iterative inner-loop refinement at inference time without any external verifier or additional training. We further introduce an uncertainty-aware refinement strategy that selectively refines regions based on self-consistency, which prevents artifacts caused by over-refinement. Experiments on state-of-the-art video generators demonstrate significant improvements in motion coherence and physics alignment, achieving over 70\\% human preference compared to the default sampler and guidance-based sampler.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18577v1",
        "pdf": "https://arxiv.org/pdf/2601.18577v1"
      },
      "arxiv_id": "2601.18577v1",
      "comment": "Project page: https://agwmon.github.io/self-refine-video/",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2601.18569v1",
      "title": "Attention-Based Neural-Augmented Kalman Filter for Legged Robot State Estimation",
      "authors": [
        "Seokju Lee",
        "Kyung-Soo Kim"
      ],
      "abstract": "In this letter, we propose an Attention-Based Neural-Augmented Kalman Filter (AttenNKF) for state estimation in legged robots. Foot slip is a major source of estimation error: when slip occurs, kinematic measurements violate the no-slip assumption and inject bias during the update step. Our objective is to estimate this slip-induced error and compensate for it. To this end, we augment an Invariant Extended Kalman Filter (InEKF) with a neural compensator that uses an attention mechanism to infer error conditioned on foot-slip severity and then applies this estimate as a post-update compensation to the InEKF state (i.e., after the filter update). The compensator is trained in a latent space, which aims to reduce sensitivity to raw input scales and encourages structured slip-conditioned compensations, while preserving the InEKF recursion. Experiments demonstrate improved performance compared to existing legged-robot state estimators, particularly under slip-prone conditions.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18569v1",
        "pdf": "https://arxiv.org/pdf/2601.18569v1"
      },
      "arxiv_id": "2601.18569v1",
      "comment": "8 pages, 6 figures, Accepted to IEEE Robotics and Automation Letters (RA-L)",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18564v1",
      "title": "An Unsupervised Tensor-Based Domain Alignment",
      "authors": [
        "Chong Hyun Lee",
        "Kibae Lee",
        "Hyun Hee Yim"
      ],
      "abstract": "We propose a tensor-based domain alignment (DA) algorithm designed to align source and target tensors within an invariant subspace through the use of alignment matrices. These matrices along with the subspace undergo iterative optimization of which constraint is on oblique manifold, which offers greater flexibility and adaptability compared to the traditional Stiefel manifold. Moreover, regularization terms defined to preserve the variance of both source and target tensors, ensures robust performance. Our framework is versatile, effectively generalizing existing tensor-based DA methods as special cases. Through extensive experiments, we demonstrate that our approach not only enhances DA conversion speed but also significantly boosts classification accuracy. This positions our method as superior to current state-of-the-art techniques, making it a preferable choice for complex domain adaptation tasks.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.LG",
        "cs.CV",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18564v1",
        "pdf": "https://arxiv.org/pdf/2601.18564v1"
      },
      "arxiv_id": "2601.18564v1",
      "comment": "5 pages, 5 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18560v1",
      "title": "AI-enabled Satellite Edge Computing: A Single-Pixel Feature based Shallow Classification Model for Hyperspectral Imaging",
      "authors": [
        "Li Fang",
        "Tianyu Li",
        "Yanghong Lin",
        "Shudong Zhou",
        "Wei Yao"
      ],
      "abstract": "As the important component of the Earth observation system, hyperspectral imaging satellites provide high-fidelity and enriched information for the formulation of related policies due to the powerful spectral measurement capabilities. However, the transmission speed of the satellite downlink has become a major bottleneck in certain applications, such as disaster monitoring and emergency mapping, which demand a fast response ability. We propose an efficient AI-enabled Satellite Edge Computing paradigm for hyperspectral image classification, facilitating the satellites to attain autonomous decision-making. To accommodate the resource constraints of satellite platforms, the proposed method adopts a lightweight, non-deep learning framework integrated with a few-shot learning strategy. Moreover, onboard processing on satellites could be faced with sensor failure and scan pattern errors, which result in degraded image quality with bad/misaligned pixels and mixed noise. To address these challenges, we develop a novel two-stage pixel-wise label propagation scheme that utilizes only intrinsic spectral features at the single pixel level without the necessity to consider spatial structural information as requested by deep neural networks. In the first stage, initial pixel labels are obtained by propagating selected anchor labels through the constructed anchor-pixel affinity matrix. Subsequently, a top-k pruned sparse graph is generated by directly computing pixel-level similarities. In the second stage, a closed-form solution derived from the sparse graph is employed to replace iterative computations. Furthermore, we developed a rank constraint-based graph clustering algorithm to determine the anchor labels.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18560v1",
        "pdf": "https://arxiv.org/pdf/2601.18560v1"
      },
      "arxiv_id": "2601.18560v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18556v1",
      "title": "Generative Diffusion Augmentation with Quantum-Enhanced Discrimination for Medical Image Diagnosis",
      "authors": [
        "Jingsong Xia",
        "Siqi Wang"
      ],
      "abstract": "In biomedical engineering, artificial intelligence has become a pivotal tool for enhancing medical diagnostics, particularly in medical image classification tasks such as detecting pneumonia from chest X-rays and breast cancer screening. However, real-world medical datasets frequently exhibit severe class imbalance, where positive samples substantially outnumber negative samples, leading to biased models with low recall rates for minority classes. This imbalance not only compromises diagnostic accuracy but also poses clinical misdiagnosis risks. To address this challenge, we propose SDA-QEC (Simplified Diffusion Augmentation with Quantum-Enhanced Classification), an innovative framework that integrates simplified diffusion-based data augmentation with quantum-enhanced feature discrimination. Our approach employs a lightweight diffusion augmentor to generate high-quality synthetic samples for minority classes, rebalancing the training distribution. Subsequently, a quantum feature layer embedded within MobileNetV2 architecture enhances the model's discriminative capability through high-dimensional feature mapping in Hilbert space. Comprehensive experiments on coronary angiography image classification demonstrate that SDA-QEC achieves 98.33% accuracy, 98.78% AUC, and 98.33% F1-score, significantly outperforming classical baselines including ResNet18, MobileNetV2, DenseNet121, and VGG16. Notably, our framework simultaneously attains 98.33% sensitivity and 98.33% specificity, achieving a balanced performance critical for clinical deployment. The proposed method validates the feasibility of integrating generative augmentation with quantum-enhanced modeling in real-world medical imaging tasks, offering a novel research pathway for developing highly reliable medical AI systems in small-sample, highly imbalanced, and high-risk diagnostic scenarios.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18556v1",
        "pdf": "https://arxiv.org/pdf/2601.18556v1"
      },
      "arxiv_id": "2601.18556v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18555v1",
      "title": "Automated Landmark Detection for assessing hip conditions: A Cross-Modality Validation of MRI versus X-ray",
      "authors": [
        "Roberto Di Via",
        "Vito Paolo Pastore",
        "Francesca Odone",
        "Siôn Glyn-Jones",
        "Irina Voiculescu"
      ],
      "abstract": "Many clinical screening decisions are based on angle measurements. In particular, FemoroAcetabular Impingement (FAI) screening relies on angles traditionally measured on X-rays. However, assessing the height and span of the impingement area requires also a 3D view through an MRI scan. The two modalities inform the surgeon on different aspects of the condition. In this work, we conduct a matched-cohort validation study (89 patients, paired MRI/X-ray) using standard heatmap regression architectures to assess cross-modality clinical equivalence. Seen that landmark detection has been proven effective on X-rays, we show that MRI also achieves equivalent localisation and diagnostic accuracy for cam-type impingement. Our method demonstrates clinical feasibility for FAI assessment in coronal views of 3D MRI volumes, opening the possibility for volumetric analysis through placing further landmarks. These results support integrating automated FAI assessment into routine MRI workflows. Code is released at https://github.com/Malga-Vision/Landmarks-Hip-Conditions",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18555v1",
        "pdf": "https://arxiv.org/pdf/2601.18555v1"
      },
      "arxiv_id": "2601.18555v1",
      "comment": "Accepted at International Symposium on Biomedical Imaging (ISBI 2026)",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18554v1",
      "title": "Deconstructing Instruction-Following: A New Benchmark for Granular Evaluation of Large Language Model Instruction Compliance Abilities",
      "authors": [
        "Alberto Purpura",
        "Li Wang",
        "Sahil Badyal",
        "Eugenio Beaufrand",
        "Adam Faulkner"
      ],
      "abstract": "Reliably ensuring Large Language Models (LLMs) follow complex instructions is a critical challenge, as existing benchmarks often fail to reflect real-world use or isolate compliance from task success. We introduce MOSAIC (MOdular Synthetic Assessment of Instruction Compliance), a modular framework that uses a dynamically generated dataset with up to 20 application-oriented generation constraints to enable a granular and independent analysis of this capability. Our evaluation of five LLMs from different families based on this new benchmark demonstrates that compliance is not a monolithic capability but varies significantly with constraint type, quantity, and position. The analysis reveals model-specific weaknesses, uncovers synergistic and conflicting interactions between instructions, and identifies distinct positional biases such as primacy and recency effects. These granular insights are critical for diagnosing model failures and developing more reliable LLMs for systems that demand strict adherence to complex instructions.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18554v1",
        "pdf": "https://arxiv.org/pdf/2601.18554v1"
      },
      "arxiv_id": "2601.18554v1",
      "comment": "Paper accepted to EACL 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18552v1",
      "title": "Unknown Unknowns: Why Hidden Intentions in LLMs Evade Detection",
      "authors": [
        "Devansh Srivastav",
        "David Pape",
        "Lea Schönherr"
      ],
      "abstract": "LLMs are increasingly embedded in everyday decision-making, yet their outputs can encode subtle, unintended behaviours that shape user beliefs and actions. We refer to these covert, goal-directed behaviours as hidden intentions, which may arise from training and optimisation artefacts, or be deliberately induced by an adversarial developer, yet remain difficult to detect in practice. We introduce a taxonomy of ten categories of hidden intentions, grounded in social science research and organised by intent, mechanism, context, and impact, shifting attention from surface-level behaviours to design-level strategies of influence. We show how hidden intentions can be easily induced in controlled models, providing both testbeds for evaluation and demonstrations of potential misuse. We systematically assess detection methods, including reasoning and non-reasoning LLM judges, and find that detection collapses in realistic open-world settings, particularly under low-prevalence conditions, where false positives overwhelm precision and false negatives conceal true risks. Stress tests on precision-prevalence and precision-FNR trade-offs reveal why auditing fails without vanishingly small false positive rates or strong priors on manipulation types. Finally, a qualitative case study shows that all ten categories manifest in deployed, state-of-the-art LLMs, emphasising the urgent need for robust frameworks. Our work provides the first systematic analysis of detectability failures of hidden intentions in LLMs under open-world settings, offering a foundation for understanding, inducing, and stress-testing such behaviours, and establishing a flexible taxonomy for anticipating evolving threats and informing governance.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18552v1",
        "pdf": "https://arxiv.org/pdf/2601.18552v1"
      },
      "arxiv_id": "2601.18552v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18547v1",
      "title": "REMAC: Reference-Based Martian Asymmetrical Image Compression",
      "authors": [
        "Qing Ding",
        "Mai Xu",
        "Shengxi Li",
        "Xin Deng",
        "Xin Zou"
      ],
      "abstract": "To expedite space exploration on Mars, it is indispensable to develop an efficient Martian image compression method for transmitting images through the constrained Mars-to-Earth communication channel. Although the existing learned compression methods have achieved promising results for natural images from earth, there remain two critical issues that hinder their effectiveness for Martian image compression: 1) They overlook the highly-limited computational resources on Mars; 2) They do not utilize the strong \\textit{inter-image} similarities across Martian images to advance image compression performance. Motivated by our empirical analysis of the strong \\textit{intra-} and \\textit{inter-image} similarities from the perspective of texture, color, and semantics, we propose a reference-based Martian asymmetrical image compression (REMAC) approach, which shifts computational complexity from the encoder to the resource-rich decoder and simultaneously improves compression performance. To leverage \\textit{inter-image} similarities, we propose a reference-guided entropy module and a ref-decoder that utilize useful information from reference images, reducing redundant operations at the encoder and achieving superior compression performance. To exploit \\textit{intra-image} similarities, the ref-decoder adopts a deep, multi-scale architecture with enlarged receptive field size to model long-range spatial dependencies. Additionally, we develop a latent feature recycling mechanism to further alleviate the extreme computational constraints on Mars. Experimental results show that REMAC reduces encoder complexity by 43.51\\% compared to the state-of-the-art method, while achieving a BD-PSNR gain of 0.2664 dB.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18547v1",
        "pdf": "https://arxiv.org/pdf/2601.18547v1"
      },
      "arxiv_id": "2601.18547v1",
      "comment": "Accepted for publication in IEEE Transactions on Geoscience and Remote Sensing (TGRS). 2025 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. 18 pages, 20 figures",
      "journal_ref": "Year: 2025, Volume: 64, Article Sequence Number: 5601018",
      "has_code": false
    },
    {
      "id": "2601.18546v1",
      "title": "Information Hidden in Gradients of Regression with Target Noise",
      "authors": [
        "Arash Jamshidi",
        "Katsiaryna Haitsiukevich",
        "Kai Puolamäki"
      ],
      "abstract": "Second-order information -- such as curvature or data covariance -- is critical for optimisation, diagnostics, and robustness. However, in many modern settings, only the gradients are observable. We show that the gradients alone can reveal the Hessian, equalling the data covariance $Σ$ for the linear regression. Our key insight is a simple variance calibration: injecting Gaussian noise so that the total target noise variance equals the batch size ensures that the empirical gradient covariance closely approximates the Hessian, even when evaluated far from the optimum. We provide non-asymptotic operator-norm guarantees under sub-Gaussian inputs. We also show that without such calibration, recovery can fail by an $Ω(1)$ factor. The proposed method is practical (a \"set target-noise variance to $n$\" rule) and robust (variance $\\mathcal{O}(n)$ suffices to recover $Σ$ up to scale). Applications include preconditioning for faster optimisation, adversarial risk estimation, and gradient-only training, for example, in distributed systems. We support our theoretical results with experiments on synthetic and real data.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18546v1",
        "pdf": "https://arxiv.org/pdf/2601.18546v1"
      },
      "arxiv_id": "2601.18546v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18543v1",
      "title": "GenAgent: Scaling Text-to-Image Generation via Agentic Multimodal Reasoning",
      "authors": [
        "Kaixun Jiang",
        "Yuzheng Wang",
        "Junjie Zhou",
        "Pandeng Li",
        "Zhihang Liu",
        "Chen-Wei Xie",
        "Zhaoyu Chen",
        "Yun Zheng",
        "Wenqiang Zhang"
      ],
      "abstract": "We introduce GenAgent, unifying visual understanding and generation through an agentic multimodal model. Unlike unified models that face expensive training costs and understanding-generation trade-offs, GenAgent decouples these capabilities through an agentic framework: understanding is handled by the multimodal model itself, while generation is achieved by treating image generation models as invokable tools. Crucially, unlike existing modular systems constrained by static pipelines, this design enables autonomous multi-turn interactions where the agent generates multimodal chains-of-thought encompassing reasoning, tool invocation, judgment, and reflection to iteratively refine outputs. We employ a two-stage training strategy: first, cold-start with supervised fine-tuning on high-quality tool invocation and reflection data to bootstrap agent behaviors; second, end-to-end agentic reinforcement learning combining pointwise rewards (final image quality) and pairwise rewards (reflection accuracy), with trajectory resampling for enhanced multi-turn exploration. GenAgent significantly boosts base generator(FLUX.1-dev) performance on GenEval++ (+23.6\\%) and WISE (+14\\%). Beyond performance gains, our framework demonstrates three key properties: 1) cross-tool generalization to generators with varying capabilities, 2) test-time scaling with consistent improvements across interaction rounds, and 3) task-adaptive reasoning that automatically adjusts to different tasks. Our code will be available at \\href{https://github.com/deep-kaixun/GenAgent}{this url}.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18543v1",
        "pdf": "https://arxiv.org/pdf/2601.18543v1"
      },
      "arxiv_id": "2601.18543v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18537v1",
      "title": "SKETCH: Semantic Key-Point Conditioning for Long-Horizon Vessel Trajectory Prediction",
      "authors": [
        "Linyong Gan",
        "Zimo Li",
        "Wenxin Xu",
        "Xingjian Li",
        "Jianhua Z. Huang",
        "Enmei Tu",
        "Shuhang Chen"
      ],
      "abstract": "Accurate long-horizon vessel trajectory prediction remains challenging due to compounded uncertainty from complex navigation behaviors and environmental factors. Existing methods often struggle to maintain global directional consistency, leading to drifting or implausible trajectories when extrapolated over long time horizons. To address this issue, we propose a semantic-key-point-conditioned trajectory modeling framework, in which future trajectories are predicted by conditioning on a high-level Next Key Point (NKP) that captures navigational intent. This formulation decomposes long-horizon prediction into global semantic decision-making and local motion modeling, effectively restricting the support of future trajectories to semantically feasible subsets. To efficiently estimate the NKP prior from historical observations, we adopt a pretrain-finetune strategy. Extensive experiments on real-world AIS data demonstrate that the proposed method consistently outperforms state-of-the-art approaches, particularly for long travel durations, directional accuracy, and fine-grained trajectory prediction.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18537v1",
        "pdf": "https://arxiv.org/pdf/2601.18537v1"
      },
      "arxiv_id": "2601.18537v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18532v1",
      "title": "From Cold Start to Active Learning: Embedding-Based Scan Selection for Medical Image Segmentation",
      "authors": [
        "Devon Levy",
        "Bar Assayag",
        "Laura Gaspar",
        "Ilan Shimshoni",
        "Bella Specktor-Fadida"
      ],
      "abstract": "Accurate segmentation annotations are critical for disease monitoring, yet manual labeling remains a major bottleneck due to the time and expertise required. Active learning (AL) alleviates this burden by prioritizing informative samples for annotation, typically through a diversity-based cold-start phase followed by uncertainty-driven selection. We propose a novel cold-start sampling strategy that combines foundation-model embeddings with clustering, including automatic selection of the number of clusters and proportional sampling across clusters, to construct a diverse and representative initial training. This is followed by an uncertainty-based AL framework that integrates spatial diversity to guide sample selection. The proposed method is intuitive and interpretable, enabling visualization of the feature-space distribution of candidate samples. We evaluate our approach on three datasets spanning X-ray and MRI modalities. On the CheXmask dataset, the cold-start strategy outperforms random selection, improving Dice from 0.918 to 0.929 and reducing the Hausdorff distance from 32.41 to 27.66 mm. In the AL setting, combined entropy and diversity selection improves Dice from 0.919 to 0.939 and reduces the Hausdorff distance from 30.10 to 19.16 mm. On the Montgomery dataset, cold-start gains are substantial, with Dice improving from 0.928 to 0.950 and Hausdorff distance decreasing from 14.22 to 9.38 mm. On the SynthStrip dataset, cold-start selection slightly affects Dice but reduces the Hausdorff distance from 9.43 to 8.69 mm, while active learning improves Dice from 0.816 to 0.826 and reduces the Hausdorff distance from 7.76 to 6.38 mm. Overall, the proposed framework consistently outperforms baseline methods in low-data regimes, improving segmentation accuracy.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18532v1",
        "pdf": "https://arxiv.org/pdf/2601.18532v1"
      },
      "arxiv_id": "2601.18532v1",
      "comment": "19 pages without references",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18525v1",
      "title": "Closing the Modality Gap Aligns Group-Wise Semantics",
      "authors": [
        "Eleonora Grassucci",
        "Giordano Cicchetti",
        "Emanuele Frasca",
        "Aurelio Uncini",
        "Danilo Comminiello"
      ],
      "abstract": "In multimodal learning, CLIP has been recognized as the \\textit{de facto} method for learning a shared latent space across multiple modalities, placing similar representations close to each other and moving them away from dissimilar ones. Although CLIP-based losses effectively align modalities at the semantic level, the resulting latent spaces often remain only partially shared, revealing a structural mismatch known as the modality gap. While the necessity of addressing this phenomenon remains debated, particularly given its limited impact on instance-wise tasks (e.g., retrieval), we prove that its influence is instead strongly pronounced in group-level tasks (e.g., clustering). To support this claim, we introduce a novel method designed to consistently reduce this discrepancy in two-modal settings, with a straightforward extension to the general $n$-modal case. Through our extensive evaluation, we demonstrate our novel insight: while reducing the gap provides only marginal or inconsistent improvements in traditional instance-wise tasks, it significantly enhances group-wise tasks. These findings may reshape our understanding of the modality gap, highlighting its key role in improving performance on tasks requiring semantic grouping.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.LG",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18525v1",
        "pdf": "https://arxiv.org/pdf/2601.18525v1"
      },
      "arxiv_id": "2601.18525v1",
      "comment": "ICLR 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18524v1",
      "title": "From Human Labels to Literature: Semi-Supervised Learning of NMR Chemical Shifts at Scale",
      "authors": [
        "Yongqi Jin",
        "Yecheng Wang",
        "Jun-jie Wang",
        "Rong Zhu",
        "Guolin Ke",
        "Weinan E"
      ],
      "abstract": "Accurate prediction of nuclear magnetic resonance (NMR) chemical shifts is fundamental to spectral analysis and molecular structure elucidation, yet existing machine learning methods rely on limited, labor-intensive atom-assigned datasets. We propose a semi-supervised framework that learns NMR chemical shifts from millions of literature-extracted spectra without explicit atom-level assignments, integrating a small amount of labeled data with large-scale unassigned spectra. We formulate chemical shift prediction from literature spectra as a permutation-invariant set supervision problem, and show that under commonly satisfied conditions on the loss function, optimal bipartite matching reduces to a sorting-based loss, enabling stable large-scale semi-supervised training beyond traditional curated datasets. Our models achieve substantially improved accuracy and robustness over state-of-the-art methods and exhibit stronger generalization on significantly larger and more diverse molecular datasets. Moreover, by incorporating solvent information at scale, our approach captures systematic solvent effects across common NMR solvents for the first time. Overall, our results demonstrate that large-scale unlabeled spectra mined from the literature can serve as a practical and effective data source for training NMR shift models, suggesting a broader role of literature-derived, weakly structured data in data-centric AI for science.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18524v1",
        "pdf": "https://arxiv.org/pdf/2601.18524v1"
      },
      "arxiv_id": "2601.18524v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18521v1",
      "title": "Scalable Transit Delay Prediction at City Scale: A Systematic Approach with Multi-Resolution Feature Engineering and Deep Learning",
      "authors": [
        "Emna Boudabbous",
        "Mohamed Karaa",
        "Lokman Sboui",
        "Julio Montecinos",
        "Omar Alam"
      ],
      "abstract": "Urban bus transit agencies need reliable, network-wide delay predictions to provide accurate arrival information to passengers and support real-time operational control. Accurate predictions help passengers plan their trips, reduce waiting time, and allow operations staff to adjust headways, dispatch extra vehicles, and manage disruptions. Although real-time feeds such as GTFS-Realtime (GTFS-RT) are now widely available, most existing delay prediction systems handle only a few routes, depend on hand-crafted features, and offer little guidance on how to design a scalable, reusable architecture.\n  We present a city-scale prediction pipeline that combines multi-resolution feature engineering, dimensionality reduction, and deep learning. The framework generates 1,683 spatiotemporal features by exploring 23 aggregation combinations over H3 cells, routes, segments, and temporal patterns, and compresses them into 83 components using Adaptive PCA while preserving 95% of the variance. To avoid the \"giant cluster\" problem that occurs when dense urban areas fall into a single H3 region, we introduce a hybrid H3+topology clustering method that yields 12 balanced route clusters (coefficient of variation 0.608) and enables efficient distributed training.\n  We compare five model architectures on six months of bus operations from the Société de transport de Montréal (STM) network in Montréal. A global LSTM with cluster-aware features achieves the best trade-off between accuracy and efficiency, outperforming transformer models by 18 to 52% while using 275 times fewer parameters. We also report multi-level evaluation at the elementary segment, segment, and trip level with walk-forward validation and latency analysis, showing that the proposed pipeline is suitable for real-time, city-scale deployment and can be reused for other networks with limited adaptation.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18521v1",
        "pdf": "https://arxiv.org/pdf/2601.18521v1"
      },
      "arxiv_id": "2601.18521v1",
      "comment": "This manuscript is a preprint of an earlier version. A revised system-oriented version is currently under review",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18513v1",
      "title": "LipNeXt: Scaling up Lipschitz-based Certified Robustness to Billion-parameter Models",
      "authors": [
        "Kai Hu",
        "Haoqi Hu",
        "Matt Fredrikson"
      ],
      "abstract": "Lipschitz-based certification offers efficient, deterministic robustness guarantees but has struggled to scale in model size, training efficiency, and ImageNet performance. We introduce \\emph{LipNeXt}, the first \\emph{constraint-free} and \\emph{convolution-free} 1-Lipschitz architecture for certified robustness. LipNeXt is built using two techniques: (1) a manifold optimization procedure that updates parameters directly on the orthogonal manifold and (2) a \\emph{Spatial Shift Module} to model spatial pattern without convolutions. The full network uses orthogonal projections, spatial shifts, a simple 1-Lipschitz $β$-Abs nonlinearity, and $L_2$ spatial pooling to maintain tight Lipschitz control while enabling expressive feature mixing. Across CIFAR-10/100 and Tiny-ImageNet, LipNeXt achieves state-of-the-art clean and certified robust accuracy (CRA), and on ImageNet it scales to 1-2B large models, improving CRA over prior Lipschitz models (e.g., up to $+8\\%$ at $\\varepsilon{=}1$) while retaining efficient, stable low-precision training. These results demonstrate that Lipschitz-based certification can benefit from modern scaling trends without sacrificing determinism or efficiency.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18513v1",
        "pdf": "https://arxiv.org/pdf/2601.18513v1"
      },
      "arxiv_id": "2601.18513v1",
      "comment": "ICLR 2026. 17 pages",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.18510v1",
      "title": "Just-In-Time Reinforcement Learning: Continual Learning in LLM Agents Without Gradient Updates",
      "authors": [
        "Yibo Li",
        "Zijie Lin",
        "Ailin Deng",
        "Xuan Zhang",
        "Yufei He",
        "Shuo Ji",
        "Tri Cao",
        "Bryan Hooi"
      ],
      "abstract": "While Large Language Model (LLM) agents excel at general tasks, they inherently struggle with continual adaptation due to the frozen weights after deployment. Conventional reinforcement learning (RL) offers a solution but incurs prohibitive computational costs and the risk of catastrophic forgetting. We introduce Just-In-Time Reinforcement Learning (JitRL), a training-free framework that enables test-time policy optimization without any gradient updates. JitRL maintains a dynamic, non-parametric memory of experiences and retrieves relevant trajectories to estimate action advantages on-the-fly. These estimates are then used to directly modulate the LLM's output logits. We theoretically prove that this additive update rule is the exact closed-form solution to the KL-constrained policy optimization objective. Extensive experiments on WebArena and Jericho demonstrate that JitRL establishes a new state-of-the-art among training-free methods. Crucially, JitRL outperforms the performance of computationally expensive fine-tuning methods (e.g., WebRL) while reducing monetary costs by over 30 times, offering a scalable path for continual learning agents. The code is available at https://github.com/liushiliushi/JitRL.",
      "published": "2026-01-26",
      "updated": "2026-01-26",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.18510v1",
        "pdf": "https://arxiv.org/pdf/2601.18510v1"
      },
      "arxiv_id": "2601.18510v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    }
  ]
}