{
  "fetched_at": "2026-01-12T00:28:25.219914",
  "total_papers": 100,
  "papers": [
    {
      "id": "2601.05251v1",
      "title": "Mesh4D: 4D Mesh Reconstruction and Tracking from Monocular Video",
      "authors": [
        "Zeren Jiang",
        "Chuanxia Zheng",
        "Iro Laina",
        "Diane Larlus",
        "Andrea Vedaldi"
      ],
      "abstract": "We propose Mesh4D, a feed-forward model for monocular 4D mesh reconstruction. Given a monocular video of a dynamic object, our model reconstructs the object's complete 3D shape and motion, represented as a deformation field. Our key contribution is a compact latent space that encodes the entire animation sequence in a single pass. This latent space is learned by an autoencoder that, during training, is guided by the skeletal structure of the training objects, providing strong priors on plausible deformations. Crucially, skeletal information is not required at inference time. The encoder employs spatio-temporal attention, yielding a more stable representation of the object's overall deformation. Building on this representation, we train a latent diffusion model that, conditioned on the input video and the mesh reconstructed from the first frame, predicts the full animation in one shot. We evaluate Mesh4D on reconstruction and novel view synthesis benchmarks, outperforming prior methods in recovering accurate 3D shape and deformation.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05251v1",
        "pdf": "https://arxiv.org/pdf/2601.05251v1"
      },
      "arxiv_id": "2601.05251v1",
      "comment": "15 pages, 8 figures, project page: https://mesh-4d.github.io/",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2601.05249v1",
      "title": "RL-AWB: Deep Reinforcement Learning for Auto White Balance Correction in Low-Light Night-time Scenes",
      "authors": [
        "Yuan-Kang Lee",
        "Kuan-Lin Chen",
        "Chia-Che Chang",
        "Yu-Lun Liu"
      ],
      "abstract": "Nighttime color constancy remains a challenging problem in computational photography due to low-light noise and complex illumination conditions. We present RL-AWB, a novel framework combining statistical methods with deep reinforcement learning for nighttime white balance. Our method begins with a statistical algorithm tailored for nighttime scenes, integrating salient gray pixel detection with novel illumination estimation. Building on this foundation, we develop the first deep reinforcement learning approach for color constancy that leverages the statistical algorithm as its core, mimicking professional AWB tuning experts by dynamically optimizing parameters for each image. To facilitate cross-sensor evaluation, we introduce the first multi-sensor nighttime dataset. Experiment results demonstrate that our method achieves superior generalization capability across low-light and well-illuminated images. Project page: https://ntuneillee.github.io/research/rl-awb/",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05249v1",
        "pdf": "https://arxiv.org/pdf/2601.05249v1"
      },
      "arxiv_id": "2601.05249v1",
      "comment": "Project page: https://ntuneillee.github.io/research/rl-awb/",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2601.05250v1",
      "title": "QNeRF: Neural Radiance Fields on a Simulated Gate-Based Quantum Computer",
      "authors": [
        "Daniele Lizzio Bosco",
        "Shuteng Wang",
        "Giuseppe Serra",
        "Vladislav Golyanik"
      ],
      "abstract": "Recently, Quantum Visual Fields (QVFs) have shown promising improvements in model compactness and convergence speed for learning the provided 2D or 3D signals. Meanwhile, novel-view synthesis has seen major advances with Neural Radiance Fields (NeRFs), where models learn a compact representation from 2D images to render 3D scenes, albeit at the cost of larger models and intensive training. In this work, we extend the approach of QVFs by introducing QNeRF, the first hybrid quantum-classical model designed for novel-view synthesis from 2D images. QNeRF leverages parameterised quantum circuits to encode spatial and view-dependent information via quantum superposition and entanglement, resulting in more compact models compared to the classical counterpart. We present two architectural variants. Full QNeRF maximally exploits all quantum amplitudes to enhance representational capabilities. In contrast, Dual-Branch QNeRF introduces a task-informed inductive bias by branching spatial and view-dependent quantum state preparations, drastically reducing the complexity of this operation and ensuring scalability and potential hardware compatibility. Our experiments demonstrate that -- when trained on images of moderate resolution -- QNeRF matches or outperforms classical NeRF baselines while using less than half the number of parameters. These results suggest that quantum machine learning can serve as a competitive alternative for continuous signal representation in mid-level tasks in computer vision, such as 3D representation learning from 2D observations.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05250v1",
        "pdf": "https://arxiv.org/pdf/2601.05250v1"
      },
      "arxiv_id": "2601.05250v1",
      "comment": "30 pages, 15 figures, 11 tables; project page: https://4dqv.mpi-inf.mpg.de/QNeRF/",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05246v1",
      "title": "Pixel-Perfect Visual Geometry Estimation",
      "authors": [
        "Gangwei Xu",
        "Haotong Lin",
        "Hongcheng Luo",
        "Haiyang Sun",
        "Bing Wang",
        "Guang Chen",
        "Sida Peng",
        "Hangjun Ye",
        "Xin Yang"
      ],
      "abstract": "Recovering clean and accurate geometry from images is essential for robotics and augmented reality. However, existing geometry foundation models still suffer severely from flying pixels and the loss of fine details. In this paper, we present pixel-perfect visual geometry models that can predict high-quality, flying-pixel-free point clouds by leveraging generative modeling in the pixel space. We first introduce Pixel-Perfect Depth (PPD), a monocular depth foundation model built upon pixel-space diffusion transformers (DiT). To address the high computational complexity associated with pixel-space diffusion, we propose two key designs: 1) Semantics-Prompted DiT, which incorporates semantic representations from vision foundation models to prompt the diffusion process, preserving global semantics while enhancing fine-grained visual details; and 2) Cascade DiT architecture that progressively increases the number of image tokens, improving both efficiency and accuracy. To further extend PPD to video (PPVD), we introduce a new Semantics-Consistent DiT, which extracts temporally consistent semantics from a multi-view geometry foundation model. We then perform reference-guided token propagation within the DiT to maintain temporal coherence with minimal computational and memory overhead. Our models achieve the best performance among all generative monocular and video depth estimation models and produce significantly cleaner point clouds than all other models.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05246v1",
        "pdf": "https://arxiv.org/pdf/2601.05246v1"
      },
      "arxiv_id": "2601.05246v1",
      "comment": "Code: https://github.com/gangweix/pixel-perfect-depth",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2601.05245v1",
      "title": "Optimal Lower Bounds for Online Multicalibration",
      "authors": [
        "Natalie Collina",
        "Jiuyao Lu",
        "Georgy Noarov",
        "Aaron Roth"
      ],
      "abstract": "We prove tight lower bounds for online multicalibration, establishing an information-theoretic separation from marginal calibration.\n  In the general setting where group functions can depend on both context and the learner's predictions, we prove an $Ω(T^{2/3})$ lower bound on expected multicalibration error using just three disjoint binary groups. This matches the upper bounds of Noarov et al. (2025) up to logarithmic factors and exceeds the $O(T^{2/3-\\varepsilon})$ upper bound for marginal calibration (Dagan et al., 2025), thereby separating the two problems.\n  We then turn to lower bounds for the more difficult case of group functions that may depend on context but not on the learner's predictions. In this case, we establish an $\\widetildeΩ(T^{2/3})$ lower bound for online multicalibration via a $Θ(T)$-sized group family constructed using orthogonal function systems, again matching upper bounds up to logarithmic factors.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.LG",
        "math.ST",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05245v1",
        "pdf": "https://arxiv.org/pdf/2601.05245v1"
      },
      "arxiv_id": "2601.05245v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05244v1",
      "title": "GREx: Generalized Referring Expression Segmentation, Comprehension, and Generation",
      "authors": [
        "Henghui Ding",
        "Chang Liu",
        "Shuting He",
        "Xudong Jiang",
        "Yu-Gang Jiang"
      ],
      "abstract": "Referring Expression Segmentation (RES) and Comprehension (REC) respectively segment and detect the object described by an expression, while Referring Expression Generation (REG) generates an expression for the selected object. Existing datasets and methods commonly support single-target expressions only, i.e., one expression refers to one object, not considering multi-target and no-target expressions. This greatly limits the real applications of REx (RES/REC/REG). This paper introduces three new benchmarks called Generalized Referring Expression Segmentation (GRES), Comprehension (GREC), and Generation (GREG), collectively denoted as GREx, which extend the classic REx to allow expressions to identify an arbitrary number of objects. We construct the first large-scale GREx dataset gRefCOCO that contains multi-target, no-target, and single-target expressions and their corresponding images with labeled targets. GREx and gRefCOCO are designed to be backward-compatible with REx, facilitating extensive experiments to study the performance gap of the existing REx methods on GREx tasks. One of the challenges of GRES/GREC is complex relationship modeling, for which we propose a baseline ReLA that adaptively divides the image into regions with sub-instance clues and explicitly models the region-region and region-language dependencies. The proposed ReLA achieves the state-of-the-art results on the both GRES and GREC tasks. The proposed gRefCOCO dataset and method are available at https://henghuiding.github.io/GREx.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05244v1",
        "pdf": "https://arxiv.org/pdf/2601.05244v1"
      },
      "arxiv_id": "2601.05244v1",
      "comment": "IJCV, Project Page: https://henghuiding.com/GREx/",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05243v1",
      "title": "Generate, Transfer, Adapt: Learning Functional Dexterous Grasping from a Single Human Demonstration",
      "authors": [
        "Xingyi He",
        "Adhitya Polavaram",
        "Yunhao Cao",
        "Om Deshmukh",
        "Tianrui Wang",
        "Xiaowei Zhou",
        "Kuan Fang"
      ],
      "abstract": "Functional grasping with dexterous robotic hands is a key capability for enabling tool use and complex manipulation, yet progress has been constrained by two persistent bottlenecks: the scarcity of large-scale datasets and the absence of integrated semantic and geometric reasoning in learned models. In this work, we present CorDex, a framework that robustly learns dexterous functional grasps of novel objects from synthetic data generated from just a single human demonstration. At the core of our approach is a correspondence-based data engine that generates diverse, high-quality training data in simulation. Based on the human demonstration, our data engine generates diverse object instances of the same category, transfers the expert grasp to the generated objects through correspondence estimation, and adapts the grasp through optimization. Building on the generated data, we introduce a multimodal prediction network that integrates visual and geometric information. By devising a local-global fusion module and an importance-aware sampling mechanism, we enable robust and computationally efficient prediction of functional dexterous grasps. Through extensive experiments across various object categories, we demonstrate that CorDex generalizes well to unseen object instances and significantly outperforms state-of-the-art baselines.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.RO",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05243v1",
        "pdf": "https://arxiv.org/pdf/2601.05243v1"
      },
      "arxiv_id": "2601.05243v1",
      "comment": "Project Page: https://cordex-manipulation.github.io/",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2601.05242v1",
      "title": "GDPO: Group reward-Decoupled Normalization Policy Optimization for Multi-reward RL Optimization",
      "authors": [
        "Shih-Yang Liu",
        "Xin Dong",
        "Ximing Lu",
        "Shizhe Diao",
        "Peter Belcak",
        "Mingjie Liu",
        "Min-Hung Chen",
        "Hongxu Yin",
        "Yu-Chiang Frank Wang",
        "Kwang-Ting Cheng",
        "Yejin Choi",
        "Jan Kautz",
        "Pavlo Molchanov"
      ],
      "abstract": "As language models become increasingly capable, users expect them to provide not only accurate responses but also behaviors aligned with diverse human preferences across a variety of scenarios. To achieve this, Reinforcement learning (RL) pipelines have begun incorporating multiple rewards, each capturing a distinct preference, to guide models toward these desired behaviors. However, recent work has defaulted to apply Group Relative Policy Optimization (GRPO) under multi-reward setting without examining its suitability. In this paper, we demonstrate that directly applying GRPO to normalize distinct rollout reward combinations causes them to collapse into identical advantage values, reducing the resolution of the training signal and resulting in suboptimal convergence and, in some cases, early training failure. We then introduce Group reward-Decoupled Normalization Policy Optimization (GDPO), a new policy optimization method to resolve these issues by decoupling the normalization of individual rewards, more faithfully preserving their relative differences and enabling more accurate multi-reward optimization, along with substantially improved training stability. We compare GDPO with GRPO across three tasks: tool calling, math reasoning, and coding reasoning, evaluating both correctness metrics (accuracy, bug ratio) and constraint adherence metrics (format, length). Across all settings, GDPO consistently outperforms GRPO, demonstrating its effectiveness and generalizability for multi-reward reinforcement learning optimization.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05242v1",
        "pdf": "https://arxiv.org/pdf/2601.05242v1"
      },
      "arxiv_id": "2601.05242v1",
      "comment": "NVIDIA-Tech Report",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05241v1",
      "title": "RoboVIP: Multi-View Video Generation with Visual Identity Prompting Augments Robot Manipulation",
      "authors": [
        "Boyang Wang",
        "Haoran Zhang",
        "Shujie Zhang",
        "Jinkun Hao",
        "Mingda Jia",
        "Qi Lv",
        "Yucheng Mao",
        "Zhaoyang Lyu",
        "Jia Zeng",
        "Xudong Xu",
        "Jiangmiao Pang"
      ],
      "abstract": "The diversity, quantity, and quality of manipulation data are critical for training effective robot policies. However, due to hardware and physical setup constraints, collecting large-scale real-world manipulation data remains difficult to scale across diverse environments. Recent work uses text-prompt conditioned image diffusion models to augment manipulation data by altering the backgrounds and tabletop objects in the visual observations. However, these approaches often overlook the practical need for multi-view and temporally coherent observations required by state-of-the-art policy models. Further, text prompts alone cannot reliably specify the scene setup. To provide the diffusion model with explicit visual guidance, we introduce visual identity prompting, which supplies exemplar images as conditioning inputs to guide the generation of the desired scene setup. To this end, we also build a scalable pipeline to curate a visual identity pool from large robotics datasets. Using our augmented manipulation data to train downstream vision-language-action and visuomotor policy models yields consistent performance gains in both simulation and real-robot settings.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05241v1",
        "pdf": "https://arxiv.org/pdf/2601.05241v1"
      },
      "arxiv_id": "2601.05241v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05240v1",
      "title": "Robust Reasoning as a Symmetry-Protected Topological Phase",
      "authors": [
        "Ilmo Sung"
      ],
      "abstract": "Large language models suffer from \"hallucinations\"-logical inconsistencies induced by semantic noise. We propose that current architectures operate in a \"Metric Phase,\" where causal order is vulnerable to spontaneous symmetry breaking. Here, we identify robust inference as an effective Symmetry-Protected Topological phase, where logical operations are formally isomorphic to non-Abelian anyon braiding, replacing fragile geometric interpolation with robust topological invariants. Empirically, we demonstrate a sharp topological phase transition: while Transformers and RNNs exhibit gapless decay, our Holonomic Network reveals a macroscopic \"mass gap,\" maintaining invariant fidelity below a critical noise threshold. Furthermore, in a variable-binding task on $S_{10}$ ($3.6 \\times 10^6$ states) representing symbolic manipulation, we demonstrate holonomic generalization: the topological model maintains perfect fidelity extrapolating $100\\times$ beyond training ($L=50 \\to 5000$), consistent with a theoretically indefinite causal horizon, whereas Transformers lose logical coherence. Ablation studies indicate this protection emerges strictly from non-Abelian gauge symmetry. This provides strong evidence for a new universality class for logical reasoning, linking causal stability to the topology of the semantic manifold.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.LG",
        "cond-mat.dis-nn",
        "cs.AI",
        "hep-th"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05240v1",
        "pdf": "https://arxiv.org/pdf/2601.05240v1"
      },
      "arxiv_id": "2601.05240v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05239v1",
      "title": "Plenoptic Video Generation",
      "authors": [
        "Xiao Fu",
        "Shitao Tang",
        "Min Shi",
        "Xian Liu",
        "Jinwei Gu",
        "Ming-Yu Liu",
        "Dahua Lin",
        "Chen-Hsuan Lin"
      ],
      "abstract": "Camera-controlled generative video re-rendering methods, such as ReCamMaster, have achieved remarkable progress. However, despite their success in single-view setting, these works often struggle to maintain consistency across multi-view scenarios. Ensuring spatio-temporal coherence in hallucinated regions remains challenging due to the inherent stochasticity of generative models. To address it, we introduce PlenopticDreamer, a framework that synchronizes generative hallucinations to maintain spatio-temporal memory. The core idea is to train a multi-in-single-out video-conditioned model in an autoregressive manner, aided by a camera-guided video retrieval strategy that adaptively selects salient videos from previous generations as conditional inputs. In addition, Our training incorporates progressive context-scaling to improve convergence, self-conditioning to enhance robustness against long-range visual degradation caused by error accumulation, and a long-video conditioning mechanism to support extended video generation. Extensive experiments on the Basic and Agibot benchmarks demonstrate that PlenopticDreamer achieves state-of-the-art video re-rendering, delivering superior view synchronization, high-fidelity visuals, accurate camera control, and diverse view transformations (e.g., third-person to third-person, and head-view to gripper-view in robotic manipulation). Project page: https://research.nvidia.com/labs/dir/plenopticdreamer/",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05239v1",
        "pdf": "https://arxiv.org/pdf/2601.05239v1"
      },
      "arxiv_id": "2601.05239v1",
      "comment": "Project Page: https://research.nvidia.com/labs/dir/plenopticdreamer/",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05237v1",
      "title": "ObjectForesight: Predicting Future 3D Object Trajectories from Human Videos",
      "authors": [
        "Rustin Soraki",
        "Homanga Bharadhwaj",
        "Ali Farhadi",
        "Roozbeh Mottaghi"
      ],
      "abstract": "Humans can effortlessly anticipate how objects might move or change through interaction--imagining a cup being lifted, a knife slicing, or a lid being closed. We aim to endow computational systems with a similar ability to predict plausible future object motions directly from passive visual observation. We introduce ObjectForesight, a 3D object-centric dynamics model that predicts future 6-DoF poses and trajectories of rigid objects from short egocentric video sequences. Unlike conventional world or dynamics models that operate in pixel or latent space, ObjectForesight represents the world explicitly in 3D at the object level, enabling geometrically grounded and temporally coherent predictions that capture object affordances and trajectories. To train such a model at scale, we leverage recent advances in segmentation, mesh reconstruction, and 3D pose estimation to curate a dataset of 2 million plus short clips with pseudo-ground-truth 3D object trajectories. Through extensive experiments, we show that ObjectForesight achieves significant gains in accuracy, geometric consistency, and generalization to unseen objects and scenes, establishing a scalable framework for learning physically grounded, object-centric dynamics models directly from observation. objectforesight.github.io",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05237v1",
        "pdf": "https://arxiv.org/pdf/2601.05237v1"
      },
      "arxiv_id": "2601.05237v1",
      "comment": "Preprint. Project Website: objectforesight.github.io",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2601.05232v1",
      "title": "Measuring and Fostering Peace through Machine Learning and Artificial Intelligence",
      "authors": [
        "P. Gilda",
        "P. Dungarwal",
        "A. Thongkham",
        "E. T. Ajayi",
        "S. Choudhary",
        "T. M. Terol",
        "C. Lam",
        "J. P. Araujo",
        "M. McFadyen-Mungalln",
        "L. S. Liebovitch",
        "P. T. Coleman",
        "H. West",
        "K. Sieck",
        "S. Carter"
      ],
      "abstract": "We used machine learning and artificial intelligence: 1) to measure levels of peace in countries from news and social media and 2) to develop on-line tools that promote peace by helping users better understand their own media diet. For news media, we used neural networks to measure levels of peace from text embeddings of on-line news sources. The model, trained on one news media dataset also showed high accuracy when used to analyze a different news dataset. For social media, such as YouTube, we developed other models to measure levels of social dimensions important in peace using word level (GoEmotions) and context level (Large Language Model) methods. To promote peace, we note that 71% of people 20-40 years old daily view most of their news through short videos on social media. Content creators of these videos are biased towards creating videos with emotional activation, making you angry to engage you, to increase clicks. We developed and tested a Chrome extension, MirrorMirror, which provides real-time feedback to YouTube viewers about the peacefulness of the media they are watching. Our long term goal is for MirrorMirror to evolve into an open-source tool for content creators, journalists, researchers, platforms, and individual users to better understand the tone of their media creation and consumption and its effects on viewers. Moving beyond simple engagement metrics, we hope to encourage more respectful, nuanced, and informative communication.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.CL",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05232v1",
        "pdf": "https://arxiv.org/pdf/2601.05232v1"
      },
      "arxiv_id": "2601.05232v1",
      "comment": "6 pages, 4 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05230v1",
      "title": "Learning Latent Action World Models In The Wild",
      "authors": [
        "Quentin Garrido",
        "Tushar Nagarajan",
        "Basile Terver",
        "Nicolas Ballas",
        "Yann LeCun",
        "Michael Rabbat"
      ],
      "abstract": "Agents capable of reasoning and planning in the real world require the ability of predicting the consequences of their actions. While world models possess this capability, they most often require action labels, that can be complex to obtain at scale. This motivates the learning of latent action models, that can learn an action space from videos alone. Our work addresses the problem of learning latent actions world models on in-the-wild videos, expanding the scope of existing works that focus on simple robotics simulations, video games, or manipulation data. While this allows us to capture richer actions, it also introduces challenges stemming from the video diversity, such as environmental noise, or the lack of a common embodiment across videos. To address some of the challenges, we discuss properties that actions should follow as well as relevant architectural choices and evaluations. We find that continuous, but constrained, latent actions are able to capture the complexity of actions from in-the-wild videos, something that the common vector quantization does not. We for example find that changes in the environment coming from agents, such as humans entering the room, can be transferred across videos. This highlights the capability of learning actions that are specific to in-the-wild videos. In the absence of a common embodiment across videos, we are mainly able to learn latent actions that become localized in space, relative to the camera. Nonetheless, we are able to train a controller that maps known actions to latent ones, allowing us to use latent actions as a universal interface and solve planning tasks with our world model with similar performance as action-conditioned baselines. Our analyses and experiments provide a step towards scaling latent action models to the real world.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05230v1",
        "pdf": "https://arxiv.org/pdf/2601.05230v1"
      },
      "arxiv_id": "2601.05230v1",
      "comment": "37 pages, 25 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05227v1",
      "title": "Stochastic Deep Learning: A Probabilistic Framework for Modeling Uncertainty in Structured Temporal Data",
      "authors": [
        "James Rice"
      ],
      "abstract": "I propose a novel framework that integrates stochastic differential equations (SDEs) with deep generative models to improve uncertainty quantification in machine learning applications involving structured and temporal data. This approach, termed Stochastic Latent Differential Inference (SLDI), embeds an Itô SDE in the latent space of a variational autoencoder, allowing for flexible, continuous-time modeling of uncertainty while preserving a principled mathematical foundation. The drift and diffusion terms of the SDE are parameterized by neural networks, enabling data-driven inference and generalizing classical time series models to handle irregular sampling and complex dynamic structure.\n  A central theoretical contribution is the co-parameterization of the adjoint state with a dedicated neural network, forming a coupled forward-backward system that captures not only latent evolution but also gradient dynamics. I introduce a pathwise-regularized adjoint loss and analyze variance-reduced gradient flows through the lens of stochastic calculus, offering new tools for improving training stability in deep latent SDEs. My paper unifies and extends variational inference, continuous-time generative modeling, and control-theoretic optimization, providing a rigorous foundation for future developments in stochastic probabilistic machine learning.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "stat.ML",
        "cs.LG",
        "econ.EM",
        "math.ST"
      ],
      "primary_category": "stat.ML",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05227v1",
        "pdf": "https://arxiv.org/pdf/2601.05227v1"
      },
      "arxiv_id": "2601.05227v1",
      "comment": "20 pages, 6330 words",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05219v1",
      "title": "CAOS: Conformal Aggregation of One-Shot Predictors",
      "authors": [
        "Maja Waldron"
      ],
      "abstract": "One-shot prediction enables rapid adaptation of pretrained foundation models to new tasks using only one labeled example, but lacks principled uncertainty quantification. While conformal prediction provides finite-sample coverage guarantees, standard split conformal methods are inefficient in the one-shot setting due to data splitting and reliance on a single predictor. We propose Conformal Aggregation of One-Shot Predictors (CAOS), a conformal framework that adaptively aggregates multiple one-shot predictors and uses a leave-one-out calibration scheme to fully exploit scarce labeled data. Despite violating classical exchangeability assumptions, we prove that CAOS achieves valid marginal coverage using a monotonicity-based argument. Experiments on one-shot facial landmarking and RAFT text classification tasks show that CAOS produces substantially smaller prediction sets than split conformal baselines while maintaining reliable coverage.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05219v1",
        "pdf": "https://arxiv.org/pdf/2601.05219v1"
      },
      "arxiv_id": "2601.05219v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05215v1",
      "title": "MineNPC-Task: Task Suite for Memory-Aware Minecraft Agents",
      "authors": [
        "Tamil Sudaravan Mohan Doss",
        "Michael Xu",
        "Sudha Rao",
        "Andrew D. Wilson",
        "Balasaravanan Thoravi Kumaravel"
      ],
      "abstract": "We present \\textsc{MineNPC-Task}, a user-authored benchmark and evaluation harness for testing memory-aware, mixed-initiative LLM agents in open-world \\emph{Minecraft}. Rather than relying on synthetic prompts, tasks are elicited from formative and summative co-play with expert players, normalized into parametric templates with explicit preconditions and dependency structure, and paired with machine-checkable validators under a bounded-knowledge policy that forbids out-of-world shortcuts. The harness captures plan/act/memory events-including plan previews, targeted clarifications, memory reads and writes, precondition checks, and repair attempts and reports outcomes relative to the total number of attempted subtasks, derived from in-world evidence.\n  As an initial snapshot, we instantiate the framework with GPT-4o and evaluate \\textbf{216} subtasks across \\textbf{8} experienced players. We observe recurring breakdown patterns in code execution, inventory/tool handling, referencing, and navigation, alongside recoveries supported by mixed-initiative clarifications and lightweight memory. Participants rated interaction quality and interface usability positively, while highlighting the need for stronger memory persistence across tasks. We release the complete task suite, validators, logs, and harness to support transparent, reproducible evaluation of future memory-aware embodied agents.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05215v1",
        "pdf": "https://arxiv.org/pdf/2601.05215v1"
      },
      "arxiv_id": "2601.05215v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05214v1",
      "title": "Internal Representations as Indicators of Hallucinations in Agent Tool Selection",
      "authors": [
        "Kait Healy",
        "Bharathi Srinivasan",
        "Visakh Madathil",
        "Jing Wu"
      ],
      "abstract": "Large Language Models (LLMs) have shown remarkable capabilities in tool calling and tool usage, but suffer from hallucinations where they choose incorrect tools, provide malformed parameters and exhibit 'tool bypass' behavior by performing simulations and generating outputs instead of invoking specialized tools or external systems. This undermines the reliability of LLM based agents in production systems as it leads to inconsistent results, and bypasses security and audit controls. Such hallucinations in agent tool selection require early detection and error handling. Unlike existing hallucination detection methods that require multiple forward passes or external validation, we present a computationally efficient framework that detects tool-calling hallucinations in real-time by leveraging LLMs' internal representations during the same forward pass used for generation. We evaluate this approach on reasoning tasks across multiple domains, demonstrating strong detection performance (up to 86.4\\% accuracy) while maintaining real-time inference capabilities with minimal computational overhead, particularly excelling at detecting parameter-level hallucinations and inappropriate tool selections, critical for reliable agent deployment.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05214v1",
        "pdf": "https://arxiv.org/pdf/2601.05214v1"
      },
      "arxiv_id": "2601.05214v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05212v1",
      "title": "FlowLet: Conditional 3D Brain MRI Synthesis using Wavelet Flow Matching",
      "authors": [
        "Danilo Danese",
        "Angela Lombardi",
        "Matteo Attimonelli",
        "Giuseppe Fasano",
        "Tommaso Di Noia"
      ],
      "abstract": "Brain Magnetic Resonance Imaging (MRI) plays a central role in studying neurological development, aging, and diseases. One key application is Brain Age Prediction (BAP), which estimates an individual's biological brain age from MRI data. Effective BAP models require large, diverse, and age-balanced datasets, whereas existing 3D MRI datasets are demographically skewed, limiting fairness and generalizability. Acquiring new data is costly and ethically constrained, motivating generative data augmentation. Current generative methods are often based on latent diffusion models, which operate in learned low dimensional latent spaces to address the memory demands of volumetric MRI data. However, these methods are typically slow at inference, may introduce artifacts due to latent compression, and are rarely conditioned on age, thereby affecting the BAP performance. In this work, we propose FlowLet, a conditional generative framework that synthesizes age-conditioned 3D MRIs by leveraging flow matching within an invertible 3D wavelet domain, helping to avoid reconstruction artifacts and reducing computational demands. Experiments show that FlowLet generates high-fidelity volumes with few sampling steps. Training BAP models with data generated by FlowLet improves performance for underrepresented age groups, and region-based analysis confirms preservation of anatomical structures.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05212v1",
        "pdf": "https://arxiv.org/pdf/2601.05212v1"
      },
      "arxiv_id": "2601.05212v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05208v1",
      "title": "MoE3D: A Mixture-of-Experts Module for 3D Reconstruction",
      "authors": [
        "Zichen Wang",
        "Ang Cao",
        "Liam J. Wang",
        "Jeong Joon Park"
      ],
      "abstract": "MoE3D is a mixture-of-experts module designed to sharpen depth boundaries and mitigate flying-point artifacts (highlighted in red) of existing feed-forward 3D reconstruction models (left side). MoE3D predicts multiple candidate depth maps and fuses them via dynamic weighting (visualized by MoE weights on the right side). When integrated with a pre-trained 3D reconstruction backbone such as VGGT, it substantially enhances reconstruction quality with minimal additional computational overhead. Best viewed digitally.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05208v1",
        "pdf": "https://arxiv.org/pdf/2601.05208v1"
      },
      "arxiv_id": "2601.05208v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05205v1",
      "title": "EARL: Energy-Aware Optimization of Liquid State Machines for Pervasive AI",
      "authors": [
        "Zain Iqbal",
        "Lorenzo Valerio"
      ],
      "abstract": "Pervasive AI increasingly depends on on-device learning systems that deliver low-latency and energy-efficient computation under strict resource constraints. Liquid State Machines (LSMs) offer a promising approach for low-power temporal processing in pervasive and neuromorphic systems, but their deployment remains challenging due to high hyperparameter sensitivity and the computational cost of traditional optimization methods that ignore energy constraints. This work presents EARL, an energy-aware reinforcement learning framework that integrates Bayesian optimization with an adaptive reinforcement learning based selection policy to jointly optimize accuracy and energy consumption. EARL employs surrogate modeling for global exploration, reinforcement learning for dynamic candidate prioritization, and an early termination mechanism to eliminate redundant evaluations, substantially reducing computational overhead. Experiments on three benchmark datasets demonstrate that EARL achieves 6 to 15 percent higher accuracy, 60 to 80 percent lower energy consumption, and up to an order of magnitude reduction in optimization time compared to leading hyperparameter tuning frameworks. These results highlight the effectiveness of energy-aware adaptive search in improving the efficiency and scalability of LSMs for resource-constrained on-device AI applications.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.LG",
        "cs.PF"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05205v1",
        "pdf": "https://arxiv.org/pdf/2601.05205v1"
      },
      "arxiv_id": "2601.05205v1",
      "comment": "6 pages, 9 figures, 2 Tables, conference [Submitted in PerConAI-2026]",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05202v1",
      "title": "Stock Market Price Prediction using Neural Prophet with Deep Neural Network",
      "authors": [
        "Navin Chhibber",
        "Suneel Khemka",
        "Navneet Kumar Tyagi",
        "Rohit Tewari",
        "Bireswar Banerjee",
        "Piyush Ranjan"
      ],
      "abstract": "Stock market price prediction is a significant interdisciplinary research domain that depends at the intersection of finance, statistics, and economics. Forecasting Accurately predicting stock prices has always been a focal point for various researchers. However, existing statistical approaches for time-series prediction often fail to effectively forecast the probability range of future stock prices. Hence, to solve this problem, the Neural Prophet with a Deep Neural Network (NP-DNN) is proposed to predict stock market prices. The preprocessing technique used in this research is Z-score normalization, which normalizes stock price data by removing scale differences, making patterns easier to detect. Missing value imputation fills gaps in historical data, enhancing the models use of complete information for more accurate predictions. The Multi-Layer Perceptron (MLP) learns complex nonlinear relationships among stock market prices and extracts hidden patterns from the input data, thereby creating meaningful feature representations for better prediction accuracy. The proposed NP-DNN model achieved an accuracy of 99.21% compared with other approaches using the Fused Large Language Model. Keywords: deep neural network, forecasting stock prices, multi-layer perceptron, neural prophet, stock market price prediction.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05202v1",
        "pdf": "https://arxiv.org/pdf/2601.05202v1"
      },
      "arxiv_id": "2601.05202v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05201v1",
      "title": "Mechanisms of Prompt-Induced Hallucination in Vision-Language Models",
      "authors": [
        "William Rudman",
        "Michal Golovanevsky",
        "Dana Arad",
        "Yonatan Belinkov",
        "Ritambhara Singh",
        "Carsten Eickhoff",
        "Kyle Mahowald"
      ],
      "abstract": "Large vision-language models (VLMs) are highly capable, yet often hallucinate by favoring textual prompts over visual evidence. We study this failure mode in a controlled object-counting setting, where the prompt overstates the number of objects in the image (e.g., asking a model to describe four waterlilies when only three are present). At low object counts, models often correct the overestimation, but as the number of objects increases, they increasingly conform to the prompt regardless of the discrepancy. Through mechanistic analysis of three VLMs, we identify a small set of attention heads whose ablation substantially reduces prompt-induced hallucinations (PIH) by at least 40% without additional training. Across models, PIH-heads mediate prompt copying in model-specific ways. We characterize these differences and show that PIH ablation increases correction toward visual evidence. Our findings offer insights into the internal mechanisms driving prompt-induced hallucinations, revealing model-specific differences in how these behaviors are implemented.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05201v1",
        "pdf": "https://arxiv.org/pdf/2601.05201v1"
      },
      "arxiv_id": "2601.05201v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05194v1",
      "title": "An interpretable data-driven approach to optimizing clinical fall risk assessment",
      "authors": [
        "Fardin Ganjkhanloo",
        "Emmett Springer",
        "Erik H. Hoyer",
        "Daniel L. Young",
        "Holley Farley",
        "Kimia Ghobadi"
      ],
      "abstract": "In this study, we aim to better align fall risk prediction from the Johns Hopkins Fall Risk Assessment Tool (JHFRAT) with additional clinically meaningful measures via a data-driven modelling approach. We conducted a retrospective cohort analysis of 54,209 inpatient admissions from three Johns Hopkins Health System hospitals between March 2022 and October 2023. A total of 20,208 admissions were included as high fall risk encounters, and 13,941 were included as low fall risk encounters. To incorporate clinical knowledge and maintain interpretability, we employed constrained score optimization (CSO) models to reweight the JHFRAT scoring weights, while preserving its additive structure and clinical thresholds. Recalibration refers to adjusting item weights so that the resulting score can order encounters more consistently by the study's risk labels, and without changing the tool's form factor or deployment workflow. The model demonstrated significant improvements in predictive performance over the current JHFRAT (CSO AUC-ROC=0.91, JHFRAT AUC-ROC=0.86). This performance improvement translates to protecting an additional 35 high-risk patients per week across the Johns Hopkins Health System. The constrained score optimization models performed similarly with and without the EHR variables. Although the benchmark black-box model (XGBoost), improves upon the performance metrics of the knowledge-based constrained logistic regression (AUC-ROC=0.94), the CSO demonstrates more robustness to variations in risk labeling. This evidence-based approach provides a robust foundation for health systems to systematically enhance inpatient fall prevention protocols and patient safety using data-driven optimization techniques, contributing to improved risk assessment and resource allocation in healthcare settings.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05194v1",
        "pdf": "https://arxiv.org/pdf/2601.05194v1"
      },
      "arxiv_id": "2601.05194v1",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2510.20714",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05191v1",
      "title": "Cutting AI Research Costs: How Task-Aware Compression Makes Large Language Model Agents Affordable",
      "authors": [
        "Zuhair Ahmed Khan Taha",
        "Mohammed Mudassir Uddin",
        "Shahnawaz Alam"
      ],
      "abstract": "When researchers deploy large language models for autonomous tasks like reviewing literature or generating hypotheses, the computational bills add up quickly. A single research session using a 70-billion parameter model can cost around $127 in cloud fees, putting these tools out of reach for many academic labs. We developed AgentCompress to tackle this problem head-on. The core idea came from a simple observation during our own work: writing a novel hypothesis clearly demands more from the model than reformatting a bibliography. Why should both tasks run at full precision? Our system uses a small neural network to gauge how hard each incoming task will be, based only on its opening words, then routes it to a suitably compressed model variant. The decision happens in under a millisecond. Testing across 500 research workflows in four scientific fields, we cut compute costs by 68.3% while keeping 96.2% of the original success rate. For labs watching their budgets, this could mean the difference between running experiments and sitting on the sidelines",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05191v1",
        "pdf": "https://arxiv.org/pdf/2601.05191v1"
      },
      "arxiv_id": "2601.05191v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05187v1",
      "title": "SimuAgent: An LLM-Based Simulink Modeling Assistant Enhanced with Reinforcement Learning",
      "authors": [
        "Yanchang Liang",
        "Xiaowei Zhao"
      ],
      "abstract": "Large language models (LLMs) have revolutionized text-based code automation, but their potential in graph-oriented engineering workflows remains under-explored. We introduce SimuAgent, an LLM-powered modeling and simulation agent tailored for Simulink. SimuAgent replaces verbose XML with a concise, dictionary-style Python representation, dramatically cutting token counts, improving interpretability, and enabling fast, in-process simulation. A lightweight plan-execute architecture, trained in two stages, equips the agent with both low-level tool skills and high-level design reasoning. To tackle sparse rewards in long-horizon tasks, we propose Reflection-GRPO (ReGRPO), which augments Group Relative Policy Optimization (GRPO) with self-reflection traces that supply rich intermediate feedback, accelerating convergence and boosting robustness. Experiments on SimuBench, our newly released benchmark comprising 5300 multi-domain modeling tasks, show that a Qwen2.5-7B model fine-tuned with SimuAgent converges faster and achieves higher modeling accuracy than standard RL baselines, and even surpasses GPT-4o when evaluated with few-shot prompting on the same benchmark. Ablations confirm that the two-stage curriculum and abstract-reconstruct data augmentation further enhance generalization. SimuAgent trains and runs entirely on-premise with modest hardware, delivering a privacy-preserving, cost-effective solution for industrial model-driven engineering. SimuAgent bridges the gap between LLMs and graphical modeling environments, offering a practical solution for AI-assisted engineering design in industrial settings.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05187v1",
        "pdf": "https://arxiv.org/pdf/2601.05187v1"
      },
      "arxiv_id": "2601.05187v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05184v1",
      "title": "Observations and Remedies for Large Language Model Bias in Self-Consuming Performative Loop",
      "authors": [
        "Yaxuan Wang",
        "Zhongteng Cai",
        "Yujia Bao",
        "Xueru Zhang",
        "Yang Liu"
      ],
      "abstract": "The rapid advancement of large language models (LLMs) has led to growing interest in using synthetic data to train future models. However, this creates a self-consuming retraining loop, where models are trained on their own outputs and may cause performance drops and induce emerging biases. In real-world applications, previously deployed LLMs may influence the data they generate, leading to a dynamic system driven by user feedback. For example, if a model continues to underserve users from a group, less query data will be collected from this particular demographic of users. In this study, we introduce the concept of \\textbf{S}elf-\\textbf{C}onsuming \\textbf{P}erformative \\textbf{L}oop (\\textbf{SCPL}) and investigate the role of synthetic data in shaping bias during these dynamic iterative training processes under controlled performative feedback. This controlled setting is motivated by the inaccessibility of real-world user preference data from dynamic production systems, and enables us to isolate and analyze feedback-driven bias evolution in a principled manner. We focus on two types of loops, including the typical retraining setting and the incremental fine-tuning setting, which is largely underexplored. Through experiments on three real-world tasks, we find that the performative loop increases preference bias and decreases disparate bias. We design a reward-based rejection sampling strategy to mitigate the bias, moving towards more trustworthy self-improving systems.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05184v1",
        "pdf": "https://arxiv.org/pdf/2601.05184v1"
      },
      "arxiv_id": "2601.05184v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05181v1",
      "title": "Spacecube: A fast inverse hyperspectral georectification system",
      "authors": [
        "Thomas P. Watson",
        "Eddie L. Jacobs"
      ],
      "abstract": "Hyperspectral cameras provide numerous advantages in terms of the utility of the data captured. They capture hundreds of data points per sample (pixel) instead of only the few of RGB or multispectral camera systems. Aerial systems sense such data remotely, but the data must be georectified to produce consistent images before analysis. We find the traditional direct georectification method to be slow, and it is prone to artifacts. To address its downsides, we propose Spacecube, a program that implements a complete hyperspectral georectification pipeline, including our own fast inverse georectification technique, using OpenGL graphics programming technologies. Spacecube operates substantially faster than real-time and eliminates pixel coverage artifacts. It facilitates high quality interactive viewing, data exploration, and export of final products. We release Spacecube's source code publicly for the community to use.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "eess.IV",
        "cs.GR"
      ],
      "primary_category": "eess.IV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05181v1",
        "pdf": "https://arxiv.org/pdf/2601.05181v1"
      },
      "arxiv_id": "2601.05181v1",
      "comment": "9 pages, 16 figures. source code available after peer-reviewed publication",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2601.05175v1",
      "title": "VideoAuto-R1: Video Auto Reasoning via Thinking Once, Answering Twice",
      "authors": [
        "Shuming Liu",
        "Mingchen Zhuge",
        "Changsheng Zhao",
        "Jun Chen",
        "Lemeng Wu",
        "Zechun Liu",
        "Chenchen Zhu",
        "Zhipeng Cai",
        "Chong Zhou",
        "Haozhe Liu",
        "Ernie Chang",
        "Saksham Suri",
        "Hongyu Xu",
        "Qi Qian",
        "Wei Wen",
        "Balakrishnan Varadarajan",
        "Zhuang Liu",
        "Hu Xu",
        "Florian Bordes",
        "Raghuraman Krishnamoorthi",
        "Bernard Ghanem",
        "Vikas Chandra",
        "Yunyang Xiong"
      ],
      "abstract": "Chain-of-thought (CoT) reasoning has emerged as a powerful tool for multimodal large language models on video understanding tasks. However, its necessity and advantages over direct answering remain underexplored. In this paper, we first demonstrate that for RL-trained video models, direct answering often matches or even surpasses CoT performance, despite CoT producing step-by-step analyses at a higher computational cost. Motivated by this, we propose VideoAuto-R1, a video understanding framework that adopts a reason-when-necessary strategy. During training, our approach follows a Thinking Once, Answering Twice paradigm: the model first generates an initial answer, then performs reasoning, and finally outputs a reviewed answer. Both answers are supervised via verifiable rewards. During inference, the model uses the confidence score of the initial answer to determine whether to proceed with reasoning. Across video QA and grounding benchmarks, VideoAuto-R1 achieves state-of-the-art accuracy with significantly improved efficiency, reducing the average response length by ~3.3x, e.g., from 149 to just 44 tokens. Moreover, we observe a low rate of thinking-mode activation on perception-oriented tasks, but a higher rate on reasoning-intensive tasks. This suggests that explicit language-based reasoning is generally beneficial but not always necessary.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05175v1",
        "pdf": "https://arxiv.org/pdf/2601.05175v1"
      },
      "arxiv_id": "2601.05175v1",
      "comment": "Project page: https://ivul-kaust.github.io/projects/videoauto-r1/",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2601.05174v1",
      "title": "FaST: Efficient and Effective Long-Horizon Forecasting for Large-Scale Spatial-Temporal Graphs via Mixture-of-Experts",
      "authors": [
        "Yiji Zhao",
        "Zihao Zhong",
        "Ao Wang",
        "Haomin Wen",
        "Ming Jin",
        "Yuxuan Liang",
        "Huaiyu Wan",
        "Hao Wu"
      ],
      "abstract": "Spatial-Temporal Graph (STG) forecasting on large-scale networks has garnered significant attention. However, existing models predominantly focus on short-horizon predictions and suffer from notorious computational costs and memory consumption when scaling to long-horizon predictions and large graphs. Targeting the above challenges, we present FaST, an effective and efficient framework based on heterogeneity-aware Mixture-of-Experts (MoEs) for long-horizon and large-scale STG forecasting, which unlocks one-week-ahead (672 steps at a 15-minute granularity) prediction with thousands of nodes. FaST is underpinned by two key innovations. First, an adaptive graph agent attention mechanism is proposed to alleviate the computational burden inherent in conventional graph convolution and self-attention modules when applied to large-scale graphs. Second, we propose a new parallel MoE module that replaces traditional feed-forward networks with Gated Linear Units (GLUs), enabling an efficient and scalable parallel structure. Extensive experiments on real-world datasets demonstrate that FaST not only delivers superior long-horizon predictive accuracy but also achieves remarkable computational efficiency compared to state-of-the-art baselines. Our source code is available at: https://github.com/yijizhao/FaST.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05174v1",
        "pdf": "https://arxiv.org/pdf/2601.05174v1"
      },
      "arxiv_id": "2601.05174v1",
      "comment": "Accepted to KDD 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05172v1",
      "title": "CoV: Chain-of-View Prompting for Spatial Reasoning",
      "authors": [
        "Haoyu Zhao",
        "Akide Liu",
        "Zeyu Zhang",
        "Weijie Wang",
        "Feng Chen",
        "Ruihan Zhu",
        "Gholamreza Haffari",
        "Bohan Zhuang"
      ],
      "abstract": "Embodied question answering (EQA) in 3D environments often requires collecting context that is distributed across multiple viewpoints and partially occluded. However, most recent vision--language models (VLMs) are constrained to a fixed and finite set of input views, which limits their ability to acquire question-relevant context at inference time and hinders complex spatial reasoning. We propose Chain-of-View (CoV) prompting, a training-free, test-time reasoning framework that transforms a VLM into an active viewpoint reasoner through a coarse-to-fine exploration process. CoV first employs a View Selection agent to filter redundant frames and identify question-aligned anchor views. It then performs fine-grained view adjustment by interleaving iterative reasoning with discrete camera actions, obtaining new observations from the underlying 3D scene representation until sufficient context is gathered or a step budget is reached.\n  We evaluate CoV on OpenEQA across four mainstream VLMs and obtain an average +11.56\\% improvement in LLM-Match, with a maximum gain of +13.62\\% on Qwen3-VL-Flash. CoV further exhibits test-time scaling: increasing the minimum action budget yields an additional +2.51\\% average improvement, peaking at +3.73\\% on Gemini-2.5-Flash. On ScanQA and SQA3D, CoV delivers strong performance (e.g., 116 CIDEr / 31.9 EM@1 on ScanQA and 51.1 EM@1 on SQA3D). Overall, these results suggest that question-aligned view selection coupled with open-view search is an effective, model-agnostic strategy for improving spatial reasoning in 3D EQA without additional training.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05172v1",
        "pdf": "https://arxiv.org/pdf/2601.05172v1"
      },
      "arxiv_id": "2601.05172v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05167v1",
      "title": "RelayLLM: Efficient Reasoning via Collaborative Decoding",
      "authors": [
        "Chengsong Huang",
        "Tong Zheng",
        "Langlin Huang",
        "Jinyuan Li",
        "Haolin Liu",
        "Jiaxin Huang"
      ],
      "abstract": "Large Language Models (LLMs) for complex reasoning is often hindered by high computational costs and latency, while resource-efficient Small Language Models (SLMs) typically lack the necessary reasoning capacity. Existing collaborative approaches, such as cascading or routing, operate at a coarse granularity by offloading entire queries to LLMs, resulting in significant computational waste when the SLM is capable of handling the majority of reasoning steps. To address this, we propose RelayLLM, a novel framework for efficient reasoning via token-level collaborative decoding. Unlike routers, RelayLLM empowers the SLM to act as an active controller that dynamically invokes the LLM only for critical tokens via a special command, effectively \"relaying\" the generation process. We introduce a two-stage training framework, including warm-up and Group Relative Policy Optimization (GRPO) to teach the model to balance independence with strategic help-seeking. Empirical results across six benchmarks demonstrate that RelayLLM achieves an average accuracy of 49.52%, effectively bridging the performance gap between the two models. Notably, this is achieved by invoking the LLM for only 1.07% of the total generated tokens, offering a 98.2% cost reduction compared to performance-matched random routers.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05167v1",
        "pdf": "https://arxiv.org/pdf/2601.05167v1"
      },
      "arxiv_id": "2601.05167v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05162v1",
      "title": "GenAI-DrawIO-Creator: A Framework for Automated Diagram Generation",
      "authors": [
        "Jinze Yu",
        "Dayuan Jiang"
      ],
      "abstract": "Diagrams are crucial for communicating complex information, yet creating and modifying them remains a labor-intensive task. We present GenAI-DrawIO-Creator, a novel framework that leverages Large Language Models (LLMs) to automate diagram generation and manipulation in the structured XML format used by draw.io. Our system integrates Claude 3.7 to reason about structured visual data and produce valid diagram representations. Key contributions include a high-level system design enabling real-time diagram updates, specialized prompt engineering and error-checking to ensure well-formed XML outputs. We demonstrate a working prototype capable of generating accurate diagrams (such as network architectures and flowcharts) from natural language or code, and even replicating diagrams from images. Simulated evaluations show that our approach significantly reduces diagram creation time and produces outputs with high structural fidelity. Our results highlight the promise of Claude 3.7 in handling structured visual reasoning tasks and lay the groundwork for future research in AI-assisted diagramming applications.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.GR",
        "cs.CV"
      ],
      "primary_category": "cs.GR",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05162v1",
        "pdf": "https://arxiv.org/pdf/2601.05162v1"
      },
      "arxiv_id": "2601.05162v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05159v1",
      "title": "Vision-Language Introspection: Mitigating Overconfident Hallucinations in MLLMs via Interpretable Bi-Causal Steering",
      "authors": [
        "Shuliang Liu",
        "Songbo Yang",
        "Dong Fang",
        "Sihang Jia",
        "Yuqi Tang",
        "Lingfeng Su",
        "Ruoshui Peng",
        "Yibo Yan",
        "Xin Zou",
        "Xuming Hu"
      ],
      "abstract": "Object hallucination critically undermines the reliability of Multimodal Large Language Models, often stemming from a fundamental failure in cognitive introspection, where models blindly trust linguistic priors over specific visual evidence. Existing mitigations remain limited: contrastive decoding approaches operate superficially without rectifying internal semantic misalignments, while current latent steering methods rely on static vectors that lack instance-specific precision. We introduce Vision-Language Introspection (VLI), a training-free inference framework that simulates a metacognitive self-correction process. VLI first performs Attributive Introspection to diagnose hallucination risks via probabilistic conflict detection and localize the causal visual anchors. It then employs Interpretable Bi-Causal Steering to actively modulate the inference process, dynamically isolating visual evidence from background noise while neutralizing blind confidence through adaptive calibration. VLI achieves state-of-the-art performance on advanced models, reducing object hallucination rates by 12.67% on MMHal-Bench and improving accuracy by 5.8% on POPE.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05159v1",
        "pdf": "https://arxiv.org/pdf/2601.05159v1"
      },
      "arxiv_id": "2601.05159v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05157v1",
      "title": "Learning Mixture Models via Efficient High-dimensional Sparse Fourier Transforms",
      "authors": [
        "Alkis Kalavasis",
        "Pravesh K. Kothari",
        "Shuchen Li",
        "Manolis Zampetakis"
      ],
      "abstract": "In this work, we give a ${\\rm poly}(d,k)$ time and sample algorithm for efficiently learning the parameters of a mixture of $k$ spherical distributions in $d$ dimensions. Unlike all previous methods, our techniques apply to heavy-tailed distributions and include examples that do not even have finite covariances. Our method succeeds whenever the cluster distributions have a characteristic function with sufficiently heavy tails. Such distributions include the Laplace distribution but crucially exclude Gaussians.\n  All previous methods for learning mixture models relied implicitly or explicitly on the low-degree moments. Even for the case of Laplace distributions, we prove that any such algorithm must use super-polynomially many samples. Our method thus adds to the short list of techniques that bypass the limitations of the method of moments.\n  Somewhat surprisingly, our algorithm does not require any minimum separation between the cluster means. This is in stark contrast to spherical Gaussian mixtures where a minimum $\\ell_2$-separation is provably necessary even information-theoretically [Regev and Vijayaraghavan '17]. Our methods compose well with existing techniques and allow obtaining ''best of both worlds\" guarantees for mixtures where every component either has a heavy-tailed characteristic function or has a sub-Gaussian tail with a light-tailed characteristic function.\n  Our algorithm is based on a new approach to learning mixture models via efficient high-dimensional sparse Fourier transforms. We believe that this method will find more applications to statistical estimation. As an example, we give an algorithm for consistent robust mean estimation against noise-oblivious adversaries, a model practically motivated by the literature on multiple hypothesis testing. It was formally proposed in a recent Master's thesis by one of the authors, and has already inspired follow-up works.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.DS",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.DS",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05157v1",
        "pdf": "https://arxiv.org/pdf/2601.05157v1"
      },
      "arxiv_id": "2601.05157v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05152v1",
      "title": "Safe Continual Reinforcement Learning Methods for Nonstationary Environments. Towards a Survey of the State of the Art",
      "authors": [
        "Timofey Tomashevskiy"
      ],
      "abstract": "This work provides a state-of-the-art survey of continual safe online reinforcement learning (COSRL) methods. We discuss theoretical aspects, challenges, and open questions in building continual online safe reinforcement learning algorithms. We provide the taxonomy and the details of continual online safe reinforcement learning methods based on the type of safe learning mechanism that takes adaptation to nonstationarity into account. We categorize safety constraints formulation for online reinforcement learning algorithms, and finally, we discuss prospects for creating reliable, safe online learning algorithms.\n  Keywords: safe RL in nonstationary environments, safe continual reinforcement learning under nonstationarity, HM-MDP, NSMDP, POMDP, safe POMDP, constraints for continual learning, safe continual reinforcement learning review, safe continual reinforcement learning survey, safe continual reinforcement learning, safe online learning under distribution shift, safe continual online adaptation, safe reinforcement learning, safe exploration, safe adaptation, constrained Markov decision processes, safe reinforcement learning, partially observable Markov decision process, safe reinforcement learning and hidden Markov decision processes, Safe Online Reinforcement Learning, safe online reinforcement learning, safe online reinforcement learning, safe meta-learning, safe meta-reinforcement learning, safe context-based reinforcement learning, formulating safety constraints for continual learning",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05152v1",
        "pdf": "https://arxiv.org/pdf/2601.05152v1"
      },
      "arxiv_id": "2601.05152v1",
      "comment": "20 pages, 4 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05151v1",
      "title": "ROOFS: RObust biOmarker Feature Selection",
      "authors": [
        "Anastasiia Bakhmach",
        "Paul Dufossé",
        "Andrea Vaglio",
        "Florence Monville",
        "Laurent Greillier",
        "Fabrice Barlési",
        "Sébastien Benzekry"
      ],
      "abstract": "Feature selection (FS) is essential for biomarker discovery and in the analysis of biomedical datasets. However, challenges such as high-dimensional feature space, low sample size, multicollinearity, and missing values make FS non-trivial. Moreover, FS performances vary across datasets and predictive tasks. We propose roofs, a Python package available at https://gitlab.inria.fr/compo/roofs, designed to help researchers in the choice of FS method adapted to their problem. Roofs benchmarks multiple FS methods on the user's data and generates reports that summarize a comprehensive set of evaluation metrics, including downstream predictive performance estimated using optimism correction, stability, reliability of individual features, and true positive and false positive rates assessed on semi-synthetic data with a simulated outcome. We demonstrate the utility of roofs on data from the PIONeeR clinical trial, aimed at identifying predictors of resistance to anti-PD-(L)1 immunotherapy in lung cancer. The PIONeeR dataset contained 374 multi-source blood and tumor biomarkers from 435 patients. A reduced subset of 214 features was obtained through iterative variance inflation factor pre-filtering. Of the 34 FS methods gathered in roofs, we evaluated 23 in combination with 11 classifiers (253 models in total) and identified a filter based on the union of Benjamini-Hochberg false discovery rate-adjusted p-values from t-test and logistic regression as the optimal approach, outperforming other methods including the widely used LASSO. We conclude that comprehensive benchmarking with roofs has the potential to improve the robustness and reproducibility of FS discoveries and increase the translational value of clinical models.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05151v1",
        "pdf": "https://arxiv.org/pdf/2601.05151v1"
      },
      "arxiv_id": "2601.05151v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05149v1",
      "title": "Multi-Scale Local Speculative Decoding for Image Generation",
      "authors": [
        "Elia Peruzzo",
        "Guillaume Sautière",
        "Amirhossein Habibian"
      ],
      "abstract": "Autoregressive (AR) models have achieved remarkable success in image synthesis, yet their sequential nature imposes significant latency constraints. Speculative Decoding offers a promising avenue for acceleration, but existing approaches are limited by token-level ambiguity and lack of spatial awareness. In this work, we introduce Multi-Scale Local Speculative Decoding (MuLo-SD), a novel framework that combines multi-resolution drafting with spatially informed verification to accelerate AR image generation. Our method leverages a low-resolution drafter paired with learned up-samplers to propose candidate image tokens, which are then verified in parallel by a high-resolution target model. Crucially, we incorporate a local rejection and resampling mechanism, enabling efficient correction of draft errors by focusing on spatial neighborhoods rather than raster-scan resampling after the first rejection. We demonstrate that MuLo-SD achieves substantial speedups - up to $\\mathbf{1.7\\times}$ - outperforming strong speculative decoding baselines such as EAGLE-2 and LANTERN in terms of acceleration, while maintaining comparable semantic alignment and perceptual quality. These results are validated using GenEval, DPG-Bench, and FID/HPSv2 on the MS-COCO 5k validation split. Extensive ablations highlight the impact of up-sampling design, probability pooling, and local rejection and resampling with neighborhood expansion. Our approach sets a new state-of-the-art in speculative decoding for image synthesis, bridging the gap between efficiency and fidelity.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05149v1",
        "pdf": "https://arxiv.org/pdf/2601.05149v1"
      },
      "arxiv_id": "2601.05149v1",
      "comment": "Project page is available at https://qualcomm-ai-research.github.io/mulo-sd-webpage",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2601.05148v1",
      "title": "Atlas 2 -- Foundation models for clinical deployment",
      "authors": [
        "Maximilian Alber",
        "Timo Milbich",
        "Alexandra Carpen-Amarie",
        "Stephan Tietz",
        "Jonas Dippel",
        "Lukas Muttenthaler",
        "Beatriz Perez Cancer",
        "Alessandro Benetti",
        "Panos Korfiatis",
        "Elias Eulig",
        "Jérôme Lüscher",
        "Jiasen Wu",
        "Sayed Abid Hashimi",
        "Gabriel Dernbach",
        "Simon Schallenberg",
        "Neelay Shah",
        "Moritz Krügener",
        "Aniruddh Jammoria",
        "Jake Matras",
        "Patrick Duffy",
        "Matt Redlon",
        "Philipp Jurmeister",
        "David Horst",
        "Lukas Ruff",
        "Klaus-Robert Müller",
        "Frederick Klauschen",
        "Andrew Norgan"
      ],
      "abstract": "Pathology foundation models substantially advanced the possibilities in computational pathology -- yet tradeoffs in terms of performance, robustness, and computational requirements remained, which limited their clinical deployment. In this report, we present Atlas 2, Atlas 2-B, and Atlas 2-S, three pathology vision foundation models which bridge these shortcomings by showing state-of-the-art performance in prediction performance, robustness, and resource efficiency in a comprehensive evaluation across eighty public benchmarks. Our models were trained on the largest pathology foundation model dataset to date comprising 5.5 million histopathology whole slide images, collected from three medical institutions Charité - Universtätsmedizin Berlin, LMU Munich, and Mayo Clinic.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05148v1",
        "pdf": "https://arxiv.org/pdf/2601.05148v1"
      },
      "arxiv_id": "2601.05148v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05144v1",
      "title": "Distilling the Thought, Watermarking the Answer: A Principle Semantic Guided Watermark for Large Reasoning Models",
      "authors": [
        "Shuliang Liu",
        "Xingyu Li",
        "Hongyi Liu",
        "Yibo Yan",
        "Bingchen Duan",
        "Qi Zheng",
        "Dong Fang",
        "Lingfeng Su",
        "Xuming Hu"
      ],
      "abstract": "Reasoning Large Language Models (RLLMs) excelling in complex tasks present unique challenges for digital watermarking, as existing methods often disrupt logical coherence or incur high computational costs. Token-based watermarking techniques can corrupt the reasoning flow by applying pseudo-random biases, while semantic-aware approaches improve quality but introduce significant latency or require auxiliary models. This paper introduces ReasonMark, a novel watermarking framework specifically designed for reasoning-intensive LLMs. Our approach decouples generation into an undisturbed Thinking Phase and a watermarked Answering Phase. We propose a Criticality Score to identify semantically pivotal tokens from the reasoning trace, which are distilled into a Principal Semantic Vector (PSV). The PSV then guides a semantically-adaptive mechanism that modulates watermark strength based on token-PSV alignment, ensuring robustness without compromising logical integrity. Extensive experiments show ReasonMark surpasses state-of-the-art methods by reducing text Perplexity by 0.35, increasing translation BLEU score by 0.164, and raising mathematical accuracy by 0.67 points. These advancements are achieved alongside a 0.34% higher watermark detection AUC and stronger robustness to attacks, all with a negligible increase in latency. This work enables the traceable and trustworthy deployment of reasoning LLMs in real-world applications.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05144v1",
        "pdf": "https://arxiv.org/pdf/2601.05144v1"
      },
      "arxiv_id": "2601.05144v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05143v1",
      "title": "A Lightweight and Explainable Vision-Language Framework for Crop Disease Visual Question Answering",
      "authors": [
        "Md. Zahid Hossain",
        "Most. Sharmin Sultana Samu",
        "Md. Rakibul Islam",
        "Md. Siam Ansary"
      ],
      "abstract": "Visual question answering for crop disease analysis requires accurate visual understanding and reliable language generation. This work presents a lightweight vision-language framework for crop and disease identification from leaf images. The proposed approach combines a Swin Transformer vision encoder with sequence-to-sequence language decoders. A two-stage training strategy is adopted to improve visual representation learning and cross-modal alignment. The model is evaluated on a large-scale crop disease dataset using classification and natural language generation metrics. Experimental results show high accuracy for both crop and disease identification. The framework also achieves strong performance on BLEU, ROUGE and BERTScore. Our proposed models outperform large-scale vision-language baselines while using significantly fewer parameters. Explainability is assessed using Grad-CAM and token-level attribution. Qualitative results demonstrate robust performance under diverse user-driven queries. These findings highlight the effectiveness of task-specific visual pretraining for crop disease visual question answering.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.CV",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05143v1",
        "pdf": "https://arxiv.org/pdf/2601.05143v1"
      },
      "arxiv_id": "2601.05143v1",
      "comment": "Preprint, manuscript is under review",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05138v1",
      "title": "VerseCrafter: Dynamic Realistic Video World Model with 4D Geometric Control",
      "authors": [
        "Sixiao Zheng",
        "Minghao Yin",
        "Wenbo Hu",
        "Xiaoyu Li",
        "Ying Shan",
        "Yanwei Fu"
      ],
      "abstract": "Video world models aim to simulate dynamic, real-world environments, yet existing methods struggle to provide unified and precise control over camera and multi-object motion, as videos inherently operate dynamics in the projected 2D image plane. To bridge this gap, we introduce VerseCrafter, a 4D-aware video world model that enables explicit and coherent control over both camera and object dynamics within a unified 4D geometric world state. Our approach is centered on a novel 4D Geometric Control representation, which encodes the world state through a static background point cloud and per-object 3D Gaussian trajectories. This representation captures not only an object's path but also its probabilistic 3D occupancy over time, offering a flexible, category-agnostic alternative to rigid bounding boxes or parametric models. These 4D controls are rendered into conditioning signals for a pretrained video diffusion model, enabling the generation of high-fidelity, view-consistent videos that precisely adhere to the specified dynamics. Unfortunately, another major challenge lies in the scarcity of large-scale training data with explicit 4D annotations. We address this by developing an automatic data engine that extracts the required 4D controls from in-the-wild videos, allowing us to train our model on a massive and diverse dataset.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05138v1",
        "pdf": "https://arxiv.org/pdf/2601.05138v1"
      },
      "arxiv_id": "2601.05138v1",
      "comment": "Project Page: https://sixiaozheng.github.io/VerseCrafter_page/",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2601.05137v1",
      "title": "Neural Algorithmic Reasoning for Approximate $k$-Coloring with Recursive Warm Starts",
      "authors": [
        "Knut Vanderbush",
        "Melanie Weber"
      ],
      "abstract": "Node coloring is the task of assigning colors to the nodes of a graph such that no two adjacent nodes have the same color, while using as few colors as possible. It is the most widely studied instance of graph coloring and of central importance in graph theory; major results include the Four Color Theorem and work on the Hadwiger-Nelson Problem. As an abstraction of classical combinatorial optimization tasks, such as scheduling and resource allocation, it is also rich in practical applications. Here, we focus on a relaxed version, approximate $k$-coloring, which is the task of assigning at most $k$ colors to the nodes of a graph such that the number of edges whose vertices have the same color is approximately minimized. While classical approaches leverage mathematical programming or SAT solvers, recent studies have explored the use of machine learning. We follow this route and explore the use of graph neural networks (GNNs) for node coloring. We first present an optimized differentiable algorithm that improves a prior approach by Schuetz et al. with orthogonal node feature initialization and a loss function that penalizes conflicting edges more heavily when their endpoints have higher degree; the latter inspired by the classical result that a graph is $k$-colorable if and only if its $k$-core is $k$-colorable. Next, we introduce a lightweight greedy local search algorithm and show that it may be improved by recursively computing a $(k-1)$-coloring to use as a warm start. We then show that applying such recursive warm starts to the GNN approach leads to further improvements. Numerical experiments on a range of different graph structures show that while the local search algorithms perform best on small inputs, the GNN exhibits superior performance at scale. The recursive warm start may be of independent interest beyond graph coloring for local search methods for combinatorial optimization.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "math.CO",
        "cs.LG"
      ],
      "primary_category": "math.CO",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05137v1",
        "pdf": "https://arxiv.org/pdf/2601.05137v1"
      },
      "arxiv_id": "2601.05137v1",
      "comment": "33 pages, 10 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05134v1",
      "title": "Sequential Subspace Noise Injection Prevents Accuracy Collapse in Certified Unlearning",
      "authors": [
        "Polina Dolgova",
        "Sebastian U. Stich"
      ],
      "abstract": "Certified unlearning based on differential privacy offers strong guarantees but remains largely impractical: the noisy fine-tuning approaches proposed so far achieve these guarantees but severely reduce model accuracy. We propose sequential noise scheduling, which distributes the noise budget across orthogonal subspaces of the parameter space, rather than injecting it all at once. This simple modification mitigates the destructive effect of noise while preserving the original certification guarantees. We extend the analysis of noisy fine-tuning to the subspace setting, proving that the same $(\\varepsilon,δ)$ privacy budget is retained. Empirical results on image classification benchmarks show that our approach substantially improves accuracy after unlearning while remaining robust to membership inference attacks. These results show that certified unlearning can achieve both rigorous guarantees and practical utility.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05134v1",
        "pdf": "https://arxiv.org/pdf/2601.05134v1"
      },
      "arxiv_id": "2601.05134v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05125v1",
      "title": "VERSE: Visual Embedding Reduction and Space Exploration. Clustering-Guided Insights for Training Data Enhancement in Visually-Rich Document Understanding",
      "authors": [
        "Ignacio de Rodrigo",
        "Alvaro J. Lopez-Lopez",
        "Jaime Boal"
      ],
      "abstract": "This work introduces VERSE, a methodology for analyzing and improving Vision-Language Models applied to Visually-rich Document Understanding by exploring their visual embedding space. VERSE enables the visualization of latent representations, supporting the assessment of model feasibility. It also facilitates the identification of problematic regions and guides the generation of synthetic data to enhance performance in those clusters. We validate the methodology by training on the synthetic MERIT Dataset and evaluating on its real-world counterpart, MERIT Secret. Results show that VERSE helps uncover the visual features associated with error-prone clusters, and that retraining with samples containing these features substantially boosts F1 performance without degrading generalization. Furthermore, we demonstrate that on-premise models such as Donut and Idefics2, when optimized with VERSE, match or even surpass the performance of SaaS solutions like GPT-4 and Pixtral.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05125v1",
        "pdf": "https://arxiv.org/pdf/2601.05125v1"
      },
      "arxiv_id": "2601.05125v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05124v1",
      "title": "Re-Align: Structured Reasoning-guided Alignment for In-Context Image Generation and Editing",
      "authors": [
        "Runze He",
        "Yiji Cheng",
        "Tiankai Hang",
        "Zhimin Li",
        "Yu Xu",
        "Zijin Yin",
        "Shiyi Zhang",
        "Wenxun Dai",
        "Penghui Du",
        "Ao Ma",
        "Chunyu Wang",
        "Qinglin Lu",
        "Jizhong Han",
        "Jiao Dai"
      ],
      "abstract": "In-context image generation and editing (ICGE) enables users to specify visual concepts through interleaved image-text prompts, demanding precise understanding and faithful execution of user intent. Although recent unified multimodal models exhibit promising understanding capabilities, these strengths often fail to transfer effectively to image generation. We introduce Re-Align, a unified framework that bridges the gap between understanding and generation through structured reasoning-guided alignment. At its core lies the In-Context Chain-of-Thought (IC-CoT), a structured reasoning paradigm that decouples semantic guidance and reference association, providing clear textual target and mitigating confusion among reference images. Furthermore, Re-Align introduces an effective RL training scheme that leverages a surrogate reward to measure the alignment between structured reasoning text and the generated image, thereby improving the model's overall performance on ICGE tasks. Extensive experiments verify that Re-Align outperforms competitive methods of comparable model scale and resources on both in-context image generation and editing tasks.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05124v1",
        "pdf": "https://arxiv.org/pdf/2601.05124v1"
      },
      "arxiv_id": "2601.05124v1",
      "comment": "13 pages, 9 figures, project page: https://github.com/hrz2000/realign",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2601.05116v1",
      "title": "From Rays to Projections: Better Inputs for Feed-Forward View Synthesis",
      "authors": [
        "Zirui Wu",
        "Zeren Jiang",
        "Martin R. Oswald",
        "Jie Song"
      ],
      "abstract": "Feed-forward view synthesis models predict a novel view in a single pass with minimal 3D inductive bias. Existing works encode cameras as Plücker ray maps, which tie predictions to the arbitrary world coordinate gauge and make them sensitive to small camera transformations, thereby undermining geometric consistency. In this paper, we ask what inputs best condition a model for robust and consistent view synthesis. We propose projective conditioning, which replaces raw camera parameters with a target-view projective cue that provides a stable 2D input. This reframes the task from a brittle geometric regression problem in ray space to a well-conditioned target-view image-to-image translation problem. Additionally, we introduce a masked autoencoding pretraining strategy tailored to this cue, enabling the use of large-scale uncalibrated data for pretraining. Our method shows improved fidelity and stronger cross-view consistency compared to ray-conditioned baselines on our view-consistency benchmark. It also achieves state-of-the-art quality on standard novel view synthesis benchmarks.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05116v1",
        "pdf": "https://arxiv.org/pdf/2601.05116v1"
      },
      "arxiv_id": "2601.05116v1",
      "comment": "Project Page: https://wuzirui.github.io/pvsm-web",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2601.05114v1",
      "title": "Evaluative Fingerprints: Stable and Systematic Differences in LLM Evaluator Behavior",
      "authors": [
        "Wajid Nasser"
      ],
      "abstract": "LLM-as-judge systems promise scalable, consistent evaluation. We find the opposite: judges are consistent, but not with each other; they are consistent with themselves. Across 3,240 evaluations (9 judges x 120 unique video x pack items x 3 independent runs), inter-judge agreement is near-zero (Krippendorff's α = 0.042). On two dimensions, judges disagree more than random noise would predict (α < 0). Yet this disagreement isn't chaos; it's structured. A classifier identifies which judge produced an evaluation with 77.1% accuracy from rubric scores alone, rising to 89.9% with disposition features. Within model families, the signal is even stronger: GPT-4.1 and GPT-5.2 are distinguishable with 99.6% accuracy. We call this the reliability paradox: judges cannot agree on what constitutes quality, yet their disagreement patterns are so stable they function as fingerprints. Each judge implements a distinct, stable theory of quality: an \"evaluative disposition\" that shapes how it interprets any rubric. We characterize these dispositions along multiple axes: harshness/leniency, dimension emphasis, within-judge stability (ICC), and evidence behavior (receipt validity, semantic linkage via NLI, and shotgun index). The implication is stark: LLM judges are not interchangeable instruments measuring a shared construct. They are distinct measurement devices, each encoding its own implicit theory of quality. Averaging their scores produces a synthetic verdict that corresponds to no judge's actual values.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05114v1",
        "pdf": "https://arxiv.org/pdf/2601.05114v1"
      },
      "arxiv_id": "2601.05114v1",
      "comment": "23 pages, 6 figures, code and artifacts at : https://github.com/wajid-nasser/evaluative-fingerprints",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2601.05111v1",
      "title": "Agent-as-a-Judge",
      "authors": [
        "Runyang You",
        "Hongru Cai",
        "Caiqi Zhang",
        "Qiancheng Xu",
        "Meng Liu",
        "Tiezheng Yu",
        "Yongqi Li",
        "Wenjie Li"
      ],
      "abstract": "LLM-as-a-Judge has revolutionized AI evaluation by leveraging large language models for scalable assessments. However, as evaluands become increasingly complex, specialized, and multi-step, the reliability of LLM-as-a-Judge has become constrained by inherent biases, shallow single-pass reasoning, and the inability to verify assessments against real-world observations. This has catalyzed the transition to Agent-as-a-Judge, where agentic judges employ planning, tool-augmented verification, multi-agent collaboration, and persistent memory to enable more robust, verifiable, and nuanced evaluations. Despite the rapid proliferation of agentic evaluation systems, the field lacks a unified framework to navigate this shifting landscape. To bridge this gap, we present the first comprehensive survey tracing this evolution. Specifically, we identify key dimensions that characterize this paradigm shift and establish a developmental taxonomy. We organize core methodologies and survey applications across general and professional domains. Furthermore, we analyze frontier challenges and identify promising research directions, ultimately providing a clear roadmap for the next generation of agentic evaluation.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05111v1",
        "pdf": "https://arxiv.org/pdf/2601.05111v1"
      },
      "arxiv_id": "2601.05111v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05110v1",
      "title": "GlimpRouter: Efficient Collaborative Inference by Glimpsing One Token of Thoughts",
      "authors": [
        "Wenhao Zeng",
        "Xuteng Zhang",
        "Yuling Shi",
        "Chao Hu",
        "Yuting Chen",
        "Beijun Shen",
        "Xiaodong Gu"
      ],
      "abstract": "Large Reasoning Models (LRMs) achieve remarkable performance by explicitly generating multi-step chains of thought, but this capability incurs substantial inference latency and computational cost. Collaborative inference offers a promising solution by selectively allocating work between lightweight and large models, yet a fundamental challenge remains: determining when a reasoning step requires the capacity of a large model or the efficiency of a small model. Existing routing strategies either rely on local token probabilities or post-hoc verification, introducing significant inference overhead. In this work, we propose a novel perspective on step-wise collaboration: the difficulty of a reasoning step can be inferred from its very first token. Inspired by the \"Aha Moment\" phenomenon in LRMs, we show that the entropy of the initial token serves as a strong predictor of step difficulty. Building on this insight, we introduce GlimpRouter, a training-free step-wise collaboration framework. GlimpRouter employs a lightweight model to generate only the first token of each reasoning step and routes the step to a larger model only when the initial token entropy exceeds a threshold. Experiments on multiple benchmarks demonstrate that our approach significantly reduces inference latency while preserving accuracy. For instance, GlimpRouter attains a substantial 10.7% improvement in accuracy while reducing inference latency by 25.9% compared to a standalone large model on AIME25. These results suggest a simple yet effective mechanism for reasoning: allocating computation based on a glimpse of thought rather than full-step evaluation.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05110v1",
        "pdf": "https://arxiv.org/pdf/2601.05110v1"
      },
      "arxiv_id": "2601.05110v1",
      "comment": "Code available at https://github.com/Zengwh02/GlimpRouter",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2601.05107v1",
      "title": "Controllable Memory Usage: Balancing Anchoring and Innovation in Long-Term Human-Agent Interaction",
      "authors": [
        "Muzhao Tian",
        "Zisu Huang",
        "Xiaohua Wang",
        "Jingwen Xu",
        "Zhengkang Guo",
        "Qi Qian",
        "Yuanzhe Shen",
        "Kaitao Song",
        "Jiakang Yuan",
        "Changze Lv",
        "Xiaoqing Zheng"
      ],
      "abstract": "As LLM-based agents are increasingly used in long-term interactions, cumulative memory is critical for enabling personalization and maintaining stylistic consistency. However, most existing systems adopt an ``all-or-nothing'' approach to memory usage: incorporating all relevant past information can lead to \\textit{Memory Anchoring}, where the agent is trapped by past interactions, while excluding memory entirely results in under-utilization and the loss of important interaction history. We show that an agent's reliance on memory can be modeled as an explicit and user-controllable dimension. We first introduce a behavioral metric of memory dependence to quantify the influence of past interactions on current outputs. We then propose \\textbf{Stee}rable \\textbf{M}emory Agent, \\texttt{SteeM}, a framework that allows users to dynamically regulate memory reliance, ranging from a fresh-start mode that promotes innovation to a high-fidelity mode that closely follows interaction history. Experiments across different scenarios demonstrate that our approach consistently outperforms conventional prompting and rigid memory masking strategies, yielding a more nuanced and effective control for personalized human-agent collaboration.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05107v1",
        "pdf": "https://arxiv.org/pdf/2601.05107v1"
      },
      "arxiv_id": "2601.05107v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05106v1",
      "title": "Token-Level LLM Collaboration via FusionRoute",
      "authors": [
        "Nuoya Xiong",
        "Yuhang Zhou",
        "Hanqing Zeng",
        "Zhaorun Chen",
        "Furong Huang",
        "Shuchao Bi",
        "Lizhu Zhang",
        "Zhuokai Zhao"
      ],
      "abstract": "Large language models (LLMs) exhibit strengths across diverse domains. However, achieving strong performance across these domains with a single general-purpose model typically requires scaling to sizes that are prohibitively expensive to train and deploy. On the other hand, while smaller domain-specialized models are much more efficient, they struggle to generalize beyond their training distributions. To address this dilemma, we propose FusionRoute, a robust and effective token-level multi-LLM collaboration framework in which a lightweight router simultaneously (i) selects the most suitable expert at each decoding step and (ii) contributes a complementary logit that refines or corrects the selected expert's next-token distribution via logit addition. Unlike existing token-level collaboration methods that rely solely on fixed expert outputs, we provide a theoretical analysis showing that pure expert-only routing is fundamentally limited: unless strong global coverage assumptions hold, it cannot in general realize the optimal decoding policy. By augmenting expert selection with a trainable complementary generator, FusionRoute expands the effective policy class and enables recovery of optimal value functions under mild conditions. Empirically, across both Llama-3 and Gemma-2 families and diverse benchmarks spanning mathematical reasoning, code generation, and instruction following, FusionRoute outperforms both sequence- and token-level collaboration, model merging, and direct fine-tuning, while remaining competitive with domain experts on their respective tasks.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05106v1",
        "pdf": "https://arxiv.org/pdf/2601.05106v1"
      },
      "arxiv_id": "2601.05106v1",
      "comment": "25 pages",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05105v1",
      "title": "UniLiPs: Unified LiDAR Pseudo-Labeling with Geometry-Grounded Dynamic Scene Decomposition",
      "authors": [
        "Filippo Ghilotti",
        "Samuel Brucker",
        "Nahku Saidy",
        "Matteo Matteucci",
        "Mario Bijelic",
        "Felix Heide"
      ],
      "abstract": "Unlabeled LiDAR logs, in autonomous driving applications, are inherently a gold mine of dense 3D geometry hiding in plain sight - yet they are almost useless without human labels, highlighting a dominant cost barrier for autonomous-perception research. In this work we tackle this bottleneck by leveraging temporal-geometric consistency across LiDAR sweeps to lift and fuse cues from text and 2D vision foundation models directly into 3D, without any manual input. We introduce an unsupervised multi-modal pseudo-labeling method relying on strong geometric priors learned from temporally accumulated LiDAR maps, alongside with a novel iterative update rule that enforces joint geometric-semantic consistency, and vice-versa detecting moving objects from inconsistencies. Our method simultaneously produces 3D semantic labels, 3D bounding boxes, and dense LiDAR scans, demonstrating robust generalization across three datasets. We experimentally validate that our method compares favorably to existing semantic segmentation and object detection pseudo-labeling methods, which often require additional manual supervision. We confirm that even a small fraction of our geometrically consistent, densified LiDAR improves depth prediction by 51.5% and 22.0% MAE in the 80-150 and 150-250 meters range, respectively.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05105v1",
        "pdf": "https://arxiv.org/pdf/2601.05105v1"
      },
      "arxiv_id": "2601.05105v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05101v1",
      "title": "Arabic Prompts with English Tools: A Benchmark",
      "authors": [
        "Konstantin Kubrak",
        "Ahmed El-Moselhy",
        "Ammar Alsulami",
        "Remaz Altuwaim",
        "Hassan Ismail Fawaz",
        "Faisal Alsaby"
      ],
      "abstract": "Large Language Models (LLMs) are now integral to numerous industries, increasingly serving as the core reasoning engine for autonomous agents that perform complex tasks through tool-use. While the development of Arabic-native LLMs is accelerating, the benchmarks for evaluating their capabilities lag behind, with most existing frameworks focusing on English. A critical and overlooked area is tool-calling, where the performance of models prompted in non-English languages like Arabic is poorly understood, especially since these models are often pretrained on predominantly English data. This paper addresses this critical gap by introducing the first dedicated benchmark for evaluating the tool-calling and agentic capabilities of LLMs in the Arabic language. Our work provides a standardized framework to measure the functional accuracy and robustness of models in Arabic agentic workflows. Our findings reveal a huge performance gap: when users interact in Arabic, tool-calling accuracy drops by an average of 5-10\\%, regardless of whether the tool descriptions themselves are in Arabic or English. By shedding light on these critical challenges, this benchmark aims to foster the development of more reliable and linguistically equitable AI agents for Arabic-speaking users.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05101v1",
        "pdf": "https://arxiv.org/pdf/2601.05101v1"
      },
      "arxiv_id": "2601.05101v1",
      "comment": "10 pages, 10 figures, LLMs, Big Data, and Multilinguality for All (LLMs4All) Workshop at IEEE BigData 2025 Conference, Macau, December 10, 2025",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05091v1",
      "title": "Code-Mix Sentiment Analysis on Hinglish Tweets",
      "authors": [
        "Aashi Garg",
        "Aneshya Das",
        "Arshi Arya",
        "Anushka Goyal",
        "Aditi"
      ],
      "abstract": "The effectiveness of brand monitoring in India is increasingly challenged by the rise of Hinglish--a hybrid of Hindi and English--used widely in user-generated content on platforms like Twitter. Traditional Natural Language Processing (NLP) models, built for monolingual data, often fail to interpret the syntactic and semantic complexity of this code-mixed language, resulting in inaccurate sentiment analysis and misleading market insights. To address this gap, we propose a high-performance sentiment classification framework specifically designed for Hinglish tweets. Our approach fine-tunes mBERT (Multilingual BERT), leveraging its multilingual capabilities to better understand the linguistic diversity of Indian social media. A key component of our methodology is the use of subword tokenization, which enables the model to effectively manage spelling variations, slang, and out-of-vocabulary terms common in Romanized Hinglish. This research delivers a production-ready AI solution for brand sentiment tracking and establishes a strong benchmark for multilingual NLP in low-resource, code-mixed environments.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05091v1",
        "pdf": "https://arxiv.org/pdf/2601.05091v1"
      },
      "arxiv_id": "2601.05091v1",
      "comment": "Accepted at the 9th International Conference on Natural Language Processing and Information Retrieval (NLPIR 2025), Fukuoka, Japan",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05084v1",
      "title": "Driver-Intention Prediction with Deep Learning: Real-Time Brain-to-Vehicle Communication",
      "authors": [
        "Niloufar Alavi",
        "Swati Shah",
        "Rezvan Alamian",
        "Stefan Goetz"
      ],
      "abstract": "Brain-computer interfaces (BCIs) allow direct communication between the brain and electronics without the need for speech or physical movement. Such interfaces can be particularly beneficial in applications requiring rapid response times, such as driving, where a vehicle's advanced driving assistance systems could benefit from immediate understanding of a driver's intentions. This study presents a novel method for predicting a driver's intention to steer using electroencephalography (EEG) signals through deep learning. A driving simulator created a controlled environment in which participants imagined controlling a vehicle during various driving scenarios, including left and right turns, as well as straight driving. A convolutional neural network (CNN) classified the detected EEG data with minimal pre-processing. Our model achieved an accuracy of 83.7% in distinguishing between the three steering intentions and demonstrated the ability of CNNs to process raw EEG data effectively. The classification accuracy was highest for right-turn segments, which suggests a potential spatial bias in brain activity. This study lays the foundation for more intuitive brain-to-vehicle communication systems.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.ET",
        "eess.SP",
        "eess.SY"
      ],
      "primary_category": "cs.HC",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05084v1",
        "pdf": "https://arxiv.org/pdf/2601.05084v1"
      },
      "arxiv_id": "2601.05084v1",
      "comment": "6 pages, 7 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05083v1",
      "title": "Driving on Registers",
      "authors": [
        "Ellington Kirby",
        "Alexandre Boulch",
        "Yihong Xu",
        "Yuan Yin",
        "Gilles Puy",
        "Éloi Zablocki",
        "Andrei Bursuc",
        "Spyros Gidaris",
        "Renaud Marlet",
        "Florent Bartoccioni",
        "Anh-Quan Cao",
        "Nermin Samet",
        "Tuan-Hung VU",
        "Matthieu Cord"
      ],
      "abstract": "We present DrivoR, a simple and efficient transformer-based architecture for end-to-end autonomous driving. Our approach builds on pretrained Vision Transformers (ViTs) and introduces camera-aware register tokens that compress multi-camera features into a compact scene representation, significantly reducing downstream computation without sacrificing accuracy. These tokens drive two lightweight transformer decoders that generate and then score candidate trajectories. The scoring decoder learns to mimic an oracle and predicts interpretable sub-scores representing aspects such as safety, comfort, and efficiency, enabling behavior-conditioned driving at inference. Despite its minimal design, DrivoR outperforms or matches strong contemporary baselines across NAVSIM-v1, NAVSIM-v2, and the photorealistic closed-loop HUGSIM benchmark. Our results show that a pure-transformer architecture, combined with targeted token compression, is sufficient for accurate, efficient, and adaptive end-to-end driving. Code and checkpoints will be made available via the project page.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05083v1",
        "pdf": "https://arxiv.org/pdf/2601.05083v1"
      },
      "arxiv_id": "2601.05083v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05082v1",
      "title": "Exploring Student Expectations and Confidence in Learning Analytics",
      "authors": [
        "Hayk Asatryan",
        "Basile Tousside",
        "Janis Mohr",
        "Malte Neugebauer",
        "Hildo Bijl",
        "Paul Spiegelberg",
        "Claudia Frohn-Schauf",
        "Jörg Frochte"
      ],
      "abstract": "Learning Analytics (LA) is nowadays ubiquitous in many educational systems, providing the ability to collect and analyze student data in order to understand and optimize learning and the environments in which it occurs. On the other hand, the collection of data requires to comply with the growing demand regarding privacy legislation. In this paper, we use the Student Expectation of Learning Analytics Questionnaire (SELAQ) to analyze the expectations and confidence of students from different faculties regarding the processing of their data for Learning Analytics purposes. This allows us to identify four clusters of students through clustering algorithms: Enthusiasts, Realists, Cautious and Indifferents. This structured analysis provides valuable insights into the acceptance and criticism of Learning Analytics among students.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.LG",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05082v1",
        "pdf": "https://arxiv.org/pdf/2601.05082v1"
      },
      "arxiv_id": "2601.05082v1",
      "comment": "7 pages, Keywords: Learning Analytics, Survey, Data Protection, Clustering",
      "journal_ref": "LAK 2024: Proceedings of the 14th Learning Analytics and Knowledge Conference, Pages 892 - 898",
      "has_code": false
    },
    {
      "id": "2601.05076v1",
      "title": "Chain-of-Sanitized-Thoughts: Plugging PII Leakage in CoT of Large Reasoning Models",
      "authors": [
        "Arghyadeep Das",
        "Sai Sreenivas Chintha",
        "Rishiraj Girmal",
        "Kinjal Pandey",
        "Sharvi Endait"
      ],
      "abstract": "Large Reasoning Models (LRMs) improve performance, reliability, and interpretability by generating explicit chain-of-thought (CoT) reasoning, but this transparency introduces a serious privacy risk: intermediate reasoning often leaks personally identifiable information (PII) even when final answers are sanitized. We study how to induce privacy-first reasoning, where models reason without exposing sensitive information, using deployable interventions rather than post-hoc redaction. We introduce PII-CoT-Bench, a supervised dataset with privacy-aware CoT annotations, and a category-balanced evaluation benchmark covering realistic and adversarial leakage scenarios. Our results reveal a capability-dependent trend: state-of-the-art models benefit most from prompt-based controls, whereas weaker models require fine-tuning to achieve meaningful leakage reduction. Across models and categories, both approaches substantially reduce PII exposure with minimal degradation in utility, demonstrating that private reasoning can be achieved without sacrificing performance. Overall, we show that private CoT reasoning can be achieved with minimal utility loss, providing practical guidance for building privacy-preserving reasoning systems.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05076v1",
        "pdf": "https://arxiv.org/pdf/2601.05076v1"
      },
      "arxiv_id": "2601.05076v1",
      "comment": "12 pages, 6 figures, 1 table",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05073v1",
      "title": "Milestones over Outcome: Unlocking Geometric Reasoning with Sub-Goal Verifiable Reward",
      "authors": [
        "Jianlong Chen",
        "Daocheng Fu",
        "Shengze Xu",
        "Jiawei Chen",
        "Yuan Feng",
        "Yue Yang",
        "Junchi Yan",
        "Hongyuan Zha",
        "Renqiu Xia"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) struggle with complex geometric reasoning, largely because \"black box\" outcome-based supervision fails to distinguish between lucky guesses and rigorous deduction. To address this, we introduce a paradigm shift towards subgoal-level evaluation and learning. We first construct GeoGoal, a benchmark synthesized via a rigorous formal verification data engine, which converts abstract proofs into verifiable numeric subgoals. This structure reveals a critical divergence between reasoning quality and outcome accuracy. Leveraging this, we propose the Sub-Goal Verifiable Reward (SGVR) framework, which replaces sparse signals with dense rewards based on the Skeleton Rate. Experiments demonstrate that SGVR not only enhances geometric performance (+9.7%) but also exhibits strong generalization, transferring gains to general math (+8.0%) and other general reasoning tasks (+2.8%), demonstrating broad applicability across diverse domains.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05073v1",
        "pdf": "https://arxiv.org/pdf/2601.05073v1"
      },
      "arxiv_id": "2601.05073v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05063v1",
      "title": "Quantitative mapping from conventional MRI using self-supervised physics-guided deep learning: applications to a large-scale, clinically heterogeneous dataset",
      "authors": [
        "Jelmer van Lune",
        "Stefano Mandija",
        "Oscar van der Heide",
        "Matteo Maspero",
        "Martin B. Schilder",
        "Jan Willem Dankbaar",
        "Cornelis A. T. van den Berg",
        "Alessandro Sbrizzi"
      ],
      "abstract": "Magnetic resonance imaging (MRI) is a cornerstone of clinical neuroimaging, yet conventional MRIs provide qualitative information heavily dependent on scanner hardware and acquisition settings. While quantitative MRI (qMRI) offers intrinsic tissue parameters, the requirement for specialized acquisition protocols and reconstruction algorithms restricts its availability and impedes large-scale biomarker research. This study presents a self-supervised physics-guided deep learning framework to infer quantitative T1, T2, and proton-density (PD) maps directly from widely available clinical conventional T1-weighted, T2-weighted, and FLAIR MRIs. The framework was trained and evaluated on a large-scale, clinically heterogeneous dataset comprising 4,121 scan sessions acquired at our institution over six years on four different 3 T MRI scanner systems, capturing real-world clinical variability. The framework integrates Bloch-based signal models directly into the training objective. Across more than 600 test sessions, the generated maps exhibited white matter and gray matter values consistent with literature ranges. Additionally, the generated maps showed invariance to scanner hardware and acquisition protocol groups, with inter-group coefficients of variation $\\leq$ 1.1%. Subject-specific analyses demonstrated excellent voxel-wise reproducibility across scanner systems and sequence parameters, with Pearson $r$ and concordance correlation coefficients exceeding 0.82 for T1 and T2. Mean relative voxel-wise differences were low across all quantitative parameters, especially for T2 ($<$ 6%). These results indicate that the proposed framework can robustly transform diverse clinical conventional MRI data into quantitative maps, potentially paving the way for large-scale quantitative biomarker research.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "physics.med-ph",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "physics.med-ph",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05063v1",
        "pdf": "https://arxiv.org/pdf/2601.05063v1"
      },
      "arxiv_id": "2601.05063v1",
      "comment": "30 pages, 13 figures, full paper",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05062v1",
      "title": "Compositional Steering of Large Language Models with Steering Tokens",
      "authors": [
        "Gorjan Radevski",
        "Kiril Gashteovski",
        "Giwon Hong",
        "Carolin Lawrence",
        "Goran Glavaš"
      ],
      "abstract": "Deploying LLMs in real-world applications requires controllable output that satisfies multiple desiderata at the same time. While existing work extensively addresses LLM steering for a single behavior, \\textit{compositional steering} -- i.e., steering LLMs simultaneously towards multiple behaviors -- remains an underexplored problem. In this work, we propose \\emph{compositional steering tokens} for multi-behavior steering. We first embed individual behaviors, expressed as natural language instructions, into dedicated tokens via self-distillation. Contrary to most prior work, which operates in the activation space, our behavior steers live in the space of input tokens, enabling more effective zero-shot composition. We then train a dedicated \\textit{composition token} on pairs of behaviors and show that it successfully captures the notion of composition: it generalizes well to \\textit{unseen} compositions, including those with unseen behaviors as well as those with an unseen \\textit{number} of behaviors. Our experiments across different LLM architectures show that steering tokens lead to superior multi-behavior control compared to competing approaches (instructions, activation steering, and LoRA merging). Moreover, we show that steering tokens complement natural language instructions, with their combination resulting in further gains.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05062v1",
        "pdf": "https://arxiv.org/pdf/2601.05062v1"
      },
      "arxiv_id": "2601.05062v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05059v1",
      "title": "From Understanding to Engagement: Personalized pharmacy Video Clips via Vision Language Models (VLMs)",
      "authors": [
        "Suyash Mishra",
        "Qiang Li",
        "Srikanth Patil",
        "Anubhav Girdhar"
      ],
      "abstract": "Vision Language Models (VLMs) are poised to revolutionize the digital transformation of pharmacyceutical industry by enabling intelligent, scalable, and automated multi-modality content processing. Traditional manual annotation of heterogeneous data modalities (text, images, video, audio, and web links), is prone to inconsistencies, quality degradation, and inefficiencies in content utilization. The sheer volume of long video and audio data further exacerbates these challenges, (e.g. long clinical trial interviews and educational seminars).\n  Here, we introduce a domain adapted Video to Video Clip Generation framework that integrates Audio Language Models (ALMs) and Vision Language Models (VLMs) to produce highlight clips. Our contributions are threefold: (i) a reproducible Cut & Merge algorithm with fade in/out and timestamp normalization, ensuring smooth transitions and audio/visual alignment; (ii) a personalization mechanism based on role definition and prompt injection for tailored outputs (marketing, training, regulatory); (iii) a cost efficient e2e pipeline strategy balancing ALM/VLM enhanced processing. Evaluations on Video MME benchmark (900) and our proprietary dataset of 16,159 pharmacy videos across 14 disease areas demonstrate 3 to 4 times speedup, 4 times cost reduction, and competitive clip quality. Beyond efficiency gains, we also report our methods improved clip coherence scores (0.348) and informativeness scores (0.721) over state of the art VLM baselines (e.g., Gemini 2.5 Pro), highlighting the potential of transparent, custom extractive, and compliance supporting video summarization for life sciences.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05059v1",
        "pdf": "https://arxiv.org/pdf/2601.05059v1"
      },
      "arxiv_id": "2601.05059v1",
      "comment": "Contributed original research to top tier conference in VLM; currently undergoing peer review",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05053v1",
      "title": "Reinforced Efficient Reasoning via Semantically Diverse Exploration",
      "authors": [
        "Ziqi Zhao",
        "Zhaochun Ren",
        "Jiahong Zou",
        "Liu Yang",
        "Zhiwei Xu",
        "Xuri Ge",
        "Zhumin Chen",
        "Xinyu Ma",
        "Daiting Shi",
        "Shuaiqiang Wang",
        "Dawei Yin",
        "Xin Xin"
      ],
      "abstract": "Reinforcement learning with verifiable rewards (RLVR) has proven effective in enhancing the reasoning of large language models (LLMs). Monte Carlo Tree Search (MCTS)-based extensions improve upon vanilla RLVR (e.g., GRPO) by providing tree-based reasoning rollouts that enable fine-grained and segment-level credit assignment. However, existing methods still suffer from limited exploration diversity and inefficient reasoning. To address the above challenges, we propose reinforced efficient reasoning via semantically diverse explorations, i.e., ROSE, for LLMs. To encourage more diverse reasoning exploration, our method incorporates a semantic-entropy-based branching strategy and an $\\varepsilon$-exploration mechanism. The former operates on already sampled reasoning rollouts to capture semantic uncertainty and select branching points with high semantic divergence to generate new successive reasoning paths, whereas the latter stochastically initiates reasoning rollouts from the root, preventing the search process from becoming overly local. To improve efficiency, we design a length-aware segment-level advantage estimator that rewards concise and correct reasoning while penalizing unnecessarily long reasoning chains. Extensive experiments on various mathematical reasoning benchmarks with Qwen and Llama models validate the effectiveness and efficiency of ROSE. Codes are available at https://github.com/ZiqiZhao1/ROSE-rl.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05053v1",
        "pdf": "https://arxiv.org/pdf/2601.05053v1"
      },
      "arxiv_id": "2601.05053v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05052v1",
      "title": "DeepWeightFlow: Re-Basined Flow Matching for Generating Neural Network Weights",
      "authors": [
        "Saumya Gupta",
        "Scott Biggs",
        "Moritz Laber",
        "Zohair Shafi",
        "Robin Walters",
        "Ayan Paul"
      ],
      "abstract": "Building efficient and effective generative models for neural network weights has been a research focus of significant interest that faces challenges posed by the high-dimensional weight spaces of modern neural networks and their symmetries. Several prior generative models are limited to generating partial neural network weights, particularly for larger models, such as ResNet and ViT. Those that do generate complete weights struggle with generation speed or require finetuning of the generated models. In this work, we present DeepWeightFlow, a Flow Matching model that operates directly in weight space to generate diverse and high-accuracy neural network weights for a variety of architectures, neural network sizes, and data modalities. The neural networks generated by DeepWeightFlow do not require fine-tuning to perform well and can scale to large networks. We apply Git Re-Basin and TransFusion for neural network canonicalization in the context of generative weight models to account for the impact of neural network permutation symmetries and to improve generation efficiency for larger model sizes. The generated networks excel at transfer learning, and ensembles of hundreds of neural networks can be generated in minutes, far exceeding the efficiency of diffusion-based methods. DeepWeightFlow models pave the way for more efficient and scalable generation of diverse sets of neural networks.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05052v1",
        "pdf": "https://arxiv.org/pdf/2601.05052v1"
      },
      "arxiv_id": "2601.05052v1",
      "comment": "25 pages, 20 tables, 2 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05051v1",
      "title": "Publishing FAIR and Machine-actionable Reviews in Materials Science: The Case for Symbolic Knowledge in Neuro-symbolic Artificial Intelligence",
      "authors": [
        "Jennifer D'Souza",
        "Soren Auer",
        "Eleni Poupaki",
        "Alex Watkins",
        "Anjana Devi",
        "Riikka L. Puurunen",
        "Bora Karasulu",
        "Adrie Mackus",
        "Erwin Kessels"
      ],
      "abstract": "Scientific reviews are central to knowledge integration in materials science, yet their key insights remain locked in narrative text and static PDF tables, limiting reuse by humans and machines alike. This article presents a case study in atomic layer deposition and etching (ALD/E) where we publish review tables as FAIR, machine-actionable comparisons in the Open Research Knowledge Graph (ORKG), turning them into structured, queryable knowledge. Building on this, we contrast symbolic querying over ORKG with large language model-based querying, and argue that a curated symbolic layer should remain the backbone of reliable neurosymbolic AI in materials science, with LLMs serving as complementary, symbolically grounded interfaces rather than standalone sources of truth.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.DL",
        "cs.IT"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05051v1",
        "pdf": "https://arxiv.org/pdf/2601.05051v1"
      },
      "arxiv_id": "2601.05051v1",
      "comment": "35 pages, 11 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05050v1",
      "title": "Large language models can effectively convince people to believe conspiracies",
      "authors": [
        "Thomas H. Costello",
        "Kellin Pelrine",
        "Matthew Kowal",
        "Antonio A. Arechar",
        "Jean-François Godbout",
        "Adam Gleave",
        "David Rand",
        "Gordon Pennycook"
      ],
      "abstract": "Large language models (LLMs) have been shown to be persuasive across a variety of context. But it remains unclear whether this persuasive power advantages truth over falsehood, or if LLMs can promote misbeliefs just as easily as refuting them. Here, we investigate this question across three pre-registered experiments in which participants (N = 2,724 Americans) discussed a conspiracy theory they were uncertain about with GPT-4o, and the model was instructed to either argue against (\"debunking\") or for (\"bunking\") that conspiracy. When using a \"jailbroken\" GPT-4o variant with guardrails removed, the AI was as effective at increasing conspiracy belief as decreasing it. Concerningly, the bunking AI was rated more positively, and increased trust in AI, more than the debunking AI. Surprisingly, we found that using standard GPT-4o produced very similar effects, such that the guardrails imposed by OpenAI did little to revent the LLM from promoting conspiracy beliefs. Encouragingly, however, a corrective conversation reversed these newly induced conspiracy beliefs, and simply prompting GPT-4o to only use accurate information dramatically reduced its ability to increase conspiracy beliefs. Our findings demonstrate that LLMs possess potent abilities to promote both truth and falsehood, but that potential solutions may exist to help mitigate this risk.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.AI",
        "econ.GN"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05050v1",
        "pdf": "https://arxiv.org/pdf/2601.05050v1"
      },
      "arxiv_id": "2601.05050v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05049v1",
      "title": "How to Set the Learning Rate for Large-Scale Pre-training?",
      "authors": [
        "Yunhua Zhou",
        "Shuhao Xing",
        "Junhao Huang",
        "Xipeng Qiu",
        "Qipeng Guo"
      ],
      "abstract": "Optimal configuration of the learning rate (LR) is a fundamental yet formidable challenge in large-scale pre-training. Given the stringent trade-off between training costs and model performance, the pivotal question is whether the optimal LR can be accurately extrapolated from low-cost experiments. In this paper, we formalize this investigation into two distinct research paradigms: Fitting and Transfer. Within the Fitting Paradigm, we innovatively introduce a Scaling Law for search factor, effectively reducing the search complexity from O(n^3) to O(n*C_D*C_η) via predictive modeling. Within the Transfer Paradigm, we extend the principles of $μ$Transfer to the Mixture of Experts (MoE) architecture, broadening its applicability to encompass model depth, weight decay, and token horizons. By pushing the boundaries of existing hyperparameter research in terms of scale, we conduct a comprehensive comparison between these two paradigms. Our empirical results challenge the scalability of the widely adopted $μ$ Transfer in large-scale pre-training scenarios. Furthermore, we provide a rigorous analysis through the dual lenses of training stability and feature learning to elucidate the underlying reasons why module-wise parameter tuning underperforms in large-scale settings. This work offers systematic practical guidelines and a fresh theoretical perspective for optimizing industrial-level pre-training.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05049v1",
        "pdf": "https://arxiv.org/pdf/2601.05049v1"
      },
      "arxiv_id": "2601.05049v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05047v1",
      "title": "Challenges and Research Directions for Large Language Model Inference Hardware",
      "authors": [
        "Xiaoyu Ma",
        "David Patterson"
      ],
      "abstract": "Large Language Model (LLM) inference is hard. The autoregressive Decode phase of the underlying Transformer model makes LLM inference fundamentally different from training. Exacerbated by recent AI trends, the primary challenges are memory and interconnect rather than compute. To address these challenges, we highlight four architecture research opportunities: High Bandwidth Flash for 10X memory capacity with HBM-like bandwidth; Processing-Near-Memory and 3D memory-logic stacking for high memory bandwidth; and low-latency interconnect to speedup communication. While our focus is datacenter AI, we also review their applicability for mobile devices.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AR",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05047v1",
        "pdf": "https://arxiv.org/pdf/2601.05047v1"
      },
      "arxiv_id": "2601.05047v1",
      "comment": "Accepted for publication by IEEE Computer, 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05038v1",
      "title": "ArcAligner: Adaptive Recursive Aligner for Compressed Context Embeddings in RAG",
      "authors": [
        "Jianbo Li",
        "Yi Jiang",
        "Sendong Zhao",
        "Bairui Hu",
        "Haochun Wang",
        "Bing Qin"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) helps LLMs stay accurate, but feeding long documents into a prompt makes the model slow and expensive. This has motivated context compression, ranging from token pruning and summarization to embedding-based compression. While researchers have tried ''compressing'' these documents into smaller summaries or mathematical embeddings, there is a catch: the more you compress the data, the more the LLM struggles to understand it. To address this challenge, we propose ArcAligner (Adaptive recursive context *Aligner*), a lightweight module integrated into the language model layers to help the model better utilize highly compressed context representations for downstream generation. It uses an adaptive ''gating'' system that only adds extra processing power when the information is complex, keeping the system fast. Across knowledge-intensive QA benchmarks, ArcAligner consistently beats compression baselines at comparable compression rates, especially on multi-hop and long-tail settings. The source code is publicly available.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05038v1",
        "pdf": "https://arxiv.org/pdf/2601.05038v1"
      },
      "arxiv_id": "2601.05038v1",
      "comment": "Code is available at https://github.com/liunian-Jay/ArcAligner.git",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2601.05036v1",
      "title": "Exponential capacity scaling of classical GANs compared to hybrid latent style-based quantum GANs",
      "authors": [
        "Milan Liepelt",
        "Julien Baglio"
      ],
      "abstract": "Quantum generative modeling is a very active area of research in looking for practical advantage in data analysis. Quantum generative adversarial networks (QGANs) are leading candidates for quantum generative modeling and have been applied to diverse areas, from high-energy physics to image generation. The latent style-based QGAN, relying on a classical variational autoencoder to encode the input data into a latent space and then using a style-based QGAN for data generation has been proven to be efficient for image generation or drug design, hinting at the use of far less trainable parameters than their classical counterpart to achieve comparable performance, however this advantage has never been systematically studied. We present in this work the first comprehensive experimental analysis of this advantage of QGANS applied to SAT4 image generation, obtaining an exponential advantage in capacity scaling for a quantum generator in the hybrid latent style-based QGAN architecture. Careful tuning of the autoencoder is crucial to obtain stable, reliable results. Once this tuning is performed and defining training optimality as when the training is stable and the FID score is low and stable as well, the optimal capacity (or number of trainable parameters) of the classical discriminator scales exponentially with respect to the capacity of the quantum generator, and the same is true for the capacity of the classical generator. This hints toward a type of quantum advantage for quantum generative modeling.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05036v1",
        "pdf": "https://arxiv.org/pdf/2601.05036v1"
      },
      "arxiv_id": "2601.05036v1",
      "comment": "34 pages, 7 figures, 7 tables",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05035v1",
      "title": "Patch-based Representation and Learning for Efficient Deformation Modeling",
      "authors": [
        "Ruochen Chen",
        "Thuy Tran",
        "Shaifali Parashar"
      ],
      "abstract": "In this paper, we present a patch-based representation of surfaces, PolyFit, which is obtained by fitting jet functions locally on surface patches. Such a representation can be learned efficiently in a supervised fashion from both analytic functions and real data. Once learned, it can be generalized to various types of surfaces. Using PolyFit, the surfaces can be efficiently deformed by updating a compact set of jet coefficients rather than optimizing per-vertex degrees of freedom for many downstream tasks in computer vision and graphics. We demonstrate the capabilities of our proposed methodologies with two applications: 1) Shape-from-template (SfT): where the goal is to deform the input 3D template of an object as seen in image/video. Using PolyFit, we adopt test-time optimization that delivers competitive accuracy while being markedly faster than offline physics-based solvers, and outperforms recent physics-guided neural simulators in accuracy at modest additional runtime. 2) Garment draping. We train a self-supervised, mesh- and garment-agnostic model that generalizes across resolutions and garment types, delivering up to an order-of-magnitude faster inference than strong baselines.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05035v1",
        "pdf": "https://arxiv.org/pdf/2601.05035v1"
      },
      "arxiv_id": "2601.05035v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05034v1",
      "title": "How to Set the Batch Size for Large-Scale Pre-training?",
      "authors": [
        "Yunhua Zhou",
        "Junhao Huang",
        "Shuhao Xin",
        "Yechen Zhang",
        "Runyu Peng",
        "Qiping Guo",
        "Xipeng Qiu"
      ],
      "abstract": "The concept of Critical Batch Size, as pioneered by OpenAI, has long served as a foundational principle for large-scale pre-training. However, with the paradigm shift towards the Warmup-Stable-Decay (WSD) learning rate scheduler, we observe that the original theoretical framework and its underlying mechanisms fail to align with new pre-training dynamics. To bridge this gap between theory and practice, this paper derives a revised E(S) relationship tailored for WSD scheduler, characterizing the trade-off between training data consumption E and steps S during pre-training. Our theoretical analysis reveals two fundamental properties of WSD-based pre-training: 1) B_min, the minimum batch size threshold required to achieve a target loss, and 2) B_opt, the optimal batch size that maximizes data efficiency by minimizing total tokens. Building upon these properties, we propose a dynamic Batch Size Scheduler. Extensive experiments demonstrate that our revised formula precisely captures the dynamics of large-scale pre-training, and the resulting scheduling strategy significantly enhances both training efficiency and final model quality.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05034v1",
        "pdf": "https://arxiv.org/pdf/2601.05034v1"
      },
      "arxiv_id": "2601.05034v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05033v1",
      "title": "A Data-Driven Predictive Framework for Inventory Optimization Using Context-Augmented Machine Learning Models",
      "authors": [
        "Anees Fatima",
        "Mohammad Abdus Salam"
      ],
      "abstract": "Demand forecasting in supply chain management (SCM) is critical for optimizing inventory, reducing waste, and improving customer satisfaction. Conventional approaches frequently neglect external influences like weather, festivities, and equipment breakdowns, resulting in inefficiencies. This research investigates the use of machine learning (ML) algorithms to improve demand prediction in retail and vending machine sectors. Four machine learning algorithms. Extreme Gradient Boosting (XGBoost), Autoregressive Integrated Moving Average (ARIMA), Facebook Prophet (Fb Prophet), and Support Vector Regression (SVR) were used to forecast inventory requirements. Ex-ternal factors like weekdays, holidays, and sales deviation indicators were methodically incorporated to enhance precision. XGBoost surpassed other models, reaching the lowest Mean Absolute Error (MAE) of 22.7 with the inclusion of external variables. ARIMAX and Fb Prophet demonstrated noteworthy enhancements, whereas SVR fell short in performance. Incorporating external factors greatly improves the precision of demand forecasting models, and XGBoost is identified as the most efficient algorithm. This study offers a strong framework for enhancing inventory management in retail and vending machine systems.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05033v1",
        "pdf": "https://arxiv.org/pdf/2601.05033v1"
      },
      "arxiv_id": "2601.05033v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05028v1",
      "title": "Approximate equivariance via projection-based regularisation",
      "authors": [
        "Torben Berndt",
        "Jan Stühmer"
      ],
      "abstract": "Equivariance is a powerful inductive bias in neural networks, improving generalisation and physical consistency. Recently, however, non-equivariant models have regained attention, due to their better runtime performance and imperfect symmetries that might arise in real-world applications. This has motivated the development of approximately equivariant models that strike a middle ground between respecting symmetries and fitting the data distribution. Existing approaches in this field usually apply sample-based regularisers which depend on data augmentation at training time, incurring a high sample complexity, in particular for continuous groups such as $SO(3)$. This work instead approaches approximate equivariance via a projection-based regulariser which leverages the orthogonal decomposition of linear layers into equivariant and non-equivariant components. In contrast to existing methods, this penalises non-equivariance at an operator level across the full group orbit, rather than point-wise. We present a mathematical framework for computing the non-equivariance penalty exactly and efficiently in both the spatial and spectral domain. In our experiments, our method consistently outperforms prior approximate equivariance approaches in both model performance and efficiency, achieving substantial runtime gains over sample-based regularisers.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05028v1",
        "pdf": "https://arxiv.org/pdf/2601.05028v1"
      },
      "arxiv_id": "2601.05028v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05027v1",
      "title": "OptiSet: Unified Optimizing Set Selection and Ranking for Retrieval-Augmented Generation",
      "authors": [
        "Yi Jiang",
        "Sendong Zhao",
        "Jianbo Li",
        "Bairui Hu",
        "Yanrui Du",
        "Haochun Wang",
        "Bing Qin"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) improves generation quality by incorporating evidence retrieved from large external corpora. However, most existing methods rely on statically selecting top-k passages based on individual relevance, which fails to exploit combinatorial gains among passages and often introduces substantial redundancy. To address this limitation, we propose OptiSet, a set-centric framework that unifies set selection and set-level ranking for RAG. OptiSet adopts an \"Expand-then-Refine\" paradigm: it first expands a query into multiple perspectives to enable a diverse candidate pool and then refines the candidate pool via re-selection to form a compact evidence set. We then devise a self-synthesis strategy without strong LLM supervision to derive preference labels from the set conditional utility changes of the generator, thereby identifying complementary and redundant evidence. Finally, we introduce a set-list wise training strategy that jointly optimizes set selection and set-level ranking, enabling the model to favor compact, high-gain evidence sets. Extensive experiments demonstrate that OptiSet improves performance on complex combinatorial problems and makes generation more efficient. The source code is publicly available.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05027v1",
        "pdf": "https://arxiv.org/pdf/2601.05027v1"
      },
      "arxiv_id": "2601.05027v1",
      "comment": "Code is available at https://github.com/liunian-Jay/OptiSet.git",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2601.05020v1",
      "title": "Scalable neural pushbroom architectures for real-time denoising of hyperspectral images onboard satellites",
      "authors": [
        "Ziyao Yi",
        "Davide Piccinini",
        "Diego Valsesia",
        "Tiziano Bianchi",
        "Enrico Magli"
      ],
      "abstract": "The next generation of Earth observation satellites will seek to deploy intelligent models directly onboard the payload in order to minimize the latency incurred by the transmission and processing chain of the ground segment, for time-critical applications. Designing neural architectures for onboard execution, particularly for satellite-based hyperspectral imagers, poses novel challenges due to the unique constraints of this environment and imaging system that are largely unexplored by the traditional computer vision literature. In this paper, we show that this setting requires addressing three competing objectives, namely high-quality inference with low complexity, dynamic power scalability and fault tolerance. We focus on the problem of hyperspectral image denoising, which is a critical task to enable effective downstream inference, and highlights the constraints of the onboard processing scenario. We propose a neural network design that addresses the three aforementioned objectives with several novel contributions. In particular, we propose a mixture of denoisers that can be resilient to radiation-induced faults as well as allowing for time-varying power scaling. Moreover, each denoiser employs an innovative architecture where an image is processed line-by-line in a causal way, with a memory of past lines, in order to match the acquisition process of pushbroom hyperspectral sensors and greatly limit memory requirements. We show that the proposed architecture can run in real-time, i.e., process one line in the time it takes to acquire the next one, on low-power hardware and provide competitive denoising quality with respect to significantly more complex state-of-the-art models. We also show that the power scalability and fault tolerance objectives provide a design space with multiple tradeoffs between those properties and denoising quality.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "eess.IV",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05020v1",
        "pdf": "https://arxiv.org/pdf/2601.05020v1"
      },
      "arxiv_id": "2601.05020v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05019v1",
      "title": "Hán Dān Xué Bù (Mimicry) or Qīng Chū Yú Lán (Mastery)? A Cognitive Perspective on Reasoning Distillation in Large Language Models",
      "authors": [
        "Yueqing Hu",
        "Xinyang Peng",
        "Shuting Peng",
        "Hanqi Wang",
        "Tianhong Wang"
      ],
      "abstract": "Recent Large Reasoning Models trained via reinforcement learning exhibit a \"natural\" alignment with human cognitive costs. However, we show that the prevailing paradigm of reasoning distillation -- training student models to mimic these traces via Supervised Fine-Tuning (SFT) -- fails to transmit this cognitive structure. Testing the \"Hán Dān Xué Bù\" (Superficial Mimicry) hypothesis across 14 models, we find that distillation induces a \"Functional Alignment Collapse\": while teacher models mirror human difficulty scaling ($\\bar{r}=0.64$), distilled students significantly degrade this alignment ($\\bar{r}=0.34$), often underperforming their own pre-distillation baselines (\"Negative Transfer\"). Our analysis suggests that SFT induces a \"Cargo Cult\" effect, where students ritualistically replicate the linguistic form of reasoning (verbosity) without internalizing the teacher's dynamic resource allocation policy. Consequently, reasoning distillation decouples computational cost from cognitive demand, revealing that human-like cognition is an emergent property of active reinforcement, not passive imitation.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.CL",
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05019v1",
        "pdf": "https://arxiv.org/pdf/2601.05019v1"
      },
      "arxiv_id": "2601.05019v1",
      "comment": "7 pages, 7 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05017v1",
      "title": "HMVI: Unifying Heterogeneous Attributes with Natural Neighbors for Missing Value Inference",
      "authors": [
        "Xiaopeng Luo",
        "Zexi Tan",
        "Zhuowei Wang"
      ],
      "abstract": "Missing value imputation is a fundamental challenge in machine intelligence, heavily dependent on data completeness. Current imputation methods often handle numerical and categorical attributes independently, overlooking critical interdependencies among heterogeneous features. To address these limitations, we propose a novel imputation approach that explicitly models cross-type feature dependencies within a unified framework. Our method leverages both complete and incomplete instances to ensure accurate and consistent imputation in tabular data. Extensive experimental results demonstrate that the proposed approach achieves superior performance over existing techniques and significantly enhances downstream machine learning tasks, providing a robust solution for real-world systems with missing data.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05017v1",
        "pdf": "https://arxiv.org/pdf/2601.05017v1"
      },
      "arxiv_id": "2601.05017v1",
      "comment": "Submitted to ICASSP 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05016v1",
      "title": "From Idea to Co-Creation: A Planner-Actor-Critic Framework for Agent Augmented 3D Modeling",
      "authors": [
        "Jin Gao",
        "Saichandu Juluri"
      ],
      "abstract": "We present a framework that extends the Actor-Critic architecture to creative 3D modeling through multi-agent self-reflection and human-in-the-loop supervision. While existing approaches rely on single-prompt agents that directly execute modeling commands via tools like Blender MCP, our approach introduces a Planner-Actor-Critic architecture. In this design, the Planner coordinates modeling steps, the Actor executes them, and the Critic provides iterative feedback, while human users act as supervisors and advisors throughout the process. Through systematic comparison between single-prompt modeling and our reflective multi-agent approach, we demonstrate improvements in geometric accuracy, aesthetic quality, and task completion rates across diverse 3D modeling scenarios. Our evaluation reveals that critic-guided reflection, combined with human supervisory input, reduces modeling errors and increases complexity and quality of the result compared to direct single-prompt execution. This work establishes that structured agent self-reflection, when augmented by human oversight and advisory guidance, produces higher-quality 3D models while maintaining efficient workflow integration through real-time Blender synchronization.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.GR",
        "cs.HC"
      ],
      "primary_category": "cs.MA",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05016v1",
        "pdf": "https://arxiv.org/pdf/2601.05016v1"
      },
      "arxiv_id": "2601.05016v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05011v1",
      "title": "Leveraging Prediction Entropy for Automatic Prompt Weighting in Zero-Shot Audio-Language Classification",
      "authors": [
        "Karim El Khoury",
        "Maxime Zanella",
        "Tiffanie Godelaine",
        "Christophe De Vleeschouwer",
        "Benoit Macq"
      ],
      "abstract": "Audio-language models have recently demonstrated strong zero-shot capabilities by leveraging natural-language supervision to classify audio events without labeled training data. Yet, their performance is highly sensitive to the wording of text prompts, with small variations leading to large fluctuations in accuracy. Prior work has mitigated this issue through prompt learning or prompt ensembling. However, these strategies either require annotated data or fail to account for the fact that some prompts may negatively impact performance. In this work, we present an entropy-guided prompt weighting approach that aims to find a robust combination of prompt contributions to maximize prediction confidence. To this end, we formulate a tailored objective function that minimizes prediction entropy to yield new prompt weights, utilizing low-entropy as a proxy for high confidence. Our approach can be applied to individual samples or a batch of audio samples, requiring no additional labels and incurring negligible computational overhead. Experiments on five audio classification datasets covering environmental, urban, and vocal sounds, demonstrate consistent gains compared to classical prompt ensembling methods in a zero-shot setting, with accuracy improvements 5-times larger across the whole benchmark.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.SD",
        "cs.LG"
      ],
      "primary_category": "cs.SD",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05011v1",
        "pdf": "https://arxiv.org/pdf/2601.05011v1"
      },
      "arxiv_id": "2601.05011v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05009v1",
      "title": "An Empirical Investigation of Robustness in Large Language Models under Tabular Distortions",
      "authors": [
        "Avik Dutta",
        "Harshit Nigam",
        "Hosein Hasanbeig",
        "Arjun Radhakrishna",
        "Sumit Gulwani"
      ],
      "abstract": "We investigate how large language models (LLMs) fail when tabular data in an otherwise canonical representation is subjected to semantic and structural distortions. Our findings reveal that LLMs lack an inherent ability to detect and correct subtle distortions in table representations. Only when provided with an explicit prior, via a system prompt, do models partially adjust their reasoning strategies and correct some distortions, though not consistently or completely. To study this phenomenon, we introduce a small, expert-curated dataset that explicitly evaluates LLMs on table question answering (TQA) tasks requiring an additional error-correction step prior to analysis. Our results reveal systematic differences in how LLMs ingest and interpret tabular information under distortion, with even SoTA models such as GPT-5.2 model exhibiting a drop of minimum 22% accuracy under distortion. These findings raise important questions for future research, particularly regarding when and how models should autonomously decide to realign tabular inputs, analogous to human behavior, without relying on explicit prompts or tabular data pre-processing.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05009v1",
        "pdf": "https://arxiv.org/pdf/2601.05009v1"
      },
      "arxiv_id": "2601.05009v1",
      "comment": "4 pages, 1 figure, 1 table",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.05002v1",
      "title": "On the Hidden Objective Biases of Group-based Reinforcement Learning",
      "authors": [
        "Aleksandar Fontana",
        "Marco Simoni",
        "Giulio Rossolini",
        "Andrea Saracino",
        "Paolo Mori"
      ],
      "abstract": "Group-based reinforcement learning methods, like Group Relative Policy Optimization (GRPO), are widely used nowadays to post-train large language models. Despite their empirical success, they exhibit structural mismatches between reward optimization and the underlying training objective. In this paper, we present a theoretical analysis of GRPO style methods by studying them within a unified surrogate formulation. This perspective reveals recurring properties that affect all the methods under analysis: (i) non-uniform group weighting induces systematic gradient biases on shared prefix tokens; (ii) interactions with the AdamW optimizer make training dynamics largely insensitive to reward scaling; and (iii) optimizer momentum can push policy updates beyond the intended clipping region under repeated optimization steps. We believe that these findings highlight fundamental limitations of current approaches and provide principled guidance for the design of future formulations.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.05002v1",
        "pdf": "https://arxiv.org/pdf/2601.05002v1"
      },
      "arxiv_id": "2601.05002v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.04996v1",
      "title": "AlgBench: To What Extent Do Large Reasoning Models Understand Algorithms?",
      "authors": [
        "Henan Sun",
        "Kaichi Yu",
        "Yuyao Wang",
        "Bowen Liu",
        "Xunkai Li",
        "Rong-Hua Li",
        "Nuo Chen",
        "Jia Li"
      ],
      "abstract": "Reasoning ability has become a central focus in the advancement of Large Reasoning Models (LRMs). Although notable progress has been achieved on several reasoning benchmarks such as MATH500 and LiveCodeBench, existing benchmarks for algorithmic reasoning remain limited, failing to answer a critical question: Do LRMs truly master algorithmic reasoning? To answer this question, we propose AlgBench, an expert-curated benchmark that evaluates LRMs under an algorithm-centric paradigm.\n  AlgBench consists of over 3,000 original problems spanning 27 algorithms, constructed by ACM algorithmic experts and organized under a comprehensive taxonomy, including Euclidean-structured, non-Euclidean-structured, non-optimized, local-optimized, global-optimized, and heuristic-optimized categories. Empirical evaluations on leading LRMs (e.g., Gemini-3-Pro, DeepSeek-v3.2-Speciale and GPT-o3) reveal substantial performance heterogeneity: while models perform well on non-optimized tasks (up to 92%), accuracy drops sharply to around 49% on globally optimized algorithms such as dynamic programming. Further analysis uncovers \\textbf{strategic over-shifts}, wherein models prematurely abandon correct algorithmic designs due to necessary low-entropy tokens. These findings expose fundamental limitations of problem-centric reinforcement learning and highlight the necessity of an algorithm-centric training paradigm for robust algorithmic reasoning.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.04996v1",
        "pdf": "https://arxiv.org/pdf/2601.04996v1"
      },
      "arxiv_id": "2601.04996v1",
      "comment": "Under review",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.04991v1",
      "title": "Higher-Order Adversarial Patches for Real-Time Object Detectors",
      "authors": [
        "Jens Bayer",
        "Stefan Becker",
        "David Münch",
        "Michael Arens",
        "Jürgen Beyerer"
      ],
      "abstract": "Higher-order adversarial attacks can directly be considered the result of a cat-and-mouse game -- an elaborate action involving constant pursuit, near captures, and repeated escapes. This idiom describes the enduring circular training of adversarial attack patterns and adversarial training the best. The following work investigates the impact of higher-order adversarial attacks on object detectors by successively training attack patterns and hardening object detectors with adversarial training. The YOLOv10 object detector is chosen as a representative, and adversarial patches are used in an evasion attack manner. Our results indicate that higher-order adversarial patches are not only affecting the object detector directly trained on but rather provide a stronger generalization capacity compared to lower-order adversarial patches. Moreover, the results highlight that solely adversarial training is not sufficient to harden an object detector efficiently against this kind of adversarial attack. Code: https://github.com/JensBayer/HigherOrder",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.04991v1",
        "pdf": "https://arxiv.org/pdf/2601.04991v1"
      },
      "arxiv_id": "2601.04991v1",
      "comment": "Under review (ICPR2026)",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.04984v1",
      "title": "OceanSplat: Object-aware Gaussian Splatting with Trinocular View Consistency for Underwater Scene Reconstruction",
      "authors": [
        "Minseong Kweon",
        "Jinsun Park"
      ],
      "abstract": "We introduce OceanSplat, a novel 3D Gaussian Splatting-based approach for accurately representing 3D geometry in underwater scenes. To overcome multi-view inconsistencies caused by underwater optical degradation, our method enforces trinocular view consistency by rendering horizontally and vertically translated camera views relative to each input view and aligning them via inverse warping. Furthermore, these translated camera views are used to derive a synthetic epipolar depth prior through triangulation, which serves as a self-supervised depth regularizer. These geometric constraints facilitate the spatial optimization of 3D Gaussians and preserve scene structure in underwater environments. We also propose a depth-aware alpha adjustment that modulates the opacity of 3D Gaussians during early training based on their $z$-component and viewing direction, deterring the formation of medium-induced primitives. With our contributions, 3D Gaussians are disentangled from the scattering medium, enabling robust representation of object geometry and significantly reducing floating artifacts in reconstructed underwater scenes. Experiments on real-world underwater and simulated scenes demonstrate that OceanSplat substantially outperforms existing methods for both scene reconstruction and restoration in scattering media.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.04984v1",
        "pdf": "https://arxiv.org/pdf/2601.04984v1"
      },
      "arxiv_id": "2601.04984v1",
      "comment": "Accepted to AAAI 2026. Project page: https://oceansplat.github.io",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2601.04982v1",
      "title": "When to Act: Calibrated Confidence for Reliable Human Intention Prediction in Assistive Robotics",
      "authors": [
        "Johannes A. Gaus",
        "Winfried Ilg",
        "Daniel Haeufle"
      ],
      "abstract": "Assistive devices must determine both what a user intends to do and how reliable that prediction is before providing support. We introduce a safety-critical triggering framework based on calibrated probabilities for multimodal next-action prediction in Activities of Daily Living. Raw model confidence often fails to reflect true correctness, posing a safety risk. Post-hoc calibration aligns predicted confidence with empirical reliability and reduces miscalibration by about an order of magnitude without affecting accuracy. The calibrated confidence drives a simple ACT/HOLD rule that acts only when reliability is high and withholds assistance otherwise. This turns the confidence threshold into a quantitative safety parameter for assisted actions and enables verifiable behavior in an assistive control loop.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "links": {
        "paper": "http://arxiv.org/abs/2601.04982v1",
        "pdf": "https://arxiv.org/pdf/2601.04982v1"
      },
      "arxiv_id": "2601.04982v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.04977v1",
      "title": "On the Definition and Detection of Cherry-Picking in Counterfactual Explanations",
      "authors": [
        "James Hinns",
        "Sofie Goethals",
        "Stephan Van der Veeken",
        "Theodoros Evgeniou",
        "David Martens"
      ],
      "abstract": "Counterfactual explanations are widely used to communicate how inputs must change for a model to alter its prediction. For a single instance, many valid counterfactuals can exist, which leaves open the possibility for an explanation provider to cherry-pick explanations that better suit a narrative of their choice, highlighting favourable behaviour and withholding examples that reveal problematic behaviour. We formally define cherry-picking for counterfactual explanations in terms of an admissible explanation space, specified by the generation procedure, and a utility function. We then study to what extent an external auditor can detect such manipulation. Considering three levels of access to the explanation process: full procedural access, partial procedural access, and explanation-only access, we show that detection is extremely limited in practice. Even with full procedural access, cherry-picked explanations can remain difficult to distinguish from non cherry-picked explanations, because the multiplicity of valid counterfactuals and flexibility in the explanation specification provide sufficient degrees of freedom to mask deliberate selection. Empirically, we demonstrate that this variability often exceeds the effect of cherry-picking on standard counterfactual quality metrics such as proximity, plausibility, and sparsity, making cherry-picked explanations statistically indistinguishable from baseline explanations. We argue that safeguards should therefore prioritise reproducibility, standardisation, and procedural constraints over post-hoc detection, and we provide recommendations for algorithm developers, explanation providers, and auditors.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.04977v1",
        "pdf": "https://arxiv.org/pdf/2601.04977v1"
      },
      "arxiv_id": "2601.04977v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.04973v1",
      "title": "ConMax: Confidence-Maximizing Compression for Efficient Chain-of-Thought Reasoning",
      "authors": [
        "Minda Hu",
        "Zexuan Qiu",
        "Zenan Xu",
        "Kun Li",
        "Bo Zhou",
        "Irwin King"
      ],
      "abstract": "Recent breakthroughs in Large Reasoning Models (LRMs) have demonstrated that extensive Chain-of-Thought (CoT) generation is critical for enabling intricate cognitive behaviors, such as self-verification and backtracking, to solve complex tasks. However, this capability often leads to ``overthinking'', where models generate redundant reasoning paths that inflate computational costs without improving accuracy. While Supervised Fine-Tuning (SFT) on reasoning traces is a standard paradigm for the 'cold start' phase, applying existing compression techniques to these traces often compromises logical coherence or incurs prohibitive sampling costs. In this paper, we introduce ConMax (Confidence-Maximizing Compression), a novel reinforcement learning framework designed to automatically compress reasoning traces while preserving essential reasoning patterns. ConMax formulates compression as a reward-driven optimization problem, training a policy to prune redundancy by maximizing a weighted combination of answer confidence for predictive fidelity and thinking confidence for reasoning validity through a frozen auxiliary LRM. Extensive experiments across five reasoning datasets demonstrate that ConMax achieves a superior efficiency-performance trade-off. Specifically, it reduces inference length by 43% over strong baselines at the cost of a mere 0.7% dip in accuracy, proving its effectiveness in generating high-quality, efficient training data for LRMs.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.04973v1",
        "pdf": "https://arxiv.org/pdf/2601.04973v1"
      },
      "arxiv_id": "2601.04973v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.04968v1",
      "title": "SparseLaneSTP: Leveraging Spatio-Temporal Priors with Sparse Transformers for 3D Lane Detection",
      "authors": [
        "Maximilian Pittner",
        "Joel Janai",
        "Mario Faigle",
        "Alexandru Paul Condurache"
      ],
      "abstract": "3D lane detection has emerged as a critical challenge in autonomous driving, encompassing identification and localization of lane markings and the 3D road surface. Conventional 3D methods detect lanes from dense birds-eye-viewed (BEV) features, though erroneous transformations often result in a poor feature representation misaligned with the true 3D road surface. While recent sparse lane detectors have surpassed dense BEV approaches, they completely disregard valuable lane-specific priors. Furthermore, existing methods fail to utilize historic lane observations, which yield the potential to resolve ambiguities in situations of poor visibility. To address these challenges, we present SparseLaneSTP, a novel method that integrates both geometric properties of the lane structure and temporal information into a sparse lane transformer. It introduces a new lane-specific spatio-temporal attention mechanism, a continuous lane representation tailored for sparse architectures as well as temporal regularization. Identifying weaknesses of existing 3D lane datasets, we also introduce a precise and consistent 3D lane dataset using a simple yet effective auto-labeling strategy. Our experimental section proves the benefits of our contributions and demonstrates state-of-the-art performance across all detection and error metrics on existing 3D lane detection benchmarks as well as on our novel dataset.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.04968v1",
        "pdf": "https://arxiv.org/pdf/2601.04968v1"
      },
      "arxiv_id": "2601.04968v1",
      "comment": "Published at IEEE/CVF International Conference on Computer Vision (ICCV) 2025",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.04963v1",
      "title": "Text as a Universal Interface for Transferable Personalization",
      "authors": [
        "Yuting Liu",
        "Jian Guan",
        "Jia-Nan Li",
        "Wei Wu",
        "Jiang-Ming Yang",
        "Jianzhe Zhao",
        "Guibing Guo"
      ],
      "abstract": "We study the problem of personalization in large language models (LLMs). Prior work predominantly represents user preferences as implicit, model-specific vectors or parameters, yielding opaque ``black-box'' profiles that are difficult to interpret and transfer across models and tasks. In contrast, we advocate natural language as a universal, model- and task-agnostic interface for preference representation. The formulation leads to interpretable and reusable preference descriptions, while naturally supporting continual evolution as new interactions are observed. To learn such representations, we introduce a two-stage training framework that combines supervised fine-tuning on high-quality synthesized data with reinforcement learning to optimize long-term utility and cross-task transferability. Based on this framework, we develop AlignXplore+, a universal preference reasoning model that generates textual preference summaries. Experiments on nine benchmarks show that our 8B model achieves state-of-the-art performanc -- outperforming substantially larger open-source models -- while exhibiting strong transferability across tasks, model families, and interaction formats.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2601.04963v1",
        "pdf": "https://arxiv.org/pdf/2601.04963v1"
      },
      "arxiv_id": "2601.04963v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.04956v1",
      "title": "TEA: Temporal Adaptive Satellite Image Semantic Segmentation",
      "authors": [
        "Juyuan Kang",
        "Hao Zhu",
        "Yan Zhu",
        "Wei Zhang",
        "Jianing Chen",
        "Tianxiang Xiao",
        "Yike Ma",
        "Hao Jiang",
        "Feng Dai"
      ],
      "abstract": "Crop mapping based on satellite images time-series (SITS) holds substantial economic value in agricultural production settings, in which parcel segmentation is an essential step. Existing approaches have achieved notable advancements in SITS segmentation with predetermined sequence lengths. However, we found that these approaches overlooked the generalization capability of models across scenarios with varying temporal length, leading to markedly poor segmentation results in such cases. To address this issue, we propose TEA, a TEmporal Adaptive SITS semantic segmentation method to enhance the model's resilience under varying sequence lengths. We introduce a teacher model that encapsulates the global sequence knowledge to guide a student model with adaptive temporal input lengths. Specifically, teacher shapes the student's feature space via intermediate embedding, prototypes and soft label perspectives to realize knowledge transfer, while dynamically aggregating student model to mitigate knowledge forgetting. Finally, we introduce full-sequence reconstruction as an auxiliary task to further enhance the quality of representations across inputs of varying temporal lengths. Through extensive experiments, we demonstrate that our method brings remarkable improvements across inputs of different temporal lengths on common benchmarks. Our code will be publicly available.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.04956v1",
        "pdf": "https://arxiv.org/pdf/2601.04956v1"
      },
      "arxiv_id": "2601.04956v1",
      "comment": "Under review. Code will be available at \\href{https://github.com/KeplerKang/TEA}{this https URL}",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2601.04954v1",
      "title": "Precision over Diversity: High-Precision Reward Generalizes to Robust Instruction Following",
      "authors": [
        "Yirong Zeng",
        "Yufei Liu",
        "Xiao Ding",
        "Yutai Hou",
        "Yuxian Wang",
        "Haonan Song",
        "Wu Ning",
        "Dandan Tu",
        "Qixun Zhang",
        "Bibo Cai",
        "Yuxiang He",
        "Ting Liu"
      ],
      "abstract": "A central belief in scaling reinforcement learning with verifiable rewards for instruction following (IF) tasks is that, a diverse mixture of verifiable hard and unverifiable soft constraints is essential for generalizing to unseen instructions. In this work, we challenge this prevailing consensus through a systematic empirical investigation. Counter-intuitively, we find that models trained on hard-only constraints consistently outperform those trained on mixed datasets. Extensive experiments reveal that reward precision, rather than constraint diversity, is the primary driver of effective alignment. The LLM judge suffers from a low recall rate in detecting false response, which leads to severe reward hacking, thereby undermining the benefits of diversity. Furthermore, analysis of the attention mechanism reveals that high-precision rewards develop a transferable meta-skill for IF. Motivated by these insights, we propose a simple yet effective data-centric refinement strategy that prioritizes reward precision. Evaluated on five benchmarks, our approach outperforms competitive baselines by 13.4\\% in performance while achieving a 58\\% reduction in training time, maintaining strong generalization beyond instruction following. Our findings advocate for a paradigm shift: moving away from the indiscriminate pursuit of data diversity toward high-precision rewards.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.04954v1",
        "pdf": "https://arxiv.org/pdf/2601.04954v1"
      },
      "arxiv_id": "2601.04954v1",
      "comment": "ACL under review 13 pages, 8 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.04946v1",
      "title": "Prototypicality Bias Reveals Blindspots in Multimodal Evaluation Metrics",
      "authors": [
        "Subhadeep Roy",
        "Gagan Bhatia",
        "Steffen Eger"
      ],
      "abstract": "Automatic metrics are now central to evaluating text-to-image models, often substituting for human judgment in benchmarking and large-scale filtering. However, it remains unclear whether these metrics truly prioritize semantic correctness or instead favor visually and socially prototypical images learned from biased data distributions. We identify and study \\emph{prototypicality bias} as a systematic failure mode in multimodal evaluation. We introduce a controlled contrastive benchmark \\textsc{\\textbf{ProtoBias}} (\\textit{\\textbf{Proto}typical \\textbf{Bias}}), spanning Animals, Objects, and Demography images, where semantically correct but non-prototypical images are paired with subtly incorrect yet prototypical adversarial counterparts. This setup enables a directional evaluation of whether metrics follow textual semantics or default to prototypes. Our results show that widely used metrics, including CLIPScore, PickScore, and VQA-based scores, frequently misrank these pairs, while even LLM-as-Judge systems exhibit uneven robustness in socially grounded cases. Human evaluations consistently favour semantic correctness with larger decision margins. Motivated by these findings, we propose \\textbf{\\textsc{ProtoScore}}, a robust 7B-parameter metric that substantially reduces failure rates and suppresses misranking, while running at orders of magnitude faster than the inference time of GPT-5, approaching the robustness of much larger closed-source judges.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.04946v1",
        "pdf": "https://arxiv.org/pdf/2601.04946v1"
      },
      "arxiv_id": "2601.04946v1",
      "comment": "First version",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.04945v1",
      "title": "T-Retriever: Tree-based Hierarchical Retrieval Augmented Generation for Textual Graphs",
      "authors": [
        "Chunyu Wei",
        "Huaiyu Qin",
        "Siyuan He",
        "Yunhai Wang",
        "Yueguo Chen"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) has significantly enhanced Large Language Models' ability to access external knowledge, yet current graph-based RAG approaches face two critical limitations in managing hierarchical information: they impose rigid layer-specific compression quotas that damage local graph structures, and they prioritize topological structure while neglecting semantic content. We introduce T-Retriever, a novel framework that reformulates attributed graph retrieval as tree-based retrieval using a semantic and structure-guided encoding tree. Our approach features two key innovations: (1) Adaptive Compression Encoding, which replaces artificial compression quotas with a global optimization strategy that preserves the graph's natural hierarchical organization, and (2) Semantic-Structural Entropy ($S^2$-Entropy), which jointly optimizes for both structural cohesion and semantic consistency when creating hierarchical partitions. Experiments across diverse graph reasoning benchmarks demonstrate that T-Retriever significantly outperforms state-of-the-art RAG methods, providing more coherent and contextually relevant responses to complex queries.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.04945v1",
        "pdf": "https://arxiv.org/pdf/2601.04945v1"
      },
      "arxiv_id": "2601.04945v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.04941v1",
      "title": "Cardinality augmented loss functions",
      "authors": [
        "Miguel O'Malley"
      ],
      "abstract": "Class imbalance is a common and pernicious issue for the training of neural networks. Often, an imbalanced majority class can dominate training to skew classifier performance towards the majority outcome. To address this problem we introduce cardinality augmented loss functions, derived from cardinality-like invariants in modern mathematics literature such as magnitude and the spread. These invariants enrich the concept of cardinality by evaluating the `effective diversity' of a metric space, and as such represent a natural solution to overly homogeneous training data. In this work, we establish a methodology for applying cardinality augmented loss functions in the training of neural networks and report results on both artificially imbalanced datasets as well as a real-world imbalanced material science dataset. We observe significant performance improvement among minority classes, as well as improvement in overall performance metrics.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.04941v1",
        "pdf": "https://arxiv.org/pdf/2601.04941v1"
      },
      "arxiv_id": "2601.04941v1",
      "comment": "12 pages, 3 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.04940v1",
      "title": "CurricuLLM: Designing Personalized and Workforce-Aligned Cybersecurity Curricula Using Fine-Tuned LLMs",
      "authors": [
        "Arthur Nijdam",
        "Harri Kähkönen",
        "Valtteri Niemi",
        "Paul Stankovski Wagner",
        "Sara Ramezanian"
      ],
      "abstract": "The cybersecurity landscape is constantly evolving, driven by increased digitalization and new cybersecurity threats. Cybersecurity programs often fail to equip graduates with skills demanded by the workforce, particularly concerning recent developments in cybersecurity, as curriculum design is costly and labor-intensive. To address this misalignment, we present a novel Large Language Model (LLM)-based framework for automated design and analysis of cybersecurity curricula, called CurricuLLM. Our approach provides three key contributions: (1) automation of personalized curriculum design, (2) a data-driven pipeline aligned with industry demands, and (3) a comprehensive methodology for leveraging fine-tuned LLMs in curriculum development.\n  CurricuLLM utilizes a two-tier approach consisting of PreprocessLM, which standardizes input data, and ClassifyLM, which assigns course content to nine Knowledge Areas in cybersecurity. We systematically evaluated multiple Natural Language Processing (NLP) architectures and fine-tuning strategies, ultimately selecting the Bidirectional Encoder Representations from Transformers (BERT) model as ClassifyLM, fine-tuned on foundational cybersecurity concepts and workforce competencies.\n  We are the first to validate our method with human experts who analyzed real-world cybersecurity curricula and frameworks, motivating that CurricuLLM is an efficient solution to replace labor-intensive curriculum analysis. Moreover, once course content has been classified, it can be integrated with established cybersecurity role-based weights, enabling alignment of the educational program with specific job roles, workforce categories, or general market needs. This lays the foundation for personalized, workforce-aligned cybersecurity curricula that prepare students for the evolving demands in cybersecurity.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "links": {
        "paper": "http://arxiv.org/abs/2601.04940v1",
        "pdf": "https://arxiv.org/pdf/2601.04940v1"
      },
      "arxiv_id": "2601.04940v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.04920v1",
      "title": "Conversational AI for Rapid Scientific Prototyping: A Case Study on ESA's ELOPE Competition",
      "authors": [
        "Nils Einecke"
      ],
      "abstract": "Large language models (LLMs) are increasingly used as coding partners, yet their role in accelerating scientific discovery remains underexplored. This paper presents a case study of using ChatGPT for rapid prototyping in ESA's ELOPE (Event-based Lunar OPtical flow Egomotion estimation) competition. The competition required participants to process event camera data to estimate lunar lander trajectories. Despite joining late, we achieved second place with a score of 0.01282, highlighting the potential of human-AI collaboration in competitive scientific settings. ChatGPT contributed not only executable code but also algorithmic reasoning, data handling routines, and methodological suggestions, such as using fixed number of events instead of fixed time spans for windowing. At the same time, we observed limitations: the model often introduced unnecessary structural changes, gets confused by intermediate discussions about alternative ideas, occasionally produced critical errors and forgets important aspects in longer scientific discussions. By analyzing these strengths and shortcomings, we show how conversational AI can both accelerate development and support conceptual insight in scientific research. We argue that structured integration of LLMs into the scientific workflow can enhance rapid prototyping by proposing best practices for AI-assisted scientific work.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.04920v1",
        "pdf": "https://arxiv.org/pdf/2601.04920v1"
      },
      "arxiv_id": "2601.04920v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.04919v1",
      "title": "What Students Ask, How a Generative AI Assistant Responds: Exploring Higher Education Students' Dialogues on Learning Analytics Feedback",
      "authors": [
        "Yildiz Uzun",
        "Andrea Gauthier",
        "Mutlu Cukurova"
      ],
      "abstract": "Learning analytics dashboards (LADs) aim to support students' regulation of learning by translating complex data into feedback. Yet students, especially those with lower self-regulated learning (SRL) competence, often struggle to engage with and interpret analytics feedback. Conversational generative artificial intelligence (GenAI) assistants have shown potential to scaffold this process through real-time, personalised, dialogue-based support. Further advancing this potential, we explored authentic dialogues between students and GenAI assistant integrated into LAD during a 10-week semester. The analysis focused on questions students with different SRL levels posed, the relevance and quality of the assistant's answers, and how students perceived the assistant's role in their learning. Findings revealed distinct query patterns. While low SRL students sought clarification and reassurance, high SRL students queried technical aspects and requested personalised strategies. The assistant provided clear and reliable explanations but limited in personalisation, handling emotionally charged queries, and integrating multiple data points for tailored responses. Findings further extend that GenAI interventions can be especially valuable for low SRL students, offering scaffolding that supports engagement with feedback and narrows gaps with their higher SRL peers. At the same time, students' reflections underscored the importance of trust, need for greater adaptivity, context-awareness, and technical refinement in future systems.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.04919v1",
        "pdf": "https://arxiv.org/pdf/2601.04919v1"
      },
      "arxiv_id": "2601.04919v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.04918v1",
      "title": "Breaking Robustness Barriers in Cognitive Diagnosis: A One-Shot Neural Architecture Search Perspective",
      "authors": [
        "Ziwen Wang",
        "Shangshang Yang",
        "Xiaoshan Yu",
        "Haiping Ma",
        "Xingyi Zhang"
      ],
      "abstract": "With the advancement of network technologies, intelligent tutoring systems (ITS) have emerged to deliver increasingly precise and tailored personalized learning services. Cognitive diagnosis (CD) has emerged as a core research task in ITS, aiming to infer learners' mastery of specific knowledge concepts by modeling the mapping between learning behavior data and knowledge states. However, existing research prioritizes model performance enhancement while neglecting the pervasive noise contamination in observed response data, significantly hindering practical deployment. Furthermore, current cognitive diagnosis models (CDMs) rely heavily on researchers' domain expertise for structural design, which fails to exhaustively explore architectural possibilities, thus leaving model architectures' full potential untapped. To address this issue, we propose OSCD, an evolutionary multi-objective One-Shot neural architecture search method for Cognitive Diagnosis, designed to efficiently and robustly improve the model's capability in assessing learner proficiency. Specifically, OSCD operates through two distinct stages: training and searching. During the training stage, we construct a search space encompassing diverse architectural combinations and train a weight-sharing supernet represented via the complete binary tree topology, enabling comprehensive exploration of potential architectures beyond manual design priors. In the searching stage, we formulate the optimal architecture search under heterogeneous noise scenarios as a multi-objective optimization problem (MOP), and develop an optimization framework integrating a Pareto-optimal solution search strategy with cross-scenario performance evaluation for resolution. Extensive experiments on real-world educational datasets validate the effectiveness and robustness of the optimal architectures discovered by our OSCD model for CD tasks.",
      "published": "2026-01-08",
      "updated": "2026-01-08",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "links": {
        "paper": "http://arxiv.org/abs/2601.04918v1",
        "pdf": "https://arxiv.org/pdf/2601.04918v1"
      },
      "arxiv_id": "2601.04918v1",
      "comment": "KDD2026, 15 pages",
      "journal_ref": "",
      "has_code": false
    }
  ]
}