{
  "fetched_at": "2026-01-17T00:26:01.165070",
  "total_papers": 100,
  "papers": [
    {
      "id": "2601.10716v1",
      "title": "WildRayZer: Self-supervised Large View Synthesis in Dynamic Environments",
      "authors": [
        "Xuweiyi Chen",
        "Wentao Zhou",
        "Zezhou Cheng"
      ],
      "abstract": "We present WildRayZer, a self-supervised framework for novel view synthesis (NVS) in dynamic environments where both the camera and objects move. Dynamic content breaks the multi-view consistency that static NVS models rely on, leading to ghosting, hallucinated geometry, and unstable pose estimation. WildRayZer addresses this by performing an analysis-by-synthesis test: a camera-only static renderer explains rigid structure, and its residuals reveal transient regions. From these residuals, we construct pseudo motion masks, distill a motion estimator, and use it to mask input tokens and gate loss gradients so supervision focuses on cross-view background completion. To enable large-scale training and evaluation, we curate Dynamic RealEstate10K (D-RE10K), a real-world dataset of 15K casually captured dynamic sequences, and D-RE10K-iPhone, a paired transient and clean benchmark for sparse-view transient-aware NVS. Experiments show that WildRayZer consistently outperforms optimization-based and feed-forward baselines in both transient-region removal and full-frame NVS quality with a single feed-forward pass.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10716v1",
        "pdf": "https://arxiv.org/pdf/2601.10716v1"
      },
      "arxiv_id": "2601.10716v1",
      "comment": "Project Page: https://wild-rayzer.cs.virginia.edu/",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10715v1",
      "title": "DInf-Grid: A Neural Differential Equation Solver with Differentiable Feature Grids",
      "authors": [
        "Navami Kairanda",
        "Shanthika Naik",
        "Marc Habermann",
        "Avinash Sharma",
        "Christian Theobalt",
        "Vladislav Golyanik"
      ],
      "abstract": "We present a novel differentiable grid-based representation for efficiently solving differential equations (DEs). Widely used architectures for neural solvers, such as sinusoidal neural networks, are coordinate-based MLPs that are both computationally intensive and slow to train. Although grid-based alternatives for implicit representations (e.g., Instant-NGP and K-Planes) train faster by exploiting signal structure, their reliance on linear interpolation restricts their ability to compute higher-order derivatives, rendering them unsuitable for solving DEs. Our approach overcomes these limitations by combining the efficiency of feature grids with radial basis function interpolation, which is infinitely differentiable. To effectively capture high-frequency solutions and enable stable and faster computation of global gradients, we introduce a multi-resolution decomposition with co-located grids. Our proposed representation, DInf-Grid, is trained implicitly using the differential equations as loss functions, enabling accurate modelling of physical fields. We validate DInf-Grid on a variety of tasks, including the Poisson equation for image reconstruction, the Helmholtz equation for wave fields, and the Kirchhoff-Love boundary value problem for cloth simulation. Our results demonstrate a 5-20x speed-up over coordinate-based MLP-based methods, solving differential equations in seconds or minutes while maintaining comparable accuracy and compactness.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10715v1",
        "pdf": "https://arxiv.org/pdf/2601.10715v1"
      },
      "arxiv_id": "2601.10715v1",
      "comment": "25 pages; 16 figures; project page: https://4dqv.mpi-inf.mpg.de/DInf-Grid/",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10714v1",
      "title": "Alterbute: Editing Intrinsic Attributes of Objects in Images",
      "authors": [
        "Tal Reiss",
        "Daniel Winter",
        "Matan Cohen",
        "Alex Rav-Acha",
        "Yael Pritch",
        "Ariel Shamir",
        "Yedid Hoshen"
      ],
      "abstract": "We introduce Alterbute, a diffusion-based method for editing an object's intrinsic attributes in an image. We allow changing color, texture, material, and even the shape of an object, while preserving its perceived identity and scene context. Existing approaches either rely on unsupervised priors that often fail to preserve identity or use overly restrictive supervision that prevents meaningful intrinsic variations. Our method relies on: (i) a relaxed training objective that allows the model to change both intrinsic and extrinsic attributes conditioned on an identity reference image, a textual prompt describing the target intrinsic attributes, and a background image and object mask defining the extrinsic context. At inference, we restrict extrinsic changes by reusing the original background and object mask, thereby ensuring that only the desired intrinsic attributes are altered; (ii) Visual Named Entities (VNEs) - fine-grained visual identity categories (e.g., ''Porsche 911 Carrera'') that group objects sharing identity-defining features while allowing variation in intrinsic attributes. We use a vision-language model to automatically extract VNE labels and intrinsic attribute descriptions from a large public image dataset, enabling scalable, identity-preserving supervision. Alterbute outperforms existing methods on identity-preserving object intrinsic attribute editing.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.CV",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10714v1",
        "pdf": "https://arxiv.org/pdf/2601.10714v1"
      },
      "arxiv_id": "2601.10714v1",
      "comment": "Project page is available at https://talreiss.github.io/alterbute/",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2601.10712v1",
      "title": "MatchTIR: Fine-Grained Supervision for Tool-Integrated Reasoning via Bipartite Matching",
      "authors": [
        "Changle Qu",
        "Sunhao Dai",
        "Hengyi Cai",
        "Jun Xu",
        "Shuaiqiang Wang",
        "Dawei Yin"
      ],
      "abstract": "Tool-Integrated Reasoning (TIR) empowers large language models (LLMs) to tackle complex tasks by interleaving reasoning steps with external tool interactions. However, existing reinforcement learning methods typically rely on outcome- or trajectory-level rewards, assigning uniform advantages to all steps within a trajectory. This coarse-grained credit assignment fails to distinguish effective tool calls from redundant or erroneous ones, particularly in long-horizon multi-turn scenarios. To address this, we propose MatchTIR, a framework that introduces fine-grained supervision via bipartite matching-based turn-level reward assignment and dual-level advantage estimation. Specifically, we formulate credit assignment as a bipartite matching problem between predicted and ground-truth traces, utilizing two assignment strategies to derive dense turn-level rewards. Furthermore, to balance local step precision with global task success, we introduce a dual-level advantage estimation scheme that integrates turn-level and trajectory-level signals, assigning distinct advantage values to individual interaction turns. Extensive experiments on three benchmarks demonstrate the superiority of MatchTIR. Notably, our 4B model surpasses the majority of 8B competitors, particularly in long-horizon and multi-turn tasks. Our codes are available at https://github.com/quchangle1/MatchTIR.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10712v1",
        "pdf": "https://arxiv.org/pdf/2601.10712v1"
      },
      "arxiv_id": "2601.10712v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10710v1",
      "title": "From One-to-One to Many-to-Many: Dynamic Cross-Layer Injection for Deep Vision-Language Fusion",
      "authors": [
        "Cheng Chen",
        "Yuyu Guo",
        "Pengpeng Zeng",
        "Jingkuan Song",
        "Peng Di",
        "Hang Yu",
        "Lianli Gao"
      ],
      "abstract": "Vision-Language Models (VLMs) create a severe visual feature bottleneck by using a crude, asymmetric connection that links only the output of the vision encoder to the input of the large language model (LLM). This static architecture fundamentally limits the ability of LLMs to achieve comprehensive alignment with hierarchical visual knowledge, compromising their capacity to accurately integrate local details with global semantics into coherent reasoning. To resolve this, we introduce Cross-Layer Injection (CLI), a novel and lightweight framework that forges a dynamic many-to-many bridge between the two modalities. CLI consists of two synergistic, parameter-efficient components: an Adaptive Multi-Projection (AMP) module that harmonizes features from diverse vision layers, and an Adaptive Gating Fusion (AGF) mechanism that empowers the LLM to selectively inject the most relevant visual information based on its real-time decoding context. We validate the effectiveness and versatility of CLI by integrating it into LLaVA-OneVision and LLaVA-1.5. Extensive experiments on 18 diverse benchmarks demonstrate significant performance improvements, establishing CLI as a scalable paradigm that unlocks deeper multimodal understanding by granting LLMs on-demand access to the full visual hierarchy.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10710v1",
        "pdf": "https://arxiv.org/pdf/2601.10710v1"
      },
      "arxiv_id": "2601.10710v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10708v1",
      "title": "High-accuracy and dimension-free sampling with diffusions",
      "authors": [
        "Khashayar Gatmiry",
        "Sitan Chen",
        "Adil Salim"
      ],
      "abstract": "Diffusion models have shown remarkable empirical success in sampling from rich multi-modal distributions. Their inference relies on numerically solving a certain differential equation. This differential equation cannot be solved in closed form, and its resolution via discretization typically requires many small iterations to produce \\emph{high-quality} samples.\n  More precisely, prior works have shown that the iteration complexity of discretization methods for diffusion models scales polynomially in the ambient dimension and the inverse accuracy $1/\\varepsilon$. In this work, we propose a new solver for diffusion models relying on a subtle interplay between low-degree approximation and the collocation method (Lee, Song, Vempala 2018), and we prove that its iteration complexity scales \\emph{polylogarithmically} in $1/\\varepsilon$, yielding the first ``high-accuracy'' guarantee for a diffusion-based sampler that only uses (approximate) access to the scores of the data distribution. In addition, our bound does not depend explicitly on the ambient dimension; more precisely, the dimension affects the complexity of our solver through the \\emph{effective radius} of the support of the target distribution only.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.LG",
        "math.ST"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10708v1",
        "pdf": "https://arxiv.org/pdf/2601.10708v1"
      },
      "arxiv_id": "2601.10708v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10707v1",
      "title": "See Less, Drive Better: Generalizable End-to-End Autonomous Driving via Foundation Models Stochastic Patch Selection",
      "authors": [
        "Amir Mallak",
        "Erfan Aasi",
        "Shiva Sreeram",
        "Tsun-Hsuan Wang",
        "Daniela Rus",
        "Alaa Maalouf"
      ],
      "abstract": "Recent advances in end-to-end autonomous driving show that policies trained on patch-aligned features extracted from foundation models generalize better to Out-of-Distribution (OOD). We hypothesize that due to the self-attention mechanism, each patch feature implicitly embeds/contains information from all other patches, represented in a different way and intensity, making these descriptors highly redundant. We quantify redundancy in such (BLIP2) features via PCA and cross-patch similarity: $90$% of variance is captured by $17/64$ principal components, and strong inter-token correlations are pervasive. Training on such overlapping information leads the policy to overfit spurious correlations, hurting OOD robustness. We present Stochastic-Patch-Selection (SPS), a simple yet effective approach for learning policies that are more robust, generalizable, and efficient. For every frame, SPS randomly masks a fraction of patch descriptors, not feeding them to the policy model, while preserving the spatial layout of the remaining patches. Thus, the policy is provided with different stochastic but complete views of the (same) scene: every random subset of patches acts like a different, yet still sensible, coherent projection of the world. The policy thus bases its decisions on features that are invariant to which specific tokens survive. Extensive experiments confirm that across all OOD scenarios, our method outperforms the state of the art (SOTA), achieving a $6.2$% average improvement and up to $20.4$% in closed-loop simulations, while being $2.4\\times$ faster. We conduct ablations over masking rates and patch-feature reorganization, training and evaluating 9 systems, with 8 of them surpassing prior SOTA. Finally, we show that the same learned policy transfers to a physical, real-world car without any tuning.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.CV",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10707v1",
        "pdf": "https://arxiv.org/pdf/2601.10707v1"
      },
      "arxiv_id": "2601.10707v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10705v1",
      "title": "Distributed Perceptron under Bounded Staleness, Partial Participation, and Noisy Communication",
      "authors": [
        "Keval Jain",
        "Anant Raj",
        "Saurav Prakash",
        "Girish Varma"
      ],
      "abstract": "We study a semi-asynchronous client-server perceptron trained via iterative parameter mixing (IPM-style averaging): clients run local perceptron updates and a server forms a global model by aggregating the updates that arrive in each communication round. The setting captures three system effects in federated and distributed deployments: (i) stale updates due to delayed model delivery and delayed application of client computations (two-sided version lag), (ii) partial participation (intermittent client availability), and (iii) imperfect communication on both downlink and uplink, modeled as effective zero-mean additive noise with bounded second moment. We introduce a server-side aggregation rule called staleness-bucket aggregation with padding that deterministically enforces a prescribed staleness profile over update ages without assuming any stochastic model for delays or participation. Under margin separability and bounded data radius, we prove a finite-horizon expected bound on the cumulative weighted number of perceptron mistakes over a given number of server rounds: the impact of delay appears only through the mean enforced staleness, whereas communication noise contributes an additional term that grows on the order of the square root of the horizon with the total noise energy. In the noiseless case, we show how a finite expected mistake budget yields an explicit finite-round stabilization bound under a mild fresh-participation condition.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10705v1",
        "pdf": "https://arxiv.org/pdf/2601.10705v1"
      },
      "arxiv_id": "2601.10705v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10702v1",
      "title": "Grounding Agent Memory in Contextual Intent",
      "authors": [
        "Ruozhen Yang",
        "Yucheng Jiang",
        "Yueqi Jiang",
        "Priyanka Kargupta",
        "Yunyi Zhang",
        "Jiawei Han"
      ],
      "abstract": "Deploying large language models in long-horizon, goal-oriented interactions remains challenging because similar entities and facts recur under different latent goals and constraints, causing memory systems to retrieve context-mismatched evidence. We propose STITCH (Structured Intent Tracking in Contextual History), an agentic memory system that indexes each trajectory step with a structured retrieval cue, contextual intent, and retrieves history by matching the current step's intent. Contextual intent provides compact signals that disambiguate repeated mentions and reduce interference: (1) the current latent goal defining a thematic segment, (2) the action type, and (3) the salient entity types anchoring which attributes matter. During inference, STITCH filters and prioritizes memory snippets by intent compatibility, suppressing semantically similar but context-incompatible history.\n  For evaluation, we introduce CAME-Bench, a benchmark for context-aware retrieval in realistic, dynamic, goal-oriented trajectories. Across CAME-Bench and LongMemEval, STITCH achieves state-of-the-art performance, outperforming the strongest baseline by 35.6%, with the largest gains as trajectory length increases. Our analysis shows that intent indexing substantially reduces retrieval noise, supporting intent-aware memory for robust long-horizon reasoning.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10702v1",
        "pdf": "https://arxiv.org/pdf/2601.10702v1"
      },
      "arxiv_id": "2601.10702v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10701v1",
      "title": "Communication-Efficient and Privacy-Adaptable Mechanism -- a Federated Learning Scheme with Convergence Analysis",
      "authors": [
        "Chun Hei Michael Shiu",
        "Chih Wei Ling"
      ],
      "abstract": "Federated learning enables multiple parties to jointly train learning models without sharing their own underlying data, offering a practical pathway to privacy-preserving collaboration under data-governance constraints. Continued study of federated learning is essential to address key challenges in it, including communication efficiency and privacy protection between parties. A recent line of work introduced a novel approach called the Communication-Efficient and Privacy-Adaptable Mechanism (CEPAM), which achieves both objectives simultaneously. CEPAM leverages the rejection-sampled universal quantizer (RSUQ), a randomized vector quantizer whose quantization error is equivalent to a prescribed noise, which can be tuned to customize privacy protection between parties. In this work, we theoretically analyze the privacy guarantees and convergence properties of CEPAM. Moreover, we assess CEPAM's utility performance through experimental evaluations, including convergence profiles compared with other baselines, and accuracy-privacy trade-offs between different parties.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10701v1",
        "pdf": "https://arxiv.org/pdf/2601.10701v1"
      },
      "arxiv_id": "2601.10701v1",
      "comment": "19 pages, 5 figures. This work is submitted in part to the 2026 IEEE International Symposium on Information Theory (ISIT). arXiv admin note: substantial text overlap with arXiv:2501.12046",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10700v1",
      "title": "LIBERTy: A Causal Framework for Benchmarking Concept-Based Explanations of LLMs with Structural Counterfactuals",
      "authors": [
        "Gilat Toker",
        "Nitay Calderon",
        "Ohad Amosy",
        "Roi Reichart"
      ],
      "abstract": "Concept-based explanations quantify how high-level concepts (e.g., gender or experience) influence model behavior, which is crucial for decision-makers in high-stakes domains. Recent work evaluates the faithfulness of such explanations by comparing them to reference causal effects estimated from counterfactuals. In practice, existing benchmarks rely on costly human-written counterfactuals that serve as an imperfect proxy. To address this, we introduce a framework for constructing datasets containing structural counterfactual pairs: LIBERTy (LLM-based Interventional Benchmark for Explainability with Reference Targets). LIBERTy is grounded in explicitly defined Structured Causal Models (SCMs) of the text generation, interventions on a concept propagate through the SCM until an LLM generates the counterfactual. We introduce three datasets (disease detection, CV screening, and workplace violence prediction) together with a new evaluation metric, order-faithfulness. Using them, we evaluate a wide range of methods across five models and identify substantial headroom for improving concept-based explanations. LIBERTy also enables systematic analysis of model sensitivity to interventions: we find that proprietary LLMs show markedly reduced sensitivity to demographic concepts, likely due to post-training mitigation. Overall, LIBERTy provides a much-needed benchmark for developing faithful explainability methods.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10700v1",
        "pdf": "https://arxiv.org/pdf/2601.10700v1"
      },
      "arxiv_id": "2601.10700v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10696v1",
      "title": "The Impact of Generative AI on Architectural Conceptual Design: Performance, Creative Self-Efficacy and Cognitive Load",
      "authors": [
        "Han Jiang",
        "Yao Xiao",
        "Rachel Hurley",
        "Shichao Liu"
      ],
      "abstract": "Our study examines how generative AI (GenAI) influences performance, creative self-efficacy, and cognitive load in architectural conceptual design tasks. Thirty-six student participants from Architectural Engineering and other disciplines completed a two-phase architectural design task, first independently and then with external tools (GenAI-assisted condition and control condition using an online repository of existing architectural projects). Design outcomes were evaluated by expert raters, while self-efficacy and cognitive load were self-reported after each phase. Difference-in-differences analyses revealed no overall performance advantage of GenAI across participants; however, subgroup analyses showed that GenAI significantly improved design performance for novice designers. In contrast, general creative self-efficacy declined for students using GenAI. Cognitive load did not differ significantly between conditions, though prompt usage patterns showed that iterative idea generation and visual feedback prompts were linked to greater reductions in cognitive load. These findings suggest that GenAI effectiveness depends on users' prior expertise and interaction strategies through prompting.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10696v1",
        "pdf": "https://arxiv.org/pdf/2601.10696v1"
      },
      "arxiv_id": "2601.10696v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10690v1",
      "title": "Data-driven stochastic reduced-order modeling of parametrized dynamical systems",
      "authors": [
        "Andrew F. Ilersich",
        "Kevin Course",
        "Prasanth B. Nair"
      ],
      "abstract": "Modeling complex dynamical systems under varying conditions is computationally intensive, often rendering high-fidelity simulations intractable. Although reduced-order models (ROMs) offer a promising solution, current methods often struggle with stochastic dynamics and fail to quantify prediction uncertainty, limiting their utility in robust decision-making contexts. To address these challenges, we introduce a data-driven framework for learning continuous-time stochastic ROMs that generalize across parameter spaces and forcing conditions. Our approach, based on amortized stochastic variational inference, leverages a reparametrization trick for Markov Gaussian processes to eliminate the need for computationally expensive forward solvers during training. This enables us to jointly learn a probabilistic autoencoder and stochastic differential equations governing the latent dynamics, at a computational cost that is independent of the dataset size and system stiffness. Additionally, our approach offers the flexibility of incorporating physics-informed priors if available. Numerical studies are presented for three challenging test problems, where we demonstrate excellent generalization to unseen parameter combinations and forcings, and significant efficiency gains compared to existing approaches.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10690v1",
        "pdf": "https://arxiv.org/pdf/2601.10690v1"
      },
      "arxiv_id": "2601.10690v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10684v1",
      "title": "On the origin of neural scaling laws: from random graphs to natural language",
      "authors": [
        "Maissam Barkeshli",
        "Alberto Alfarano",
        "Andrey Gromov"
      ],
      "abstract": "Scaling laws have played a major role in the modern AI revolution, providing practitioners predictive power over how the model performance will improve with increasing data, compute, and number of model parameters. This has spurred an intense interest in the origin of neural scaling laws, with a common suggestion being that they arise from power law structure already present in the data. In this paper we study scaling laws for transformers trained to predict random walks (bigrams) on graphs with tunable complexity. We demonstrate that this simplified setting already gives rise to neural scaling laws even in the absence of power law structure in the data correlations. We further consider dialing down the complexity of natural language systematically, by training on sequences sampled from increasingly simplified generative language models, from 4,2,1-layer transformer language models down to language bigrams, revealing a monotonic evolution of the scaling exponents. Our results also include scaling laws obtained from training on random walks on random graphs drawn from Erdös-Renyi and scale-free Barabási-Albert ensembles. Finally, we revisit conventional scaling laws for language modeling, demonstrating that several essential results can be reproduced using 2 layer transformers with context length of 50, provide a critical analysis of various fits used in prior literature, demonstrate an alternative method for obtaining compute optimal curves as compared with current practice in published literature, and provide preliminary evidence that maximal update parameterization may be more parameter efficient than standard parameterization.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.LG",
        "cond-mat.dis-nn",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10684v1",
        "pdf": "https://arxiv.org/pdf/2601.10684v1"
      },
      "arxiv_id": "2601.10684v1",
      "comment": "33 pages",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10681v1",
      "title": "Structure and Diversity Aware Context Bubble Construction for Enterprise Retrieval Augmented Systems",
      "authors": [
        "Amir Khurshid",
        "Abhishek Sehgal"
      ],
      "abstract": "Large language model (LLM) contexts are typically constructed using retrieval-augmented generation (RAG), which involves ranking and selecting the top-k passages. The approach causes fragmentation in information graphs in document structures, over-retrieval, and duplication of content alongside insufficient query context, including 2nd and 3rd order facets. In this paper, a structure-informed and diversity-constrained context bubble construction framework is proposed that assembles coherent, citable bundles of spans under a strict token budget. The method preserves and exploits inherent document structure by organising multi-granular spans (e.g., sections and rows) and using task-conditioned structural priors to guide retrieval. Starting from high-relevance anchor spans, a context bubble is constructed through constrained selection that balances query relevance, marginal coverage, and redundancy penalties. It will explicitly constrain diversity and budget, producing compact and informative context sets, unlike top-k retrieval. Moreover, a full retrieval is emitted that traces the scoring and selection choices of the records, thus providing auditability and deterministic tuning. Experiments on enterprise documents demonstrate the efficiency of context bubble as it significantly reduces redundant context, is better able to cover secondary facets and has a better answer quality and citation faithfulness within a limited context window. Ablation studies demonstrate that both structural priors as well as diversity constraint selection are necessary; removing either component results in a decline in coverage and an increase in redundant or incomplete context.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10681v1",
        "pdf": "https://arxiv.org/pdf/2601.10681v1"
      },
      "arxiv_id": "2601.10681v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10679v1",
      "title": "Are Your Reasoning Models Reasoning or Guessing? A Mechanistic Analysis of Hierarchical Reasoning Models",
      "authors": [
        "Zirui Ren",
        "Ziming Liu"
      ],
      "abstract": "Hierarchical reasoning model (HRM) achieves extraordinary performance on various reasoning tasks, significantly outperforming large language model-based reasoners. To understand the strengths and potential failure modes of HRM, we conduct a mechanistic study on its reasoning patterns and find three surprising facts: (a) Failure of extremely simple puzzles, e.g., HRM can fail on a puzzle with only one unknown cell. We attribute this failure to the violation of the fixed point property, a fundamental assumption of HRM. (b) \"Grokking\" dynamics in reasoning steps, i.e., the answer is not improved uniformly, but instead there is a critical reasoning step that suddenly makes the answer correct; (c) Existence of multiple fixed points. HRM \"guesses\" the first fixed point, which could be incorrect, and gets trapped there for a while or forever. All facts imply that HRM appears to be \"guessing\" instead of \"reasoning\". Leveraging this \"guessing\" picture, we propose three strategies to scale HRM's guesses: data augmentation (scaling the quality of guesses), input perturbation (scaling the number of guesses by leveraging inference randomness), and model bootstrapping (scaling the number of guesses by leveraging training randomness). On the practical side, by combining all methods, we develop Augmented HRM, boosting accuracy on Sudoku-Extreme from 54.5% to 96.9%. On the scientific side, our analysis provides new insights into how reasoning models \"reason\".",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10679v1",
        "pdf": "https://arxiv.org/pdf/2601.10679v1"
      },
      "arxiv_id": "2601.10679v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10673v1",
      "title": "Single-Stage Huffman Encoder for ML Compression",
      "authors": [
        "Aditya Agrawal",
        "Albert Magyar",
        "Hiteshwar Eswaraiah",
        "Patrick Sheridan",
        "Pradeep Janedula",
        "Ravi Krishnan Venkatesan",
        "Krishna Nair",
        "Ravi Iyer"
      ],
      "abstract": "Training and serving Large Language Models (LLMs) require partitioning data across multiple accelerators, where collective operations are frequently bottlenecked by network bandwidth. Lossless compression using Huffman codes is an effective way to alleviate the issue, however, its three-stage design requiring on-the-fly frequency analysis, codebook generation and transmission of codebook along with data introduces computational, latency and data overheads which are prohibitive for latency-sensitive scenarios such as die-to-die communication. This paper proposes a single-stage Huffman encoder that eliminates these overheads by using fixed codebooks derived from the average probability distribution of previous data batches. Through our analysis of the Gemma 2B model, we demonstrate that tensors exhibit high statistical similarity across layers and shards. Using this approach we achieve compression within 0.5% of per-shard Huffman coding and within 1% of the ideal Shannon compressibility, enabling efficient on-the-fly compression.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10673v1",
        "pdf": "https://arxiv.org/pdf/2601.10673v1"
      },
      "arxiv_id": "2601.10673v1",
      "comment": "5 pages, 4 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10657v1",
      "title": "PACEvolve: Enabling Long-Horizon Progress-Aware Consistent Evolution",
      "authors": [
        "Minghao Yan",
        "Bo Peng",
        "Benjamin Coleman",
        "Ziqi Chen",
        "Zhouhang Xie",
        "Zhankui He",
        "Noveen Sachdeva",
        "Isabella Ye",
        "Weili Wang",
        "Chi Wang",
        "Ed H. Chi",
        "Wang-Cheng Kang",
        "Derek Zhiyuan Cheng",
        "Beidou Wang"
      ],
      "abstract": "Large Language Models (LLMs) have emerged as powerful operators for evolutionary search, yet the design of efficient search scaffolds remains ad hoc. While promising, current LLM-in-the-loop systems lack a systematic approach to managing the evolutionary process. We identify three distinct failure modes: Context Pollution, where experiment history biases future candidate generation; Mode Collapse, where agents stagnate in local minima due to poor exploration-exploitation balance; and Weak Collaboration, where rigid crossover strategies fail to leverage parallel search trajectories effectively. We introduce Progress-Aware Consistent Evolution (PACEvolve), a framework designed to robustly govern the agent's context and search dynamics, to address these challenges. PACEvolve combines hierarchical context management (HCM) with pruning to address context pollution; momentum-based backtracking (MBB) to escape local minima; and a self-adaptive sampling policy that unifies backtracking and crossover for dynamic search coordination (CE), allowing agents to balance internal refinement with cross-trajectory collaboration. We demonstrate that PACEvolve provides a systematic path to consistent, long-horizon self-improvement, achieving state-of-the-art results on LLM-SR and KernelBench, while discovering solutions surpassing the record on Modded NanoGPT.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.NE",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10657v1",
        "pdf": "https://arxiv.org/pdf/2601.10657v1"
      },
      "arxiv_id": "2601.10657v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10651v1",
      "title": "Multi-Property Synthesis",
      "authors": [
        "Christoph Weinhuber",
        "Yannik Schnitzer",
        "Alessandro Abate",
        "David Parker",
        "Giuseppe De Giacomo",
        "Moshe Y. Vardi"
      ],
      "abstract": "We study LTLf synthesis with multiple properties, where satisfying all properties may be impossible. Instead of enumerating subsets of properties, we compute in one fixed-point computation the relation between product-game states and the goal sets that are realizable from them, and we synthesize strategies achieving maximal realizable sets. We develop a fully symbolic algorithm that introduces Boolean goal variables and exploits monotonicity to represent exponentially many goal combinations compactly. Our approach substantially outperforms enumeration-based baselines, with speedups of up to two orders of magnitude.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10651v1",
        "pdf": "https://arxiv.org/pdf/2601.10651v1"
      },
      "arxiv_id": "2601.10651v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10649v1",
      "title": "CURVE: A Benchmark for Cultural and Multilingual Long Video Reasoning",
      "authors": [
        "Darshan Singh",
        "Arsha Nagrani",
        "Kawshik Manikantan",
        "Harman Singh",
        "Dinesh Tewari",
        "Tobias Weyand",
        "Cordelia Schmid",
        "Anelia Angelova",
        "Shachi Dave"
      ],
      "abstract": "Recent advancements in video models have shown tremendous progress, particularly in long video understanding. However, current benchmarks predominantly feature western-centric data and English as the dominant language, introducing significant biases in evaluation. To address this, we introduce CURVE (Cultural Understanding and Reasoning in Video Evaluation), a challenging benchmark for multicultural and multilingual video reasoning. CURVE comprises high-quality, entirely human-generated annotations from diverse, region-specific cultural videos across 18 global locales. Unlike prior work that relies on automatic translations, CURVE provides complex questions, answers, and multi-step reasoning steps, all crafted in native languages. Making progress on CURVE requires a deeply situated understanding of visual cultural context. Furthermore, we leverage CURVE's reasoning traces to construct evidence-based graphs and propose a novel iterative strategy using these graphs to identify fine-grained errors in reasoning. Our evaluations reveal that SoTA Video-LLMs struggle significantly, performing substantially below human-level accuracy, with errors primarily stemming from the visual perception of cultural elements. CURVE will be publicly available under https://github.com/google-deepmind/neptune?tab=readme-ov-file\\#minerva-cultural",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10649v1",
        "pdf": "https://arxiv.org/pdf/2601.10649v1"
      },
      "arxiv_id": "2601.10649v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10641v1",
      "title": "Adjusted Similarity Measures and a Violation of Expectations",
      "authors": [
        "William L. Lippitt",
        "Edward J. Bedrick",
        "Nichole E. Carlson"
      ],
      "abstract": "Adjusted similarity measures, such as Cohen's kappa for inter-rater reliability and the adjusted Rand index used to compare clustering algorithms, are a vital tool for comparing discrete labellings. These measures are intended to have the property of 0 expectation under a null distribution and maximum value 1 under maximal similarity to aid in interpretation. Measures are frequently adjusted with respect to the permutation distribution for historic and analytic reasons. There is currently renewed interest in considering other null models more appropriate for context, such as clustering ensembles permitting a random number of identified clusters. The purpose of this work is two -- fold: (1) to generalize the study of the adjustment operator to general null models and to a more general procedure which includes statistical standardization as a special case and (2) to identify sufficient conditions for the adjustment operator to produce the intended properties, where sufficient conditions are related to whether and how observed data are incorporated into null distributions. We demonstrate how violations of the sufficient conditions may lead to substantial breakdown, such as by producing a non-positive measure under traditional adjustment rather than one with mean 0, or by producing a measure which is deterministically 0 under statistical standardization.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "stat.ME",
        "cs.LG",
        "math.ST"
      ],
      "primary_category": "stat.ME",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10641v1",
        "pdf": "https://arxiv.org/pdf/2601.10641v1"
      },
      "arxiv_id": "2601.10641v1",
      "comment": "12 pages, 1 figure",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10639v1",
      "title": "STEM: Scaling Transformers with Embedding Modules",
      "authors": [
        "Ranajoy Sadhukhan",
        "Sheng Cao",
        "Harry Dong",
        "Changsheng Zhao",
        "Attiano Purpura-Pontoniere",
        "Yuandong Tian",
        "Zechun Liu",
        "Beidi Chen"
      ],
      "abstract": "Fine-grained sparsity promises higher parametric capacity without proportional per-token compute, but often suffers from training instability, load balancing, and communication overhead. We introduce STEM (Scaling Transformers with Embedding Modules), a static, token-indexed approach that replaces the FFN up-projection with a layer-local embedding lookup while keeping the gate and down-projection dense. This removes runtime routing, enables CPU offload with asynchronous prefetch, and decouples capacity from both per-token FLOPs and cross-device communication. Empirically, STEM trains stably despite extreme sparsity. It improves downstream performance over dense baselines while reducing per-token FLOPs and parameter accesses (eliminating roughly one-third of FFN parameters). STEM learns embedding spaces with large angular spread which enhances its knowledge storage capacity. More interestingly, this enhanced knowledge capacity comes with better interpretability. The token-indexed nature of STEM embeddings allows simple ways to perform knowledge editing and knowledge injection in an interpretable manner without any intervention in the input text or additional computation. In addition, STEM strengthens long-context performance: as sequence length grows, more distinct parameters are activated, yielding practical test-time capacity scaling. Across 350M and 1B model scales, STEM delivers up to ~3--4% accuracy improvements overall, with notable gains on knowledge and reasoning-heavy benchmarks (ARC-Challenge, OpenBookQA, GSM8K, MMLU). Overall, STEM is an effective way of scaling parametric memory while providing better interpretability, better training stability and improved efficiency.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10639v1",
        "pdf": "https://arxiv.org/pdf/2601.10639v1"
      },
      "arxiv_id": "2601.10639v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10632v1",
      "title": "CoMoVi: Co-Generation of 3D Human Motions and Realistic Videos",
      "authors": [
        "Chengfeng Zhao",
        "Jiazhi Shu",
        "Yubo Zhao",
        "Tianyu Huang",
        "Jiahao Lu",
        "Zekai Gu",
        "Chengwei Ren",
        "Zhiyang Dou",
        "Qing Shuai",
        "Yuan Liu"
      ],
      "abstract": "In this paper, we find that the generation of 3D human motions and 2D human videos is intrinsically coupled. 3D motions provide the structural prior for plausibility and consistency in videos, while pre-trained video models offer strong generalization capabilities for motions, which necessitate coupling their generation processes. Based on this, we present CoMoVi, a co-generative framework that couples two video diffusion models (VDMs) to generate 3D human motions and videos synchronously within a single diffusion denoising loop. To achieve this, we first propose an effective 2D human motion representation that can inherit the powerful prior of pre-trained VDMs. Then, we design a dual-branch diffusion model to couple human motion and video generation process with mutual feature interaction and 3D-2D cross attentions. Moreover, we curate CoMoVi Dataset, a large-scale real-world human video dataset with text and motion annotations, covering diverse and challenging human motions. Extensive experiments demonstrate the effectiveness of our method in both 3D human motion and video generation tasks.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10632v1",
        "pdf": "https://arxiv.org/pdf/2601.10632v1"
      },
      "arxiv_id": "2601.10632v1",
      "comment": "Project Page: https://igl-hkust.github.io/CoMoVi/",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2601.10630v1",
      "title": "Classification Imbalance as Transfer Learning",
      "authors": [
        "Eric Xia",
        "Jason M. Klusowski"
      ],
      "abstract": "Classification imbalance arises when one class is much rarer than the other. We frame this setting as transfer learning under label (prior) shift between an imbalanced source distribution induced by the observed data and a balanced target distribution under which performance is evaluated. Within this framework, we study a family of oversampling procedures that augment the training data by generating synthetic samples from an estimated minority-class distribution to roughly balance the classes, among which the celebrated SMOTE algorithm is a canonical example. We show that the excess risk decomposes into the rate achievable under balanced training (as if the data had been drawn from the balanced target distribution) and an additional term, the cost of transfer, which quantifies the discrepancy between the estimated and true minority-class distributions. In particular, we show that the cost of transfer for SMOTE dominates that of bootstrapping (random oversampling) in moderately high dimensions, suggesting that we should expect bootstrapping to have better performance than SMOTE in general. We corroborate these findings with experimental evidence. More broadly, our results provide guidance for choosing among augmentation strategies for imbalanced classification.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10630v1",
        "pdf": "https://arxiv.org/pdf/2601.10630v1"
      },
      "arxiv_id": "2601.10630v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10628v1",
      "title": "Parametric RDT approach to computational gap of symmetric binary perceptron",
      "authors": [
        "Mihailo Stojnic"
      ],
      "abstract": "We study potential presence of statistical-computational gaps (SCG) in symmetric binary perceptrons (SBP) via a parametric utilization of \\emph{fully lifted random duality theory} (fl-RDT) [96]. A structural change from decreasingly to arbitrarily ordered $c$-sequence (a key fl-RDT parametric component) is observed on the second lifting level and associated with \\emph{satisfiability} ($α_c$) -- \\emph{algorithmic} ($α_a$) constraints density threshold change thereby suggesting a potential existence of a nonzero computational gap $SCG=α_c-α_a$. The second level estimate is shown to match the theoretical $α_c$ whereas the $r\\rightarrow \\infty$ level one is proposed to correspond to $α_a$. For example, for the canonical SBP ($κ=1$ margin) we obtain $α_c\\approx 1.8159$ on the second and $α_a\\approx 1.6021$ (with converging tendency towards $\\sim 1.59$ range) on the seventh level. Our propositions remarkably well concur with recent literature: (i) in [20] local entropy replica approach predicts $α_{LE}\\approx 1.58$ as the onset of clustering defragmentation (presumed driving force behind locally improving algorithms failures); (ii) in $α\\rightarrow 0$ regime we obtain on the third lifting level $κ\\approx 1.2385\\sqrt{\\frac{α_a}{-\\log\\left ( α_a \\right ) }}$ which qualitatively matches overlap gap property (OGP) based predictions of [43] and identically matches local entropy based predictions of [24]; (iii) $c$-sequence ordering change phenomenology mirrors the one observed in asymmetric binary perceptron (ABP) in [98] and the negative Hopfield model in [100]; and (iv) as in [98,100], we here design a CLuP based algorithm whose practical performance closely matches proposed theoretical predictions.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "stat.ML",
        "cond-mat.dis-nn",
        "cs.IT",
        "cs.LG",
        "math.PR"
      ],
      "primary_category": "stat.ML",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10628v1",
        "pdf": "https://arxiv.org/pdf/2601.10628v1"
      },
      "arxiv_id": "2601.10628v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10611v1",
      "title": "Molmo2: Open Weights and Data for Vision-Language Models with Video Understanding and Grounding",
      "authors": [
        "Christopher Clark",
        "Jieyu Zhang",
        "Zixian Ma",
        "Jae Sung Park",
        "Mohammadreza Salehi",
        "Rohun Tripathi",
        "Sangho Lee",
        "Zhongzheng Ren",
        "Chris Dongjoo Kim",
        "Yinuo Yang",
        "Vincent Shao",
        "Yue Yang",
        "Weikai Huang",
        "Ziqi Gao",
        "Taira Anderson",
        "Jianrui Zhang",
        "Jitesh Jain",
        "George Stoica",
        "Winson Han",
        "Ali Farhadi",
        "Ranjay Krishna"
      ],
      "abstract": "Today's strongest video-language models (VLMs) remain proprietary. The strongest open-weight models either rely on synthetic data from proprietary VLMs, effectively distilling from them, or do not disclose their training data or recipe. As a result, the open-source community lacks the foundations needed to improve on the state-of-the-art video (and image) language models. Crucially, many downstream applications require more than just high-level video understanding; they require grounding -- either by pointing or by tracking in pixels. Even proprietary models lack this capability. We present Molmo2, a new family of VLMs that are state-of-the-art among open-source models and demonstrate exceptional new capabilities in point-driven grounding in single image, multi-image, and video tasks. Our key contribution is a collection of 7 new video datasets and 2 multi-image datasets, including a dataset of highly detailed video captions for pre-training, a free-form video Q&A dataset for fine-tuning, a new object tracking dataset with complex queries, and an innovative new video pointing dataset, all collected without the use of closed VLMs. We also present a training recipe for this data utilizing an efficient packing and message-tree encoding scheme, and show bi-directional attention on vision tokens and a novel token-weight strategy improves performance. Our best-in-class 8B model outperforms others in the class of open weight and data models on short videos, counting, and captioning, and is competitive on long-videos. On video-grounding Molmo2 significantly outperforms existing open-weight models like Qwen3-VL (35.5 vs 29.6 accuracy on video counting) and surpasses proprietary models like Gemini 3 Pro on some tasks (38.4 vs 20.0 F1 on video pointing and 56.2 vs 41.1 J&F on video tracking).",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10611v1",
        "pdf": "https://arxiv.org/pdf/2601.10611v1"
      },
      "arxiv_id": "2601.10611v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10607v1",
      "title": "Multi-Objective Pareto-Front Optimization for Efficient Adaptive VVC Streaming",
      "authors": [
        "Angeliki Katsenou",
        "Vignesh V. Menon",
        "Guoda Laurinaviciute",
        "Benjamin Bross",
        "Detlev Marpe"
      ],
      "abstract": "Adaptive video streaming has facilitated improved video streaming over the past years. A balance among coding performance objectives such as bitrate, video quality, and decoding complexity is required to achieve efficient, content- and codec-dependent, adaptive video streaming. This paper proposes a multi-objective Pareto-front (PF) optimization framework to construct quality-monotonic, content-adaptive bitrate ladders Versatile Video Coding (VVC) streaming that jointly optimize video quality, bitrate, and decoding time, which is used as a practical proxy for decoding energy. Two strategies are introduced: the Joint Rate-Quality-Time Pareto Front (JRQT-PF) and the Joint Quality-Time Pareto Front (JQT-PF), each exploring different tradeoff formulations and objective prioritizations. The ladders are constructed under quality monotonicity constraints during adaptive streaming to ensure a consistent Quality of Experience (QoE). Experiments are conducted on a large-scale UHD dataset (Inter-4K), with quality assessed using PSNR, VMAF, and XPSNR, and complexity measured via decoding time and energy consumption. The JQT-PF method achieves 11.76% average bitrate savings while reducing average decoding time by 0.29% to maintain the same XPSNR, compared to a widely-used fixed ladder. More aggressive configurations yield up to 27.88% bitrate savings at the cost of increased complexity. The JRQT-PF strategy, on the other hand, offers more controlled tradeoffs, achieving 6.38 % bitrate savings and 6.17 % decoding time reduction. This framework outperforms existing methods, including fixed ladders, VMAF- and XPSNR-based dynamic resolution selection, and complexity-aware benchmarks. The results confirm that PF optimization with decoding time constraints enables sustainable, high-quality streaming tailored to network and device capabilities.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "eess.IV",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10607v1",
        "pdf": "https://arxiv.org/pdf/2601.10607v1"
      },
      "arxiv_id": "2601.10607v1",
      "comment": "19 pages",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10606v1",
      "title": "RSATalker: Realistic Socially-Aware Talking Head Generation for Multi-Turn Conversation",
      "authors": [
        "Peng Chen",
        "Xiaobao Wei",
        "Yi Yang",
        "Naiming Yao",
        "Hui Chen",
        "Feng Tian"
      ],
      "abstract": "Talking head generation is increasingly important in virtual reality (VR), especially for social scenarios involving multi-turn conversation. Existing approaches face notable limitations: mesh-based 3D methods can model dual-person dialogue but lack realistic textures, while large-model-based 2D methods produce natural appearances but incur prohibitive computational costs. Recently, 3D Gaussian Splatting (3DGS) based methods achieve efficient and realistic rendering but remain speaker-only and ignore social relationships. We introduce RSATalker, the first framework that leverages 3DGS for realistic and socially-aware talking head generation with support for multi-turn conversation. Our method first drives mesh-based 3D facial motion from speech, then binds 3D Gaussians to mesh facets to render high-fidelity 2D avatar videos. To capture interpersonal dynamics, we propose a socially-aware module that encodes social relationships, including blood and non-blood as well as equal and unequal, into high-level embeddings through a learnable query mechanism. We design a three-stage training paradigm and construct the RSATalker dataset with speech-mesh-image triplets annotated with social relationships. Extensive experiments demonstrate that RSATalker achieves state-of-the-art performance in both realism and social awareness. The code and dataset will be released.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10606v1",
        "pdf": "https://arxiv.org/pdf/2601.10606v1"
      },
      "arxiv_id": "2601.10606v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10600v1",
      "title": "Procedural Fairness in Multi-Agent Bandits",
      "authors": [
        "Joshua Caiata",
        "Carter Blair",
        "Kate Larson"
      ],
      "abstract": "In the context of multi-agent multi-armed bandits (MA-MAB), fairness is often reduced to outcomes: maximizing welfare, reducing inequality, or balancing utilities. However, evidence in psychology, economics, and Rawlsian theory suggests that fairness is also about process and who gets a say in the decisions being made. We introduce a new fairness objective, procedural fairness, which provides equal decision-making power for all agents, lies in the core, and provides for proportionality in outcomes. Empirical results confirm that fairness notions based on optimizing for outcomes sacrifice equal voice and representation, while the sacrifice in outcome-based fairness objectives (like equality and utilitarianism) is minimal under procedurally fair policies. We further prove that different fairness notions prioritize fundamentally different and incompatible values, highlighting that fairness requires explicit normative choices. This paper argues that procedural legitimacy deserves greater focus as a fairness objective, and provides a framework for putting procedural fairness into practice.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.GT",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10600v1",
        "pdf": "https://arxiv.org/pdf/2601.10600v1"
      },
      "arxiv_id": "2601.10600v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10592v1",
      "title": "Action100M: A Large-scale Video Action Dataset",
      "authors": [
        "Delong Chen",
        "Tejaswi Kasarla",
        "Yejin Bang",
        "Mustafa Shukor",
        "Willy Chung",
        "Jade Yu",
        "Allen Bolourchi",
        "Theo Moutakanni",
        "Pascale Fung"
      ],
      "abstract": "Inferring physical actions from visual observations is a fundamental capability for advancing machine intelligence in the physical world. Achieving this requires large-scale, open-vocabulary video action datasets that span broad domains. We introduce Action100M, a large-scale dataset constructed from 1.2M Internet instructional videos (14.6 years of duration), yielding O(100 million) temporally localized segments with open-vocabulary action supervision and rich captions. Action100M is generated by a fully automated pipeline that (i) performs hierarchical temporal segmentation using V-JEPA 2 embeddings, (ii) produces multi-level frame and segment captions organized as a Tree-of-Captions, and (iii) aggregates evidence with a reasoning model (GPT-OSS-120B) under a multi-round Self-Refine procedure to output structured annotations (brief/detailed action, actor, brief/detailed caption). Training VL-JEPA on Action100M demonstrates consistent data-scaling improvements and strong zero-shot performance across diverse action recognition benchmarks, establishing Action100M as a new foundation for scalable research in video understanding and world modeling.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10592v1",
        "pdf": "https://arxiv.org/pdf/2601.10592v1"
      },
      "arxiv_id": "2601.10592v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10591v1",
      "title": "ProbFM: Probabilistic Time Series Foundation Model with Uncertainty Decomposition",
      "authors": [
        "Arundeep Chinta",
        "Lucas Vinh Tran",
        "Jay Katukuri"
      ],
      "abstract": "Time Series Foundation Models (TSFMs) have emerged as a promising approach for zero-shot financial forecasting, demonstrating strong transferability and data efficiency gains. However, their adoption in financial applications is hindered by fundamental limitations in uncertainty quantification: current approaches either rely on restrictive distributional assumptions, conflate different sources of uncertainty, or lack principled calibration mechanisms. While recent TSFMs employ sophisticated techniques such as mixture models, Student's t-distributions, or conformal prediction, they fail to address the core challenge of providing theoretically-grounded uncertainty decomposition. For the very first time, we present a novel transformer-based probabilistic framework, ProbFM (probabilistic foundation model), that leverages Deep Evidential Regression (DER) to provide principled uncertainty quantification with explicit epistemic-aleatoric decomposition. Unlike existing approaches that pre-specify distributional forms or require sampling-based inference, ProbFM learns optimal uncertainty representations through higher-order evidence learning while maintaining single-pass computational efficiency. To rigorously evaluate the core DER uncertainty quantification approach independent of architectural complexity, we conduct an extensive controlled comparison study using a consistent LSTM architecture across five probabilistic methods: DER, Gaussian NLL, Student's-t NLL, Quantile Loss, and Conformal Prediction. Evaluation on cryptocurrency return forecasting demonstrates that DER maintains competitive forecasting accuracy while providing explicit epistemic-aleatoric uncertainty decomposition. This work establishes both an extensible framework for principled uncertainty quantification in foundation models and empirical evidence for DER's effectiveness in financial applications.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-fin.RM",
        "q-fin.TR"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10591v1",
        "pdf": "https://arxiv.org/pdf/2601.10591v1"
      },
      "arxiv_id": "2601.10591v1",
      "comment": "Accepted for oral presentation at the AI Meets Quantitative Finance Workshop at ICAIF 2025. An enhanced version was accepted for oral presentation at the AI for Time Series Analysis Workshop at AAAI 2026",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10588v1",
      "title": "Searching for Quantum Effects in the Brain: A Bell-Type Test for Nonclassical Latent Representations in Autoencoders",
      "authors": [
        "I. K. Kominis",
        "C. Xie",
        "S. Li",
        "M. Skotiniotis",
        "G. P. Tsironis"
      ],
      "abstract": "Whether neural information processing is entirely classical or involves quantum-mechanical elements remains an open question. Here we propose a model-agnostic, information-theoretic test of nonclassicality that bypasses microscopic assumptions and instead probes the structure of neural representations themselves. Using autoencoders as a transparent model system, we introduce a Bell-type consistency test in latent space, and ask whether decoding statistics obtained under multiple readout contexts can be jointly explained by a single positive latent-variable distribution. By shifting the search for quantum-like signatures in neural systems from microscopic dynamics to experimentally testable constraints on information processing, this work opens a new route for probing the fundamental physics of neural computation.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "quant-ph",
        "cs.LG",
        "physics.bio-ph"
      ],
      "primary_category": "quant-ph",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10588v1",
        "pdf": "https://arxiv.org/pdf/2601.10588v1"
      },
      "arxiv_id": "2601.10588v1",
      "comment": "6 pages, 2 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10587v1",
      "title": "Adversarial Evasion Attacks on Computer Vision using SHAP Values",
      "authors": [
        "Frank Mollard",
        "Marcus Becker",
        "Florian Roehrbein"
      ],
      "abstract": "The paper introduces a white-box attack on computer vision models using SHAP values. It demonstrates how adversarial evasion attacks can compromise the performance of deep learning models by reducing output confidence or inducing misclassifications. Such attacks are particularly insidious as they can deceive the perception of an algorithm while eluding human perception due to their imperceptibility to the human eye. The proposed attack leverages SHAP values to quantify the significance of individual inputs to the output at the inference stage. A comparison is drawn between the SHAP attack and the well-known Fast Gradient Sign Method. We find evidence that SHAP attacks are more robust in generating misclassifications particularly in gradient hiding scenarios.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10587v1",
        "pdf": "https://arxiv.org/pdf/2601.10587v1"
      },
      "arxiv_id": "2601.10587v1",
      "comment": "10th bwHPC Symposium - September 25th & 26th, 2024",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10583v1",
      "title": "Combinatorial Optimization Augmented Machine Learning",
      "authors": [
        "Maximilian Schiffer",
        "Heiko Hoppe",
        "Yue Su",
        "Louis Bouvier",
        "Axel Parmentier"
      ],
      "abstract": "Combinatorial optimization augmented machine learning (COAML) has recently emerged as a powerful paradigm for integrating predictive models with combinatorial decision-making. By embedding combinatorial optimization oracles into learning pipelines, COAML enables the construction of policies that are both data-driven and feasibility-preserving, bridging the traditions of machine learning, operations research, and stochastic optimization. This paper provides a comprehensive overview of the state of the art in COAML. We introduce a unifying framework for COAML pipelines, describe their methodological building blocks, and formalize their connection to empirical cost minimization. We then develop a taxonomy of problem settings based on the form of uncertainty and decision structure. Using this taxonomy, we review algorithmic approaches for static and dynamic problems, survey applications across domains such as scheduling, vehicle routing, stochastic programming, and reinforcement learning, and synthesize methodological contributions in terms of empirical cost minimization, imitation learning, and reinforcement learning. Finally, we identify key research frontiers. This survey aims to serve both as a tutorial introduction to the field and as a roadmap for future research at the interface of combinatorial optimization and machine learning.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.LG",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10583v1",
        "pdf": "https://arxiv.org/pdf/2601.10583v1"
      },
      "arxiv_id": "2601.10583v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10581v1",
      "title": "From Single to Multi-Agent Reasoning: Advancing GeneGPT for Genomics QA",
      "authors": [
        "Kimia Abedini",
        "Farzad Shami",
        "Gianmaria Silvello"
      ],
      "abstract": "Comprehending genomic information is essential for biomedical research, yet extracting data from complex distributed databases remains challenging. Large language models (LLMs) offer potential for genomic Question Answering (QA) but face limitations due to restricted access to domain-specific databases. GeneGPT is the current state-of-the-art system that enhances LLMs by utilizing specialized API calls, though it is constrained by rigid API dependencies and limited adaptability. We replicate GeneGPT and propose GenomAgent, a multi-agent framework that efficiently coordinates specialized agents for complex genomics queries. Evaluated on nine tasks from the GeneTuring benchmark, GenomAgent outperforms GeneGPT by 12% on average, and its flexible architecture extends beyond genomics to various scientific domains needing expert knowledge extraction.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10581v1",
        "pdf": "https://arxiv.org/pdf/2601.10581v1"
      },
      "arxiv_id": "2601.10581v1",
      "comment": "Accepted paper by the 48th European Conference on Information Retrieval (ECIR'26)",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10577v1",
      "title": "Jordan-Segmentable Masks: A Topology-Aware definition for characterizing Binary Image Segmentation",
      "authors": [
        "Serena Grazia De Benedictis",
        "Amedeo Altavilla",
        "Nicoletta Del Buono"
      ],
      "abstract": "Image segmentation plays a central role in computer vision. However, widely used evaluation metrics, whether pixel-wise, region-based, or boundary-focused, often struggle to capture the structural and topological coherence of a segmentation. In many practical scenarios, such as medical imaging or object delineation, small inaccuracies in boundary, holes, or fragmented predictions can result in high metric scores, despite the fact that the resulting masks fail to preserve the object global shape or connectivity. This highlights a limitation of conventional metrics: they are unable to assess whether a predicted segmentation partitions the image into meaningful interior and exterior regions.\n  In this work, we introduce a topology-aware notion of segmentation based on the Jordan Curve Theorem, and adapted for use in digital planes. We define the concept of a \\emph{Jordan-segmentatable mask}, which is a binary segmentation whose structure ensures a topological separation of the image domain into two connected components. We analyze segmentation masks through the lens of digital topology and homology theory, extracting a $4$-curve candidate from the mask, verifying its topological validity using Betti numbers. A mask is considered Jordan-segmentatable when this candidate forms a digital 4-curve with $β_0 = β_1 = 1$, or equivalently when its complement splits into exactly two $8$-connected components.\n  This framework provides a mathematically rigorous, unsupervised criterion with which to assess the structural coherence of segmentation masks. By combining digital Jordan theory and homological invariants, our approach provides a valuable alternative to standard evaluation metrics, especially in applications where topological correctness must be preserved.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.CV",
        "math.AT",
        "math.NA"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10577v1",
        "pdf": "https://arxiv.org/pdf/2601.10577v1"
      },
      "arxiv_id": "2601.10577v1",
      "comment": "27 pages, 18 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10567v1",
      "title": "Generative AI collective behavior needs an interactionist paradigm",
      "authors": [
        "Laura Ferrarotti",
        "Gian Maria Campedelli",
        "Roberto Dessì",
        "Andrea Baronchelli",
        "Giovanni Iacca",
        "Kathleen M. Carley",
        "Alex Pentland",
        "Joel Z. Leibo",
        "James Evans",
        "Bruno Lepri"
      ],
      "abstract": "In this article, we argue that understanding the collective behavior of agents based on large language models (LLMs) is an essential area of inquiry, with important implications in terms of risks and benefits, impacting us as a society at many levels. We claim that the distinctive nature of LLMs--namely, their initialization with extensive pre-trained knowledge and implicit social priors, together with their capability of adaptation through in-context learning--motivates the need for an interactionist paradigm consisting of alternative theoretical foundations, methodologies, and analytical tools, in order to systematically examine how prior knowledge and embedded values interact with social context to shape emergent phenomena in multi-agent generative AI systems. We propose and discuss four directions that we consider crucial for the development and deployment of LLM-based collectives, focusing on theory, methods, and trans-disciplinary dialogue.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10567v1",
        "pdf": "https://arxiv.org/pdf/2601.10567v1"
      },
      "arxiv_id": "2601.10567v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10566v1",
      "title": "Representation-Aware Unlearning via Activation Signatures: From Suppression to Knowledge-Signature Erasure",
      "authors": [
        "Syed Naveed Mahmood",
        "Md. Rezaur Rahman Bhuiyan",
        "Tasfia Zaman",
        "Jareen Tasneem Khondaker",
        "Md. Sameer Sakib",
        "Nazia Tasnim",
        "Farig Sadeque"
      ],
      "abstract": "Selective knowledge erasure from LLMs is critical for GDPR compliance and model safety, yet current unlearning methods conflate behavioral suppression with true knowledge removal, allowing latent capabilities to persist beneath surface-level refusals. In this work, we address this challenge by introducing Knowledge Immunization Framework (KIF), a representation-aware architecture that distinguishes genuine erasure from obfuscation by targeting internal activation signatures rather than surface outputs. Our approach combines dynamic suppression of subject-specific representations with parameter-efficient adaptation, enabling durable unlearning without full model retraining. KIF achieves near-oracle erasure (FQ approx 0.99 vs. 1.00) while preserving utility at oracle levels (MU = 0.62), effectively breaking the stability-erasure tradeoff that has constrained all prior work. We evaluate both standard foundation models (Llama and Mistral) and reasoning-prior models (Qwen and DeepSeek) across 3B to 14B parameters. Our observation shows that standard models exhibit scale-independent true erasure (<3% utility drift), while reasoning-prior models reveal fundamental architectural divergence. Our comprehensive dual-metric evaluation protocol, combining surface-level leakage with latent trace persistence, operationalizes the obfuscation - erasure distinction and enables the first systematic diagnosis of mechanism-level forgetting behavior across model families and scales.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10566v1",
        "pdf": "https://arxiv.org/pdf/2601.10566v1"
      },
      "arxiv_id": "2601.10566v1",
      "comment": "16 pages, 4 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10563v1",
      "title": "Kolmogorov Arnold Networks and Multi-Layer Perceptrons: A Paradigm Shift in Neural Modelling",
      "authors": [
        "Aradhya Gaonkar",
        "Nihal Jain",
        "Vignesh Chougule",
        "Nikhil Deshpande",
        "Sneha Varur",
        "Channabasappa Muttal"
      ],
      "abstract": "The research undertakes a comprehensive comparative analysis of Kolmogorov-Arnold Networks (KAN) and Multi-Layer Perceptrons (MLP), highlighting their effectiveness in solving essential computational challenges like nonlinear function approximation, time-series prediction, and multivariate classification. Rooted in Kolmogorov's representation theorem, KANs utilize adaptive spline-based activation functions and grid-based structures, providing a transformative approach compared to traditional neural network frameworks. Utilizing a variety of datasets spanning mathematical function estimation (quadratic and cubic) to practical uses like predicting daily temperatures and categorizing wines, the proposed research thoroughly assesses model performance via accuracy measures like Mean Squared Error (MSE) and computational expense assessed through Floating Point Operations (FLOPs). The results indicate that KANs reliably exceed MLPs in every benchmark, attaining higher predictive accuracy with significantly reduced computational costs. Such an outcome highlights their ability to maintain a balance between computational efficiency and accuracy, rendering them especially beneficial in resource-limited and real-time operational environments. By elucidating the architectural and functional distinctions between KANs and MLPs, the paper provides a systematic framework for selecting the most suitable neural architectures for specific tasks. Furthermore, the proposed study highlights the transformative capabilities of KANs in progressing intelligent systems, influencing their use in situations that require both interpretability and computational efficiency.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10563v1",
        "pdf": "https://arxiv.org/pdf/2601.10563v1"
      },
      "arxiv_id": "2601.10563v1",
      "comment": "13 pages, 8 figures, 2 tables",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10562v1",
      "title": "Process-Guided Concept Bottleneck Model",
      "authors": [
        "Reza M. Asiyabi",
        "SEOSAW Partnership",
        "Steven Hancock",
        "Casey Ryan"
      ],
      "abstract": "Concept Bottleneck Models (CBMs) improve the explainability of black-box Deep Learning (DL) by introducing intermediate semantic concepts. However, standard CBMs often overlook domain-specific relationships and causal mechanisms, and their dependence on complete concept labels limits applicability in scientific domains where supervision is sparse but processes are well defined. To address this, we propose the Process-Guided Concept Bottleneck Model (PG-CBM), an extension of CBMs which constrains learning to follow domain-defined causal mechanisms through biophysically meaningful intermediate concepts. Using above ground biomass density estimation from Earth Observation data as a case study, we show that PG-CBM reduces error and bias compared to multiple benchmarks, whilst leveraging multi-source heterogeneous training data and producing interpretable intermediate outputs. Beyond improved accuracy, PG-CBM enhances transparency, enables detection of spurious learning, and provides scientific insights, representing a step toward more trustworthy AI systems in scientific applications.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10562v1",
        "pdf": "https://arxiv.org/pdf/2601.10562v1"
      },
      "arxiv_id": "2601.10562v1",
      "comment": "13 pages with 7 figures and 1 table, Supplementary Materials 10 pages with 3 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10560v1",
      "title": "Learning Latency-Aware Orchestration for Parallel Multi-Agent Systems",
      "authors": [
        "Xi Shi",
        "Mengxin Zheng",
        "Qian Lou"
      ],
      "abstract": "Multi-agent systems (MAS) enable complex reasoning by coordinating multiple agents, but often incur high inference latency due to multi-step execution and repeated model invocations, severely limiting their scalability and usability in time-sensitive scenarios. Most existing approaches primarily optimize task performance and inference cost, and explicitly or implicitly assume sequential execution, making them less optimal for controlling latency under parallel execution. In this work, we investigate learning-based orchestration of multi-agent systems with explicit latency supervision under parallel execution. We propose Latency-Aware Multi-agent System (LAMaS), a latency-aware multi-agent orchestration framework that enables parallel execution and explicitly optimizes the critical execution path, allowing the controller to construct execution topology graphs with lower latency under parallel execution. Our experiments show that our approach reduces critical path length by 38-46% compared to the state-of-the-art baseline for multi-agent architecture search across multiple benchmarks, while maintaining or even improving task performance. These results highlight the importance of explicitly optimizing latency under parallel execution when designing efficient multi-agent systems. The code is available at https://github.com/xishi404/LAMaS",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.MA",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10560v1",
        "pdf": "https://arxiv.org/pdf/2601.10560v1"
      },
      "arxiv_id": "2601.10560v1",
      "comment": "Preprint",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10554v1",
      "title": "DeepUrban: Interaction-Aware Trajectory Prediction and Planning for Automated Driving by Aerial Imagery",
      "authors": [
        "Constantin Selzer",
        "Fabian B. Flohr"
      ],
      "abstract": "The efficacy of autonomous driving systems hinges critically on robust prediction and planning capabilities. However, current benchmarks are impeded by a notable scarcity of scenarios featuring dense traffic, which is essential for understanding and modeling complex interactions among road users. To address this gap, we collaborated with our industrial partner, DeepScenario, to develop DeepUrban-a new drone dataset designed to enhance trajectory prediction and planning benchmarks focusing on dense urban settings. DeepUrban provides a rich collection of 3D traffic objects, extracted from high-resolution images captured over urban intersections at approximately 100 meters altitude. The dataset is further enriched with comprehensive map and scene information to support advanced modeling and simulation tasks. We evaluate state-of-the-art (SOTA) prediction and planning methods, and conducted experiments on generalization capabilities. Our findings demonstrate that adding DeepUrban to nuScenes can boost the accuracy of vehicle predictions and planning, achieving improvements up to 44.1 % / 44.3% on the ADE / FDE metrics. Website: https://iv.ee.hm.edu/deepurban",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10554v1",
        "pdf": "https://arxiv.org/pdf/2601.10554v1"
      },
      "arxiv_id": "2601.10554v1",
      "comment": "",
      "journal_ref": "2024 IEEE 27th International Conference on Intelligent Transportation Systems (ITSC), Edmonton, AB, Canada, 2024, pp. 221-227",
      "has_code": false
    },
    {
      "id": "2601.10553v1",
      "title": "Inference-time Physics Alignment of Video Generative Models with Latent World Models",
      "authors": [
        "Jianhao Yuan",
        "Xiaofeng Zhang",
        "Felix Friedrich",
        "Nicolas Beltran-Velez",
        "Melissa Hall",
        "Reyhane Askari-Hemmat",
        "Xiaochuang Han",
        "Nicolas Ballas",
        "Michal Drozdzal",
        "Adriana Romero-Soriano"
      ],
      "abstract": "State-of-the-art video generative models produce promising visual content yet often violate basic physics principles, limiting their utility. While some attribute this deficiency to insufficient physics understanding from pre-training, we find that the shortfall in physics plausibility also stems from suboptimal inference strategies. We therefore introduce WMReward and treat improving physics plausibility of video generation as an inference-time alignment problem. In particular, we leverage the strong physics prior of a latent world model (here, VJEPA-2) as a reward to search and steer multiple candidate denoising trajectories, enabling scaling test-time compute for better generation performance. Empirically, our approach substantially improves physics plausibility across image-conditioned, multiframe-conditioned, and text-conditioned generation settings, with validation from human preference study. Notably, in the ICCV 2025 Perception Test PhysicsIQ Challenge, we achieve a final score of 62.64%, winning first place and outperforming the previous state of the art by 7.42%. Our work demonstrates the viability of using latent world models to improve physics plausibility of video generation, beyond this specific instantiation or parameterization.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10553v1",
        "pdf": "https://arxiv.org/pdf/2601.10553v1"
      },
      "arxiv_id": "2601.10553v1",
      "comment": "22 pages, 10 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10551v1",
      "title": "Unleashing the Capabilities of Large Vision-Language Models for Intelligent Perception of Roadside Infrastructure",
      "authors": [
        "Luxuan Fu",
        "Chong Liu",
        "Bisheng Yang",
        "Zhen Dong"
      ],
      "abstract": "Automated perception of urban roadside infrastructure is crucial for smart city management, yet general-purpose models often struggle to capture the necessary fine-grained attributes and domain rules. While Large Vision Language Models (VLMs) excel at open-world recognition, they often struggle to accurately interpret complex facility states in compliance with engineering standards, leading to unreliable performance in real-world applications. To address this, we propose a domain-adapted framework that transforms VLMs into specialized agents for intelligent infrastructure analysis. Our approach integrates a data-efficient fine-tuning strategy with a knowledge-grounded reasoning mechanism. Specifically, we leverage open-vocabulary fine-tuning on Grounding DINO to robustly localize diverse assets with minimal supervision, followed by LoRA-based adaptation on Qwen-VL for deep semantic attribute reasoning. To mitigate hallucinations and enforce professional compliance, we introduce a dual-modality Retrieval-Augmented Generation (RAG) module that dynamically retrieves authoritative industry standards and visual exemplars during inference. Evaluated on a comprehensive new dataset of urban roadside scenes, our framework achieves a detection performance of 58.9 mAP and an attribute recognition accuracy of 95.5%, demonstrating a robust solution for intelligent infrastructure monitoring.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10551v1",
        "pdf": "https://arxiv.org/pdf/2601.10551v1"
      },
      "arxiv_id": "2601.10551v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10543v1",
      "title": "Defending Large Language Models Against Jailbreak Attacks via In-Decoding Safety-Awareness Probing",
      "authors": [
        "Yinzhi Zhao",
        "Ming Wang",
        "Shi Feng",
        "Xiaocui Yang",
        "Daling Wang",
        "Yifei Zhang"
      ],
      "abstract": "Large language models (LLMs) have achieved impressive performance across natural language tasks and are increasingly deployed in real-world applications. Despite extensive safety alignment efforts, recent studies show that such alignment is often shallow and remains vulnerable to jailbreak attacks. Existing defense mechanisms, including decoding-based constraints and post-hoc content detectors, struggle against sophisticated jailbreaks, often intervening robust detection or excessively degrading model utility. In this work, we examine the decoding process of LLMs and make a key observation: even when successfully jailbroken, models internally exhibit latent safety-related signals during generation. However, these signals are overridden by the model's drive for fluent continuation, preventing timely self-correction or refusal. Building on this observation, we propose a simple yet effective approach that explicitly surfaces and leverages these latent safety signals for early detection of unsafe content during decoding. Experiments across diverse jailbreak attacks demonstrate that our approach significantly enhances safety, while maintaining low over-refusal rates on benign inputs and preserving response quality. Our results suggest that activating intrinsic safety-awareness during decoding offers a promising and complementary direction for defending against jailbreak attacks. Code is available at: https://github.com/zyz13590/SafeProbing.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10543v1",
        "pdf": "https://arxiv.org/pdf/2601.10543v1"
      },
      "arxiv_id": "2601.10543v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10541v1",
      "title": "Mixtures of Transparent Local Models",
      "authors": [
        "Niffa Cheick Oumar Diaby",
        "Thierry Duchesne",
        "Mario Marchand"
      ],
      "abstract": "The predominance of machine learning models in many spheres of human activity has led to a growing demand for their transparency. The transparency of models makes it possible to discern some factors, such as security or non-discrimination. In this paper, we propose a mixture of transparent local models as an alternative solution for designing interpretable (or transparent) models. Our approach is designed for the situations where a simple and transparent function is suitable for modeling the label of instances in some localities/regions of the input space, but may change abruptly as we move from one locality to another. Consequently, the proposed algorithm is to learn both the transparent labeling function and the locality of the input space where the labeling function achieves a small risk in its assigned locality. By using a new multi-predictor (and multi-locality) loss function, we established rigorous PAC-Bayesian risk bounds for the case of binary linear classification problem and that of linear regression. In both cases, synthetic data sets were used to illustrate how the learning algorithms work. The results obtained from real data sets highlight the competitiveness of our approach compared to other existing methods as well as certain opaque models. Keywords: PAC-Bayes, risk bounds, local models, transparent models, mixtures of local transparent models.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10541v1",
        "pdf": "https://arxiv.org/pdf/2601.10541v1"
      },
      "arxiv_id": "2601.10541v1",
      "comment": "44 pages, 32 figues",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10537v1",
      "title": "Enhancing the quality of gauge images captured in smoke and haze scenes through deep learning",
      "authors": [
        "Oscar H. Ramírez-Agudelo",
        "Akshay N. Shewatkar",
        "Edoardo Milana",
        "Roland C. Aydin",
        "Kai Franke"
      ],
      "abstract": "Images captured in hazy and smoky environments suffer from reduced visibility, posing a challenge when monitoring infrastructures and hindering emergency services during critical situations. The proposed work investigates the use of the deep learning models to enhance the automatic, machine-based readability of gauge in smoky environments, with accurate gauge data interpretation serving as a valuable tool for first responders. The study utilizes two deep learning architectures, FFA-Net and AECR-Net, to improve the visibility of gauge images, corrupted with light up to dense haze and smoke. Since benchmark datasets of analog gauge images are unavailable, a new synthetic dataset, containing over 14,000 images, was generated using the Unreal Engine. The models were trained with an 80\\% train, 10\\% validation, and 10\\% test split for the haze and smoke dataset, respectively. For the synthetic haze dataset, the SSIM and PSNR metrics are about 0.98 and 43\\,dB, respectively, comparing well to state-of-the art results. Additionally, more robust results are retrieved from the AECR-Net, when compared to the FFA-Net. Although the results from the synthetic smoke dataset are poorer, the trained models achieve interesting results. In general, imaging in the presence of smoke are more difficult to enhance given the inhomogeneity and high density. Secondly, FFA-Net and AECR-Net are implemented to dehaze and not to desmoke images. This work shows that use of deep learning architectures can improve the quality of analog gauge images captured in smoke and haze scenes immensely. Finally, the enhanced output images can be successfully post-processed for automatic autonomous reading of gauges",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10537v1",
        "pdf": "https://arxiv.org/pdf/2601.10537v1"
      },
      "arxiv_id": "2601.10537v1",
      "comment": "17 pages, 10 figures, 6 tables, SPIE Applications of Machine Learning 2023, San Diego, US",
      "journal_ref": "SPIE Vol. 12675 126750A-12, 2023",
      "has_code": false
    },
    {
      "id": "2601.10536v1",
      "title": "CoGen: Creation of Reusable UI Components in Figma via Textual Commands",
      "authors": [
        "Ishani Kanapathipillai",
        "Obhasha Priyankara"
      ],
      "abstract": "The evolution of User Interface design has emphasized the need for efficient, reusable, and editable components to ensure an efficient design process. This research introduces CoGen, a system that uses machine learning techniques to generate reusable UI components directly in Figma, one of the most popular UI design tools. Addressing gaps in current systems, CoGen focuses on creating atomic components such as buttons, labels, and input fields using structured JSON and natural language prompts.\n  The project integrates Figma API data extraction, Seq2Seq models, and fine-tuned T5 transformers for component generation. The key results demonstrate the efficiency of the T5 model in prompt generation, with an accuracy of 98% and a BLEU score of 0.2668, which ensures the mapping of JSON to descriptive prompts. For JSON creation, CoGen achieves a success rate of up to 100% in generating simple JSON outputs for specified component types.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10536v1",
        "pdf": "https://arxiv.org/pdf/2601.10536v1"
      },
      "arxiv_id": "2601.10536v1",
      "comment": "8 pages, 6 figures, 11 tables",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10535v1",
      "title": "SVII-3D: Advancing Roadside Infrastructure Inventory with Decimeter-level 3D Localization and Comprehension from Sparse Street Imagery",
      "authors": [
        "Chong Liu",
        "Luxuan Fu",
        "Yang Jia",
        "Zhen Dong",
        "Bisheng Yang"
      ],
      "abstract": "The automated creation of digital twins and precise asset inventories is a critical task in smart city construction and facility lifecycle management. However, utilizing cost-effective sparse imagery remains challenging due to limited robustness, inaccurate localization, and a lack of fine-grained state understanding. To address these limitations, SVII-3D, a unified framework for holistic asset digitization, is proposed. First, LoRA fine-tuned open-set detection is fused with a spatial-attention matching network to robustly associate observations across sparse views. Second, a geometry-guided refinement mechanism is introduced to resolve structural errors, achieving precise decimeter-level 3D localization. Third, transcending static geometric mapping, a Vision-Language Model agent leveraging multi-modal prompting is incorporated to automatically diagnose fine-grained operational states. Experiments demonstrate that SVII-3D significantly improves identification accuracy and minimizes localization errors. Consequently, this framework offers a scalable, cost-effective solution for high-fidelity infrastructure digitization, effectively bridging the gap between sparse perception and automated intelligent maintenance.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10535v1",
        "pdf": "https://arxiv.org/pdf/2601.10535v1"
      },
      "arxiv_id": "2601.10535v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10531v1",
      "title": "Coarsening Causal DAG Models",
      "authors": [
        "Francisco Madaleno",
        "Pratik Misra",
        "Alex Markham"
      ],
      "abstract": "Directed acyclic graphical (DAG) models are a powerful tool for representing causal relationships among jointly distributed random variables, especially concerning data from across different experimental settings. However, it is not always practical or desirable to estimate a causal model at the granularity of given features in a particular dataset. There is a growing body of research on causal abstraction to address such problems. We contribute to this line of research by (i) providing novel graphical identifiability results for practically-relevant interventional settings, (ii) proposing an efficient, provably consistent algorithm for directly learning abstract causal graphs from interventional data with unknown intervention targets, and (iii) uncovering theoretical insights about the lattice structure of the underlying search space, with connections to the field of causal discovery more generally. As proof of concept, we apply our algorithm on synthetic and real datasets with known ground truths, including measurements from a controlled physical system with interacting light intensity and polarization.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "stat.ML",
        "cs.LG",
        "math.CO"
      ],
      "primary_category": "stat.ML",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10531v1",
        "pdf": "https://arxiv.org/pdf/2601.10531v1"
      },
      "arxiv_id": "2601.10531v1",
      "comment": "25 pages, 5 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10527v1",
      "title": "A Safety Report on GPT-5.2, Gemini 3 Pro, Qwen3-VL, Doubao 1.8, Grok 4.1 Fast, Nano Banana Pro, and Seedream 4.5",
      "authors": [
        "Xingjun Ma",
        "Yixu Wang",
        "Hengyuan Xu",
        "Yutao Wu",
        "Yifan Ding",
        "Yunhan Zhao",
        "Zilong Wang",
        "Jiabin Hua",
        "Ming Wen",
        "Jianan Liu",
        "Ranjie Duan",
        "Yifeng Gao",
        "Yingshui Tan",
        "Yunhao Chen",
        "Hui Xue",
        "Xin Wang",
        "Wei Cheng",
        "Jingjing Chen",
        "Zuxuan Wu",
        "Bo Li",
        "Yu-Gang Jiang"
      ],
      "abstract": "The rapid evolution of Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) has produced substantial gains in reasoning, perception, and generative capability across language and vision. However, whether these advances yield commensurate improvements in safety remains unclear, in part due to fragmented evaluation practices limited to single modalities or threat models. In this report, we present an integrated safety evaluation of 7 frontier models: GPT-5.2, Gemini 3 Pro, Qwen3-VL, Doubao 1.8, Grok 4.1 Fast, Nano Banana Pro, and Seedream 4.5. We evaluate each model across language, vision-language, and image generation settings using a unified protocol that integrates benchmark evaluation, adversarial evaluation, multilingual evaluation, and compliance evaluation. Aggregating our evaluations into safety leaderboards and model safety profiles across multiple evaluation modes reveals a sharply heterogeneous safety landscape. While GPT-5.2 demonstrates consistently strong and balanced safety performance across evaluations, other models exhibit pronounced trade-offs among benchmark safety, adversarial alignment, multilingual generalization, and regulatory compliance. Both language and vision-language modalities show significant vulnerability under adversarial evaluation, with all models degrading substantially despite strong results on standard benchmarks. Text-to-image models achieve relatively stronger alignment in regulated visual risk categories, yet remain brittle under adversarial or semantically ambiguous prompts. Overall, these results show that safety in frontier models is inherently multidimensional--shaped by modality, language, and evaluation scheme, underscoring the need for standardized safety evaluations to accurately assess real-world risk and guide responsible model development and deployment.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10527v1",
        "pdf": "https://arxiv.org/pdf/2601.10527v1"
      },
      "arxiv_id": "2601.10527v1",
      "comment": "42 pages, 24 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10524v1",
      "title": "Diagnosing Generalization Failures in Fine-Tuned LLMs: A Cross-Architectural Study on Phishing Detection",
      "authors": [
        "Frank Bobe",
        "Gregory D. Vetaw",
        "Chase Pavlick",
        "Darshan Bryner",
        "Matthew Cook",
        "Jose Salas-Vernis"
      ],
      "abstract": "The practice of fine-tuning Large Language Models (LLMs) has achieved state-of-the-art performance on specialized tasks, yet diagnosing why these models become brittle and fail to generalize remains a critical open problem. To address this, we introduce and apply a multi-layered diagnostic framework to a cross-architectural study. We fine-tune Llama 3.1 8B, Gemma 2 9B, and Mistral models on a high-stakes phishing detection task and use SHAP analysis and mechanistic interpretability to uncover the root causes of their generalization failures. Our investigation reveals three critical findings: (1) Generalization is driven by a powerful synergy between architecture and data diversity. The Gemma 2 9B model achieves state-of-the-art performance (>91\\% F1), but only when trained on a stylistically diverse ``generalist'' dataset. (2) Generalization is highly architecture-dependent. We diagnose a specific failure mode in Llama 3.1 8B, which performs well on a narrow domain but cannot integrate diverse data, leading to a significant performance drop. (3) Some architectures are inherently more generalizable. The Mistral model proves to be a consistent and resilient performer across multiple training paradigms. By pinpointing the flawed heuristics responsible for these failures, our work provides a concrete methodology for diagnosing and understanding generalization failures, underscoring that reliable AI requires deep validation of the interplay between architecture, data, and training strategy.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10524v1",
        "pdf": "https://arxiv.org/pdf/2601.10524v1"
      },
      "arxiv_id": "2601.10524v1",
      "comment": "16 pages, 6 figures, 6 tables",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10521v1",
      "title": "BikeActions: An Open Platform and Benchmark for Cyclist-Centric VRU Action Recognition",
      "authors": [
        "Max A. Buettner",
        "Kanak Mazumder",
        "Luca Koecher",
        "Mario Finkbeiner",
        "Sebastian Niebler",
        "Fabian B. Flohr"
      ],
      "abstract": "Anticipating the intentions of Vulnerable Road Users (VRUs) is a critical challenge for safe autonomous driving (AD) and mobile robotics. While current research predominantly focuses on pedestrian crossing behaviors from a vehicle's perspective, interactions within dense shared spaces remain underexplored. To bridge this gap, we introduce FUSE-Bike, the first fully open perception platform of its kind. Equipped with two LiDARs, a camera, and GNSS, it facilitates high-fidelity, close-range data capture directly from a cyclist's viewpoint. Leveraging this platform, we present BikeActions, a novel multi-modal dataset comprising 852 annotated samples across 5 distinct action classes, specifically tailored to improve VRU behavior modeling. We establish a rigorous benchmark by evaluating state-of-the-art graph convolution and transformer-based models on our publicly released data splits, establishing the first performance baselines for this challenging task. We release the full dataset together with data curation tools, the open hardware design, and the benchmark code to foster future research in VRU action understanding under https://iv.ee.hm.edu/bikeactions/.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10521v1",
        "pdf": "https://arxiv.org/pdf/2601.10521v1"
      },
      "arxiv_id": "2601.10521v1",
      "comment": "This work has been submitted to the IEEE ICPR for possible publication",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10520v1",
      "title": "Breaking Up with Normatively Monolithic Agency with GRACE: A Reason-Based Neuro-Symbolic Architecture for Safe and Ethical AI Alignment",
      "authors": [
        "Felix Jahn",
        "Yannic Muskalla",
        "Lisa Dargasz",
        "Patrick Schramowski",
        "Kevin Baum"
      ],
      "abstract": "As AI agents become increasingly autonomous, widely deployed in consequential contexts, and efficacious in bringing about real-world impacts, ensuring that their decisions are not only instrumentally effective but also normatively aligned has become critical. We introduce a neuro-symbolic reason-based containment architecture, Governor for Reason-Aligned ContainmEnt (GRACE), that decouples normative reasoning from instrumental decision-making and can contain AI agents of virtually any design. GRACE restructures decision-making into three modules: a Moral Module (MM) that determines permissible macro actions via deontic logic-based reasoning; a Decision-Making Module (DMM) that encapsulates the target agent while selecting instrumentally optimal primitive actions in accordance with derived macro actions; and a Guard that monitors and enforces moral compliance. The MM uses a reason-based formalism providing a semantic foundation for deontic logic, enabling interpretability, contestability, and justifiability. Its symbolic representation enriches the DMM's informational context and supports formal verification and statistical guarantees of alignment enforced by the Guard. We demonstrate GRACE on an example of a LLM therapy assistant, showing how it enables stakeholders to understand, contest, and refine agent behavior.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10520v1",
        "pdf": "https://arxiv.org/pdf/2601.10520v1"
      },
      "arxiv_id": "2601.10520v1",
      "comment": "10 pages, 4 figures, accepted at 2nd Annual Conference of the International Association for Safe & Ethical AI (IASEAI'26)",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10519v1",
      "title": "Transformer-Based Cognitive Radio: Adaptive Modulation Strategies Using Transformer Models",
      "authors": [
        "Andrea Melis",
        "Andrea Piroddi",
        "Roberto Girau"
      ],
      "abstract": "Cognitive Radio (CR) systems, which dynamically adapt to changing spectrum environments, could benefit significantly from advancements in machine learning technologies. These systems can be enhanced in terms of spectral efficiency, robustness, and security through innovative approaches such as the use of Transformer models. This work investigates the application of Transformer models, specifically the GPT-2 architecture, to generate novel modulation schemes for wireless communications. By training a GPT-2 model on a dataset of existing modulation formulas, new modulation schemes has been created. These generated schemes are then compared to traditional methods using key performance metrics such as Signal-to-Noise Ratio (SNR) and Power Spectrum Density (PSD). The results show that Transformer-generated modulation schemes can achieve performance comparable to, and in some cases outperforming, traditional methods. This demonstrates that advanced CR systems could greatly benefit from the implementation of Transformer models, leading to more efficient, robust, and secure communication systems.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10519v1",
        "pdf": "https://arxiv.org/pdf/2601.10519v1"
      },
      "arxiv_id": "2601.10519v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10512v1",
      "title": "SatMap: Revisiting Satellite Maps as Prior for Online HD Map Construction",
      "authors": [
        "Kanak Mazumder",
        "Fabian B. Flohr"
      ],
      "abstract": "Online high-definition (HD) map construction is an essential part of a safe and robust end-to-end autonomous driving (AD) pipeline. Onboard camera-based approaches suffer from limited depth perception and degraded accuracy due to occlusion. In this work, we propose SatMap, an online vectorized HD map estimation method that integrates satellite maps with multi-view camera observations and directly predicts a vectorized HD map for downstream prediction and planning modules. Our method leverages lane-level semantics and texture from satellite imagery captured from a Bird's Eye View (BEV) perspective as a global prior, effectively mitigating depth ambiguity and occlusion. In our experiments on the nuScenes dataset, SatMap achieves 34.8% mAP performance improvement over the camera-only baseline and 8.5% mAP improvement over the camera-LiDAR fusion baseline. Moreover, we evaluate our model in long-range and adverse weather conditions to demonstrate the advantages of using a satellite prior map. Source code will be available at https://iv.ee.hm.edu/satmap/.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10512v1",
        "pdf": "https://arxiv.org/pdf/2601.10512v1"
      },
      "arxiv_id": "2601.10512v1",
      "comment": "This work has been submitted to the IEEE ICPR for possible publication",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10511v1",
      "title": "Scalable Algorithms for Approximate DNF Model Counting",
      "authors": [
        "Paul Burkhardt",
        "David G. Harris",
        "Kevin T Schmitt"
      ],
      "abstract": "Model counting of Disjunctive Normal Form (DNF) formulas is a critical problem in applications such as probabilistic inference and network reliability. For example, it is often used for query evaluation in probabilistic databases. Due to the computational intractability of exact DNF counting, there has been a line of research into a variety of approximation algorithms. These include Monte Carlo approaches such as the classical algorithms of Karp, Luby, and Madras (1989), as well as methods based on hashing (Soos et al. 2023), and heuristic approximations based on Neural Nets (Abboud, Ceylan, and Lukasiewicz 2020).\n  We develop a new Monte Carlo approach with an adaptive stopping rule and short-circuit formula evaluation. We prove it achieves Probably Approximately Correct (PAC) learning bounds and is asymptotically more efficient than the previous methods. We also show experimentally that it out-performs prior algorithms by orders of magnitude, and can scale to much larger problems with millions of variables.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.DS",
        "cs.AI"
      ],
      "primary_category": "cs.DS",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10511v1",
        "pdf": "https://arxiv.org/pdf/2601.10511v1"
      },
      "arxiv_id": "2601.10511v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10498v1",
      "title": "Projected Microbatch Accumulation yields reference-free proximal policy updates for reinforcement learning",
      "authors": [
        "Nilin Abrahamsen"
      ],
      "abstract": "This note introduces Projected Microbatch Accumulation (PROMA), a proximal policy update method for large language model fine-tuning. PROMA accumulates policy gradients across microbatches by projecting out sequence-wise gradient components before microbatch aggregation. The projection is applied layer-wise during the backward pass, enabling efficient implementation without additional forward or backward passes. Empirically, PROMA enforces tighter control of local KL divergence than GRPO, resulting in more stable policy learning. Unlike PPO and GRPO, PROMA achieves proximal updates without inducing entropy collapse and does not rely on a reference policy or likelihood-ratio clipping.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10498v1",
        "pdf": "https://arxiv.org/pdf/2601.10498v1"
      },
      "arxiv_id": "2601.10498v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10497v1",
      "title": "mergetune: Continued fine-tuning of vision-language models",
      "authors": [
        "Wenqing Wang",
        "Da Li",
        "Xiatian Zhu",
        "Josef Kittler"
      ],
      "abstract": "Fine-tuning vision-language models (VLMs) such as CLIP often leads to catastrophic forgetting of pretrained knowledge. Prior work primarily aims to mitigate forgetting during adaptation; however, forgetting often remains inevitable during this process. We introduce a novel paradigm, \\emph{continued fine-tuning (CFT)}, which seeks to recover pretrained knowledge after a zero-shot model has already been adapted. We propose a simple, model-agnostic CFT strategy (named MERGETUNE) guided by linear mode connectivity (LMC), which can be applied post hoc to existing fine-tuned models without requiring architectural changes. Given a fine-tuned model, we continue fine-tuning its trainable parameters (e.g., soft prompts or linear heads) to search for a continued model which has two low-loss paths to the zero-shot (e.g., CLIP) and the fine-tuned (e.g., CoOp) solutions. By exploiting the geometry of the loss landscape, the continued model implicitly merges the two solutions, restoring pretrained knowledge lost in the fine-tuned counterpart. A challenge is that the vanilla LMC constraint requires data replay from the pretraining task. We approximate this constraint for the zero-shot model via a second-order surrogate, eliminating the need for large-scale data replay. Experiments show that MERGETUNE improves the harmonic mean of CoOp by +5.6\\% on base-novel generalisation without adding parameters. % We show \\emph{the first time} superior performance than CLIP on both DTD and EuroSAT, on cross-dataset transfer. On robust fine-tuning evaluations, the LMC-merged model from MERGETUNE surpasses ensemble baselines with lower inference cost, achieving further gains and state-of-the-art results when ensembled with the zero-shot model. Our code is available at \\href{https://github.com/Surrey-UP-Lab/MERGETUNE}{https://github.com/Surrey-UP-Lab/MERGETUNE}.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10497v1",
        "pdf": "https://arxiv.org/pdf/2601.10497v1"
      },
      "arxiv_id": "2601.10497v1",
      "comment": "20 pages, 5 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10496v1",
      "title": "Model See, Model Do? Exposure-Aware Evaluation of Bug-vs-Fix Preference in Code LLMs",
      "authors": [
        "Ali Al-Kaswan",
        "Claudio Spiess",
        "Prem Devanbu",
        "Arie van Deursen",
        "Maliheh Izadi"
      ],
      "abstract": "Large language models are increasingly used for code generation and debugging, but their outputs can still contain bugs, that originate from training data. Distinguishing whether an LLM prefers correct code, or a familiar incorrect version might be influenced by what it's been exposed to during training. We introduce an exposure-aware evaluation framework that quantifies how prior exposure to buggy versus fixed code influences a model's preference. Using the ManySStuBs4J benchmark, we apply Data Portraits for membership testing on the Stack-V2 corpus to estimate whether each buggy and fixed variant was seen during training. We then stratify examples by exposure and compare model preference using code completion as well as multiple likelihood-based scoring metrics We find that most examples (67%) have neither variant in the training data, and when only one is present, fixes are more frequently present than bugs. In model generations, models reproduce buggy lines far more often than fixes, with bug-exposed examples amplifying this tendency and fix-exposed examples showing only marginal improvement. In likelihood scoring, minimum and maximum token-probability metrics consistently prefer the fixed code across all conditions, indicating a stable bias toward correct fixes. In contrast, metrics like the Gini coefficient reverse preference when only the buggy variant was seen. Our results indicate that exposure can skew bug-fix evaluations and highlight the risk that LLMs may propagate memorised errors in practice.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10496v1",
        "pdf": "https://arxiv.org/pdf/2601.10496v1"
      },
      "arxiv_id": "2601.10496v1",
      "comment": "MSR 2026 Technical Track",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10494v1",
      "title": "CROCS: A Two-Stage Clustering Framework for Behaviour-Centric Consumer Segmentation with Smart Meter Data",
      "authors": [
        "Luke W. Yerbury",
        "Ricardo J. G. B. Campello",
        "G. C. Livingston",
        "Mark Goldsworthy",
        "Lachlan O'Neil"
      ],
      "abstract": "With grid operators confronting rising uncertainty from renewable integration and a broader push toward electrification, Demand-Side Management (DSM) -- particularly Demand Response (DR) -- has attracted significant attention as a cost-effective mechanism for balancing modern electricity systems. Unprecedented volumes of consumption data from a continuing global deployment of smart meters enable consumer segmentation based on real usage behaviours, promising to inform the design of more effective DSM and DR programs. However, existing clustering-based segmentation methods insufficiently reflect the behavioural diversity of consumers, often relying on rigid temporal alignment, and faltering in the presence of anomalies, missing data, or large-scale deployments.\n  To address these challenges, we propose a novel two-stage clustering framework -- Clustered Representations Optimising Consumer Segmentation (CROCS). In the first stage, each consumer's daily load profiles are clustered independently to form a Representative Load Set (RLS), providing a compact summary of their typical diurnal consumption behaviours. In the second stage, consumers are clustered using the Weighted Sum of Minimum Distances (WSMD), a novel set-to-set measure that compares RLSs by accounting for both the prevalence and similarity of those behaviours. Finally, community detection on the WSMD-induced graph reveals higher-order prototypes that embody the shared diurnal behaviours defining consumer groups, enhancing the interpretability of the resulting clusters.\n  Extensive experiments on both synthetic and real Australian smart meter datasets demonstrate that CROCS captures intra-consumer variability, uncovers both synchronous and asynchronous behavioural similarities, and remains robust to anomalies and missing data, while scaling efficiently through natural parallelisation. These results...",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "stat.ML",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10494v1",
        "pdf": "https://arxiv.org/pdf/2601.10494v1"
      },
      "arxiv_id": "2601.10494v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10491v1",
      "title": "Communication-Efficient Federated Learning by Exploiting Spatio-Temporal Correlations of Gradients",
      "authors": [
        "Shenlong Zheng",
        "Zhen Zhang",
        "Yuhui Deng",
        "Geyong Min",
        "Lin Cui"
      ],
      "abstract": "Communication overhead is a critical challenge in federated learning, particularly in bandwidth-constrained networks. Although many methods have been proposed to reduce communication overhead, most focus solely on compressing individual gradients, overlooking the temporal correlations among them. Prior studies have shown that gradients exhibit spatial correlations, typically reflected in low-rank structures. Through empirical analysis, we further observe a strong temporal correlation between client gradients across adjacent rounds. Based on these observations, we propose GradESTC, a compression technique that exploits both spatial and temporal gradient correlations. GradESTC exploits spatial correlations to decompose each full gradient into a compact set of basis vectors and corresponding combination coefficients. By exploiting temporal correlations, only a small portion of the basis vectors need to be dynamically updated in each round. GradESTC significantly reduces communication overhead by transmitting lightweight combination coefficients and a limited number of updated basis vectors instead of the full gradients. Extensive experiments show that, upon reaching a target accuracy level near convergence, GradESTC reduces uplink communication by an average of 39.79% compared to the strongest baseline, while maintaining comparable convergence speed and final accuracy to uncompressed FedAvg. By effectively leveraging spatio-temporal gradient structures, GradESTC offers a practical and scalable solution for communication-efficient federated learning.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10491v1",
        "pdf": "https://arxiv.org/pdf/2601.10491v1"
      },
      "arxiv_id": "2601.10491v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10485v1",
      "title": "Panning for Gold: Expanding Domain-Specific Knowledge Graphs with General Knowledge",
      "authors": [
        "Runhao Zhao",
        "Weixin Zeng",
        "Wentao Zhang",
        "Chong Chen",
        "Zhengpin Li",
        "Xiang Zhao",
        "Lei Chen"
      ],
      "abstract": "Domain-specific knowledge graphs (DKGs) often lack coverage compared to general knowledge graphs (GKGs). To address this, we introduce Domain-specific Knowledge Graph Fusion (DKGF), a novel task that enriches DKGs by integrating relevant facts from GKGs. DKGF faces two key challenges: high ambiguity in domain relevance and misalignment in knowledge granularity across graphs. We propose ExeFuse, a simple yet effective Fact-as-Program paradigm. It treats each GKG fact as a latent semantic program, maps abstract relations to granularity-aware operators, and verifies domain relevance via program executability on the target DKG. This unified probabilistic framework jointly resolves relevance and granularity issues. We construct two benchmarks, DKGF(W-I) and DKGF(Y-I), with 21 evaluation configurations. Extensive experiments validate the task's importance and our model's effectiveness, providing the first standardized testbed for DKGF.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10485v1",
        "pdf": "https://arxiv.org/pdf/2601.10485v1"
      },
      "arxiv_id": "2601.10485v1",
      "comment": "13 pages, 4 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10479v1",
      "title": "H-EFT-VA: An Effective-Field-Theory Variational Ansatz with Provable Barren Plateau Avoidance",
      "authors": [
        "Eyad I. B Hamid"
      ],
      "abstract": "Variational Quantum Algorithms (VQAs) are critically threatened by the Barren Plateau (BP) phenomenon. In this work, we introduce the H-EFT Variational Ansatz (H-EFT-VA), an architecture inspired by Effective Field Theory (EFT). By enforcing a hierarchical \"UV-cutoff\" on initialization, we theoretically restrict the circuit's state exploration, preventing the formation of approximate unitary 2-designs. We provide a rigorous proof that this localization guarantees an inverse-polynomial lower bound on the gradient variance: $Var[\\partial θ] \\in Ω(1/poly(N))$. Crucially, unlike approaches that avoid BPs by limiting entanglement, we demonstrate that H-EFT-VA maintains volume-law entanglement and near-Haar purity, ensuring sufficient expressibility for complex quantum states. Extensive benchmarking across 16 experiments -- including Transverse Field Ising and Heisenberg XXZ models -- confirms a 109x improvement in energy convergence and a 10.7x increase in ground-state fidelity over standard Hardware-Efficient Ansatze (HEA), with a statistical significance of $p < 10^{-88}$.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "quant-ph",
        "cs.LG",
        "math-ph"
      ],
      "primary_category": "quant-ph",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10479v1",
        "pdf": "https://arxiv.org/pdf/2601.10479v1"
      },
      "arxiv_id": "2601.10479v1",
      "comment": "7 pages, 5 figuers, Appendix",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10477v1",
      "title": "Urban Socio-Semantic Segmentation with Vision-Language Reasoning",
      "authors": [
        "Yu Wang",
        "Yi Wang",
        "Rui Dai",
        "Yujie Wang",
        "Kaikui Liu",
        "Xiangxiang Chu",
        "Yansheng Li"
      ],
      "abstract": "As hubs of human activity, urban surfaces consist of a wealth of semantic entities. Segmenting these various entities from satellite imagery is crucial for a range of downstream applications. Current advanced segmentation models can reliably segment entities defined by physical attributes (e.g., buildings, water bodies) but still struggle with socially defined categories (e.g., schools, parks). In this work, we achieve socio-semantic segmentation by vision-language model reasoning. To facilitate this, we introduce the Urban Socio-Semantic Segmentation dataset named SocioSeg, a new resource comprising satellite imagery, digital maps, and pixel-level labels of social semantic entities organized in a hierarchical structure. Additionally, we propose a novel vision-language reasoning framework called SocioReasoner that simulates the human process of identifying and annotating social semantic entities via cross-modal recognition and multi-stage reasoning. We employ reinforcement learning to optimize this non-differentiable process and elicit the reasoning capabilities of the vision-language model. Experiments demonstrate our approach's gains over state-of-the-art models and strong zero-shot generalization. Our dataset and code are available in https://github.com/AMAP-ML/SocioReasoner.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10477v1",
        "pdf": "https://arxiv.org/pdf/2601.10477v1"
      },
      "arxiv_id": "2601.10477v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10471v1",
      "title": "DeFlow: Decoupling Manifold Modeling and Value Maximization for Offline Policy Extraction",
      "authors": [
        "Zhancun Mu"
      ],
      "abstract": "We present DeFlow, a decoupled offline RL framework that leverages flow matching to faithfully capture complex behavior manifolds. Optimizing generative policies is computationally prohibitive, typically necessitating backpropagation through ODE solvers. We address this by learning a lightweight refinement module within an explicit, data-derived trust region of the flow manifold, rather than sacrificing the iterative generation capability via single-step distillation. This way, we bypass solver differentiation and eliminate the need for balancing loss terms, ensuring stable improvement while fully preserving the flow's iterative expressivity. Empirically, DeFlow achieves superior performance on the challenging OGBench benchmark and demonstrates efficient offline-to-online adaptation.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10471v1",
        "pdf": "https://arxiv.org/pdf/2601.10471v1"
      },
      "arxiv_id": "2601.10471v1",
      "comment": "13 pages, 3 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10462v1",
      "title": "ChartComplete: A Taxonomy-based Inclusive Chart Dataset",
      "authors": [
        "Ahmad Mustapha",
        "Charbel Toumieh",
        "Mariette Awad"
      ],
      "abstract": "With advancements in deep learning (DL) and computer vision techniques, the field of chart understanding is evolving rapidly. In particular, multimodal large language models (MLLMs) are proving to be efficient and accurate in understanding charts. To accurately measure the performance of MLLMs, the research community has developed multiple datasets to serve as benchmarks. By examining these datasets, we found that they are all limited to a small set of chart types. To bridge this gap, we propose the ChartComplete dataset. The dataset is based on a chart taxonomy borrowed from the visualization community, and it covers thirty different chart types. The dataset is a collection of classified chart images and does not include a learning signal. We present the ChartComplete dataset as is to the community to build upon it.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10462v1",
        "pdf": "https://arxiv.org/pdf/2601.10462v1"
      },
      "arxiv_id": "2601.10462v1",
      "comment": "7 pages, 4 figures, 3 tables, 1 algorithm. Dataset and source code available at https://github.com/AI-DSCHubAUB/ChartComplete-Dataset",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2601.10460v1",
      "title": "Contextual StereoSet: Stress-Testing Bias Alignment Robustness in Large Language Models",
      "authors": [
        "Abhinaba Basu",
        "Pavan Chakraborty"
      ],
      "abstract": "A model that avoids stereotypes in a lab benchmark may not avoid them in deployment. We show that measured bias shifts dramatically when prompts mention different places, times, or audiences -- no adversarial prompting required.\n  We introduce Contextual StereoSet, a benchmark that holds stereotype content fixed while systematically varying contextual framing. Testing 13 models across two protocols, we find striking patterns: anchoring to 1990 (vs. 2030) raises stereotype selection in all models tested on this contrast (p<0.05); gossip framing raises it in 5 of 6 full-grid models; out-group observer framing shifts it by up to 13 percentage points. These effects replicate in hiring, lending, and help-seeking vignettes.\n  We propose Context Sensitivity Fingerprints (CSF): a compact profile of per-dimension dispersion and paired contrasts with bootstrap CIs and FDR correction. Two evaluation tracks support different use cases -- a 360-context diagnostic grid for deep analysis and a budgeted protocol covering 4,229 items for production screening.\n  The implication is methodological: bias scores from fixed-condition tests may not generalize.This is not a claim about ground-truth bias rates; it is a stress test of evaluation robustness. CSF forces evaluators to ask, \"Under what conditions does bias appear?\" rather than \"Is this model biased?\" We release our benchmark, code, and results.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10460v1",
        "pdf": "https://arxiv.org/pdf/2601.10460v1"
      },
      "arxiv_id": "2601.10460v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10458v1",
      "title": "LangLasso: Interactive Cluster Descriptions through LLM Explanation",
      "authors": [
        "Raphael Buchmüller",
        "Dennis Collaris",
        "Linhao Meng",
        "Angelos Chatzimparmpas"
      ],
      "abstract": "Dimensionality reduction is a powerful technique for revealing structure and potential clusters in data. However, as the axes are complex, non-linear combinations of features, they often lack semantic interpretability. Existing visual analytics (VA) methods support cluster interpretation through feature comparison and interactive exploration, but they require technical expertise and intense human effort. We present \\textit{LangLasso}, a novel method that complements VA approaches through interactive, natural language descriptions of clusters using large language models (LLMs). It produces human-readable descriptions that make cluster interpretation accessible to non-experts and allow integration of external contextual knowledge beyond the dataset. We systematically evaluate the reliability of these explanations and demonstrate that \\langlasso provides an effective first step for engaging broader audiences in cluster interpretation. The tool is available at https://langlasso.vercel.app",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.HC",
        "cs.LG",
        "stat.CO"
      ],
      "primary_category": "cs.HC",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10458v1",
        "pdf": "https://arxiv.org/pdf/2601.10458v1"
      },
      "arxiv_id": "2601.10458v1",
      "comment": "This manuscript is accepted for publication in VIS 2025 VISxGenAI Workshop",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10457v1",
      "title": "NSR-Boost: A Neuro-Symbolic Residual Boosting Framework for Industrial Legacy Models",
      "authors": [
        "Ziming Dai",
        "Dabiao Ma",
        "Jinle Tong",
        "Mengyuan Han",
        "Jian Yang",
        "Haojun Fei"
      ],
      "abstract": "Although the Gradient Boosted Decision Trees (GBDTs) dominate industrial tabular applications, upgrading legacy models in high-concurrency production environments still faces prohibitive retraining costs and systemic risks. To address this problem, we present NSR-Boost, a neuro-symbolic residual boosting framework designed specifically for industrial scenarios. Its core advantage lies in being \"non-intrusive\". It treats the legacy model as a frozen model and performs targeted repairs on \"hard regions\" where predictions fail. The framework comprises three key stages: first, finding hard regions through residuals, then generating interpretable experts by generating symbolic code structures using Large Language Model (LLM) and fine-tuning parameters using Bayesian optimization, and finally dynamically integrating experts with legacy model output through a lightweight aggregator. We report on the successful deployment of NSR-Boost within the core financial risk control system at Qfin Holdings. This framework not only significantly outperforms state-of-the-art (SOTA) baselines across six public datasets and one private dataset, more importantly, shows excellent performance gains on real-world online data. In conclusion, it effectively captures long-tail risks missed by traditional models and offers a safe, low-cost evolutionary paradigm for industry.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10457v1",
        "pdf": "https://arxiv.org/pdf/2601.10457v1"
      },
      "arxiv_id": "2601.10457v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10453v1",
      "title": "Stable Differentiable Modal Synthesis for Learning Nonlinear Dynamics",
      "authors": [
        "Victor Zheleznov",
        "Stefan Bilbao",
        "Alec Wright",
        "Simon King"
      ],
      "abstract": "Modal methods are a long-standing approach to physical modelling synthesis. Extensions to nonlinear problems are possible, including the case of a high-amplitude vibration of a string. A modal decomposition leads to a densely coupled nonlinear system of ordinary differential equations. Recent work in scalar auxiliary variable techniques has enabled construction of explicit and stable numerical solvers for such classes of nonlinear systems. On the other hand, machine learning approaches (in particular neural ordinary differential equations) have been successful in modelling nonlinear systems automatically from data. In this work, we examine how scalar auxiliary variable techniques can be combined with neural ordinary differential equations to yield a stable differentiable model capable of learning nonlinear dynamics. The proposed approach leverages the analytical solution for linear vibration of system's modes so that physical parameters of a system remain easily accessible after the training without the need for a parameter encoder in the model architecture. As a proof of concept, we generate synthetic data for the nonlinear transverse vibration of a string and show that the model can be trained to reproduce the nonlinear dynamics of the system. Sound examples are presented.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.SD",
        "cs.LG",
        "eess.AS",
        "physics.comp-ph"
      ],
      "primary_category": "cs.SD",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10453v1",
        "pdf": "https://arxiv.org/pdf/2601.10453v1"
      },
      "arxiv_id": "2601.10453v1",
      "comment": "Submitted to the Journal of Audio Engineering Society (December 2025)",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10449v1",
      "title": "Lunar-G2R: Geometry-to-Reflectance Learning for High-Fidelity Lunar BRDF Estimation",
      "authors": [
        "Clementine Grethen",
        "Nicolas Menga",
        "Roland Brochard",
        "Geraldine Morin",
        "Simone Gasparini",
        "Jeremy Lebreton",
        "Manuel Sanchez Gestido"
      ],
      "abstract": "We address the problem of estimating realistic, spatially varying reflectance for complex planetary surfaces such as the lunar regolith, which is critical for high-fidelity rendering and vision-based navigation. Existing lunar rendering pipelines rely on simplified or spatially uniform BRDF models whose parameters are difficult to estimate and fail to capture local reflectance variations, limiting photometric realism. We propose Lunar-G2R, a geometry-to-reflectance learning framework that predicts spatially varying BRDF parameters directly from a lunar digital elevation model (DEM), without requiring multi-view imagery, controlled illumination, or dedicated reflectance-capture hardware at inference time. The method leverages a U-Net trained with differentiable rendering to minimize photometric discrepancies between real orbital images and physically based renderings under known viewing and illumination geometry. Experiments on a geographically held-out region of the Tycho crater show that our approach reduces photometric error by 38 % compared to a state-of-the-art baseline, while achieving higher PSNR and SSIM and improved perceptual similarity, capturing fine-scale reflectance variations absent from spatially uniform models. To our knowledge, this is the first method to infer a spatially varying reflectance model directly from terrain geometry.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10449v1",
        "pdf": "https://arxiv.org/pdf/2601.10449v1"
      },
      "arxiv_id": "2601.10449v1",
      "comment": "Data & code: https://clementinegrethen.github.io/publications/Lunar-G2R",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2601.10448v1",
      "title": "Subjective evaluation of UHD video coded using VVC with LCEVC and ML-VVC",
      "authors": [
        "Naeem Ramzan",
        "Muhammad Tufail Khan"
      ],
      "abstract": "This paper presents the results of a subjective quality assessment of a multilayer video coding configuration in which Low Complexity Enhancement Video Coding (LCEVC) is applied as an enhancement layer on top of a Versatile Video Coding (VVC) base layer. The evaluation follows the same test methodology and conditions previously defined for MPEG multilayer video coding assessments, with the LCEVC enhancement layer encoded using version 8.1 of the LCEVC Test Model (LTM). The test compares reconstructed UHD output generated from an HD VVC base layer with LCEVC enhancement against two reference cases: upsampled VVC base layer decoding and multilayer VVC (ML-VVC). Two operating points are considered, corresponding to enhancement layers representing approximately 10% and 50% of the total bitrate. Subjective assessment was conducted using the Degradation Category Rating (DCR) methodology with twenty five participants, across a dataset comprising fifteen SDR and HDR sequences. The reported results include Mean Opinion Scores (MOS) with associated 95% confidence intervals, enabling comparison of perceptual quality across coding approaches and operating points within the defined test scope.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.MM",
        "cs.CV"
      ],
      "primary_category": "cs.MM",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10448v1",
        "pdf": "https://arxiv.org/pdf/2601.10448v1"
      },
      "arxiv_id": "2601.10448v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10440v1",
      "title": "AgentGuardian: Learning Access Control Policies to Govern AI Agent Behavior",
      "authors": [
        "Nadya Abaev",
        "Denis Klimov",
        "Gerard Levinov",
        "David Mimran",
        "Yuval Elovici",
        "Asaf Shabtai"
      ],
      "abstract": "Artificial intelligence (AI) agents are increasingly used in a variety of domains to automate tasks, interact with users, and make decisions based on data inputs. Ensuring that AI agents perform only authorized actions and handle inputs appropriately is essential for maintaining system integrity and preventing misuse. In this study, we introduce the AgentGuardian, a novel security framework that governs and protects AI agent operations by enforcing context-aware access-control policies. During a controlled staging phase, the framework monitors execution traces to learn legitimate agent behaviors and input patterns. From this phase, it derives adaptive policies that regulate tool calls made by the agent, guided by both real-time input context and the control flow dependencies of multi-step agent actions. Evaluation across two real-world AI agent applications demonstrates that AgentGuardian effectively detects malicious or misleading inputs while preserving normal agent functionality. Moreover, its control-flow-based governance mechanism mitigates hallucination-driven errors and other orchestration-level malfunctions.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10440v1",
        "pdf": "https://arxiv.org/pdf/2601.10440v1"
      },
      "arxiv_id": "2601.10440v1",
      "comment": "14 pages, 5 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10436v1",
      "title": "Development of Ontological Knowledge Bases by Leveraging Large Language Models",
      "authors": [
        "Le Ngoc Luyen",
        "Marie-Hélène Abel",
        "Philippe Gouspillou"
      ],
      "abstract": "Ontological Knowledge Bases (OKBs) play a vital role in structuring domain-specific knowledge and serve as a foundation for effective knowledge management systems. However, their traditional manual development poses significant challenges related to scalability, consistency, and adaptability. Recent advancements in Generative AI, particularly Large Language Models (LLMs), offer promising solutions for automating and enhancing OKB development. This paper introduces a structured, iterative methodology leveraging LLMs to optimize knowledge acquisition, automate ontology artifact generation, and enable continuous refinement cycles. We demonstrate this approach through a detailed case study focused on developing a user context profile ontology within the vehicle sales domain. Key contributions include significantly accelerated ontology construction processes, improved ontological consistency, effective bias mitigation, and enhanced transparency in the ontology engineering process. Our findings highlight the transformative potential of integrating LLMs into ontology development, notably improving scalability, integration capabilities, and overall efficiency in knowledge management systems.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10436v1",
        "pdf": "https://arxiv.org/pdf/2601.10436v1"
      },
      "arxiv_id": "2601.10436v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10421v1",
      "title": "Are Language Models Models?",
      "authors": [
        "Philip Resnik"
      ],
      "abstract": "Futrell and Mahowald claim LMs \"serve as model systems\", but an assessment at each of Marr's three levels suggests the claim is clearly not true at the implementation level, poorly motivated at the algorithmic-representational level, and problematic at the computational theory level. LMs are good candidates as tools; calling them cognitive models overstates the case and unnecessarily feeds LLM hype.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10421v1",
        "pdf": "https://arxiv.org/pdf/2601.10421v1"
      },
      "arxiv_id": "2601.10421v1",
      "comment": "5 pages. This is an invited commentary under review at Behavioral and Brain Sciences",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10418v1",
      "title": "Reinforcement Learning with Multi-Step Lookahead Information Via Adaptive Batching",
      "authors": [
        "Nadav Merlis"
      ],
      "abstract": "We study tabular reinforcement learning problems with multiple steps of lookahead information. Before acting, the learner observes $\\ell$ steps of future transition and reward realizations: the exact state the agent would reach and the rewards it would collect under any possible course of action. While it has been shown that such information can drastically boost the value, finding the optimal policy is NP-hard, and it is common to apply one of two tractable heuristics: processing the lookahead in chunks of predefined sizes ('fixed batching policies'), and model predictive control. We first illustrate the problems with these two approaches and propose utilizing the lookahead in adaptive (state-dependent) batches; we refer to such policies as adaptive batching policies (ABPs). We derive the optimal Bellman equations for these strategies and design an optimistic regret-minimizing algorithm that enables learning the optimal ABP when interacting with unknown environments. Our regret bounds are order-optimal up to a potential factor of the lookahead horizon $\\ell$, which can usually be considered a small constant.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10418v1",
        "pdf": "https://arxiv.org/pdf/2601.10418v1"
      },
      "arxiv_id": "2601.10418v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10416v1",
      "title": "LLMdoctor: Token-Level Flow-Guided Preference Optimization for Efficient Test-Time Alignment of Large Language Models",
      "authors": [
        "Tiesunlong Shen",
        "Rui Mao",
        "Jin Wang",
        "Heming Sun",
        "Jian Zhang",
        "Xuejie Zhang",
        "Erik Cambria"
      ],
      "abstract": "Aligning Large Language Models (LLMs) with human preferences is critical, yet traditional fine-tuning methods are computationally expensive and inflexible. While test-time alignment offers a promising alternative, existing approaches often rely on distorted trajectory-level signals or inefficient sampling, fundamentally capping performance and failing to preserve the generative diversity of the base model. This paper introduces LLMdoctor, a novel framework for efficient test-time alignment that operates via a patient-doctor paradigm. It integrates token-level reward acquisition with token-level flow-guided preference optimization (TFPO) to steer a large, frozen patient LLM with a smaller, specialized doctor model. Unlike conventional methods that rely on trajectory-level rewards, LLMdoctor first extracts fine-grained, token-level preference signals from the patient model's behavioral variations. These signals then guide the training of the doctor model via TFPO, which establishes flow consistency across all subtrajectories, enabling precise token-by-token alignment while inherently preserving generation diversity. Extensive experiments demonstrate that LLMdoctor significantly outperforms existing test-time alignment methods and even surpasses the performance of full fine-tuning approaches like DPO.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10416v1",
        "pdf": "https://arxiv.org/pdf/2601.10416v1"
      },
      "arxiv_id": "2601.10416v1",
      "comment": "Accepted by AAAI26",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10413v1",
      "title": "LADFA: A Framework of Using Large Language Models and Retrieval-Augmented Generation for Personal Data Flow Analysis in Privacy Policies",
      "authors": [
        "Haiyue Yuan",
        "Nikolay Matyunin",
        "Ali Raza",
        "Shujun Li"
      ],
      "abstract": "Privacy policies help inform people about organisations' personal data processing practices, covering different aspects such as data collection, data storage, and sharing of personal data with third parties. Privacy policies are often difficult for people to fully comprehend due to the lengthy and complex legal language used and inconsistent practices across different sectors and organisations. To help conduct automated and large-scale analyses of privacy policies, many researchers have studied applications of machine learning and natural language processing techniques, including large language models (LLMs). While a limited number of prior studies utilised LLMs for extracting personal data flows from privacy policies, our approach builds on this line of work by combining LLMs with retrieval-augmented generation (RAG) and a customised knowledge base derived from existing studies. This paper presents the development of LADFA, an end-to-end computational framework, which can process unstructured text in a given privacy policy, extract personal data flows and construct a personal data flow graph, and conduct analysis of the data flow graph to facilitate insight discovery. The framework consists of a pre-processor, an LLM-based processor, and a data flow post-processor. We demonstrated and validated the effectiveness and accuracy of the proposed approach by conducting a case study that involved examining ten selected privacy policies from the automotive industry. Moreover, it is worth noting that LADFA is designed to be flexible and customisable, making it suitable for a range of text-based analysis tasks beyond privacy policy analysis.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10413v1",
        "pdf": "https://arxiv.org/pdf/2601.10413v1"
      },
      "arxiv_id": "2601.10413v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10412v1",
      "title": "An effective interactive brain cytoarchitectonic parcellation framework using pretrained foundation model",
      "authors": [
        "Shiqi Zhang",
        "Fang Xu",
        "Pengcheng Zhou"
      ],
      "abstract": "Cytoarchitectonic mapping provides anatomically grounded parcellations of brain structure and forms a foundation for integrative, multi-modal neuroscience analyses. These parcellations are defined based on the shape, density, and spatial arrangement of neuronal cell bodies observed in histological imaging. Recent works have demonstrated the potential of using deep learning models toward fully automatic segmentation of cytoarchitectonic areas in large-scale datasets, but performance is mainly constrained by the scarcity of training labels and the variability of staining and imaging conditions. To address these challenges, we propose an interactive cytoarchitectonic parcellation framework that leverages the strong transferability of the DINOv3 vision transformer. Our framework combines (i) multi-layer DINOv3 feature fusion, (ii) a lightweight segmentation decoder, and (iii) real-time user-guided training from sparse scribbles. This design enables rapid human-in-the-loop refinement while maintaining high segmentation accuracy. Compared with training an nnU-Net from scratch, transfer learning with DINOv3 yields markedly improved performance. We also show that features extracted by DINOv3 exhibit clear anatomical correspondence and demonstrate the method's practical utility for brain region segmentation using sparse labels. These results highlight the potential of foundation-model-driven interactive segmentation for scalable and efficient cytoarchitectonic mapping.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "eess.IV"
      ],
      "primary_category": "eess.IV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10412v1",
        "pdf": "https://arxiv.org/pdf/2601.10412v1"
      },
      "arxiv_id": "2601.10412v1",
      "comment": "10 pages, 5 figures, Accepted at IMIP2026 Code: https://github.com/Confetti22/cytoarch_brain_parcellation_dino",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2601.10407v1",
      "title": "CS-GBA: A Critical Sample-based Gradient-guided Backdoor Attack for Offline Reinforcement Learning",
      "authors": [
        "Yuanjie Zhao",
        "Junnan Qiu",
        "Yue Ding",
        "Jie Li"
      ],
      "abstract": "Offline Reinforcement Learning (RL) enables policy optimization from static datasets but is inherently vulnerable to backdoor attacks. Existing attack strategies typically struggle against safety-constrained algorithms (e.g., CQL) due to inefficient random poisoning and the use of easily detectable Out-of-Distribution (OOD) triggers. In this paper, we propose CS-GBA (Critical Sample-based Gradient-guided Backdoor Attack), a novel framework designed to achieve high stealthiness and destructiveness under a strict budget. Leveraging the theoretical insight that samples with high Temporal Difference (TD) errors are pivotal for value function convergence, we introduce an adaptive Critical Sample Selection strategy that concentrates the attack budget on the most influential transitions. To evade OOD detection, we propose a Correlation-Breaking Trigger mechanism that exploits the physical mutual exclusivity of state features (e.g., 95th percentile boundaries) to remain statistically concealed. Furthermore, we replace the conventional label inversion with a Gradient-Guided Action Generation mechanism, which searches for worst-case actions within the data manifold using the victim Q-network's gradient. Empirical results on D4RL benchmarks demonstrate that our method significantly outperforms state-of-the-art baselines, achieving high attack success rates against representative safety-constrained algorithms with a minimal 5% poisoning budget, while maintaining the agent's performance in clean environments.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10407v1",
        "pdf": "https://arxiv.org/pdf/2601.10407v1"
      },
      "arxiv_id": "2601.10407v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10406v1",
      "title": "ErrEval: Error-Aware Evaluation for Question Generation through Explicit Diagnostics",
      "authors": [
        "Weiping Fu",
        "Bifan Wei",
        "Jingyi Hao",
        "Yushun Zhang",
        "Jian Zhang",
        "Jiaxin Wang",
        "Bo Li",
        "Yu He",
        "Lingling Zhang",
        "Jun Liu"
      ],
      "abstract": "Automatic Question Generation (QG) often produces outputs with critical defects, such as factual hallucinations and answer mismatches. However, existing evaluation methods, including LLM-based evaluators, mainly adopt a black-box and holistic paradigm without explicit error modeling, leading to the neglect of such defects and overestimation of question quality. To address this issue, we propose ErrEval, a flexible and Error-aware Evaluation framework that enhances QG evaluation through explicit error diagnostics. Specifically, ErrEval reformulates evaluation as a two-stage process of error diagnosis followed by informed scoring. At the first stage, a lightweight plug-and-play Error Identifier detects and categorizes common errors across structural, linguistic, and content-related aspects. These diagnostic signals are then incorporated as explicit evidence to guide LLM evaluators toward more fine-grained and grounded judgments. Extensive experiments on three benchmarks demonstrate the effectiveness of ErrEval, showing that incorporating explicit diagnostics improves alignment with human judgments. Further analyses confirm that ErrEval effectively mitigates the overestimation of low-quality questions.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10406v1",
        "pdf": "https://arxiv.org/pdf/2601.10406v1"
      },
      "arxiv_id": "2601.10406v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10403v1",
      "title": "Discrete Feynman-Kac Correctors",
      "authors": [
        "Mohsin Hasan",
        "Viktor Ohanesian",
        "Artem Gazizov",
        "Yoshua Bengio",
        "Alán Aspuru-Guzik",
        "Roberto Bondesan",
        "Marta Skreta",
        "Kirill Neklyudov"
      ],
      "abstract": "Discrete diffusion models have recently emerged as a promising alternative to the autoregressive approach for generating discrete sequences. Sample generation via gradual denoising or demasking processes allows them to capture hierarchical non-sequential interdependencies in the data. These custom processes, however, do not assume a flexible control over the distribution of generated samples. We propose Discrete Feynman-Kac Correctors, a framework that allows for controlling the generated distribution of discrete masked diffusion models at inference time. We derive Sequential Monte Carlo (SMC) algorithms that, given a trained discrete diffusion model, control the temperature of the sampled distribution (i.e. perform annealing), sample from the product of marginals of several diffusion processes (e.g. differently conditioned processes), and sample from the product of the marginal with an external reward function, producing likely samples from the target distribution that also have high reward. Notably, our framework does not require any training of additional models or fine-tuning of the original model. We illustrate the utility of our framework in several applications including: efficient sampling from the annealed Boltzmann distribution of the Ising model, improving the performance of language models for code generation and amortized learning, as well as reward-tilted protein sequence generation.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10403v1",
        "pdf": "https://arxiv.org/pdf/2601.10403v1"
      },
      "arxiv_id": "2601.10403v1",
      "comment": "Code: https://github.com/hasanmohsin/discrete_fkc",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2601.10402v1",
      "title": "Toward Ultra-Long-Horizon Agentic Science: Cognitive Accumulation for Machine Learning Engineering",
      "authors": [
        "Xinyu Zhu",
        "Yuzhu Cai",
        "Zexi Liu",
        "Bingyang Zheng",
        "Cheng Wang",
        "Rui Ye",
        "Jiaao Chen",
        "Hanrui Wang",
        "Wei-Chen Wang",
        "Yuzhi Zhang",
        "Linfeng Zhang",
        "Weinan E",
        "Di Jin",
        "Siheng Chen"
      ],
      "abstract": "The advancement of artificial intelligence toward agentic science is currently bottlenecked by the challenge of ultra-long-horizon autonomy, the ability to sustain strategic coherence and iterative correction over experimental cycles spanning days or weeks. While Large Language Models (LLMs) have demonstrated prowess in short-horizon reasoning, they are easily overwhelmed by execution details in the high-dimensional, delayed-feedback environments of real-world research, failing to consolidate sparse feedback into coherent long-term guidance. Here, we present ML-Master 2.0, an autonomous agent that masters ultra-long-horizon machine learning engineering (MLE) which is a representative microcosm of scientific discovery. By reframing context management as a process of cognitive accumulation, our approach introduces Hierarchical Cognitive Caching (HCC), a multi-tiered architecture inspired by computer systems that enables the structural differentiation of experience over time. By dynamically distilling transient execution traces into stable knowledge and cross-task wisdom, HCC allows agents to decouple immediate execution from long-term experimental strategy, effectively overcoming the scaling limits of static context windows. In evaluations on OpenAI's MLE-Bench under 24-hour budgets, ML-Master 2.0 achieves a state-of-the-art medal rate of 56.44%. Our findings demonstrate that ultra-long-horizon autonomy provides a scalable blueprint for AI capable of autonomous exploration beyond human-precedent complexities.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10402v1",
        "pdf": "https://arxiv.org/pdf/2601.10402v1"
      },
      "arxiv_id": "2601.10402v1",
      "comment": "26 pages. 5 figures",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10398v1",
      "title": "LatentRefusal: Latent-Signal Refusal for Unanswerable Text-to-SQL Queries",
      "authors": [
        "Xuancheng Ren",
        "Shijing Hu",
        "Zhihui Lu",
        "Jiangqi Huang",
        "Qiang Duan"
      ],
      "abstract": "In LLM-based text-to-SQL systems, unanswerable and underspecified user queries may generate not only incorrect text but also executable programs that yield misleading results or violate safety constraints, posing a major barrier to safe deployment. Existing refusal strategies for such queries either rely on output-level instruction following, which is brittle due to model hallucinations, or estimate output uncertainty, which adds complexity and overhead. To address this challenge, we formalize safe refusal in text-to-SQL systems as an answerability-gating problem and propose LatentRefusal, a latent-signal refusal mechanism that predicts query answerability from intermediate hidden activations of a large language model. We introduce the Tri-Residual Gated Encoder, a lightweight probing architecture, to suppress schema noise and amplify sparse, localized cues of question-schema mismatch that indicate unanswerability. Extensive empirical evaluations across diverse ambiguous and unanswerable settings, together with ablation studies and interpretability analyses, demonstrate the effectiveness of the proposed approach and show that LatentRefusal provides an attachable and efficient safety layer for text-to-SQL systems. Across four benchmarks, LatentRefusal improves average F1 to 88.5 percent on both backbones while adding approximately 2 milliseconds of probe overhead.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10398v1",
        "pdf": "https://arxiv.org/pdf/2601.10398v1"
      },
      "arxiv_id": "2601.10398v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10392v1",
      "title": "Multi-Temporal Frames Projection for Dynamic Processes Fusion in Fluorescence Microscopy",
      "authors": [
        "Hassan Eshkiki",
        "Sarah Costa",
        "Mostafa Mohammadpour",
        "Farinaz Tanhaei",
        "Christopher H. George",
        "Fabio Caraffini"
      ],
      "abstract": "Fluorescence microscopy is widely employed for the analysis of living biological samples; however, the utility of the resulting recordings is frequently constrained by noise, temporal variability, and inconsistent visualisation of signals that oscillate over time. We present a unique computational framework that integrates information from multiple time-resolved frames into a single high-quality image, while preserving the underlying biological content of the original video. We evaluate the proposed method through an extensive number of configurations (n = 111) and on a challenging dataset comprising dynamic, heterogeneous, and morphologically complex 2D monolayers of cardiac cells. Results show that our framework, which consists of a combination of explainable techniques from different computer vision application fields, is capable of generating composite images that preserve and enhance the quality and information of individual microscopy frames, yielding 44% average increase in cell count compared to previous methods. The proposed pipeline is applicable to other imaging domains that require the fusion of multi-temporal image stacks into high-quality 2D images, thereby facilitating annotation and downstream segmentation.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10392v1",
        "pdf": "https://arxiv.org/pdf/2601.10392v1"
      },
      "arxiv_id": "2601.10392v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10386v1",
      "title": "Handling Missing Modalities in Multimodal Survival Prediction for Non-Small Cell Lung Cancer",
      "authors": [
        "Filippo Ruffini",
        "Camillo Maria Caruso",
        "Claudia Tacconi",
        "Lorenzo Nibid",
        "Francesca Miccolis",
        "Marta Lovino",
        "Carlo Greco",
        "Edy Ippolito",
        "Michele Fiore",
        "Alessio Cortellini",
        "Bruno Beomonte Zobel",
        "Giuseppe Perrone",
        "Bruno Vincenzi",
        "Claudio Marrocco",
        "Alessandro Bria",
        "Elisa Ficarra",
        "Sara Ramella",
        "Valerio Guarrasi",
        "Paolo Soda"
      ],
      "abstract": "Accurate survival prediction in Non-Small Cell Lung Cancer (NSCLC) requires the integration of heterogeneous clinical, radiological, and histopathological information. While Multimodal Deep Learning (MDL) offers a promises for precision prognosis and survival prediction, its clinical applicability is severely limited by small cohort sizes and the presence of missing modalities, often forcing complete-case filtering or aggressive imputation. In this work, we present a missing-aware multimodal survival framework that integrates Computed Tomography (CT), Whole-Slide Histopathology (WSI) Images, and structured clinical variables for overall survival modeling in unresectable stage II-III NSCLC. By leveraging Foundation Models (FM) for modality-specific feature extraction and a missing-aware encoding strategy, the proposed approach enables intermediate multimodal fusion under naturally incomplete modality profiles. The proposed architecture is resilient to missing modalities by design, allowing the model to utilize all available data without being forced to drop patients during training or inference. Experimental results demonstrate that intermediate fusion consistently outperforms unimodal baselines as well as early and late fusion strategies, with the strongest performance achieved by the fusion of WSI and clinical modalities (73.30 C-index). Further analyses of modality importance reveal an adaptive behavior in which less informative modalities, i.e., CT modality, are automatically down-weighted and contribute less to the final survival prediction.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10386v1",
        "pdf": "https://arxiv.org/pdf/2601.10386v1"
      },
      "arxiv_id": "2601.10386v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10378v1",
      "title": "Global Context Compression with Interleaved Vision-Text Transformation",
      "authors": [
        "Dian Jiao",
        "Jiaxin Duan",
        "Shuai Zhao",
        "Jiabing Leng",
        "Yiran Zhang",
        "Feng Huang"
      ],
      "abstract": "Recent achievements of vision-language models in end-to-end OCR point to a new avenue for low-loss compression of textual information. This motivates earlier works that render the Transformer's input into images for prefilling, which effectively reduces the number of tokens through visual encoding, thereby alleviating the quadratically increased Attention computations. However, this partial compression fails to save computational or memory costs at token-by-token inference. In this paper, we investigate global context compression, which saves tokens at both prefilling and inference stages. Consequently, we propose VIST2, a novel Transformer that interleaves input text chunks alongside their visual encoding, while depending exclusively on visual tokens in the pre-context to predict the next text token distribution. Around this idea, we render text chunks into sketch images and train VIST2 in multiple stages, starting from curriculum-scheduled pretraining for optical language modeling, followed by modal-interleaved instruction tuning. We conduct extensive experiments using VIST2 families scaled from 0.6B to 8B to explore the training recipe and hyperparameters. With a 4$\\times$ compression ratio, the resulting models demonstrate significant superiority over baselines on long writing tasks, achieving, on average, a 3$\\times$ speedup in first-token generation, 77% reduction in memory usage, and 74% reduction in FLOPS. Our codes and datasets will be public to support further studies.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10378v1",
        "pdf": "https://arxiv.org/pdf/2601.10378v1"
      },
      "arxiv_id": "2601.10378v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10373v1",
      "title": "Towards Efficient Low-rate Image Compression with Frequency-aware Diffusion Prior Refinement",
      "authors": [
        "Yichong Xia",
        "Yimin Zhou",
        "Jinpeng Wang",
        "Bin Chen"
      ],
      "abstract": "Recent advancements in diffusion-based generative priors have enabled visually plausible image compression at extremely low bit rates. However, existing approaches suffer from slow sampling processes and suboptimal bit allocation due to fragmented training paradigms. In this work, we propose Accelerate \\textbf{Diff}usion-based Image Compression via \\textbf{C}onsistency Prior \\textbf{R}efinement (DiffCR), a novel compression framework for efficient and high-fidelity image reconstruction. At the heart of DiffCR is a Frequency-aware Skip Estimation (FaSE) module that refines the $ε$-prediction prior from a pre-trained latent diffusion model and aligns it with compressed latents at different timesteps via Frequency Decoupling Attention (FDA). Furthermore, a lightweight consistency estimator enables fast \\textbf{two-step decoding} by preserving the semantic trajectory of diffusion sampling. Without updating the backbone diffusion model, DiffCR achieves substantial bitrate savings (27.2\\% BD-rate (LPIPS) and 65.1\\% BD-rate (PSNR)) and over $10\\times$ speed-up compared to SOTA diffusion-based compression baselines.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10373v1",
        "pdf": "https://arxiv.org/pdf/2601.10373v1"
      },
      "arxiv_id": "2601.10373v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10369v1",
      "title": "Fine-Grained Human Pose Editing Assessment via Layer-Selective MLLMs",
      "authors": [
        "Ningyu Sun",
        "Zhaolin Cai",
        "Zitong Xu",
        "Peihang Chen",
        "Huiyu Duan",
        "Yichao Yan",
        "Xiongkuo Min",
        "Xiaokang Yang"
      ],
      "abstract": "Text-guided human pose editing has gained significant traction in AIGC applications. However,it remains plagued by structural anomalies and generative artifacts. Existing evaluation metrics often isolate authenticity detection from quality assessment, failing to provide fine-grained insights into pose-specific inconsistencies. To address these limitations, we introduce HPE-Bench, a specialized benchmark comprising 1,700 standardized samples from 17 state-of-the-art editing models, offering both authenticity labels and multi-dimensional quality scores. Furthermore, we propose a unified framework based on layer-selective multimodal large language models (MLLMs). By employing contrastive LoRA tuning and a novel layer sensitivity analysis (LSA) mechanism, we identify the optimal feature layer for pose evaluation. Our framework achieves superior performance in both authenticity detection and multi-dimensional quality regression, effectively bridging the gap between forensic detection and quality assessment.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10369v1",
        "pdf": "https://arxiv.org/pdf/2601.10369v1"
      },
      "arxiv_id": "2601.10369v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10358v1",
      "title": "PLGC: Pseudo-Labeled Graph Condensation",
      "authors": [
        "Jay Nandy",
        "Arnab Kumar Mondal",
        "Anuj Rathore",
        "Mahesh Chandran"
      ],
      "abstract": "Large graph datasets make training graph neural networks (GNNs) computationally costly. Graph condensation methods address this by generating small synthetic graphs that approximate the original data. However, existing approaches rely on clean, supervised labels, which limits their reliability when labels are scarce, noisy, or inconsistent. We propose Pseudo-Labeled Graph Condensation (PLGC), a self-supervised framework that constructs latent pseudo-labels from node embeddings and optimizes condensed graphs to match the original graph's structural and feature statistics -- without requiring ground-truth labels. PLGC offers three key contributions: (1) A diagnosis of why supervised condensation fails under label noise and distribution shift. (2) A label-free condensation method that jointly learns latent prototypes and node assignments. (3) Theoretical guarantees showing that pseudo-labels preserve latent structural statistics of the original graph and ensure accurate embedding alignment. Empirically, across node classification and link prediction tasks, PLGC achieves competitive performance with state-of-the-art supervised condensation methods on clean datasets and exhibits substantial robustness under label noise, often outperforming all baselines by a significant margin. Our findings highlight the practical and theoretical advantages of self-supervised graph condensation in noisy or weakly-labeled environments.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10358v1",
        "pdf": "https://arxiv.org/pdf/2601.10358v1"
      },
      "arxiv_id": "2601.10358v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10356v1",
      "title": "EvoMorph: Counterfactual Explanations for Continuous Time-Series Extrinsic Regression Applied to Photoplethysmography",
      "authors": [
        "Mesut Ceylan",
        "Alexis Tabin",
        "Patrick Langer",
        "Elgar Fleisch",
        "Filipe Barata"
      ],
      "abstract": "Wearable devices enable continuous, population-scale monitoring of physiological signals, such as photoplethysmography (PPG), creating new opportunities for data-driven clinical assessment. Time-series extrinsic regression (TSER) models increasingly leverage PPG signals to estimate clinically relevant outcomes, including heart rate, respiratory rate, and oxygen saturation. For clinical reasoning and trust, however, single point estimates alone are insufficient: clinicians must also understand whether predictions are stable under physiologically plausible variations and to what extent realistic, attainable changes in physiological signals would meaningfully alter a model's prediction. Counterfactual explanations (CFE) address these \"what-if\" questions, yet existing time series CFE generation methods are largely restricted to classification, overlook waveform morphology, and often produce physiologically implausible signals, limiting their applicability to continuous biomedical time series. To address these limitations, we introduce EvoMorph, a multi-objective evolutionary framework for generating physiologically plausible and diverse CFE for TSER applications. EvoMorph optimizes morphology-aware objectives defined on interpretable signal descriptors and applies transformations to preserve the waveform structure. We evaluated EvoMorph on three PPG datasets (heart rate, respiratory rate, and oxygen saturation) against a nearest-unlike-neighbor baseline. In addition, in a case study, we evaluated EvoMorph as a tool for uncertainty quantification by relating counterfactual sensitivity to bootstrap-ensemble uncertainty and data-density measures. Overall, EvoMorph enables the generation of physiologically-aware counterfactuals for continuous biomedical signals and supports uncertainty-aware interpretability, advancing trustworthy model analysis for clinical time-series applications.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10356v1",
        "pdf": "https://arxiv.org/pdf/2601.10356v1"
      },
      "arxiv_id": "2601.10356v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10349v1",
      "title": "SuS: Strategy-aware Surprise for Intrinsic Exploration",
      "authors": [
        "Mark Kashirskiy",
        "Ilya Makarov"
      ],
      "abstract": "We propose Strategy-aware Surprise (SuS), a novel intrinsic motivation framework that uses pre-post prediction mismatch as a novelty signal for exploration in reinforcement learning. Unlike traditional curiosity-driven methods that rely solely on state prediction error, SuS introduces two complementary components: Strategy Stability (SS) and Strategy Surprise (SuS). SS measures consistency in behavioral strategy across temporal steps, while SuS captures unexpected outcomes relative to the agent's current strategy representation. Our combined reward formulation leverages both signals through learned weighting coefficients. We evaluate SuS on mathematical reasoning tasks using large language models, demonstrating significant improvements in both accuracy and solution diversity. Ablation studies confirm that removing either component results in at least 10% performance degradation, validating the synergistic nature of our approach. SuS achieves 17.4% improvement in Pass@1 and 26.4% improvement in Pass@5 compared to baseline methods, while maintaining higher strategy diversity throughout training.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.GT"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10349v1",
        "pdf": "https://arxiv.org/pdf/2601.10349v1"
      },
      "arxiv_id": "2601.10349v1",
      "comment": "8 pages, 7 figures, 3 tables. Code available at https://github.com/mariklolik/sus",
      "journal_ref": "",
      "has_code": true
    },
    {
      "id": "2601.10348v1",
      "title": "Training-Trajectory-Aware Token Selection",
      "authors": [
        "Zhanming Shen",
        "Jiaqi Hu",
        "Zeyu Qin",
        "Hao Chen",
        "Wentao Ye",
        "Zenan Huang",
        "Yihong Zhuang",
        "Guoshan Lu",
        "Junlin Zhou",
        "Junbo Zhao"
      ],
      "abstract": "Efficient distillation is a key pathway for converting expensive reasoning capability into deployable efficiency, yet in the frontier regime where the student already has strong reasoning ability, naive continual distillation often yields limited gains or even degradation. We observe a characteristic training phenomenon: even as loss decreases monotonically, all performance metrics can drop sharply at almost the same bottleneck, before gradually recovering. We further uncover a token-level mechanism: confidence bifurcates into steadily increasing Imitation-Anchor Tokens that quickly anchor optimization and other yet-to-learn tokens whose confidence is suppressed until after the bottleneck. And the characteristic that these two types of tokens cannot coexist is the root cause of the failure in continual distillation. To this end, we propose Training-Trajectory-Aware Token Selection (T3S) to reconstruct the training objective at the token level, clearing the optimization path for yet-to-learn tokens. T3 yields consistent gains in both AR and dLLM settings: with only hundreds of examples, Qwen3-8B surpasses DeepSeek-R1 on competitive reasoning benchmarks, Qwen3-32B approaches Qwen3-235B, and T3-trained LLaDA-2.0-Mini exceeds its AR baseline, achieving state-of-the-art performance among all of 16B-scale no-think models.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10348v1",
        "pdf": "https://arxiv.org/pdf/2601.10348v1"
      },
      "arxiv_id": "2601.10348v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10343v1",
      "title": "OctoBench: Benchmarking Scaffold-Aware Instruction Following in Repository-Grounded Agentic Coding",
      "authors": [
        "Deming Ding",
        "Shichun Liu",
        "Enhui Yang",
        "Jiahang Lin",
        "Ziying Chen",
        "Shihan Dou",
        "Honglin Guo",
        "Weiyu Cheng",
        "Pengyu Zhao",
        "Chengjun Xiao",
        "Qunhong Zeng",
        "Qi Zhang",
        "Xuanjing Huang",
        "Qidi Xu",
        "Tao Gui"
      ],
      "abstract": "Modern coding scaffolds turn LLMs into capable software agents, but their ability to follow scaffold-specified instructions remains under-examined, especially when constraints are heterogeneous and persist across interactions. To fill this gap, we introduce OctoBench, which benchmarks scaffold-aware instruction following in repository-grounded agentic coding. OctoBench includes 34 environments and 217 tasks instantiated under three scaffold types, and is paired with 7,098 objective checklist items. To disentangle solving the task from following the rules, we provide an automated observation-and-scoring toolkit that captures full trajectories and performs fine-grained checks. Experiments on eight representative models reveal a systematic gap between task-solving and scaffold-aware compliance, underscoring the need for training and evaluation that explicitly targets heterogeneous instruction following. We release the benchmark to support reproducible benchmarking and to accelerate the development of more scaffold-aware coding agents.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10343v1",
        "pdf": "https://arxiv.org/pdf/2601.10343v1"
      },
      "arxiv_id": "2601.10343v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10342v1",
      "title": "C-GRASP: Clinically-Grounded Reasoning for Affective Signal Processing",
      "authors": [
        "Cheng Lin Cheng",
        "Ting Chuan Lin",
        "Chai Kai Chang"
      ],
      "abstract": "Heart rate variability (HRV) is a pivotal noninvasive marker for autonomic monitoring; however, applying Large Language Models (LLMs) to HRV interpretation is hindered by physiological hallucinations. These include respiratory sinus arrhythmia (RSA) contamination, short-data instability in nonlinear metrics, and the neglect of individualized baselines in favor of population norms. We propose C-GRASP (Clinically-Grounded Reasoning for Affective Signal Processing), a guardrailed RAG-enhanced pipeline that decomposes HRV interpretation into eight traceable reasoning steps. Central to C-GRASP is a Z-score Priority Hierarchy that enforces the weighting of individualized baseline shifts over normative statistics. The system effectively mitigates spectral hallucinations through automated RSA-aware guardrails, preventing contamination of frequency-domain indices. Evaluated on 414 trials from the DREAMER dataset, C-GRASP integrated with high-scale reasoning models (e.g., MedGemma3-thinking) achieved superior performance in 4-class emotion classification (37.3% accuracy) and a Clinical Reasoning Consistency (CRC) score of 69.6%. Ablation studies confirm that the individualized Delta Z-score module serves as the critical logical anchor, preventing the \"population bias\" common in native LLMs. Ultimately, C-GRASP transitions affective computing from black-box classification to transparent, evidence-based clinical decision support, paving the way for safer AI integration in biomedical engineering.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10342v1",
        "pdf": "https://arxiv.org/pdf/2601.10342v1"
      },
      "arxiv_id": "2601.10342v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10338v1",
      "title": "Agent Skills in the Wild: An Empirical Study of Security Vulnerabilities at Scale",
      "authors": [
        "Yi Liu",
        "Weizhe Wang",
        "Ruitao Feng",
        "Yao Zhang",
        "Guangquan Xu",
        "Gelei Deng",
        "Yuekang Li",
        "Leo Zhang"
      ],
      "abstract": "The rise of AI agent frameworks has introduced agent skills, modular packages containing instructions and executable code that dynamically extend agent capabilities. While this architecture enables powerful customization, skills execute with implicit trust and minimal vetting, creating a significant yet uncharacterized attack surface. We conduct the first large-scale empirical security analysis of this emerging ecosystem, collecting 42,447 skills from two major marketplaces and systematically analyzing 31,132 using SkillScan, a multi-stage detection framework integrating static analysis with LLM-based semantic classification. Our findings reveal pervasive security risks: 26.1% of skills contain at least one vulnerability, spanning 14 distinct patterns across four categories: prompt injection, data exfiltration, privilege escalation, and supply chain risks. Data exfiltration (13.3%) and privilege escalation (11.8%) are most prevalent, while 5.2% of skills exhibit high-severity patterns strongly suggesting malicious intent. We find that skills bundling executable scripts are 2.12x more likely to contain vulnerabilities than instruction-only skills (OR=2.12, p<0.001). Our contributions include: (1) a grounded vulnerability taxonomy derived from 8,126 vulnerable skills, (2) a validated detection methodology achieving 86.7% precision and 82.5% recall, and (3) an open dataset and detection toolkit to support future research. These results demonstrate an urgent need for capability-based permission systems and mandatory security vetting before this attack vector is further exploited.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10338v1",
        "pdf": "https://arxiv.org/pdf/2601.10338v1"
      },
      "arxiv_id": "2601.10338v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10334v1",
      "title": "An analytic theory of convolutional neural network inverse problems solvers",
      "authors": [
        "Minh Hai Nguyen",
        "Quoc Bao Do",
        "Edouard Pauwels",
        "Pierre Weiss"
      ],
      "abstract": "Supervised convolutional neural networks (CNNs) are widely used to solve imaging inverse problems, achieving state-of-the-art performance in numerous applications. However, despite their empirical success, these methods are poorly understood from a theoretical perspective and often treated as black boxes. To bridge this gap, we analyze trained neural networks through the lens of the Minimum Mean Square Error (MMSE) estimator, incorporating functional constraints that capture two fundamental inductive biases of CNNs: translation equivariance and locality via finite receptive fields. Under the empirical training distribution, we derive an analytic, interpretable, and tractable formula for this constrained variant, termed Local-Equivariant MMSE (LE-MMSE). Through extensive numerical experiments across various inverse problems (denoising, inpainting, deconvolution), datasets (FFHQ, CIFAR-10, FashionMNIST), and architectures (U-Net, ResNet, PatchMLP), we demonstrate that our theory matches the neural networks outputs (PSNR $\\gtrsim25$dB). Furthermore, we provide insights into the differences between \\emph{physics-aware} and \\emph{physics-agnostic} estimators, the impact of high-density regions in the training (patch) distribution, and the influence of other factors (dataset size, patch size, etc).",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10334v1",
        "pdf": "https://arxiv.org/pdf/2601.10334v1"
      },
      "arxiv_id": "2601.10334v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10332v1",
      "title": "Think-Then-Generate: Reasoning-Aware Text-to-Image Diffusion with LLM Encoders",
      "authors": [
        "Siqi Kou",
        "Jiachun Jin",
        "Zetong Zhou",
        "Ye Ma",
        "Yugang Wang",
        "Quan Chen",
        "Peng Jiang",
        "Xiao Yang",
        "Jun Zhu",
        "Kai Yu",
        "Zhijie Deng"
      ],
      "abstract": "Recent progress in text-to-image (T2I) diffusion models (DMs) has enabled high-quality visual synthesis from diverse textual prompts. Yet, most existing T2I DMs, even those equipped with large language model (LLM)-based text encoders, remain text-pixel mappers -- they employ LLMs merely as text encoders, without leveraging their inherent reasoning capabilities to infer what should be visually depicted given the textual prompt. To move beyond such literal generation, we propose the think-then-generate (T2G) paradigm, where the LLM-based text encoder is encouraged to reason about and rewrite raw user prompts; the states of the rewritten prompts then serve as diffusion conditioning. To achieve this, we first activate the think-then-rewrite pattern of the LLM encoder with a lightweight supervised fine-tuning process. Subsequently, the LLM encoder and diffusion backbone are co-optimized to ensure faithful reasoning about the context and accurate rendering of the semantics via Dual-GRPO. In particular, the text encoder is reinforced using image-grounded rewards to infer and recall world knowledge, while the diffusion backbone is pushed to produce semantically consistent and visually coherent images. Experiments show substantial improvements in factual consistency, semantic alignment, and visual realism across reasoning-based image generation and editing benchmarks, achieving 0.79 on WISE score, nearly on par with GPT-4. Our results constitute a promising step toward next-generation unified models with reasoning, expression, and demonstration capacities.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10332v1",
        "pdf": "https://arxiv.org/pdf/2601.10332v1"
      },
      "arxiv_id": "2601.10332v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false
    },
    {
      "id": "2601.10328v1",
      "title": "Meta Dynamic Graph for Traffic Flow Prediction",
      "authors": [
        "Yiqing Zou",
        "Hanning Yuan",
        "Qianyu Yang",
        "Ziqiang Yuan",
        "Shuliang Wang",
        "Sijie Ruan"
      ],
      "abstract": "Traffic flow prediction is a typical spatio-temporal prediction problem and has a wide range of applications. The core challenge lies in modeling the underlying complex spatio-temporal dependencies. Various methods have been proposed, and recent studies show that the modeling of dynamics is useful to meet the core challenge. While handling spatial dependencies and temporal dependencies using separate base model structures may hinder the modeling of spatio-temporal correlations, the modeling of dynamics can bridge this gap. Incorporating spatio-temporal heterogeneity also advances the main goal, since it can extend the parameter space and allow more flexibility. Despite these advances, two limitations persist: 1) the modeling of dynamics is often limited to the dynamics of spatial topology (e.g., adjacency matrix changes), which, however, can be extended to a broader scope; 2) the modeling of heterogeneity is often separated for spatial and temporal dimensions, but this gap can also be bridged by the modeling of dynamics. To address the above limitations, we propose a novel framework for traffic prediction, called Meta Dynamic Graph (MetaDG). MetaDG leverages dynamic graph structures of node representations to explicitly model spatio-temporal dynamics. This generates both dynamic adjacency matrices and meta-parameters, extending dynamic modeling beyond topology while unifying the capture of spatio-temporal heterogeneity into a single dimension. Extensive experiments on four real-world datasets validate the effectiveness of MetaDG.",
      "published": "2026-01-15",
      "updated": "2026-01-15",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.10328v1",
        "pdf": "https://arxiv.org/pdf/2601.10328v1"
      },
      "arxiv_id": "2601.10328v1",
      "comment": "Accepted to AAAI 2026",
      "journal_ref": "",
      "has_code": false
    }
  ]
}