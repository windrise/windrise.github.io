{
  "filtered_at": "{\"timestamp\": \"now\"}",
  "total_papers": 10,
  "papers": [
    {
      "id": "2602.11145v1",
      "title": "SCRAPL: Scattering Transform with Random Paths for Machine Learning",
      "authors": [
        "Christopher Mitcheltree",
        "Vincent Lostanlen",
        "Emmanouil Benetos",
        "Mathieu Lagrange"
      ],
      "abstract": "The Euclidean distance between wavelet scattering transform coefficients (known as paths) provides informative gradients for perceptual quality assessment of deep inverse problems in computer vision, speech, and audio processing. However, these transforms are computationally expensive when employed as differentiable loss functions for stochastic gradient descent due to their numerous paths, which significantly limits their use in neural network training. Against this problem, we propose \"Scattering transform with Random Paths for machine Learning\" (SCRAPL): a stochastic optimization scheme for efficient evaluation of multivariable scattering transforms. We implement SCRAPL for the joint time-frequency scattering transform (JTFS) which demodulates spectrotemporal patterns at multiple scales and rates, allowing a fine characterization of intermittent auditory textures. We apply SCRAPL to differentiable digital signal processing (DDSP), specifically, unsupervised sound matching of a granular synthesizer and the Roland TR-808 drum machine. We also propose an initialization heuristic based on importance sampling, which adapts SCRAPL to the perceptual content of the dataset, improving neural network convergence and evaluation performance. We make our code and audio samples available and provide SCRAPL as a Python package.",
      "published": "2026-02-11",
      "updated": "2026-02-11",
      "categories": [
        "cs.SD",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "links": {
        "paper": "http://arxiv.org/abs/2602.11145v1",
        "pdf": "https://arxiv.org/pdf/2602.11145v1"
      },
      "arxiv_id": "2602.11145v1",
      "comment": "Accepted to ICLR 2026. Code, audio samples, and Python package provided at https://christhetree.github.io/scrapl/",
      "journal_ref": "",
      "has_code": true,
      "relevance_score": 5.1194915254237285,
      "score_breakdown": {
        "total_score": 5.12,
        "field_match": {
          "score": 0.42,
          "matches": [
            "computer vision"
          ],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 10,
          "venue": "ICLR",
          "weight": 0.25
        },
        "citation_potential": {
          "score": 6.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 10.0,
          "has_code": true,
          "weight": 0.1
        },
        "practicality": {
          "score": 5.5,
          "weight": 0.1
        }
      }
    },
    {
      "id": "2602.10975v1",
      "title": "FeatureBench: Benchmarking Agentic Coding for Complex Feature Development",
      "authors": [
        "Qixing Zhou",
        "Jiacheng Zhang",
        "Haiyang Wang",
        "Rui Hao",
        "Jiahe Wang",
        "Minghao Han",
        "Yuxue Yang",
        "Shuzhe Wu",
        "Feiyang Pan",
        "Lue Fan",
        "Dandan Tu",
        "Zhaoxiang Zhang"
      ],
      "abstract": "Agents powered by large language models (LLMs) are increasingly adopted in the software industry, contributing code as collaborators or even autonomous developers. As their presence grows, it becomes important to assess the current boundaries of their coding abilities. Existing agentic coding benchmarks, however, cover a limited task scope, e.g., bug fixing within a single pull request (PR), and often rely on non-executable evaluations or lack an automated approach for continually updating the evaluation coverage. To address such issues, we propose FeatureBench, a benchmark designed to evaluate agentic coding performance in end-to-end, feature-oriented software development. FeatureBench incorporates an execution-based evaluation protocol and a scalable test-driven method that automatically derives tasks from code repositories with minimal human effort. By tracing from unit tests along a dependency graph, our approach can identify feature-level coding tasks spanning multiple commits and PRs scattered across the development timeline, while ensuring the proper functioning of other features after the separation. Using this framework, we curated 200 challenging evaluation tasks and 3825 executable environments from 24 open-source repositories in the first version of our benchmark. Empirical evaluation reveals that the state-of-the-art agentic model, such as Claude 4.5 Opus, which achieves a 74.4% resolved rate on SWE-bench, succeeds on only 11.0% of tasks, opening new opportunities for advancing agentic coding. Moreover, benefiting from our automated task collection toolkit, FeatureBench can be easily scaled and updated over time to mitigate data leakage. The inherent verifiability of constructed environments also makes our method potentially valuable for agent training.",
      "published": "2026-02-11",
      "updated": "2026-02-11",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "links": {
        "paper": "http://arxiv.org/abs/2602.10975v1",
        "pdf": "https://arxiv.org/pdf/2602.10975v1"
      },
      "arxiv_id": "2602.10975v1",
      "comment": "Accepted by ICLR 2026",
      "journal_ref": "",
      "has_code": false,
      "relevance_score": 4.85,
      "score_breakdown": {
        "total_score": 4.85,
        "field_match": {
          "score": 0.0,
          "matches": [],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 10,
          "venue": "ICLR",
          "weight": 0.25
        },
        "citation_potential": {
          "score": 10.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 3.0,
          "has_code": false,
          "weight": 0.1
        },
        "practicality": {
          "score": 5.5,
          "weight": 0.1
        }
      }
    },
    {
      "id": "2602.11005v1",
      "title": "Interpretable Vision Transformers in Monocular Depth Estimation via SVDA",
      "authors": [
        "Vasileios Arampatzakis",
        "George Pavlidis",
        "Nikolaos Mitianoudis",
        "Nikos Papamarkos"
      ],
      "abstract": "Monocular depth estimation is a central problem in computer vision with applications in robotics, AR, and autonomous driving, yet the self-attention mechanisms that drive modern Transformer architectures remain opaque. We introduce SVD-Inspired Attention (SVDA) into the Dense Prediction Transformer (DPT), providing the first spectrally structured formulation of attention for dense prediction tasks. SVDA decouples directional alignment from spectral modulation by embedding a learnable diagonal matrix into normalized query-key interactions, enabling attention maps that are intrinsically interpretable rather than post-hoc approximations. Experiments on KITTI and NYU-v2 show that SVDA preserves or slightly improves predictive accuracy while adding only minor computational overhead. More importantly, SVDA unlocks six spectral indicators that quantify entropy, rank, sparsity, alignment, selectivity, and robustness. These reveal consistent cross-dataset and depth-wise patterns in how attention organizes during training, insights that remain inaccessible in standard Transformers. By shifting the role of attention from opaque mechanism to quantifiable descriptor, SVDA redefines interpretability in monocular depth estimation and opens a principled avenue toward transparent dense prediction models.",
      "published": "2026-02-11",
      "updated": "2026-02-11",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.11005v1",
        "pdf": "https://arxiv.org/pdf/2602.11005v1"
      },
      "arxiv_id": "2602.11005v1",
      "comment": "8 pages, 2 figures, submitted to CVPR Conference 2026",
      "journal_ref": "",
      "has_code": false,
      "relevance_score": 4.469491525423729,
      "score_breakdown": {
        "total_score": 4.47,
        "field_match": {
          "score": 0.42,
          "matches": [
            "computer vision"
          ],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 10,
          "venue": "CVPR",
          "weight": 0.25
        },
        "citation_potential": {
          "score": 6.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 3.0,
          "has_code": false,
          "weight": 0.1
        },
        "practicality": {
          "score": 6.0,
          "weight": 0.1
        }
      }
    },
    {
      "id": "2602.11057v1",
      "title": "Divide, Harmonize, Then Conquer It: Shooting Multi-Commodity Flow Problems with Multimodal Language Models",
      "authors": [
        "Xinyu Yuan",
        "Yan Qiao",
        "Zonghui Wang",
        "Wenzhi Chen"
      ],
      "abstract": "The multi-commodity flow (MCF) problem is a fundamental topic in network flow and combinatorial optimization, with broad applications in transportation, communication, and logistics, etc. Nowadays, the rapid expansion of allocation systems has posed challenges for existing optimization engines in balancing optimality and tractability. In this paper, we present Pram, the first ML-based method that leverages the reasoning power of multimodal language models (MLMs) for addressing the trade-off dilemma -- a great need of service providers. As part of our proposal, Pram (i) quickly computes high-quality allocations by dividing the original problem into local subproblems, which are then resolved by an MLM-powered \"agent\", and (ii) ensures global consistency by harmonizing these subproblems via a multi-agent reinforcement learning algorithm. Theoretically, we show that Pram, which learns to perform gradient descent in context, provably converges to the optimum within the family of MCF problems. Empirically, on real-world datasets and public topologies, Pram achieves performance comparable to, and in some cases even surpassing, linear programming solvers (very close to the optimal solution), and substantially lower runtimes (1 to 2 orders of magnitude faster). Moreover, Pram exhibits strong robustness (<10\\% performance degradation under link failures or flow bursts), demonstrating MLM's generalization ability to unforeseen events. Pram is objective-agnostic and seamlessly integrates with mainstream allocation systems, providing a practical and scalable solution for future networks.",
      "published": "2026-02-11",
      "updated": "2026-02-11",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.11057v1",
        "pdf": "https://arxiv.org/pdf/2602.11057v1"
      },
      "arxiv_id": "2602.11057v1",
      "comment": "Published as a conference paper at ICLR 2026",
      "journal_ref": "",
      "has_code": false,
      "relevance_score": 4.4,
      "score_breakdown": {
        "total_score": 4.4,
        "field_match": {
          "score": 0.0,
          "matches": [],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 10,
          "venue": "ICLR",
          "weight": 0.25
        },
        "citation_potential": {
          "score": 6.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 3.0,
          "has_code": false,
          "weight": 0.1
        },
        "practicality": {
          "score": 7.0,
          "weight": 0.1
        }
      }
    },
    {
      "id": "2602.10884v1",
      "title": "ResWorld: Temporal Residual World Model for End-to-End Autonomous Driving",
      "authors": [
        "Jinqing Zhang",
        "Zehua Fu",
        "Zelin Xu",
        "Wenying Dai",
        "Qingjie Liu",
        "Yunhong Wang"
      ],
      "abstract": "The comprehensive understanding capabilities of world models for driving scenarios have significantly improved the planning accuracy of end-to-end autonomous driving frameworks. However, the redundant modeling of static regions and the lack of deep interaction with trajectories hinder world models from exerting their full effectiveness. In this paper, we propose Temporal Residual World Model (TR-World), which focuses on dynamic object modeling. By calculating the temporal residuals of scene representations, the information of dynamic objects can be extracted without relying on detection and tracking. TR-World takes only temporal residuals as input, thus predicting the future spatial distribution of dynamic objects more precisely. By combining the prediction with the static object information contained in the current BEV features, accurate future BEV features can be obtained. Furthermore, we propose Future-Guided Trajectory Refinement (FGTR) module, which conducts interaction between prior trajectories (predicted from the current scene representation) and the future BEV features. This module can not only utilize future road conditions to refine trajectories, but also provides sparse spatial-temporal supervision on future BEV features to prevent world model collapse. Comprehensive experiments conducted on the nuScenes and NAVSIM datasets demonstrate that our method, namely ResWorld, achieves state-of-the-art planning performance. The code is available at https://github.com/mengtan00/ResWorld.git.",
      "published": "2026-02-11",
      "updated": "2026-02-11",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.10884v1",
        "pdf": "https://arxiv.org/pdf/2602.10884v1"
      },
      "arxiv_id": "2602.10884v1",
      "comment": "ICLR 2026",
      "journal_ref": "",
      "has_code": false,
      "relevance_score": 4.3999999999999995,
      "score_breakdown": {
        "total_score": 4.4,
        "field_match": {
          "score": 0.0,
          "matches": [],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 10,
          "venue": "ICLR",
          "weight": 0.25
        },
        "citation_potential": {
          "score": 7.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 3.0,
          "has_code": false,
          "weight": 0.1
        },
        "practicality": {
          "score": 5.5,
          "weight": 0.1
        }
      }
    },
    {
      "id": "2602.11105v1",
      "title": "FastFlow: Accelerating The Generative Flow Matching Models with Bandit Inference",
      "authors": [
        "Divya Jyoti Bajpai",
        "Dhruv Bhardwaj",
        "Soumya Roy",
        "Tejas Duseja",
        "Harsh Agarwal",
        "Aashay Sandansing",
        "Manjesh Kumar Hanawal"
      ],
      "abstract": "Flow-matching models deliver state-of-the-art fidelity in image and video generation, but the inherent sequential denoising process renders them slower. Existing acceleration methods like distillation, trajectory truncation, and consistency approaches are static, require retraining, and often fail to generalize across tasks. We propose FastFlow, a plug-and-play adaptive inference framework that accelerates generation in flow matching models. FastFlow identifies denoising steps that produce only minor adjustments to the denoising path and approximates them without using the full neural network models used for velocity predictions. The approximation utilizes finite-difference velocity estimates from prior predictions to efficiently extrapolate future states, enabling faster advancements along the denoising path at zero compute cost. This enables skipping computation at intermediary steps. We model the decision of how many steps to safely skip before requiring a full model computation as a multi-armed bandit problem. The bandit learns the optimal skips to balance speed with performance. FastFlow integrates seamlessly with existing pipelines and generalizes across image generation, video generation, and editing tasks. Experiments demonstrate a speedup of over 2.6x while maintaining high-quality outputs. The source code for this work can be found at https://github.com/Div290/FastFlow.",
      "published": "2026-02-11",
      "updated": "2026-02-11",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.11105v1",
        "pdf": "https://arxiv.org/pdf/2602.11105v1"
      },
      "arxiv_id": "2602.11105v1",
      "comment": "Accepted at International Conference on Learning Representations (ICLR) 2026",
      "journal_ref": "",
      "has_code": false,
      "relevance_score": 4.35,
      "score_breakdown": {
        "total_score": 4.35,
        "field_match": {
          "score": 0.0,
          "matches": [],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 10,
          "venue": "ICLR",
          "weight": 0.25
        },
        "citation_potential": {
          "score": 7.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 3.0,
          "has_code": false,
          "weight": 0.1
        },
        "practicality": {
          "score": 5.0,
          "weight": 0.1
        }
      }
    },
    {
      "id": "2602.10911v1",
      "title": "Tuning the burn-in phase in training recurrent neural networks improves their performance",
      "authors": [
        "Julian D. Schiller",
        "Malte Heinrich",
        "Victor G. Lopez",
        "Matthias A. MÃ¼ller"
      ],
      "abstract": "Training recurrent neural networks (RNNs) with standard backpropagation through time (BPTT) can be challenging, especially in the presence of long input sequences. A practical alternative to reduce computational and memory overhead is to perform BPTT repeatedly over shorter segments of the training data set, corresponding to truncated BPTT. In this paper, we examine the training of RNNs when using such a truncated learning approach for time series tasks. Specifically, we establish theoretical bounds on the accuracy and performance loss when optimizing over subsequences instead of the full data sequence. This reveals that the burn-in phase of the RNN is an important tuning knob in its training, with significant impact on the performance guarantees. We validate our theoretical results through experiments on standard benchmarks from the fields of system identification and time series forecasting. In all experiments, we observe a strong influence of the burn-in phase on the training process, and proper tuning can lead to a reduction of the prediction error on the training and test data of more than 60% in some cases.",
      "published": "2026-02-11",
      "updated": "2026-02-11",
      "categories": [
        "cs.LG",
        "eess.SY",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.10911v1",
        "pdf": "https://arxiv.org/pdf/2602.10911v1"
      },
      "arxiv_id": "2602.10911v1",
      "comment": "Published as a conference paper at ICLR 2026, https://openreview.net/forum?id=jwkdKpioHJ",
      "journal_ref": "",
      "has_code": false,
      "relevance_score": 4.300000000000001,
      "score_breakdown": {
        "total_score": 4.3,
        "field_match": {
          "score": 0.0,
          "matches": [],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 10,
          "venue": "ICLR",
          "weight": 0.25
        },
        "citation_potential": {
          "score": 6.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 3.0,
          "has_code": false,
          "weight": 0.1
        },
        "practicality": {
          "score": 6.0,
          "weight": 0.1
        }
      }
    },
    {
      "id": "2602.10908v1",
      "title": "SoftMatcha 2: A Fast and Soft Pattern Matcher for Trillion-Scale Corpora",
      "authors": [
        "Masataka Yoneda",
        "Yusuke Matsushita",
        "Go Kamoda",
        "Kohei Suenaga",
        "Takuya Akiba",
        "Masaki Waga",
        "Sho Yokoi"
      ],
      "abstract": "We present an ultra-fast and flexible search algorithm that enables search over trillion-scale natural language corpora in under 0.3 seconds while handling semantic variations (substitution, insertion, and deletion). Our approach employs string matching based on suffix arrays that scales well with corpus size. To mitigate the combinatorial explosion induced by the semantic relaxation of queries, our method is built on two key algorithmic ideas: fast exact lookup enabled by a disk-aware design, and dynamic corpus-aware pruning. We theoretically show that the proposed method suppresses exponential growth in the search space with respect to query length by leveraging statistical properties of natural language. In experiments on FineWeb-Edu (Lozhkov et al., 2024) (1.4T tokens), we show that our method achieves significantly lower search latency than existing methods: infini-gram (Liu et al., 2024), infini-gram mini (Xu et al., 2025), and SoftMatcha (Deguchi et al., 2025). As a practical application, we demonstrate that our method identifies benchmark contamination in training corpora, unidentified by existing approaches. We also provide an online demo of fast, soft search across corpora in seven languages.",
      "published": "2026-02-11",
      "updated": "2026-02-11",
      "categories": [
        "cs.CL",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2602.10908v1",
        "pdf": "https://arxiv.org/pdf/2602.10908v1"
      },
      "arxiv_id": "2602.10908v1",
      "comment": "Project Page & Web Interface: https://softmatcha.github.io/v2/, Source Code: https://github.com/softmatcha/softmatcha2",
      "journal_ref": "",
      "has_code": true,
      "relevance_score": 4.1000000000000005,
      "score_breakdown": {
        "total_score": 4.1,
        "field_match": {
          "score": 0.0,
          "matches": [],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 5.0,
          "venue": null,
          "weight": 0.25
        },
        "citation_potential": {
          "score": 8.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 10.0,
          "has_code": true,
          "weight": 0.1
        },
        "practicality": {
          "score": 6.5,
          "weight": 0.1
        }
      }
    },
    {
      "id": "2602.11146v1",
      "title": "Beyond VLM-Based Rewards: Diffusion-Native Latent Reward Modeling",
      "authors": [
        "Gongye Liu",
        "Bo Yang",
        "Yida Zhi",
        "Zhizhou Zhong",
        "Lei Ke",
        "Didan Deng",
        "Han Gao",
        "Yongxiang Huang",
        "Kaihao Zhang",
        "Hongbo Fu",
        "Wenhan Luo"
      ],
      "abstract": "Preference optimization for diffusion and flow-matching models relies on reward functions that are both discriminatively robust and computationally efficient. Vision-Language Models (VLMs) have emerged as the primary reward provider, leveraging their rich multimodal priors to guide alignment. However, their computation and memory cost can be substantial, and optimizing a latent diffusion generator through a pixel-space reward introduces a domain mismatch that complicates alignment. In this paper, we propose DiNa-LRM, a diffusion-native latent reward model that formulates preference learning directly on noisy diffusion states. Our method introduces a noise-calibrated Thurstone likelihood with diffusion-noise-dependent uncertainty. DiNa-LRM leverages a pretrained latent diffusion backbone with a timestep-conditioned reward head, and supports inference-time noise ensembling, providing a diffusion-native mechanism for test-time scaling and robust rewarding. Across image alignment benchmarks, DiNa-LRM substantially outperforms existing diffusion-based reward baselines and achieves performance competitive with state-of-the-art VLMs at a fraction of the computational cost. In preference optimization, we demonstrate that DiNa-LRM improves preference optimization dynamics, enabling faster and more resource-efficient model alignment.",
      "published": "2026-02-11",
      "updated": "2026-02-11",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.11146v1",
        "pdf": "https://arxiv.org/pdf/2602.11146v1"
      },
      "arxiv_id": "2602.11146v1",
      "comment": "Code: https://github.com/HKUST-C4G/diffusion-rm",
      "journal_ref": "",
      "has_code": true,
      "relevance_score": 4.0,
      "score_breakdown": {
        "total_score": 4.0,
        "field_match": {
          "score": 0.0,
          "matches": [],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 5.0,
          "venue": null,
          "weight": 0.25
        },
        "citation_potential": {
          "score": 8.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 10.0,
          "has_code": true,
          "weight": 0.1
        },
        "practicality": {
          "score": 5.5,
          "weight": 0.1
        }
      }
    },
    {
      "id": "2602.11117v1",
      "title": "HairWeaver: Few-Shot Photorealistic Hair Motion Synthesis with Sim-to-Real Guided Video Diffusion",
      "authors": [
        "Di Chang",
        "Ji Hou",
        "Aljaz Bozic",
        "Assaf Neuberger",
        "Felix Juefei-Xu",
        "Olivier Maury",
        "Gene Wei-Chin Lin",
        "Tuur Stuyck",
        "Doug Roble",
        "Mohammad Soleymani",
        "Stephane Grabli"
      ],
      "abstract": "We present HairWeaver, a diffusion-based pipeline that animates a single human image with realistic and expressive hair dynamics. While existing methods successfully control body pose, they lack specific control over hair, and as a result, fail to capture the intricate hair motions, resulting in stiff and unrealistic animations. HairWeaver overcomes this limitation using two specialized modules: a Motion-Context-LoRA to integrate motion conditions and a Sim2Real-Domain-LoRA to preserve the subject's photoreal appearance across different data domains. These lightweight components are designed to guide a video diffusion backbone while maintaining its core generative capabilities. By training on a specialized dataset of dynamic human motion generated from a CG simulator, HairWeaver affords fine control over hair motion and ultimately learns to produce highly realistic hair that responds naturally to movement. Comprehensive evaluations demonstrate that our approach sets a new state of the art, producing lifelike human hair animations with dynamic details.",
      "published": "2026-02-11",
      "updated": "2026-02-11",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.11117v1",
        "pdf": "https://arxiv.org/pdf/2602.11117v1"
      },
      "arxiv_id": "2602.11117v1",
      "comment": "Website: https://boese0601.github.io/hairweaver/",
      "journal_ref": "",
      "has_code": true,
      "relevance_score": 4.0,
      "score_breakdown": {
        "total_score": 4.0,
        "field_match": {
          "score": 0.0,
          "matches": [],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 5.0,
          "venue": null,
          "weight": 0.25
        },
        "citation_potential": {
          "score": 8.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 10.0,
          "has_code": true,
          "weight": 0.1
        },
        "practicality": {
          "score": 5.5,
          "weight": 0.1
        }
      }
    }
  ]
}