{
  "filtered_at": "{\"timestamp\": \"now\"}",
  "total_papers": 10,
  "papers": [
    {
      "id": "2601.20857v1",
      "title": "FreeFix: Boosting 3D Gaussian Splatting via Fine-Tuning-Free Diffusion Models",
      "authors": [
        "Hongyu Zhou",
        "Zisen Shao",
        "Sheng Miao",
        "Pan Wang",
        "Dongfeng Bai",
        "Bingbing Liu",
        "Yiyi Liao"
      ],
      "abstract": "Neural Radiance Fields and 3D Gaussian Splatting have advanced novel view synthesis, yet still rely on dense inputs and often degrade at extrapolated views. Recent approaches leverage generative models, such as diffusion models, to provide additional supervision, but face a trade-off between generalization and fidelity: fine-tuning diffusion models for artifact removal improves fidelity but risks overfitting, while fine-tuning-free methods preserve generalization but often yield lower fidelity. We introduce FreeFix, a fine-tuning-free approach that pushes the boundary of this trade-off by enhancing extrapolated rendering with pretrained image diffusion models. We present an interleaved 2D-3D refinement strategy, showing that image diffusion models can be leveraged for consistent refinement without relying on costly video diffusion models. Furthermore, we take a closer look at the guidance signal for 2D refinement and propose a per-pixel confidence mask to identify uncertain regions for targeted improvement. Experiments across multiple datasets show that FreeFix improves multi-frame consistency and achieves performance comparable to or surpassing fine-tuning-based methods, while retaining strong generalization ability.",
      "published": "2026-01-28",
      "updated": "2026-01-28",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.20857v1",
        "pdf": "https://arxiv.org/pdf/2601.20857v1"
      },
      "arxiv_id": "2601.20857v1",
      "comment": "Our project page is at https://xdimlab.github.io/freefix",
      "journal_ref": "",
      "has_code": true,
      "relevance_score": 4.7652542372881355,
      "score_breakdown": {
        "total_score": 4.77,
        "field_match": {
          "score": 2.29,
          "matches": [
            "3d gaussian",
            "gaussian splatting",
            "neural radiance"
          ],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 5.0,
          "venue": null,
          "weight": 0.25
        },
        "citation_potential": {
          "score": 7.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 10.0,
          "has_code": true,
          "weight": 0.1
        },
        "practicality": {
          "score": 5.5,
          "weight": 0.1
        }
      },
      "ai_summaries": {
        "short": "Neural Radiance Fields and 3D Gaussian Splatting have advanced novel view synthesis, yet still rely on dense inputs and often degrade at extrapolated views. Recent approaches leverage generative models, such as diffusion models, to provide additional supervision, but face a trade-off between generalization and fidelity: fine-tuning diffusion models for artifact removal improves fidelity but risks ...",
        "key_contributions": [
          "Neural Radiance Fields and 3D Gaussian Splatting have advanced novel view synthesis, yet still rely on dense inputs and often degrade at extrapolated views.",
          "Recent approaches leverage generative models, such as diffusion models, to provide additional supervision, but face a trade-off between generalization and fidelity: fine-tuning diffusion models for artifact removal improves fidelity but risks overfitting, while fine-tuning-free methods preserve generalization but often yield lower fidelity.",
          "We introduce FreeFix, a fine-tuning-free approach that pushes the boundary of this trade-off by enhancing extrapolated rendering with pretrained image diffusion models."
        ],
        "provider": "gemini",
        "audio_url": "/audio/2601.20857v1.mp3"
      }
    },
    {
      "id": "2601.20775v1",
      "title": "Active Learning for Decision Trees with Provable Guarantees",
      "authors": [
        "Arshia Soltani Moakhar",
        "Tanapoom Laoaron",
        "Faraz Ghahremani",
        "Kiarash Banihashem",
        "MohammadTaghi Hajiaghayi"
      ],
      "abstract": "This paper advances the theoretical understanding of active learning label complexity for decision trees as binary classifiers. We make two main contributions. First, we provide the first analysis of the disagreement coefficient for decision trees-a key parameter governing active learning label complexity. Our analysis holds under two natural assumptions required for achieving polylogarithmic label complexity, (i) each root-to-leaf path queries distinct feature dimensions, and (ii) the input data has a regular, grid-like structure. We show these assumptions are essential, as relaxing them leads to polynomial label complexity. Second, we present the first general active learning algorithm for binary classification that achieves a multiplicative error guarantee, producing a $(1+ε)$-approximate classifier. By combining these results, we design an active learning algorithm for decision trees that uses only a polylogarithmic number of label queries in the dataset size, under the stated assumptions. Finally, we establish a label complexity lower bound, showing our algorithm's dependence on the error tolerance $ε$ is close to optimal.",
      "published": "2026-01-28",
      "updated": "2026-01-28",
      "categories": [
        "cs.LG",
        "cs.CC",
        "cs.DS"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.20775v1",
        "pdf": "https://arxiv.org/pdf/2601.20775v1"
      },
      "arxiv_id": "2601.20775v1",
      "comment": "10 pages, 43 pages with appendix, ICLR 2026, Conference URL: https://openreview.net/forum?id=NOkjJPJIit",
      "journal_ref": "",
      "has_code": false,
      "relevance_score": 4.3999999999999995,
      "score_breakdown": {
        "total_score": 4.4,
        "field_match": {
          "score": 0.0,
          "matches": [],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 10,
          "venue": "ICLR",
          "weight": 0.25
        },
        "citation_potential": {
          "score": 7.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 3.0,
          "has_code": false,
          "weight": 0.1
        },
        "practicality": {
          "score": 5.5,
          "weight": 0.1
        }
      },
      "ai_summaries": {
        "short": "This paper advances the theoretical understanding of active learning label complexity for decision trees as binary classifiers. We make two main contributions. First, we provide the first analysis of the disagreement coefficient for decision trees-a key parameter governing active learning label complexity. Our analysis holds under two natural assumptions required for achieving polylogarithmic labe...",
        "key_contributions": [
          "This paper advances the theoretical understanding of active learning label complexity for decision trees as binary classifiers.",
          "We make two main contributions.",
          "First, we provide the first analysis of the disagreement coefficient for decision trees-a key parameter governing active learning label complexity."
        ],
        "provider": "gemini",
        "audio_url": "/audio/2601.20775v1.mp3"
      }
    },
    {
      "id": "2601.20694v1",
      "title": "Is Pure Exploitation Sufficient in Exogenous MDPs with Linear Function Approximation?",
      "authors": [
        "Hao Liang",
        "Jiayu Cheng",
        "Sean R. Sinclair",
        "Yali Du"
      ],
      "abstract": "Exogenous MDPs (Exo-MDPs) capture sequential decision-making where uncertainty comes solely from exogenous inputs that evolve independently of the learner's actions. This structure is especially common in operations research applications such as inventory control, energy storage, and resource allocation, where exogenous randomness (e.g., demand, arrivals, or prices) drives system behavior. Despite decades of empirical evidence that greedy, exploitation-only methods work remarkably well in these settings, theory has lagged behind: all existing regret guarantees for Exo-MDPs rely on explicit exploration or tabular assumptions. We show that exploration is unnecessary. We propose Pure Exploitation Learning (PEL) and prove the first general finite-sample regret bounds for exploitation-only algorithms in Exo-MDPs. In the tabular case, PEL achieves $\\widetilde{O}(H^2|Ξ|\\sqrt{K})$. For large, continuous endogenous state spaces, we introduce LSVI-PE, a simple linear-approximation method whose regret is polynomial in the feature dimension, exogenous state space, and horizon, independent of the endogenous state and action spaces. Our analysis introduces two new tools: counterfactual trajectories and Bellman-closed feature transport, which together allow greedy policies to have accurate value estimates without optimism. Experiments on synthetic and resource-management tasks show that PEL consistently outperforming baselines. Overall, our results overturn the conventional wisdom that exploration is required, demonstrating that in Exo-MDPs, pure exploitation is enough.",
      "published": "2026-01-28",
      "updated": "2026-01-28",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.20694v1",
        "pdf": "https://arxiv.org/pdf/2601.20694v1"
      },
      "arxiv_id": "2601.20694v1",
      "comment": "Accepted to ICLR 2026",
      "journal_ref": "",
      "has_code": false,
      "relevance_score": 4.3999999999999995,
      "score_breakdown": {
        "total_score": 4.4,
        "field_match": {
          "score": 0.0,
          "matches": [],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 10,
          "venue": "ICLR",
          "weight": 0.25
        },
        "citation_potential": {
          "score": 7.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 3.0,
          "has_code": false,
          "weight": 0.1
        },
        "practicality": {
          "score": 5.5,
          "weight": 0.1
        }
      },
      "ai_summaries": {
        "short": "Exogenous MDPs (Exo-MDPs) capture sequential decision-making where uncertainty comes solely from exogenous inputs that evolve independently of the learner's actions. This structure is especially common in operations research applications such as inventory control, energy storage, and resource allocation, where exogenous randomness (e.g., demand, arrivals, or prices) drives system behavior. Despite...",
        "key_contributions": [
          "Exogenous MDPs (Exo-MDPs) capture sequential decision-making where uncertainty comes solely from exogenous inputs that evolve independently of the learner's actions.",
          "This structure is especially common in operations research applications such as inventory control, energy storage, and resource allocation, where exogenous randomness (e.",
          "g."
        ],
        "provider": "gemini",
        "audio_url": "/audio/2601.20694v1.mp3"
      }
    },
    {
      "id": "2601.20614v1",
      "title": "Harder Is Better: Boosting Mathematical Reasoning via Difficulty-Aware GRPO and Multi-Aspect Question Reformulation",
      "authors": [
        "Yanqi Dai",
        "Yuxiang Ji",
        "Xiao Zhang",
        "Yong Wang",
        "Xiangxiang Chu",
        "Zhiwu Lu"
      ],
      "abstract": "Reinforcement Learning with Verifiable Rewards (RLVR) offers a robust mechanism for enhancing mathematical reasoning in large models. However, we identify a systematic lack of emphasis on more challenging questions in existing methods from both algorithmic and data perspectives, despite their importance for refining underdeveloped capabilities. Algorithmically, widely used Group Relative Policy Optimization (GRPO) suffers from an implicit imbalance where the magnitude of policy updates is lower for harder questions. Data-wise, augmentation approaches primarily rephrase questions to enhance diversity without systematically increasing intrinsic difficulty. To address these issues, we propose a two-dual MathForge framework to improve mathematical reasoning by targeting harder questions from both perspectives, which comprises a Difficulty-Aware Group Policy Optimization (DGPO) algorithm and a Multi-Aspect Question Reformulation (MQR) strategy. Specifically, DGPO first rectifies the implicit imbalance in GRPO via difficulty-balanced group advantage estimation, and further prioritizes harder questions by difficulty-aware question-level weighting. Meanwhile, MQR reformulates questions across multiple aspects to increase difficulty while maintaining the original gold answer. Overall, MathForge forms a synergistic loop: MQR expands the data frontier, and DGPO effectively learns from the augmented data. Extensive experiments show that MathForge significantly outperforms existing methods on various mathematical reasoning tasks. The code and augmented data are all available at https://github.com/AMAP-ML/MathForge.",
      "published": "2026-01-28",
      "updated": "2026-01-28",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.20614v1",
        "pdf": "https://arxiv.org/pdf/2601.20614v1"
      },
      "arxiv_id": "2601.20614v1",
      "comment": "Accepted for ICLR 2026",
      "journal_ref": "",
      "has_code": false,
      "relevance_score": 4.35,
      "score_breakdown": {
        "total_score": 4.35,
        "field_match": {
          "score": 0.0,
          "matches": [],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 10,
          "venue": "ICLR",
          "weight": 0.25
        },
        "citation_potential": {
          "score": 7.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 3.0,
          "has_code": false,
          "weight": 0.1
        },
        "practicality": {
          "score": 5.0,
          "weight": 0.1
        }
      },
      "ai_summaries": {
        "short": "Reinforcement Learning with Verifiable Rewards (RLVR) offers a robust mechanism for enhancing mathematical reasoning in large models. However, we identify a systematic lack of emphasis on more challenging questions in existing methods from both algorithmic and data perspectives, despite their importance for refining underdeveloped capabilities. Algorithmically, widely used Group Relative Policy Op...",
        "key_contributions": [
          "Reinforcement Learning with Verifiable Rewards (RLVR) offers a robust mechanism for enhancing mathematical reasoning in large models.",
          "However, we identify a systematic lack of emphasis on more challenging questions in existing methods from both algorithmic and data perspectives, despite their importance for refining underdeveloped capabilities.",
          "Algorithmically, widely used Group Relative Policy Optimization (GRPO) suffers from an implicit imbalance where the magnitude of policy updates is lower for harder questions."
        ],
        "provider": "gemini",
        "audio_url": "/audio/2601.20614v1.mp3"
      }
    },
    {
      "id": "2601.20520v1",
      "title": "Context Tokens are Anchors: Understanding the Repetition Curse in dMLLMs from an Information Flow Perspective",
      "authors": [
        "Qiyan Zhao",
        "Xiaofeng Zhang",
        "Shuochen Chang",
        "Qianyu Chen",
        "Xiaosong Yuan",
        "Xuhang Chen",
        "Luoqi Liu",
        "Jiajun Zhang",
        "Xu-Yao Zhang",
        "Da-Han Wang"
      ],
      "abstract": "Recent diffusion-based Multimodal Large Language Models (dMLLMs) suffer from high inference latency and therefore rely on caching techniques to accelerate decoding. However, the application of cache mechanisms often introduces undesirable repetitive text generation, a phenomenon we term the \\textbf{Repeat Curse}. To better investigate underlying mechanism behind this issue, we analyze repetition generation through the lens of information flow. Our work reveals three key findings: (1) context tokens aggregate semantic information as anchors and guide the final predictions; (2) as information propagates across layers, the entropy of context tokens converges in deeper layers, reflecting the model's growing prediction certainty; (3) Repetition is typically linked to disruptions in the information flow of context tokens and to the inability of their entropy to converge in deeper layers. Based on these insights, we present \\textbf{CoTA}, a plug-and-play method for mitigating repetition. CoTA enhances the attention of context tokens to preserve intrinsic information flow patterns, while introducing a penalty term to the confidence score during decoding to avoid outputs driven by uncertain context tokens. With extensive experiments, CoTA demonstrates significant effectiveness in alleviating repetition and achieves consistent performance improvements on general tasks. Code is available at https://github.com/ErikZ719/CoTA",
      "published": "2026-01-28",
      "updated": "2026-01-28",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.20520v1",
        "pdf": "https://arxiv.org/pdf/2601.20520v1"
      },
      "arxiv_id": "2601.20520v1",
      "comment": "Accepted in ICLR 2026",
      "journal_ref": "",
      "has_code": false,
      "relevance_score": 4.25,
      "score_breakdown": {
        "total_score": 4.25,
        "field_match": {
          "score": 0.0,
          "matches": [],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 10,
          "venue": "ICLR",
          "weight": 0.25
        },
        "citation_potential": {
          "score": 6.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 3.0,
          "has_code": false,
          "weight": 0.1
        },
        "practicality": {
          "score": 5.5,
          "weight": 0.1
        }
      },
      "ai_summaries": {
        "short": "Recent diffusion-based Multimodal Large Language Models (dMLLMs) suffer from high inference latency and therefore rely on caching techniques to accelerate decoding. However, the application of cache mechanisms often introduces undesirable repetitive text generation, a phenomenon we term the \\textbf{Repeat Curse}. To better investigate underlying mechanism behind this issue, we analyze repetition g...",
        "key_contributions": [
          "Recent diffusion-based Multimodal Large Language Models (dMLLMs) suffer from high inference latency and therefore rely on caching techniques to accelerate decoding.",
          "However, the application of cache mechanisms often introduces undesirable repetitive text generation, a phenomenon we term the \\textbf{Repeat Curse}.",
          "To better investigate underlying mechanism behind this issue, we analyze repetition generation through the lens of information flow."
        ],
        "provider": "gemini",
        "audio_url": "/audio/2601.20520v1.mp3"
      }
    },
    {
      "id": "2601.20704v1",
      "title": "Structurally Human, Semantically Biased: Detecting LLM-Generated References with Embeddings and GNNs",
      "authors": [
        "Melika Mobini",
        "Vincent Holst",
        "Floriano Tori",
        "Andres Algaba",
        "Vincent Ginis"
      ],
      "abstract": "Large language models are increasingly used to curate bibliographies, raising the question: are their reference lists distinguishable from human ones? We build paired citation graphs, ground truth and GPT-4o-generated (from parametric knowledge), for 10,000 focal papers ($\\approx$ 275k references) from SciSciNet, and added a field-matched random baseline that preserves out-degree and field distributions while breaking latent structure. We compare (i) structure-only node features (degree/closeness/eigenvector centrality, clustering, edge count) with (ii) 3072-D title/abstract embeddings, using an RF on graph-level aggregates and Graph Neural Networks with node features. Structure alone barely separates GPT from ground truth (RF accuracy $\\approx$ 0.60) despite cleanly rejecting the random baseline ($\\approx$ 0.89--0.92). By contrast, embeddings sharply increase separability: RF on aggregated embeddings reaches $\\approx$ 0.83, and GNNs with embedding node features achieve 93\\% test accuracy on GPT vs.\\ ground truth. We show the robustness of our findings by replicating the pipeline with Claude Sonnet 4.5 and with multiple embedding models (OpenAI and SPECTER), with RF separability for ground truth vs.\\ Claude $\\approx 0.77$ and clean rejection of the random baseline. Thus, LLM bibliographies, generated purely from parametric knowledge, closely mimic human citation topology, but leave detectable semantic fingerprints; detection and debiasing should target content signals rather than global graph structure.",
      "published": "2026-01-28",
      "updated": "2026-01-28",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.20704v1",
        "pdf": "https://arxiv.org/pdf/2601.20704v1"
      },
      "arxiv_id": "2601.20704v1",
      "comment": "34 pages, 20 figures. Accepted at ICLR 2026",
      "journal_ref": "",
      "has_code": false,
      "relevance_score": 4.2,
      "score_breakdown": {
        "total_score": 4.2,
        "field_match": {
          "score": 0.0,
          "matches": [],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 10,
          "venue": "ICLR",
          "weight": 0.25
        },
        "citation_potential": {
          "score": 6.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 3.0,
          "has_code": false,
          "weight": 0.1
        },
        "practicality": {
          "score": 5.0,
          "weight": 0.1
        }
      },
      "ai_summaries": {
        "short": "Large language models are increasingly used to curate bibliographies, raising the question: are their reference lists distinguishable from human ones? We build paired citation graphs, ground truth and GPT-4o-generated (from parametric knowledge), for 10,000 focal papers ($\\approx$ 275k references) from SciSciNet, and added a field-matched random baseline that preserves out-degree and field distrib...",
        "key_contributions": [
          "Large language models are increasingly used to curate bibliographies, raising the question: are their reference lists distinguishable from human ones? We build paired citation graphs, ground truth and GPT-4o-generated (from parametric knowledge), for 10,000 focal papers ($\\approx$ 275k references) from SciSciNet, and added a field-matched random baseline that preserves out-degree and field distributions while breaking latent structure.",
          "We compare (i) structure-only node features (degree/closeness/eigenvector centrality, clustering, edge count) with (ii) 3072-D title/abstract embeddings, using an RF on graph-level aggregates and Graph Neural Networks with node features.",
          "Structure alone barely separates GPT from ground truth (RF accuracy $\\approx$ 0."
        ],
        "provider": "gemini",
        "audio_url": "/audio/2601.20704v1.mp3"
      }
    },
    {
      "id": "2601.20650v1",
      "title": "OS-Marathon: Benchmarking Computer-Use Agents on Long-Horizon Repetitive Tasks",
      "authors": [
        "Jing Wu",
        "Daphne Barretto",
        "Yiye Chen",
        "Nicholas Gydé",
        "Yanan Jian",
        "Yuhang He",
        "Vibhav Vineet"
      ],
      "abstract": "Long-horizon, repetitive workflows are common in professional settings, such as processing expense reports from receipts and entering student grades from exam papers. These tasks are often tedious for humans since they can extend to extreme lengths proportional to the size of the data to process. However, they are ideal for Computer-Use Agents (CUAs) due to their structured, recurring sub-workflows with logic that can be systematically learned. Identifying the absence of an evaluation benchmark as a primary bottleneck, we establish OS-Marathon, comprising 242 long-horizon, repetitive tasks across 2 domains to evaluate state-of-the-art (SOTA) agents. We then introduce a cost-effective method to construct a condensed demonstration using only few-shot examples to teach agents the underlying workflow logic, enabling them to execute similar workflows effectively on larger, unseen data collections. Extensive experiments demonstrate both the inherent challenges of these tasks and the effectiveness of our proposed method. Project website: https://os-marathon.github.io/.",
      "published": "2026-01-28",
      "updated": "2026-01-28",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.20650v1",
        "pdf": "https://arxiv.org/pdf/2601.20650v1"
      },
      "arxiv_id": "2601.20650v1",
      "comment": "22 Pages, Project Page: \\url{https://os-marathon.github.io/}",
      "journal_ref": "",
      "has_code": true,
      "relevance_score": 4.1499999999999995,
      "score_breakdown": {
        "total_score": 4.15,
        "field_match": {
          "score": 0.0,
          "matches": [],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 5.0,
          "venue": null,
          "weight": 0.25
        },
        "citation_potential": {
          "score": 9.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 10.0,
          "has_code": true,
          "weight": 0.1
        },
        "practicality": {
          "score": 5.5,
          "weight": 0.1
        }
      },
      "ai_summaries": {
        "short": "Long-horizon, repetitive workflows are common in professional settings, such as processing expense reports from receipts and entering student grades from exam papers. These tasks are often tedious for humans since they can extend to extreme lengths proportional to the size of the data to process. However, they are ideal for Computer-Use Agents (CUAs) due to their structured, recurring sub-workflow...",
        "key_contributions": [
          "Long-horizon, repetitive workflows are common in professional settings, such as processing expense reports from receipts and entering student grades from exam papers.",
          "These tasks are often tedious for humans since they can extend to extreme lengths proportional to the size of the data to process.",
          "However, they are ideal for Computer-Use Agents (CUAs) due to their structured, recurring sub-workflows with logic that can be systematically learned."
        ],
        "provider": "gemini",
        "audio_url": "/audio/2601.20650v1.mp3"
      }
    },
    {
      "id": "2601.20852v1",
      "title": "C3Box: A CLIP-based Class-Incremental Learning Toolbox",
      "authors": [
        "Hao Sun",
        "Da-Wei Zhou"
      ],
      "abstract": "Traditional machine learning systems are typically designed for static data distributions, which suffer from catastrophic forgetting when learning from evolving data streams. Class-Incremental Learning (CIL) addresses this challenge by enabling learning systems to continuously learn new classes while preserving prior knowledge. With the rise of pre-trained models (PTMs) such as CLIP, leveraging their strong generalization and semantic alignment capabilities has become a promising direction in CIL. However, existing CLIP-based CIL methods are often scattered across disparate codebases, rely on inconsistent configurations, hindering fair comparisons, reproducibility, and practical adoption. Therefore, we propose C3Box (CLIP-based Class-inCremental learning toolBOX), a modular and comprehensive Python toolbox. C3Box integrates representative traditional CIL methods, ViT-based CIL methods, and state-of-the-art CLIP-based CIL methods into a unified CLIP-based framework. By inheriting the streamlined design of PyCIL, C3Box provides a JSON-based configuration and standardized execution pipeline. This design enables reproducible experimentation with low engineering overhead and makes C3Box a reliable benchmark platform for continual learning research. Designed to be user-friendly, C3Box relies only on widely used open-source libraries and supports major operating systems. The code is available at https://github.com/LAMDA-CL/C3Box.",
      "published": "2026-01-28",
      "updated": "2026-01-28",
      "categories": [
        "cs.LG",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.20852v1",
        "pdf": "https://arxiv.org/pdf/2601.20852v1"
      },
      "arxiv_id": "2601.20852v1",
      "comment": "The code is available at https://github.com/LAMDA-CL/C3Box",
      "journal_ref": "",
      "has_code": true,
      "relevance_score": 4.050000000000001,
      "score_breakdown": {
        "total_score": 4.05,
        "field_match": {
          "score": 0.0,
          "matches": [],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 5.0,
          "venue": null,
          "weight": 0.25
        },
        "citation_potential": {
          "score": 8.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 10.0,
          "has_code": true,
          "weight": 0.1
        },
        "practicality": {
          "score": 6.0,
          "weight": 0.1
        }
      },
      "ai_summaries": {
        "short": "Traditional machine learning systems are typically designed for static data distributions, which suffer from catastrophic forgetting when learning from evolving data streams. Class-Incremental Learning (CIL) addresses this challenge by enabling learning systems to continuously learn new classes while preserving prior knowledge. With the rise of pre-trained models (PTMs) such as CLIP, leveraging th...",
        "key_contributions": [
          "Traditional machine learning systems are typically designed for static data distributions, which suffer from catastrophic forgetting when learning from evolving data streams.",
          "Class-Incremental Learning (CIL) addresses this challenge by enabling learning systems to continuously learn new classes while preserving prior knowledge.",
          "With the rise of pre-trained models (PTMs) such as CLIP, leveraging their strong generalization and semantic alignment capabilities has become a promising direction in CIL."
        ],
        "provider": "gemini",
        "audio_url": "/audio/2601.20852v1.mp3"
      }
    },
    {
      "id": "2601.20642v1",
      "title": "Detecting and Mitigating Memorization in Diffusion Models through Anisotropy of the Log-Probability",
      "authors": [
        "Rohan Asthana",
        "Vasileios Belagiannis"
      ],
      "abstract": "Diffusion-based image generative models produce high-fidelity images through iterative denoising but remain vulnerable to memorization, where they unintentionally reproduce exact copies or parts of training images. Recent memorization detection methods are primarily based on the norm of score difference as indicators of memorization. We prove that such norm-based metrics are mainly effective under the assumption of isotropic log-probability distributions, which generally holds at high or medium noise levels. In contrast, analyzing the anisotropic regime reveals that memorized samples exhibit strong angular alignment between the guidance vector and unconditional scores in the low-noise setting. Through these insights, we develop a memorization detection metric by integrating isotropic norm and anisotropic alignment. Our detection metric can be computed directly on pure noise inputs via two conditional and unconditional forward passes, eliminating the need for costly denoising steps. Detection experiments on Stable Diffusion v1.4 and v2 show that our metric outperforms existing denoising-free detection methods while being at least approximately 5x faster than the previous best approach. Finally, we demonstrate the effectiveness of our approach by utilizing a mitigation strategy that adapts memorized prompts based on our developed metric.",
      "published": "2026-01-28",
      "updated": "2026-01-28",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.20642v1",
        "pdf": "https://arxiv.org/pdf/2601.20642v1"
      },
      "arxiv_id": "2601.20642v1",
      "comment": "Accepted at ICLR 2026",
      "journal_ref": "",
      "has_code": false,
      "relevance_score": 4.05,
      "score_breakdown": {
        "total_score": 4.05,
        "field_match": {
          "score": 0.0,
          "matches": [],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 10,
          "venue": "ICLR",
          "weight": 0.25
        },
        "citation_potential": {
          "score": 5.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 3.0,
          "has_code": false,
          "weight": 0.1
        },
        "practicality": {
          "score": 5.0,
          "weight": 0.1
        }
      },
      "ai_summaries": {
        "short": "Diffusion-based image generative models produce high-fidelity images through iterative denoising but remain vulnerable to memorization, where they unintentionally reproduce exact copies or parts of training images. Recent memorization detection methods are primarily based on the norm of score difference as indicators of memorization. We prove that such norm-based metrics are mainly effective under...",
        "key_contributions": [
          "Diffusion-based image generative models produce high-fidelity images through iterative denoising but remain vulnerable to memorization, where they unintentionally reproduce exact copies or parts of training images.",
          "Recent memorization detection methods are primarily based on the norm of score difference as indicators of memorization.",
          "We prove that such norm-based metrics are mainly effective under the assumption of isotropic log-probability distributions, which generally holds at high or medium noise levels."
        ],
        "provider": "gemini",
        "audio_url": "/audio/2601.20642v1.mp3"
      }
    },
    {
      "id": "2601.20843v1",
      "title": "Deep Researcher with Sequential Plan Reflection and Candidates Crossover (Deep Researcher Reflect Evolve)",
      "authors": [
        "Saurav Prateek"
      ],
      "abstract": "This paper introduces a novel Deep Researcher architecture designed to generate detailed research reports on complex PhD level topics by addressing the inherent limitations of the Parallel Scaling paradigm. Our system utilizes two key innovations: Sequential Research Plan Refinement via Reflection and a Candidates Crossover algorithm. The sequential refinement process is demonstrated as an efficient method that allows the agent to maintain a centralized Global Research Context, enabling it to look back at current progress, reason about the research plan, and intelligently make changes at runtime. This dynamic adaptation contrasts with parallel approaches, which often suffer from siloed knowledge. The Candidates Crossover algorithm further enhances search efficiency by deploying multiple LLM candidates with varied parameters to explore a larger search space, with their findings synthesized to curate a comprehensive final research response. The process concludes with One Shot Report Generation, ensuring the final document is informed by a unified narrative and high fact density. Powered by the Gemini 2.5 Pro model, our Deep Researcher was evaluated on the DeepResearch Bench, a globally recognized benchmark of 100 doctoral level research tasks. Our architecture achieved an overall score of 46.21, demonstrating superior performance by surpassing leading deep research agents such as Claude Researcher, Nvidia AIQ Research Assistant, Perplexity Research, Kimi Researcher and Grok Deeper Search present on the DeepResearch Bench actively running leaderboard. This performance marginally exceeds our previous work, Static DRA, and reinforces the finding that sequential scaling consistently outperforms the parallel self consistency paradigm.",
      "published": "2026-01-28",
      "updated": "2026-01-28",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.20843v1",
        "pdf": "https://arxiv.org/pdf/2601.20843v1"
      },
      "arxiv_id": "2601.20843v1",
      "comment": "11 pages, 6 figures, 2 tables, source code: https://github.com/SauravP97/deep-researcher-reflect-evolve/",
      "journal_ref": "",
      "has_code": true,
      "relevance_score": 3.8499999999999996,
      "score_breakdown": {
        "total_score": 3.85,
        "field_match": {
          "score": 0.0,
          "matches": [],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 5.0,
          "venue": null,
          "weight": 0.25
        },
        "citation_potential": {
          "score": 7.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 10.0,
          "has_code": true,
          "weight": 0.1
        },
        "practicality": {
          "score": 5.5,
          "weight": 0.1
        }
      },
      "ai_summaries": {
        "short": "This paper introduces a novel Deep Researcher architecture designed to generate detailed research reports on complex PhD level topics by addressing the inherent limitations of the Parallel Scaling paradigm. Our system utilizes two key innovations: Sequential Research Plan Refinement via Reflection and a Candidates Crossover algorithm. The sequential refinement process is demonstrated as an efficie...",
        "key_contributions": [
          "This paper introduces a novel Deep Researcher architecture designed to generate detailed research reports on complex PhD level topics by addressing the inherent limitations of the Parallel Scaling paradigm.",
          "Our system utilizes two key innovations: Sequential Research Plan Refinement via Reflection and a Candidates Crossover algorithm.",
          "The sequential refinement process is demonstrated as an efficient method that allows the agent to maintain a centralized Global Research Context, enabling it to look back at current progress, reason about the research plan, and intelligently make changes at runtime."
        ],
        "provider": "gemini",
        "audio_url": "/audio/2601.20843v1.mp3"
      }
    }
  ]
}