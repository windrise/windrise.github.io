{
  "filtered_at": "{\"timestamp\": \"now\"}",
  "total_papers": 10,
  "papers": [
    {
      "id": "2602.15775v1",
      "title": "NeRFscopy: Neural Radiance Fields for in-vivo Time-Varying Tissues from Endoscopy",
      "authors": [
        "Laura Salort-Benejam",
        "Antonio Agudo"
      ],
      "abstract": "Endoscopy is essential in medical imaging, used for diagnosis, prognosis and treatment. Developing a robust dynamic 3D reconstruction pipeline for endoscopic videos could enhance visualization, improve diagnostic accuracy, aid in treatment planning, and guide surgery procedures. However, challenges arise due to the deformable nature of the tissues, the use of monocular cameras, illumination changes, occlusions and unknown camera trajectories. Inspired by neural rendering, we introduce NeRFscopy, a self-supervised pipeline for novel view synthesis and 3D reconstruction of deformable endoscopic tissues from a monocular video. NeRFscopy includes a deformable model with a canonical radiance field and a time-dependent deformation field parameterized by SE(3) transformations. In addition, the color images are efficiently exploited by introducing sophisticated terms to learn a 3D implicit model without assuming any template or pre-trained model, solely from data. NeRFscopy achieves accurate results in terms of novel view synthesis, outperforming competing methods across various challenging endoscopy scenes.",
      "published": "2026-02-17",
      "updated": "2026-02-17",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.15775v1",
        "pdf": "https://arxiv.org/pdf/2602.15775v1"
      },
      "arxiv_id": "2602.15775v1",
      "comment": "ISBI 2026",
      "journal_ref": "",
      "has_code": false,
      "relevance_score": 4.988135593220339,
      "score_breakdown": {
        "total_score": 4.99,
        "field_match": {
          "score": 3.22,
          "matches": [
            "medical imaging",
            "self-supervised",
            "3d reconstruction",
            "neural radiance",
            "nerf"
          ],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 8,
          "venue": "ISBI",
          "weight": 0.25
        },
        "citation_potential": {
          "score": 6.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 3.0,
          "has_code": false,
          "weight": 0.1
        },
        "practicality": {
          "score": 5.0,
          "weight": 0.1
        }
      },
      "ai_summaries": {
        "short": "Endoscopy is essential in medical imaging, used for diagnosis, prognosis and treatment. Developing a robust dynamic 3D reconstruction pipeline for endoscopic videos could enhance visualization, improve diagnostic accuracy, aid in treatment planning, and guide surgery procedures. However, challenges arise due to the deformable nature of the tissues, the use of monocular cameras, illumination change...",
        "key_contributions": [
          "Endoscopy is essential in medical imaging, used for diagnosis, prognosis and treatment.",
          "Developing a robust dynamic 3D reconstruction pipeline for endoscopic videos could enhance visualization, improve diagnostic accuracy, aid in treatment planning, and guide surgery procedures.",
          "However, challenges arise due to the deformable nature of the tissues, the use of monocular cameras, illumination changes, occlusions and unknown camera trajectories."
        ],
        "provider": "gemini",
        "audio_url": "/audio/2602.15775v1.mp3"
      }
    },
    {
      "id": "2602.15752v1",
      "title": "Beyond Match Maximization and Fairness: Retention-Optimized Two-Sided Matching",
      "authors": [
        "Ren Kishimoto",
        "Rikiya Takehi",
        "Koichi Tanaka",
        "Masahiro Nomura",
        "Riku Togashi",
        "Yoji Tomita",
        "Yuta Saito"
      ],
      "abstract": "On two-sided matching platforms such as online dating and recruiting, recommendation algorithms often aim to maximize the total number of matches. However, this objective creates an imbalance, where some users receive far too many matches while many others receive very few and eventually abandon the platform. Retaining users is crucial for many platforms, such as those that depend heavily on subscriptions. Some may use fairness objectives to solve the problem of match maximization. However, fairness in itself is not the ultimate objective for many platforms, as users do not suddenly reward the platform simply because exposure is equalized. In practice, where user retention is often the ultimate goal, casually relying on fairness will leave the optimization of retention up to luck.\n  In this work, instead of maximizing matches or axiomatically defining fairness, we formally define the new problem setting of maximizing user retention in two-sided matching platforms. To this end, we introduce a dynamic learning-to-rank (LTR) algorithm called Matching for Retention (MRet). Unlike conventional algorithms for two-sided matching, our approach models user retention by learning personalized retention curves from each user's profile and interaction history. Based on these curves, MRet dynamically adapts recommendations by jointly considering the retention gains of both the user receiving recommendations and those who are being recommended, so that limited matching opportunities can be allocated where they most improve overall retention. Naturally but importantly, empirical evaluations on synthetic and real-world datasets from a major online dating platform show that MRet achieves higher user retention, since conventional methods optimize matches or fairness rather than retention.",
      "published": "2026-02-17",
      "updated": "2026-02-17",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.15752v1",
        "pdf": "https://arxiv.org/pdf/2602.15752v1"
      },
      "arxiv_id": "2602.15752v1",
      "comment": "Published as a conference paper at ICLR 2026",
      "journal_ref": "",
      "has_code": false,
      "relevance_score": 4.6,
      "score_breakdown": {
        "total_score": 4.6,
        "field_match": {
          "score": 0.0,
          "matches": [],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 10,
          "venue": "ICLR",
          "weight": 0.25
        },
        "citation_potential": {
          "score": 8.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 3.0,
          "has_code": false,
          "weight": 0.1
        },
        "practicality": {
          "score": 6.0,
          "weight": 0.1
        }
      },
      "ai_summaries": {
        "short": "On two-sided matching platforms such as online dating and recruiting, recommendation algorithms often aim to maximize the total number of matches. However, this objective creates an imbalance, where some users receive far too many matches while many others receive very few and eventually abandon the platform. Retaining users is crucial for many platforms, such as those that depend heavily on subsc...",
        "key_contributions": [
          "On two-sided matching platforms such as online dating and recruiting, recommendation algorithms often aim to maximize the total number of matches.",
          "However, this objective creates an imbalance, where some users receive far too many matches while many others receive very few and eventually abandon the platform.",
          "Retaining users is crucial for many platforms, such as those that depend heavily on subscriptions."
        ],
        "provider": "gemini",
        "audio_url": "/audio/2602.15752v1.mp3"
      }
    },
    {
      "id": "2602.15669v1",
      "title": "PERSONA: Dynamic and Compositional Inference-Time Personality Control via Activation Vector Algebra",
      "authors": [
        "Xiachong Feng",
        "Liang Zhao",
        "Weihong Zhong",
        "Yichong Huang",
        "Yuxuan Gu",
        "Lingpeng Kong",
        "Xiaocheng Feng",
        "Bing Qin"
      ],
      "abstract": "Current methods for personality control in Large Language Models rely on static prompting or expensive fine-tuning, failing to capture the dynamic and compositional nature of human traits. We introduce PERSONA, a training-free framework that achieves fine-tuning level performance through direct manipulation of personality vectors in activation space. Our key insight is that personality traits appear as extractable, approximately orthogonal directions in the model's representation space that support algebraic operations. The framework operates through three stages: Persona-Base extracts orthogonal trait vectors via contrastive activation analysis; Persona-Algebra enables precise control through vector arithmetic (scalar multiplication for intensity, addition for composition, subtraction for suppression); and Persona-Flow achieves context-aware adaptation by dynamically composing these vectors during inference. On PersonalityBench, our approach achieves a mean score of 9.60, nearly matching the supervised fine-tuning upper bound of 9.61 without any gradient updates. On our proposed Persona-Evolve benchmark for dynamic personality adaptation, we achieve up to 91% win rates across diverse model families. These results provide evidence that aspects of LLM personality are mathematically tractable, opening new directions for interpretable and efficient behavioral control.",
      "published": "2026-02-17",
      "updated": "2026-02-17",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.15669v1",
        "pdf": "https://arxiv.org/pdf/2602.15669v1"
      },
      "arxiv_id": "2602.15669v1",
      "comment": "ICLR 2026",
      "journal_ref": "",
      "has_code": false,
      "relevance_score": 4.55,
      "score_breakdown": {
        "total_score": 4.55,
        "field_match": {
          "score": 0.0,
          "matches": [],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 10,
          "venue": "ICLR",
          "weight": 0.25
        },
        "citation_potential": {
          "score": 8.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 3.0,
          "has_code": false,
          "weight": 0.1
        },
        "practicality": {
          "score": 5.5,
          "weight": 0.1
        }
      },
      "ai_summaries": {
        "short": "Current methods for personality control in Large Language Models rely on static prompting or expensive fine-tuning, failing to capture the dynamic and compositional nature of human traits. We introduce PERSONA, a training-free framework that achieves fine-tuning level performance through direct manipulation of personality vectors in activation space. Our key insight is that personality traits appe...",
        "key_contributions": [
          "Current methods for personality control in Large Language Models rely on static prompting or expensive fine-tuning, failing to capture the dynamic and compositional nature of human traits.",
          "We introduce PERSONA, a training-free framework that achieves fine-tuning level performance through direct manipulation of personality vectors in activation space.",
          "Our key insight is that personality traits appear as extractable, approximately orthogonal directions in the model's representation space that support algebraic operations."
        ],
        "provider": "gemini",
        "audio_url": "/audio/2602.15669v1.mp3"
      }
    },
    {
      "id": "2602.15677v1",
      "title": "CAMEL: An ECG Language Model for Forecasting Cardiac Events",
      "authors": [
        "Neelay Velingker",
        "Alaia Solko-Breslin",
        "Mayank Keoliya",
        "Seewon Choi",
        "Jiayi Xin",
        "Anika Marathe",
        "Alireza Oraii",
        "Rajat Deo",
        "Sameed Khatana",
        "Rajeev Alur",
        "Mayur Naik",
        "Eric Wong"
      ],
      "abstract": "Electrocardiograms (ECG) are electrical recordings of the heart that are critical for diagnosing cardiovascular conditions. ECG language models (ELMs) have recently emerged as a promising framework for ECG classification accompanied by report generation. However, current models cannot forecast future cardiac events despite the immense clinical value for planning earlier intervention. To address this gap, we propose CAMEL, the first ELM that is capable of inference over longer signal durations which enables its forecasting capability. Our key insight is a specialized ECG encoder which enables cross-understanding of ECG signals with text. We train CAMEL using established LLM training procedures, combining LoRA adaptation with a curriculum learning pipeline. Our curriculum includes ECG classification, metrics calculations, and multi-turn conversations to elicit reasoning. CAMEL demonstrates strong zero-shot performance across 6 tasks and 9 datasets, including ECGForecastBench, a new benchmark that we introduce for forecasting arrhythmias. CAMEL is on par with or surpasses ELMs and fully supervised baselines both in- and out-of-distribution, achieving SOTA results on ECGBench (+7.0% absolute average gain) as well as ECGForecastBench (+12.4% over fully supervised models and +21.1% over zero-shot ELMs).",
      "published": "2026-02-17",
      "updated": "2026-02-17",
      "categories": [
        "cs.LG",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.15677v1",
        "pdf": "https://arxiv.org/pdf/2602.15677v1"
      },
      "arxiv_id": "2602.15677v1",
      "comment": "24 pages, 6 figures",
      "journal_ref": "",
      "has_code": false,
      "relevance_score": 4.276271186440678,
      "score_breakdown": {
        "total_score": 4.28,
        "field_match": {
          "score": 1.44,
          "matches": [
            "cardiac",
            "heart"
          ],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 5.0,
          "venue": null,
          "weight": 0.25
        },
        "citation_potential": {
          "score": 10.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 3.0,
          "has_code": false,
          "weight": 0.1
        },
        "practicality": {
          "score": 6.5,
          "weight": 0.1
        }
      },
      "ai_summaries": {
        "short": "Electrocardiograms (ECG) are electrical recordings of the heart that are critical for diagnosing cardiovascular conditions. ECG language models (ELMs) have recently emerged as a promising framework for ECG classification accompanied by report generation. However, current models cannot forecast future cardiac events despite the immense clinical value for planning earlier intervention. To address th...",
        "key_contributions": [
          "Electrocardiograms (ECG) are electrical recordings of the heart that are critical for diagnosing cardiovascular conditions.",
          "ECG language models (ELMs) have recently emerged as a promising framework for ECG classification accompanied by report generation.",
          "However, current models cannot forecast future cardiac events despite the immense clinical value for planning earlier intervention."
        ],
        "provider": "gemini",
        "audio_url": "/audio/2602.15677v1.mp3"
      }
    },
    {
      "id": "2602.15817v1",
      "title": "Solving Parameter-Robust Avoid Problems with Unknown Feasibility using Reinforcement Learning",
      "authors": [
        "Oswin So",
        "Eric Yang Yu",
        "Songyuan Zhang",
        "Matthew Cleaveland",
        "Mitchell Black",
        "Chuchu Fan"
      ],
      "abstract": "Recent advances in deep reinforcement learning (RL) have achieved strong results on high-dimensional control tasks, but applying RL to reachability problems raises a fundamental mismatch: reachability seeks to maximize the set of states from which a system remains safe indefinitely, while RL optimizes expected returns over a user-specified distribution. This mismatch can result in policies that perform poorly on low-probability states that are still within the safe set. A natural alternative is to frame the problem as a robust optimization over a set of initial conditions that specify the initial state, dynamics and safe set, but whether this problem has a solution depends on the feasibility of the specified set, which is unknown a priori. We propose Feasibility-Guided Exploration (FGE), a method that simultaneously identifies a subset of feasible initial conditions under which a safe policy exists, and learns a policy to solve the reachability problem over this set of initial conditions. Empirical results demonstrate that FGE learns policies with over 50% more coverage than the best existing method for challenging initial conditions across tasks in the MuJoCo simulator and the Kinetix simulator with pixel observations.",
      "published": "2026-02-17",
      "updated": "2026-02-17",
      "categories": [
        "cs.LG",
        "cs.RO",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2602.15817v1",
        "pdf": "https://arxiv.org/pdf/2602.15817v1"
      },
      "arxiv_id": "2602.15817v1",
      "comment": "ICLR 2026. The project page can be found at https://oswinso.xyz/fge",
      "journal_ref": "",
      "has_code": false,
      "relevance_score": 4.2,
      "score_breakdown": {
        "total_score": 4.2,
        "field_match": {
          "score": 0.0,
          "matches": [],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 10,
          "venue": "ICLR",
          "weight": 0.25
        },
        "citation_potential": {
          "score": 6.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 3.0,
          "has_code": false,
          "weight": 0.1
        },
        "practicality": {
          "score": 5.0,
          "weight": 0.1
        }
      },
      "ai_summaries": {
        "short": "Recent advances in deep reinforcement learning (RL) have achieved strong results on high-dimensional control tasks, but applying RL to reachability problems raises a fundamental mismatch: reachability seeks to maximize the set of states from which a system remains safe indefinitely, while RL optimizes expected returns over a user-specified distribution. This mismatch can result in policies that pe...",
        "key_contributions": [
          "Recent advances in deep reinforcement learning (RL) have achieved strong results on high-dimensional control tasks, but applying RL to reachability problems raises a fundamental mismatch: reachability seeks to maximize the set of states from which a system remains safe indefinitely, while RL optimizes expected returns over a user-specified distribution.",
          "This mismatch can result in policies that perform poorly on low-probability states that are still within the safe set.",
          "A natural alternative is to frame the problem as a robust optimization over a set of initial conditions that specify the initial state, dynamics and safe set, but whether this problem has a solution depends on the feasibility of the specified set, which is unknown a priori."
        ],
        "provider": "gemini",
        "audio_url": "/audio/2602.15817v1.mp3"
      }
    },
    {
      "id": "2602.15776v1",
      "title": "GlobeDiff: State Diffusion Process for Partial Observability in Multi-Agent Systems",
      "authors": [
        "Yiqin Yang",
        "Xu Yang",
        "Yuhua Jiang",
        "Ni Mu",
        "Hao Hu",
        "Runpeng Xie",
        "Ziyou Zhang",
        "Siyuan Li",
        "Yuan-Hua Ni",
        "Qianchuan Zhao",
        "Bo Xu"
      ],
      "abstract": "In the realm of multi-agent systems, the challenge of \\emph{partial observability} is a critical barrier to effective coordination and decision-making. Existing approaches, such as belief state estimation and inter-agent communication, often fall short. Belief-based methods are limited by their focus on past experiences without fully leveraging global information, while communication methods often lack a robust model to effectively utilize the auxiliary information they provide. To solve this issue, we propose Global State Diffusion Algorithm~(GlobeDiff) to infer the global state based on the local observations. By formulating the state inference process as a multi-modal diffusion process, GlobeDiff overcomes ambiguities in state estimation while simultaneously inferring the global state with high fidelity. We prove that the estimation error of GlobeDiff under both unimodal and multi-modal distributions can be bounded. Extensive experimental results demonstrate that GlobeDiff achieves superior performance and is capable of accurately inferring the global state.",
      "published": "2026-02-17",
      "updated": "2026-02-17",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2602.15776v1",
        "pdf": "https://arxiv.org/pdf/2602.15776v1"
      },
      "arxiv_id": "2602.15776v1",
      "comment": "",
      "journal_ref": "ICLR-2026",
      "has_code": false,
      "relevance_score": 4.2,
      "score_breakdown": {
        "total_score": 4.2,
        "field_match": {
          "score": 0.0,
          "matches": [],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 10,
          "venue": "ICLR",
          "weight": 0.25
        },
        "citation_potential": {
          "score": 6.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 3.0,
          "has_code": false,
          "weight": 0.1
        },
        "practicality": {
          "score": 5.0,
          "weight": 0.1
        }
      },
      "ai_summaries": {
        "short": "In the realm of multi-agent systems, the challenge of \\emph{partial observability} is a critical barrier to effective coordination and decision-making. Existing approaches, such as belief state estimation and inter-agent communication, often fall short. Belief-based methods are limited by their focus on past experiences without fully leveraging global information, while communication methods often...",
        "key_contributions": [
          "In the realm of multi-agent systems, the challenge of \\emph{partial observability} is a critical barrier to effective coordination and decision-making.",
          "Existing approaches, such as belief state estimation and inter-agent communication, often fall short.",
          "Belief-based methods are limited by their focus on past experiences without fully leveraging global information, while communication methods often lack a robust model to effectively utilize the auxiliary information they provide."
        ],
        "provider": "gemini",
        "audio_url": "/audio/2602.15776v1.mp3"
      }
    },
    {
      "id": "2602.15772v1",
      "title": "Understanding vs. Generation: Navigating Optimization Dilemma in Multimodal Models",
      "authors": [
        "Sen Ye",
        "Mengde Xu",
        "Shuyang Gu",
        "Di He",
        "Liwei Wang",
        "Han Hu"
      ],
      "abstract": "Current research in multimodal models faces a key challenge where enhancing generative capabilities often comes at the expense of understanding, and vice versa. We analyzed this trade-off and identify the primary cause might be the potential conflict between generation and understanding, which creates a competitive dynamic within the model. To address this, we propose the Reason-Reflect-Refine (R3) framework. This innovative algorithm re-frames the single-step generation task into a multi-step process of \"generate-understand-regenerate\". By explicitly leveraging the model's understanding capability during generation, we successfully mitigate the optimization dilemma, achieved stronger generation results and improved understanding ability which are related to the generation process. This offers valuable insights for designing next-generation unified multimodal models. Code is available at https://github.com/sen-ye/R3.",
      "published": "2026-02-17",
      "updated": "2026-02-17",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.15772v1",
        "pdf": "https://arxiv.org/pdf/2602.15772v1"
      },
      "arxiv_id": "2602.15772v1",
      "comment": "Accepted to ICLR2026",
      "journal_ref": "",
      "has_code": false,
      "relevance_score": 4.2,
      "score_breakdown": {
        "total_score": 4.2,
        "field_match": {
          "score": 0.0,
          "matches": [],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 10,
          "venue": "ICLR",
          "weight": 0.25
        },
        "citation_potential": {
          "score": 6.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 3.0,
          "has_code": false,
          "weight": 0.1
        },
        "practicality": {
          "score": 5.0,
          "weight": 0.1
        }
      },
      "ai_summaries": {
        "short": "Current research in multimodal models faces a key challenge where enhancing generative capabilities often comes at the expense of understanding, and vice versa. We analyzed this trade-off and identify the primary cause might be the potential conflict between generation and understanding, which creates a competitive dynamic within the model. To address this, we propose the Reason-Reflect-Refine (R3...",
        "key_contributions": [
          "Current research in multimodal models faces a key challenge where enhancing generative capabilities often comes at the expense of understanding, and vice versa.",
          "We analyzed this trade-off and identify the primary cause might be the potential conflict between generation and understanding, which creates a competitive dynamic within the model.",
          "To address this, we propose the Reason-Reflect-Refine (R3) framework."
        ],
        "provider": "gemini",
        "audio_url": "/audio/2602.15772v1.mp3"
      }
    },
    {
      "id": "2602.15727v1",
      "title": "Spanning the Visual Analogy Space with a Weight Basis of LoRAs",
      "authors": [
        "Hila Manor",
        "Rinon Gal",
        "Haggai Maron",
        "Tomer Michaeli",
        "Gal Chechik"
      ],
      "abstract": "Visual analogy learning enables image manipulation through demonstration rather than textual description, allowing users to specify complex transformations difficult to articulate in words. Given a triplet $\\{\\mathbf{a}$, $\\mathbf{a}'$, $\\mathbf{b}\\}$, the goal is to generate $\\mathbf{b}'$ such that $\\mathbf{a} : \\mathbf{a}' :: \\mathbf{b} : \\mathbf{b}'$. Recent methods adapt text-to-image models to this task using a single Low-Rank Adaptation (LoRA) module, but they face a fundamental limitation: attempting to capture the diverse space of visual transformations within a fixed adaptation module constrains generalization capabilities. Inspired by recent work showing that LoRAs in constrained domains span meaningful, interpolatable semantic spaces, we propose LoRWeB, a novel approach that specializes the model for each analogy task at inference time through dynamic composition of learned transformation primitives, informally, choosing a point in a \"space of LoRAs\". We introduce two key components: (1) a learnable basis of LoRA modules, to span the space of different visual transformations, and (2) a lightweight encoder that dynamically selects and weighs these basis LoRAs based on the input analogy pair. Comprehensive evaluations demonstrate our approach achieves state-of-the-art performance and significantly improves generalization to unseen visual transformations. Our findings suggest that LoRA basis decompositions are a promising direction for flexible visual manipulation. Code and data are in https://research.nvidia.com/labs/par/lorweb",
      "published": "2026-02-17",
      "updated": "2026-02-17",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.15727v1",
        "pdf": "https://arxiv.org/pdf/2602.15727v1"
      },
      "arxiv_id": "2602.15727v1",
      "comment": "Code and data are in https://research.nvidia.com/labs/par/lorweb",
      "journal_ref": "",
      "has_code": true,
      "relevance_score": 4.1,
      "score_breakdown": {
        "total_score": 4.1,
        "field_match": {
          "score": 0.0,
          "matches": [],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 5.0,
          "venue": null,
          "weight": 0.25
        },
        "citation_potential": {
          "score": 9.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 10.0,
          "has_code": true,
          "weight": 0.1
        },
        "practicality": {
          "score": 5.0,
          "weight": 0.1
        }
      },
      "ai_summaries": {
        "short": "Visual analogy learning enables image manipulation through demonstration rather than textual description, allowing users to specify complex transformations difficult to articulate in words. Given a triplet $\\{\\mathbf{a}$, $\\mathbf{a}'$, $\\mathbf{b}\\}$, the goal is to generate $\\mathbf{b}'$ such that $\\mathbf{a} : \\mathbf{a}' :: \\mathbf{b} : \\mathbf{b}'$. Recent methods adapt text-to-image models t...",
        "key_contributions": [
          "Visual analogy learning enables image manipulation through demonstration rather than textual description, allowing users to specify complex transformations difficult to articulate in words.",
          "Given a triplet $\\{\\mathbf{a}$, $\\mathbf{a}'$, $\\mathbf{b}\\}$, the goal is to generate $\\mathbf{b}'$ such that $\\mathbf{a} : \\mathbf{a}' :: \\mathbf{b} : \\mathbf{b}'$.",
          "Recent methods adapt text-to-image models to this task using a single Low-Rank Adaptation (LoRA) module, but they face a fundamental limitation: attempting to capture the diverse space of visual transformations within a fixed adaptation module constrains generalization capabilities."
        ],
        "provider": "gemini",
        "audio_url": "/audio/2602.15727v1.mp3"
      }
    },
    {
      "id": "2602.15660v1",
      "title": "Bayesian Optimization for Design Parameters of 3D Image Data Analysis",
      "authors": [
        "David Exler",
        "Joaquin Eduardo Urrutia Gómez",
        "Martin Krüger",
        "Maike Schliephake",
        "John Jbeily",
        "Mario Vitacolonna",
        "Rüdiger Rudolf",
        "Markus Reischl"
      ],
      "abstract": "Deep learning-based segmentation and classification are crucial to large-scale biomedical imaging, particularly for 3D data, where manual analysis is impractical. Although many methods exist, selecting suitable models and tuning parameters remains a major bottleneck in practice. Hence, we introduce the 3D data Analysis Optimization Pipeline, a method designed to facilitate the design and parameterization of segmentation and classification using two Bayesian Optimization stages. First, the pipeline selects a segmentation model and optimizes postprocessing parameters using a domain-adapted syntactic benchmark dataset. To ensure a concise evaluation of segmentation performance, we introduce a segmentation quality metric that serves as the objective function. Second, the pipeline optimizes design choices of a classifier, such as encoder and classifier head architectures, incorporation of prior knowledge, and pretraining strategies. To reduce manual annotation effort, this stage includes an assisted class-annotation workflow that extracts predicted instances from the segmentation results and sequentially presents them to the operator, eliminating the need for manual tracking. In four case studies, the 3D data Analysis Optimization Pipeline efficiently identifies effective model and parameter configurations for individual datasets.",
      "published": "2026-02-17",
      "updated": "2026-02-17",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.15660v1",
        "pdf": "https://arxiv.org/pdf/2602.15660v1"
      },
      "arxiv_id": "2602.15660v1",
      "comment": "10 pages, 7 figures",
      "journal_ref": "",
      "has_code": false,
      "relevance_score": 4.077966101694916,
      "score_breakdown": {
        "total_score": 4.08,
        "field_match": {
          "score": 1.69,
          "matches": [
            "medical imaging",
            "segmentation",
            "deep learning"
          ],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 5.0,
          "venue": null,
          "weight": 0.25
        },
        "citation_potential": {
          "score": 8.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 3.0,
          "has_code": false,
          "weight": 0.1
        },
        "practicality": {
          "score": 6.5,
          "weight": 0.1
        }
      },
      "ai_summaries": {
        "short": "Deep learning-based segmentation and classification are crucial to large-scale biomedical imaging, particularly for 3D data, where manual analysis is impractical. Although many methods exist, selecting suitable models and tuning parameters remains a major bottleneck in practice. Hence, we introduce the 3D data Analysis Optimization Pipeline, a method designed to facilitate the design and parameter...",
        "key_contributions": [
          "Deep learning-based segmentation and classification are crucial to large-scale biomedical imaging, particularly for 3D data, where manual analysis is impractical.",
          "Although many methods exist, selecting suitable models and tuning parameters remains a major bottleneck in practice.",
          "Hence, we introduce the 3D data Analysis Optimization Pipeline, a method designed to facilitate the design and parameterization of segmentation and classification using two Bayesian Optimization stages."
        ],
        "provider": "gemini",
        "audio_url": "/audio/2602.15660v1.mp3"
      }
    },
    {
      "id": "2602.15516v1",
      "title": "Semantic-Guided 3D Gaussian Splatting for Transient Object Removal",
      "authors": [
        "Aditi Prabakaran",
        "Priyesh Shukla"
      ],
      "abstract": "Transient objects in casual multi-view captures cause ghosting artifacts in 3D Gaussian Splatting (3DGS) reconstruction. Existing solutions relied on scene decomposition at significant memory cost or on motion-based heuristics that were vulnerable to parallax ambiguity. A semantic filtering framework was proposed for category-aware transient removal using vision-language models. CLIP similarity scores between rendered views and distractor text prompts were accumulated per-Gaussian across training iterations. Gaussians exceeding a calibrated threshold underwent opacity regularization and periodic pruning. Unlike motion-based approaches, semantic classification resolved parallax ambiguity by identifying object categories independently of motion patterns. Experiments on the RobustNeRF benchmark demonstrated consistent improvement in reconstruction quality over vanilla 3DGS across four sequences, while maintaining minimal memory overhead and real-time rendering performance. Threshold calibration and comparisons with baselines validated semantic guidance as a practical strategy for transient removal in scenarios with predictable distractor categories.",
      "published": "2026-02-17",
      "updated": "2026-02-17",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2602.15516v1",
        "pdf": "https://arxiv.org/pdf/2602.15516v1"
      },
      "arxiv_id": "2602.15516v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false,
      "relevance_score": 3.965254237288136,
      "score_breakdown": {
        "total_score": 3.97,
        "field_match": {
          "score": 2.29,
          "matches": [
            "3d gaussian",
            "gaussian splatting",
            "nerf"
          ],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 5.0,
          "venue": null,
          "weight": 0.25
        },
        "citation_potential": {
          "score": 6.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 3.0,
          "has_code": false,
          "weight": 0.1
        },
        "practicality": {
          "score": 6.0,
          "weight": 0.1
        }
      },
      "ai_summaries": {
        "short": "Transient objects in casual multi-view captures cause ghosting artifacts in 3D Gaussian Splatting (3DGS) reconstruction. Existing solutions relied on scene decomposition at significant memory cost or on motion-based heuristics that were vulnerable to parallax ambiguity. A semantic filtering framework was proposed for category-aware transient removal using vision-language models. CLIP similarity sc...",
        "key_contributions": [
          "Transient objects in casual multi-view captures cause ghosting artifacts in 3D Gaussian Splatting (3DGS) reconstruction.",
          "Existing solutions relied on scene decomposition at significant memory cost or on motion-based heuristics that were vulnerable to parallax ambiguity.",
          "A semantic filtering framework was proposed for category-aware transient removal using vision-language models."
        ],
        "provider": "gemini",
        "audio_url": "/audio/2602.15516v1.mp3"
      }
    }
  ]
}