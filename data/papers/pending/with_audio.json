{
  "filtered_at": "{\"timestamp\": \"now\"}",
  "total_papers": 10,
  "papers": [
    {
      "id": "2601.23159v1",
      "title": "Segment Any Events with Language",
      "authors": [
        "Seungjun Lee",
        "Gim Hee Lee"
      ],
      "abstract": "Scene understanding with free-form language has been widely explored within diverse modalities such as images, point clouds, and LiDAR. However, related studies on event sensors are scarce or narrowly centered on semantic-level understanding. We introduce SEAL, the first Semantic-aware Segment Any Events framework that addresses Open-Vocabulary Event Instance Segmentation (OV-EIS). Given the visual prompt, our model presents a unified framework to support both event segmentation and open-vocabulary mask classification at multiple levels of granularity, including instance-level and part-level. To enable thorough evaluation on OV-EIS, we curate four benchmarks that cover label granularity from coarse to fine class configurations and semantic granularity from instance-level to part-level understanding. Extensive experiments show that our SEAL largely outperforms proposed baselines in terms of performance and inference speed with a parameter-efficient architecture. In the Appendix, we further present a simple variant of our SEAL achieving generic spatiotemporal OV-EIS that does not require any visual prompts from users in the inference. Check out our project page in https://0nandon.github.io/SEAL",
      "published": "2026-01-30",
      "updated": "2026-01-30",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.23159v1",
        "pdf": "https://arxiv.org/pdf/2601.23159v1"
      },
      "arxiv_id": "2601.23159v1",
      "comment": "ICLR 2026. Project Page: https://0nandon.github.io/SEAL",
      "journal_ref": "",
      "has_code": true,
      "relevance_score": 5.303389830508475,
      "score_breakdown": {
        "total_score": 5.3,
        "field_match": {
          "score": 0.51,
          "matches": [
            "segmentation"
          ],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 10,
          "venue": "ICLR",
          "weight": 0.25
        },
        "citation_potential": {
          "score": 7.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 10.0,
          "has_code": true,
          "weight": 0.1
        },
        "practicality": {
          "score": 5.5,
          "weight": 0.1
        }
      },
      "ai_summaries": {
        "short": "Scene understanding with free-form language has been widely explored within diverse modalities such as images, point clouds, and LiDAR. However, related studies on event sensors are scarce or narrowly centered on semantic-level understanding. We introduce SEAL, the first Semantic-aware Segment Any Events framework that addresses Open-Vocabulary Event Instance Segmentation (OV-EIS). Given the visua...",
        "key_contributions": [
          "Scene understanding with free-form language has been widely explored within diverse modalities such as images, point clouds, and LiDAR.",
          "However, related studies on event sensors are scarce or narrowly centered on semantic-level understanding.",
          "We introduce SEAL, the first Semantic-aware Segment Any Events framework that addresses Open-Vocabulary Event Instance Segmentation (OV-EIS)."
        ],
        "provider": "gemini",
        "audio_url": "/audio/2601.23159v1.mp3"
      }
    },
    {
      "id": "2601.23048v1",
      "title": "From Abstract to Contextual: What LLMs Still Cannot Do in Mathematics",
      "authors": [
        "Bowen Cao",
        "Dongdong Zhang",
        "Yixia Li",
        "Junpeng Liu",
        "Shijue Huang",
        "Chufan Shi",
        "Hongyuan Lu",
        "Yaokang Wu",
        "Guanhua Chen",
        "Wai Lam",
        "Furu Wei"
      ],
      "abstract": "Large language models now solve many benchmark math problems at near-expert levels, yet this progress has not fully translated into reliable performance in real-world applications. We study this gap through contextual mathematical reasoning, where the mathematical core must be formulated from descriptive scenarios. We introduce ContextMATH, a benchmark that repurposes AIME and MATH-500 problems into two contextual settings: Scenario Grounding (SG), which embeds abstract problems into realistic narratives without increasing reasoning complexity, and Complexity Scaling (CS), which transforms explicit conditions into sub-problems to capture how constraints often appear in practice. Evaluating 61 proprietary and open-source models, we observe sharp drops: on average, open-source models decline by 13 and 34 points on SG and CS, while proprietary models drop by 13 and 20. Error analysis shows that errors are dominated by incorrect problem formulation, with formulation accuracy declining as original problem difficulty increases. Correct formulation emerges as a prerequisite for success, and its sufficiency improves with model scale, indicating that larger models advance in both understanding and reasoning. Nevertheless, formulation and reasoning remain two complementary bottlenecks that limit contextual mathematical problem solving. Finally, we find that fine-tuning with scenario data improves performance, whereas formulation-only training is ineffective. However, performance gaps are only partially alleviated, highlighting contextual mathematical reasoning as a central unsolved challenge for LLMs.",
      "published": "2026-01-30",
      "updated": "2026-01-30",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.23048v1",
        "pdf": "https://arxiv.org/pdf/2601.23048v1"
      },
      "arxiv_id": "2601.23048v1",
      "comment": "ICLR 2026",
      "journal_ref": "",
      "has_code": false,
      "relevance_score": 4.5,
      "score_breakdown": {
        "total_score": 4.5,
        "field_match": {
          "score": 0.0,
          "matches": [],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 10,
          "venue": "ICLR",
          "weight": 0.25
        },
        "citation_potential": {
          "score": 7.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 3.0,
          "has_code": false,
          "weight": 0.1
        },
        "practicality": {
          "score": 6.5,
          "weight": 0.1
        }
      },
      "ai_summaries": {
        "short": "Large language models now solve many benchmark math problems at near-expert levels, yet this progress has not fully translated into reliable performance in real-world applications. We study this gap through contextual mathematical reasoning, where the mathematical core must be formulated from descriptive scenarios. We introduce ContextMATH, a benchmark that repurposes AIME and MATH-500 problems in...",
        "key_contributions": [
          "Large language models now solve many benchmark math problems at near-expert levels, yet this progress has not fully translated into reliable performance in real-world applications.",
          "We study this gap through contextual mathematical reasoning, where the mathematical core must be formulated from descriptive scenarios.",
          "We introduce ContextMATH, a benchmark that repurposes AIME and MATH-500 problems into two contextual settings: Scenario Grounding (SG), which embeds abstract problems into realistic narratives without increasing reasoning complexity, and Complexity Scaling (CS), which transforms explicit conditions into sub-problems to capture how constraints often appear in practice."
        ],
        "provider": "gemini",
        "audio_url": "/audio/2601.23048v1.mp3"
      }
    },
    {
      "id": "2601.23007v1",
      "title": "Leveraging Multi-Rater Annotations to Calibrate Object Detectors in Microscopy Imaging",
      "authors": [
        "Francesco Campi",
        "Lucrezia Tondo",
        "Ekin Karabati",
        "Johannes Betge",
        "Marie Piraud"
      ],
      "abstract": "Deep learning-based object detectors have achieved impressive performance in microscopy imaging, yet their confidence estimates often lack calibration, limiting their reliability for biomedical applications. In this work, we introduce a new approach to improve model calibration by leveraging multi-rater annotations. We propose to train separate models on the annotations from single experts and aggregate their predictions to emulate consensus. This improves upon label sampling strategies, where models are trained on mixed annotations, and offers a more principled way to capture inter-rater variability. Experiments on a colorectal organoid dataset annotated by two experts demonstrate that our rater-specific ensemble strategy improves calibration performance while maintaining comparable detection accuracy. These findings suggest that explicitly modelling rater disagreement can lead to more trustworthy object detectors in biomedical imaging.",
      "published": "2026-01-30",
      "updated": "2026-01-30",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.23007v1",
        "pdf": "https://arxiv.org/pdf/2601.23007v1"
      },
      "arxiv_id": "2601.23007v1",
      "comment": "Accepted as a conference paper at ISBI 2026",
      "journal_ref": "",
      "has_code": false,
      "relevance_score": 4.4245762711864405,
      "score_breakdown": {
        "total_score": 4.42,
        "field_match": {
          "score": 1.19,
          "matches": [
            "medical imaging",
            "deep learning"
          ],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 8,
          "venue": "ISBI",
          "weight": 0.25
        },
        "citation_potential": {
          "score": 7.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 3.0,
          "has_code": false,
          "weight": 0.1
        },
        "practicality": {
          "score": 6.0,
          "weight": 0.1
        }
      },
      "ai_summaries": {
        "short": "Deep learning-based object detectors have achieved impressive performance in microscopy imaging, yet their confidence estimates often lack calibration, limiting their reliability for biomedical applications. In this work, we introduce a new approach to improve model calibration by leveraging multi-rater annotations. We propose to train separate models on the annotations from single experts and agg...",
        "key_contributions": [
          "Deep learning-based object detectors have achieved impressive performance in microscopy imaging, yet their confidence estimates often lack calibration, limiting their reliability for biomedical applications.",
          "In this work, we introduce a new approach to improve model calibration by leveraging multi-rater annotations.",
          "We propose to train separate models on the annotations from single experts and aggregate their predictions to emulate consensus."
        ],
        "provider": "gemini",
        "audio_url": "/audio/2601.23007v1.mp3"
      }
    },
    {
      "id": "2601.23201v1",
      "title": "Scale-Cascaded Diffusion Models for Super-Resolution in Medical Imaging",
      "authors": [
        "Darshan Thaker",
        "Mahmoud Mostapha",
        "Radu Miron",
        "Shihan Qiu",
        "Mariappan Nadar"
      ],
      "abstract": "Diffusion models have been increasingly used as strong generative priors for solving inverse problems such as super-resolution in medical imaging. However, these approaches typically utilize a diffusion prior trained at a single scale, ignoring the hierarchical scale structure of image data. In this work, we propose to decompose images into Laplacian pyramid scales and train separate diffusion priors for each frequency band. We then develop an algorithm to perform super-resolution that utilizes these priors to progressively refine reconstructions across different scales. Evaluated on brain, knee, and prostate MRI data, our approach both improves perceptual quality over baselines and reduces inference time through smaller coarse-scale networks. Our framework unifies multiscale reconstruction and diffusion priors for medical image super-resolution.",
      "published": "2026-01-30",
      "updated": "2026-01-30",
      "categories": [
        "eess.IV",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.23201v1",
        "pdf": "https://arxiv.org/pdf/2601.23201v1"
      },
      "arxiv_id": "2601.23201v1",
      "comment": "Accepted at IEEE International Symposium for Biomedical Imaging (ISBI) 2026",
      "journal_ref": "",
      "has_code": false,
      "relevance_score": 4.310169491525424,
      "score_breakdown": {
        "total_score": 4.31,
        "field_match": {
          "score": 1.53,
          "matches": [
            "medical image",
            "medical imaging"
          ],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 8,
          "venue": "ISBI",
          "weight": 0.25
        },
        "citation_potential": {
          "score": 6.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 3.0,
          "has_code": false,
          "weight": 0.1
        },
        "practicality": {
          "score": 5.0,
          "weight": 0.1
        }
      },
      "ai_summaries": {
        "short": "Diffusion models have been increasingly used as strong generative priors for solving inverse problems such as super-resolution in medical imaging. However, these approaches typically utilize a diffusion prior trained at a single scale, ignoring the hierarchical scale structure of image data. In this work, we propose to decompose images into Laplacian pyramid scales and train separate diffusion pri...",
        "key_contributions": [
          "Diffusion models have been increasingly used as strong generative priors for solving inverse problems such as super-resolution in medical imaging.",
          "However, these approaches typically utilize a diffusion prior trained at a single scale, ignoring the hierarchical scale structure of image data.",
          "In this work, we propose to decompose images into Laplacian pyramid scales and train separate diffusion priors for each frequency band."
        ],
        "provider": "gemini",
        "audio_url": "/audio/2601.23201v1.mp3"
      }
    },
    {
      "id": "2601.23045v1",
      "title": "The Hot Mess of AI: How Does Misalignment Scale With Model Intelligence and Task Complexity?",
      "authors": [
        "Alexander Hägele",
        "Aryo Pradipta Gema",
        "Henry Sleight",
        "Ethan Perez",
        "Jascha Sohl-Dickstein"
      ],
      "abstract": "As AI becomes more capable, we entrust it with more general and consequential tasks. The risks from failure grow more severe with increasing task scope. It is therefore important to understand how extremely capable AI models will fail: Will they fail by systematically pursuing goals we do not intend? Or will they fail by being a hot mess, and taking nonsensical actions that do not further any goal? We operationalize this question using a bias-variance decomposition of the errors made by AI models: An AI's \\emph{incoherence} on a task is measured over test-time randomness as the fraction of its error that stems from variance rather than bias in task outcome. Across all tasks and frontier models we measure, the longer models spend reasoning and taking actions, \\emph{the more incoherent} their failures become. Incoherence changes with model scale in a way that is experiment dependent. However, in several settings, larger, more capable models are more incoherent than smaller models. Consequently, scale alone seems unlikely to eliminate incoherence. Instead, as more capable AIs pursue harder tasks, requiring more sequential action and thought, our results predict failures to be accompanied by more incoherent behavior. This suggests a future where AIs sometimes cause industrial accidents (due to unpredictable misbehavior), but are less likely to exhibit consistent pursuit of a misaligned goal. This increases the relative importance of alignment research targeting reward hacking or goal misspecification.",
      "published": "2026-01-30",
      "updated": "2026-01-30",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.23045v1",
        "pdf": "https://arxiv.org/pdf/2601.23045v1"
      },
      "arxiv_id": "2601.23045v1",
      "comment": "ICLR 2026",
      "journal_ref": "",
      "has_code": false,
      "relevance_score": 4.2,
      "score_breakdown": {
        "total_score": 4.2,
        "field_match": {
          "score": 0.0,
          "matches": [],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 10,
          "venue": "ICLR",
          "weight": 0.25
        },
        "citation_potential": {
          "score": 6.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 3.0,
          "has_code": false,
          "weight": 0.1
        },
        "practicality": {
          "score": 5.0,
          "weight": 0.1
        }
      },
      "ai_summaries": {
        "short": "As AI becomes more capable, we entrust it with more general and consequential tasks. The risks from failure grow more severe with increasing task scope. It is therefore important to understand how extremely capable AI models will fail: Will they fail by systematically pursuing goals we do not intend? Or will they fail by being a hot mess, and taking nonsensical actions that do not further any goal...",
        "key_contributions": [
          "As AI becomes more capable, we entrust it with more general and consequential tasks.",
          "The risks from failure grow more severe with increasing task scope.",
          "It is therefore important to understand how extremely capable AI models will fail: Will they fail by systematically pursuing goals we do not intend? Or will they fail by being a hot mess, and taking nonsensical actions that do not further any goal? We operationalize this question using a bias-variance decomposition of the errors made by AI models: An AI's \\emph{incoherence} on a task is measured over test-time randomness as the fraction of its error that stems from variance rather than bias in task outcome."
        ],
        "provider": "gemini",
        "audio_url": "/audio/2601.23045v1.mp3"
      }
    },
    {
      "id": "2601.23212v1",
      "title": "Disentangling multispecific antibody function with graph neural networks",
      "authors": [
        "Joshua Southern",
        "Changpeng Lu",
        "Santrupti Nerli",
        "Samuel D. Stanton",
        "Andrew M. Watkins",
        "Franziska Seeger",
        "Frédéric A. Dreyer"
      ],
      "abstract": "Multispecific antibodies offer transformative therapeutic potential by engaging multiple epitopes simultaneously, yet their efficacy is an emergent property governed by complex molecular architectures. Rational design is often bottlenecked by the inability to predict how subtle changes in domain topology influence functional outcomes, a challenge exacerbated by the scarcity of comprehensive experimental data. Here, we introduce a computational framework to address part of this gap. First, we present a generative method for creating large-scale, realistic synthetic functional landscapes that capture non-linear interactions where biological activity depends on domain connectivity. Second, we propose a graph neural network architecture that explicitly encodes these topological constraints, distinguishing between format configurations that appear identical to sequence-only models. We demonstrate that this model, trained on synthetic landscapes, recapitulates complex functional properties and, via transfer learning, has the potential to achieve high predictive accuracy on limited biological datasets. We showcase the model's utility by optimizing trade-offs between efficacy and toxicity in trispecific T-cell engagers and retrieving optimal common light chains. This work provides a robust benchmarking environment for disentangling the combinatorial complexity of multispecifics, accelerating the design of next-generation therapeutics.",
      "published": "2026-01-30",
      "updated": "2026-01-30",
      "categories": [
        "q-bio.BM",
        "cs.AI"
      ],
      "primary_category": "q-bio.BM",
      "links": {
        "paper": "http://arxiv.org/abs/2601.23212v1",
        "pdf": "https://arxiv.org/pdf/2601.23212v1"
      },
      "arxiv_id": "2601.23212v1",
      "comment": "16 pages, 5 figures, code available at https://github.com/prescient-design/synapse",
      "journal_ref": "",
      "has_code": true,
      "relevance_score": 4.1000000000000005,
      "score_breakdown": {
        "total_score": 4.1,
        "field_match": {
          "score": 0.0,
          "matches": [],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 5.0,
          "venue": null,
          "weight": 0.25
        },
        "citation_potential": {
          "score": 8.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 10.0,
          "has_code": true,
          "weight": 0.1
        },
        "practicality": {
          "score": 6.5,
          "weight": 0.1
        }
      },
      "ai_summaries": {
        "short": "Multispecific antibodies offer transformative therapeutic potential by engaging multiple epitopes simultaneously, yet their efficacy is an emergent property governed by complex molecular architectures. Rational design is often bottlenecked by the inability to predict how subtle changes in domain topology influence functional outcomes, a challenge exacerbated by the scarcity of comprehensive experi...",
        "key_contributions": [
          "Multispecific antibodies offer transformative therapeutic potential by engaging multiple epitopes simultaneously, yet their efficacy is an emergent property governed by complex molecular architectures.",
          "Rational design is often bottlenecked by the inability to predict how subtle changes in domain topology influence functional outcomes, a challenge exacerbated by the scarcity of comprehensive experimental data.",
          "Here, we introduce a computational framework to address part of this gap."
        ],
        "provider": "gemini",
        "audio_url": "/audio/2601.23212v1.mp3"
      }
    },
    {
      "id": "2601.23131v1",
      "title": "Regularisation in neural networks: a survey and empirical analysis of approaches",
      "authors": [
        "Christiaan P. Opperman",
        "Anna S. Bosman",
        "Katherine M. Malan"
      ],
      "abstract": "Despite huge successes on a wide range of tasks, neural networks are known to sometimes struggle to generalise to unseen data. Many approaches have been proposed over the years to promote the generalisation ability of neural networks, collectively known as regularisation techniques. These are used as common practice under the assumption that any regularisation added to the pipeline would result in a performance improvement. In this study, we investigate whether this assumption holds in practice. First, we provide a broad review of regularisation techniques, including modern theories such as double descent. We propose a taxonomy of methods under four broad categories, namely: (1) data-based strategies, (2) architecture strategies, (3) training strategies, and (4) loss function strategies. Notably, we highlight the contradictions and correspondences between the approaches in these broad classes. Further, we perform an empirical comparison of the various regularisation techniques on classification tasks for ten numerical and image datasets applied to the multi-layer perceptron and convolutional neural network architectures. Results show that the efficacy of regularisation is dataset-dependent. For example, the use of a regularisation term only improved performance on numeric datasets, whereas batch normalisation improved performance on image datasets only. Generalisation is crucial to machine learning; thus, understanding the effects of applying regularisation techniques, and considering the connections between them is essential to the appropriate use of these methods in practice.",
      "published": "2026-01-30",
      "updated": "2026-01-30",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.23131v1",
        "pdf": "https://arxiv.org/pdf/2601.23131v1"
      },
      "arxiv_id": "2601.23131v1",
      "comment": "15 pages, 4 figures, 4 tables and for associated to the code, see https://github.com/Christo08/Benchmarks-of-regularisation-techniques.git",
      "journal_ref": "",
      "has_code": true,
      "relevance_score": 4.050000000000001,
      "score_breakdown": {
        "total_score": 4.05,
        "field_match": {
          "score": 0.0,
          "matches": [],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 5.0,
          "venue": null,
          "weight": 0.25
        },
        "citation_potential": {
          "score": 8.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 10.0,
          "has_code": true,
          "weight": 0.1
        },
        "practicality": {
          "score": 6.0,
          "weight": 0.1
        }
      },
      "ai_summaries": {
        "short": "Despite huge successes on a wide range of tasks, neural networks are known to sometimes struggle to generalise to unseen data. Many approaches have been proposed over the years to promote the generalisation ability of neural networks, collectively known as regularisation techniques. These are used as common practice under the assumption that any regularisation added to the pipeline would result in...",
        "key_contributions": [
          "Despite huge successes on a wide range of tasks, neural networks are known to sometimes struggle to generalise to unseen data.",
          "Many approaches have been proposed over the years to promote the generalisation ability of neural networks, collectively known as regularisation techniques.",
          "These are used as common practice under the assumption that any regularisation added to the pipeline would result in a performance improvement."
        ],
        "provider": "gemini",
        "audio_url": "/audio/2601.23131v1.mp3"
      }
    },
    {
      "id": "2601.23103v1",
      "title": "Vision-Language Controlled Deep Unfolding for Joint Medical Image Restoration and Segmentation",
      "authors": [
        "Ping Chen",
        "Zicheng Huang",
        "Xiangming Wang",
        "Yungeng Liu",
        "Bingyu Liang",
        "Haijin Zeng",
        "Yongyong Chen"
      ],
      "abstract": "We propose VL-DUN, a principled framework for joint All-in-One Medical Image Restoration and Segmentation (AiOMIRS) that bridges the gap between low-level signal recovery and high-level semantic understanding. While standard pipelines treat these tasks in isolation, our core insight is that they are fundamentally synergistic: restoration provides clean anatomical structures to improve segmentation, while semantic priors regularize the restoration process. VL-DUN resolves the sub-optimality of sequential processing through two primary innovations. (1) We formulate AiOMIRS as a unified optimization problem, deriving an interpretable joint unfolding mechanism where restoration and segmentation are mathematically coupled for mutual refinement. (2) We introduce a frequency-aware Mamba mechanism to capture long-range dependencies for global segmentation while preserving the high-frequency textures necessary for restoration. This allows for efficient global context modeling with linear complexity, effectively mitigating the spectral bias of standard architectures. As a pioneering work in the AiOMIRS task, VL-DUN establishes a new state-of-the-art across multi-modal benchmarks, improving PSNR by 0.92 dB and the Dice coefficient by 9.76\\%. Our results demonstrate that joint collaborative learning offers a superior, more robust solution for complex clinical workflows compared to isolated task processing. The codes are provided in https://github.com/cipi666/VLDUN.",
      "published": "2026-01-30",
      "updated": "2026-01-30",
      "categories": [
        "eess.IV",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.23103v1",
        "pdf": "https://arxiv.org/pdf/2601.23103v1"
      },
      "arxiv_id": "2601.23103v1",
      "comment": "18 pages, medical image",
      "journal_ref": "",
      "has_code": false,
      "relevance_score": 4.008474576271187,
      "score_breakdown": {
        "total_score": 4.01,
        "field_match": {
          "score": 1.27,
          "matches": [
            "medical image",
            "segmentation"
          ],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 5.0,
          "venue": null,
          "weight": 0.25
        },
        "citation_potential": {
          "score": 9.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 3.0,
          "has_code": false,
          "weight": 0.1
        },
        "practicality": {
          "score": 6.0,
          "weight": 0.1
        }
      },
      "ai_summaries": {
        "short": "We propose VL-DUN, a principled framework for joint All-in-One Medical Image Restoration and Segmentation (AiOMIRS) that bridges the gap between low-level signal recovery and high-level semantic understanding. While standard pipelines treat these tasks in isolation, our core insight is that they are fundamentally synergistic: restoration provides clean anatomical structures to improve segmentation...",
        "key_contributions": [
          "We propose VL-DUN, a principled framework for joint All-in-One Medical Image Restoration and Segmentation (AiOMIRS) that bridges the gap between low-level signal recovery and high-level semantic understanding.",
          "While standard pipelines treat these tasks in isolation, our core insight is that they are fundamentally synergistic: restoration provides clean anatomical structures to improve segmentation, while semantic priors regularize the restoration process.",
          "VL-DUN resolves the sub-optimality of sequential processing through two primary innovations."
        ],
        "provider": "gemini",
        "audio_url": "/audio/2601.23103v1.mp3"
      }
    },
    {
      "id": "2601.23065v1",
      "title": "EAG-PT: Emission-Aware Gaussians and Path Tracing for Indoor Scene Reconstruction and Editing",
      "authors": [
        "Xijie Yang",
        "Mulin Yu",
        "Changjian Jiang",
        "Kerui Ren",
        "Tao Lu",
        "Jiangmiao Pang",
        "Dahua Lin",
        "Bo Dai",
        "Linning Xu"
      ],
      "abstract": "Recent reconstruction methods based on radiance field such as NeRF and 3DGS reproduce indoor scenes with high visual fidelity, but break down under scene editing due to baked illumination and the lack of explicit light transport. In contrast, physically based inverse rendering relies on mesh representations and path tracing, which enforce correct light transport but place strong requirements on geometric fidelity, becoming a practical bottleneck for real indoor scenes. In this work, we propose Emission-Aware Gaussians and Path Tracing (EAG-PT), aiming for physically based light transport with a unified 2D Gaussian representation. Our design is based on three cores: (1) using 2D Gaussians as a unified scene representation and transport-friendly geometry proxy that avoids reconstructed mesh, (2) explicitly separating emissive and non-emissive components during reconstruction for further scene editing, and (3) decoupling reconstruction from final rendering by using efficient single-bounce optimization and high-quality multi-bounce path tracing after scene editing. Experiments on synthetic and real indoor scenes show that EAG-PT produces more natural and physically consistent renders after editing than radiant scene reconstructions, while preserving finer geometric detail and avoiding mesh-induced artifacts compared to mesh-based inverse path tracing. These results suggest promising directions for future use in interior design, XR content creation, and embodied AI.",
      "published": "2026-01-30",
      "updated": "2026-01-30",
      "categories": [
        "cs.GR",
        "cs.CV"
      ],
      "primary_category": "cs.GR",
      "links": {
        "paper": "http://arxiv.org/abs/2601.23065v1",
        "pdf": "https://arxiv.org/pdf/2601.23065v1"
      },
      "arxiv_id": "2601.23065v1",
      "comment": "project page: https://eag-pt.github.io",
      "journal_ref": "",
      "has_code": true,
      "relevance_score": 3.93728813559322,
      "score_breakdown": {
        "total_score": 3.94,
        "field_match": {
          "score": 0.59,
          "matches": [
            "nerf"
          ],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 5.0,
          "venue": null,
          "weight": 0.25
        },
        "citation_potential": {
          "score": 6.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 10.0,
          "has_code": true,
          "weight": 0.1
        },
        "practicality": {
          "score": 5.5,
          "weight": 0.1
        }
      },
      "ai_summaries": {
        "short": "Recent reconstruction methods based on radiance field such as NeRF and 3DGS reproduce indoor scenes with high visual fidelity, but break down under scene editing due to baked illumination and the lack of explicit light transport. In contrast, physically based inverse rendering relies on mesh representations and path tracing, which enforce correct light transport but place strong requirements on ge...",
        "key_contributions": [
          "Recent reconstruction methods based on radiance field such as NeRF and 3DGS reproduce indoor scenes with high visual fidelity, but break down under scene editing due to baked illumination and the lack of explicit light transport.",
          "In contrast, physically based inverse rendering relies on mesh representations and path tracing, which enforce correct light transport but place strong requirements on geometric fidelity, becoming a practical bottleneck for real indoor scenes.",
          "In this work, we propose Emission-Aware Gaussians and Path Tracing (EAG-PT), aiming for physically based light transport with a unified 2D Gaussian representation."
        ],
        "provider": "gemini",
        "audio_url": "/audio/2601.23065v1.mp3"
      }
    },
    {
      "id": "2601.23220v1",
      "title": "Med-Scout: Curing MLLMs' Geometric Blindness in Medical Perception via Geometry-Aware RL Post-Training",
      "authors": [
        "Anglin Liu",
        "Ruichao Chen",
        "Yi Lu",
        "Hongxia Xu",
        "Jintai Chen"
      ],
      "abstract": "Despite recent Multimodal Large Language Models (MLLMs)' linguistic prowess in medical diagnosis, we find even state-of-the-art MLLMs suffer from a critical perceptual deficit: geometric blindness. This failure to ground outputs in objective geometric constraints leads to plausible yet factually incorrect hallucinations, rooted in training paradigms that prioritize linguistic fluency over geometric fidelity. This paper introduces Med-Scout, a novel framework that \"cures\" this blindness via Reinforcement Learning (RL) that leverages the intrinsic geometric logic latent within unlabeled medical images. Instead of relying on costly expert annotations, Med-Scout derives verifiable supervision signals through three strategic proxy tasks: Hierarchical Scale Localization, Topological Jigsaw Reconstruction, and Anomaly Consistency Detection. To rigorously quantify this deficit, we present Med-Scout-Bench, a new benchmark specifically designed to evaluate geometric perception. Extensive evaluations show that Med-Scout significantly mitigates geometric blindness, outperforming leading proprietary and open-source MLLMs by over 40% on our benchmark. Furthermore, this enhanced geometric perception generalizes to broader medical understanding, achieving superior results on radiological and comprehensive medical VQA tasks.",
      "published": "2026-01-30",
      "updated": "2026-01-30",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.23220v1",
        "pdf": "https://arxiv.org/pdf/2601.23220v1"
      },
      "arxiv_id": "2601.23220v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false,
      "relevance_score": 3.9050847457627116,
      "score_breakdown": {
        "total_score": 3.91,
        "field_match": {
          "score": 0.76,
          "matches": [
            "medical image"
          ],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 5.0,
          "venue": null,
          "weight": 0.25
        },
        "citation_potential": {
          "score": 10.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 3.0,
          "has_code": false,
          "weight": 0.1
        },
        "practicality": {
          "score": 5.5,
          "weight": 0.1
        }
      },
      "ai_summaries": {
        "short": "Despite recent Multimodal Large Language Models (MLLMs)' linguistic prowess in medical diagnosis, we find even state-of-the-art MLLMs suffer from a critical perceptual deficit: geometric blindness. This failure to ground outputs in objective geometric constraints leads to plausible yet factually incorrect hallucinations, rooted in training paradigms that prioritize linguistic fluency over geometri...",
        "key_contributions": [
          "Despite recent Multimodal Large Language Models (MLLMs)' linguistic prowess in medical diagnosis, we find even state-of-the-art MLLMs suffer from a critical perceptual deficit: geometric blindness.",
          "This failure to ground outputs in objective geometric constraints leads to plausible yet factually incorrect hallucinations, rooted in training paradigms that prioritize linguistic fluency over geometric fidelity.",
          "This paper introduces Med-Scout, a novel framework that \"cures\" this blindness via Reinforcement Learning (RL) that leverages the intrinsic geometric logic latent within unlabeled medical images."
        ],
        "provider": "gemini",
        "audio_url": "/audio/2601.23220v1.mp3"
      }
    }
  ]
}