{
  "filtered_at": "{\"timestamp\": \"now\"}",
  "total_papers": 10,
  "papers": [
    {
      "id": "2601.11350v1",
      "title": "FEATHer: Fourier-Efficient Adaptive Temporal Hierarchy Forecaster for Time-Series Forecasting",
      "authors": [
        "Jaehoon Lee",
        "Seungwoo Lee",
        "Younghwi Kim",
        "Dohee Kim",
        "Sunghyun Sim"
      ],
      "abstract": "Time-series forecasting is fundamental in industrial domains like manufacturing and smart factories. As systems evolve toward automation, models must operate on edge devices (e.g., PLCs, microcontrollers) with strict constraints on latency and memory, limiting parameters to a few thousand. Conventional deep architectures are often impractical here. We propose the Fourier-Efficient Adaptive Temporal Hierarchy Forecaster (FEATHer) for accurate long-term forecasting under severe limits. FEATHer introduces: (i) ultra-lightweight multiscale decomposition into frequency pathways; (ii) a shared Dense Temporal Kernel using projection-depthwise convolution-projection without recurrence or attention; (iii) frequency-aware branch gating that adaptively fuses representations based on spectral characteristics; and (iv) a Sparse Period Kernel reconstructing outputs via period-wise downsampling to capture seasonality. FEATHer maintains a compact architecture (as few as 400 parameters) while outperforming baselines. Across eight benchmarks, it achieves the best ranking, recording 60 first-place results with an average rank of 2.05. These results demonstrate that reliable long-range forecasting is achievable on constrained edge hardware, offering a practical direction for industrial real-time inference.",
      "published": "2026-01-16",
      "updated": "2026-01-16",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.11350v1",
        "pdf": "https://arxiv.org/pdf/2601.11350v1"
      },
      "arxiv_id": "2601.11350v1",
      "comment": "Submitted to IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)",
      "journal_ref": "",
      "has_code": false,
      "relevance_score": 4.6,
      "score_breakdown": {
        "total_score": 4.6,
        "field_match": {
          "score": 0.0,
          "matches": [],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 10,
          "venue": "PAMI",
          "weight": 0.25
        },
        "citation_potential": {
          "score": 8.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 3.0,
          "has_code": false,
          "weight": 0.1
        },
        "practicality": {
          "score": 6.0,
          "weight": 0.1
        }
      },
      "ai_summaries": {
        "short": "Time-series forecasting is fundamental in industrial domains like manufacturing and smart factories. As systems evolve toward automation, models must operate on edge devices (e.g., PLCs, microcontrollers) with strict constraints on latency and memory, limiting parameters to a few thousand. Conventional deep architectures are often impractical here. We propose the Fourier-Efficient Adaptive Tempora...",
        "key_contributions": [
          "Time-series forecasting is fundamental in industrial domains like manufacturing and smart factories.",
          "As systems evolve toward automation, models must operate on edge devices (e.",
          "g."
        ],
        "provider": "gemini"
      }
    },
    {
      "id": "2601.11468v1",
      "title": "Exploring LLM Features in Predictive Process Monitoring for Small-Scale Event-Logs",
      "authors": [
        "Alessandro Padella",
        "Massimiliano de Leoni",
        "Marlon Dumas"
      ],
      "abstract": "Predictive Process Monitoring is a branch of process mining that aims to predict the outcome of an ongoing process. Recently, it leveraged machine-and-deep learning architectures. In this paper, we extend our prior LLM-based Predictive Process Monitoring framework, which was initially focused on total time prediction via prompting. The extension consists of comprehensively evaluating its generality, semantic leverage, and reasoning mechanisms, also across multiple Key Performance Indicators. Empirical evaluations conducted on three distinct event logs and across the Key Performance Indicators of Total Time and Activity Occurrence prediction indicate that, in data-scarce settings with only 100 traces, the LLM surpasses the benchmark methods. Furthermore, the experiments also show that the LLM exploits both its embodied prior knowledge and the internal correlations among training traces. Finally, we examine the reasoning strategies employed by the model, demonstrating that the LLM does not merely replicate existing predictive methods but performs higher-order reasoning to generate the predictions.",
      "published": "2026-01-16",
      "updated": "2026-01-16",
      "categories": [
        "cs.AI",
        "cs.IT"
      ],
      "primary_category": "cs.AI",
      "links": {
        "paper": "http://arxiv.org/abs/2601.11468v1",
        "pdf": "https://arxiv.org/pdf/2601.11468v1"
      },
      "arxiv_id": "2601.11468v1",
      "comment": "19 pages, 4 figure, TMIS journal submission",
      "journal_ref": "",
      "has_code": false,
      "relevance_score": 4.419491525423728,
      "score_breakdown": {
        "total_score": 4.42,
        "field_match": {
          "score": 0.42,
          "matches": [
            "deep learning"
          ],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 10,
          "venue": "TMI",
          "weight": 0.25
        },
        "citation_potential": {
          "score": 6.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 3.0,
          "has_code": false,
          "weight": 0.1
        },
        "practicality": {
          "score": 5.5,
          "weight": 0.1
        }
      },
      "ai_summaries": {
        "short": "Predictive Process Monitoring is a branch of process mining that aims to predict the outcome of an ongoing process. Recently, it leveraged machine-and-deep learning architectures. In this paper, we extend our prior LLM-based Predictive Process Monitoring framework, which was initially focused on total time prediction via prompting. The extension consists of comprehensively evaluating its generalit...",
        "key_contributions": [
          "Predictive Process Monitoring is a branch of process mining that aims to predict the outcome of an ongoing process.",
          "Recently, it leveraged machine-and-deep learning architectures.",
          "In this paper, we extend our prior LLM-based Predictive Process Monitoring framework, which was initially focused on total time prediction via prompting."
        ],
        "provider": "gemini"
      }
    },
    {
      "id": "2601.11514v1",
      "title": "ShapeR: Robust Conditional 3D Shape Generation from Casual Captures",
      "authors": [
        "Yawar Siddiqui",
        "Duncan Frost",
        "Samir Aroudj",
        "Armen Avetisyan",
        "Henry Howard-Jenkins",
        "Daniel DeTone",
        "Pierre Moulon",
        "Qirui Wu",
        "Zhengqin Li",
        "Julian Straub",
        "Richard Newcombe",
        "Jakob Engel"
      ],
      "abstract": "Recent advances in 3D shape generation have achieved impressive results, but most existing methods rely on clean, unoccluded, and well-segmented inputs. Such conditions are rarely met in real-world scenarios. We present ShapeR, a novel approach for conditional 3D object shape generation from casually captured sequences. Given an image sequence, we leverage off-the-shelf visual-inertial SLAM, 3D detection algorithms, and vision-language models to extract, for each object, a set of sparse SLAM points, posed multi-view images, and machine-generated captions. A rectified flow transformer trained to effectively condition on these modalities then generates high-fidelity metric 3D shapes. To ensure robustness to the challenges of casually captured data, we employ a range of techniques including on-the-fly compositional augmentations, a curriculum training scheme spanning object- and scene-level datasets, and strategies to handle background clutter. Additionally, we introduce a new evaluation benchmark comprising 178 in-the-wild objects across 7 real-world scenes with geometry annotations. Experiments show that ShapeR significantly outperforms existing approaches in this challenging setting, achieving an improvement of 2.7x in Chamfer distance compared to state of the art.",
      "published": "2026-01-16",
      "updated": "2026-01-16",
      "categories": [
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.11514v1",
        "pdf": "https://arxiv.org/pdf/2601.11514v1"
      },
      "arxiv_id": "2601.11514v1",
      "comment": "Project Page: http://facebookresearch.github.io/ShapeR Video: https://www.youtube.com/watch?v=EbY30KAA55I",
      "journal_ref": "",
      "has_code": true,
      "relevance_score": 4.25,
      "score_breakdown": {
        "total_score": 4.25,
        "field_match": {
          "score": 0.0,
          "matches": [],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 5.0,
          "venue": null,
          "weight": 0.25
        },
        "citation_potential": {
          "score": 9.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 10.0,
          "has_code": true,
          "weight": 0.1
        },
        "practicality": {
          "score": 6.5,
          "weight": 0.1
        }
      },
      "ai_summaries": {
        "short": "Recent advances in 3D shape generation have achieved impressive results, but most existing methods rely on clean, unoccluded, and well-segmented inputs. Such conditions are rarely met in real-world scenarios. We present ShapeR, a novel approach for conditional 3D object shape generation from casually captured sequences. Given an image sequence, we leverage off-the-shelf visual-inertial SLAM, 3D de...",
        "key_contributions": [
          "Recent advances in 3D shape generation have achieved impressive results, but most existing methods rely on clean, unoccluded, and well-segmented inputs.",
          "Such conditions are rarely met in real-world scenarios.",
          "We present ShapeR, a novel approach for conditional 3D object shape generation from casually captured sequences."
        ],
        "provider": "gemini"
      }
    },
    {
      "id": "2601.11522v1",
      "title": "UniX: Unifying Autoregression and Diffusion for Chest X-Ray Understanding and Generation",
      "authors": [
        "Ruiheng Zhang",
        "Jingfeng Yao",
        "Huangxuan Zhao",
        "Hao Yan",
        "Xiao He",
        "Lei Chen",
        "Zhou Wei",
        "Yong Luo",
        "Zengmao Wang",
        "Lefei Zhang",
        "Dacheng Tao",
        "Bo Du"
      ],
      "abstract": "Despite recent progress, medical foundation models still struggle to unify visual understanding and generation, as these tasks have inherently conflicting goals: semantic abstraction versus pixel-level reconstruction. Existing approaches, typically based on parameter-shared autoregressive architectures, frequently lead to compromised performance in one or both tasks. To address this, we present UniX, a next-generation unified medical foundation model for chest X-ray understanding and generation. UniX decouples the two tasks into an autoregressive branch for understanding and a diffusion branch for high-fidelity generation. Crucially, a cross-modal self-attention mechanism is introduced to dynamically guide the generation process with understanding features. Coupled with a rigorous data cleaning pipeline and a multi-stage training strategy, this architecture enables synergistic collaboration between tasks while leveraging the strengths of diffusion models for superior generation. On two representative benchmarks, UniX achieves a 46.1% improvement in understanding performance (Micro-F1) and a 24.2% gain in generation quality (FD-RadDino), using only a quarter of the parameters of LLM-CXR. By achieving performance on par with task-specific models, our work establishes a scalable paradigm for synergistic medical image understanding and generation. Codes and models are available at https://github.com/ZrH42/UniX.",
      "published": "2026-01-16",
      "updated": "2026-01-16",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.11522v1",
        "pdf": "https://arxiv.org/pdf/2601.11522v1"
      },
      "arxiv_id": "2601.11522v1",
      "comment": "Codes and models are available at https://github.com/ZrH42/UniX",
      "journal_ref": "",
      "has_code": true,
      "relevance_score": 4.155084745762712,
      "score_breakdown": {
        "total_score": 4.16,
        "field_match": {
          "score": 0.76,
          "matches": [
            "medical image"
          ],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 5.0,
          "venue": null,
          "weight": 0.25
        },
        "citation_potential": {
          "score": 7.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 10.0,
          "has_code": true,
          "weight": 0.1
        },
        "practicality": {
          "score": 5.5,
          "weight": 0.1
        }
      },
      "ai_summaries": {
        "short": "Despite recent progress, medical foundation models still struggle to unify visual understanding and generation, as these tasks have inherently conflicting goals: semantic abstraction versus pixel-level reconstruction. Existing approaches, typically based on parameter-shared autoregressive architectures, frequently lead to compromised performance in one or both tasks. To address this, we present Un...",
        "key_contributions": [
          "Despite recent progress, medical foundation models still struggle to unify visual understanding and generation, as these tasks have inherently conflicting goals: semantic abstraction versus pixel-level reconstruction.",
          "Existing approaches, typically based on parameter-shared autoregressive architectures, frequently lead to compromised performance in one or both tasks.",
          "To address this, we present UniX, a next-generation unified medical foundation model for chest X-ray understanding and generation."
        ],
        "provider": "gemini"
      }
    },
    {
      "id": "2601.11488v1",
      "title": "CTest-Metric: A Unified Framework to Assess Clinical Validity of Metrics for CT Report Generation",
      "authors": [
        "Vanshali Sharma",
        "Andrea Mia Bejar",
        "Gorkem Durak",
        "Ulas Bagci"
      ],
      "abstract": "In the generative AI era, where even critical medical tasks are increasingly automated, radiology report generation (RRG) continues to rely on suboptimal metrics for quality assessment. Developing domain-specific metrics has therefore been an active area of research, yet it remains challenging due to the lack of a unified, well-defined framework to assess their robustness and applicability in clinical contexts. To address this, we present CTest-Metric, a first unified metric assessment framework with three modules determining the clinical feasibility of metrics for CT RRG. The modules test: (i) Writing Style Generalizability (WSG) via LLM-based rephrasing; (ii) Synthetic Error Injection (SEI) at graded severities; and (iii) Metrics-vs-Expert correlation (MvE) using clinician ratings on 175 \"disagreement\" cases. Eight widely used metrics (BLEU, ROUGE, METEOR, BERTScore-F1, F1-RadGraph, RaTEScore, GREEN Score, CRG) are studied across seven LLMs built on a CT-CLIP encoder. Using our novel framework, we found that lexical NLG metrics are highly sensitive to stylistic variations; GREEN Score aligns best with expert judgments (Spearman~0.70), while CRG shows negative correlation; and BERTScore-F1 is least sensitive to factual error injection. We will release the framework, code, and allowable portion of the anonymized evaluation data (rephrased/error-injected CT reports), to facilitate reproducible benchmarking and future metric development.",
      "published": "2026-01-16",
      "updated": "2026-01-16",
      "categories": [
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2601.11488v1",
        "pdf": "https://arxiv.org/pdf/2601.11488v1"
      },
      "arxiv_id": "2601.11488v1",
      "comment": "Accepted at ISBI 2026",
      "journal_ref": "",
      "has_code": false,
      "relevance_score": 4.1,
      "score_breakdown": {
        "total_score": 4.1,
        "field_match": {
          "score": 0.0,
          "matches": [],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 8,
          "venue": "ISBI",
          "weight": 0.25
        },
        "citation_potential": {
          "score": 8.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 3.0,
          "has_code": false,
          "weight": 0.1
        },
        "practicality": {
          "score": 6.0,
          "weight": 0.1
        }
      },
      "ai_summaries": {
        "short": "In the generative AI era, where even critical medical tasks are increasingly automated, radiology report generation (RRG) continues to rely on suboptimal metrics for quality assessment. Developing domain-specific metrics has therefore been an active area of research, yet it remains challenging due to the lack of a unified, well-defined framework to assess their robustness and applicability in clin...",
        "key_contributions": [
          "In the generative AI era, where even critical medical tasks are increasingly automated, radiology report generation (RRG) continues to rely on suboptimal metrics for quality assessment.",
          "Developing domain-specific metrics has therefore been an active area of research, yet it remains challenging due to the lack of a unified, well-defined framework to assess their robustness and applicability in clinical contexts.",
          "To address this, we present CTest-Metric, a first unified metric assessment framework with three modules determining the clinical feasibility of metrics for CT RRG."
        ],
        "provider": "gemini"
      }
    },
    {
      "id": "2601.11235v1",
      "title": "Bio-inspired fine-tuning for selective transfer learning in image classification",
      "authors": [
        "Ana Davila",
        "Jacinto Colan",
        "Yasuhisa Hasegawa"
      ],
      "abstract": "Deep learning has significantly advanced image analysis across diverse domains but often depends on large, annotated datasets for success. Transfer learning addresses this challenge by utilizing pre-trained models to tackle new tasks with limited labeled data. However, discrepancies between source and target domains can hinder effective transfer learning. We introduce BioTune, a novel adaptive fine-tuning technique utilizing evolutionary optimization. BioTune enhances transfer learning by optimally choosing which layers to freeze and adjusting learning rates for unfrozen layers. Through extensive evaluation on nine image classification datasets, spanning natural and specialized domains such as medical imaging, BioTune demonstrates superior accuracy and efficiency over state-of-the-art fine-tuning methods, including AutoRGN and LoRA, highlighting its adaptability to various data characteristics and distribution changes. Additionally, BioTune consistently achieves top performance across four different CNN architectures, underscoring its flexibility. Ablation studies provide valuable insights into the impact of BioTune's key components on overall performance. The source code is available at https://github.com/davilac/BioTune.",
      "published": "2026-01-16",
      "updated": "2026-01-16",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.11235v1",
        "pdf": "https://arxiv.org/pdf/2601.11235v1"
      },
      "arxiv_id": "2601.11235v1",
      "comment": "",
      "journal_ref": "Published in IEEE Access, vol. 13, pp. 129234-129249, 2025",
      "has_code": false,
      "relevance_score": 4.094067796610169,
      "score_breakdown": {
        "total_score": 4.09,
        "field_match": {
          "score": 1.61,
          "matches": [
            "medical imaging",
            "deep learning",
            "image analysis"
          ],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 5.0,
          "venue": null,
          "weight": 0.25
        },
        "citation_potential": {
          "score": 9.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 3.0,
          "has_code": false,
          "weight": 0.1
        },
        "practicality": {
          "score": 5.5,
          "weight": 0.1
        }
      },
      "ai_summaries": {
        "short": "Deep learning has significantly advanced image analysis across diverse domains but often depends on large, annotated datasets for success. Transfer learning addresses this challenge by utilizing pre-trained models to tackle new tasks with limited labeled data. However, discrepancies between source and target domains can hinder effective transfer learning. We introduce BioTune, a novel adaptive fin...",
        "key_contributions": [
          "Deep learning has significantly advanced image analysis across diverse domains but often depends on large, annotated datasets for success.",
          "Transfer learning addresses this challenge by utilizing pre-trained models to tackle new tasks with limited labeled data.",
          "However, discrepancies between source and target domains can hinder effective transfer learning."
        ],
        "provider": "gemini"
      }
    },
    {
      "id": "2601.11255v1",
      "title": "Reasoning in Trees: Improving Retrieval-Augmented Generation for Multi-Hop Question Answering",
      "authors": [
        "Yuling Shi",
        "Maolin Sun",
        "Zijun Liu",
        "Mo Yang",
        "Yixiong Fang",
        "Tianran Sun",
        "Xiaodong Gu"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) has demonstrated significant effectiveness in enhancing large language models (LLMs) for complex multi-hop question answering (QA). For multi-hop QA tasks, current iterative approaches predominantly rely on LLMs to self-guide and plan multi-step exploration paths during retrieval, leading to substantial challenges in maintaining reasoning coherence across steps from inaccurate query decomposition and error propagation. To address these issues, we introduce Reasoning Tree Guided RAG (RT-RAG), a novel hierarchical framework for complex multi-hop QA. RT-RAG systematically decomposes multi-hop questions into explicit reasoning trees, minimizing inaccurate decomposition through structured entity analysis and consensus-based tree selection that clearly separates core queries, known entities, and unknown entities. Subsequently, a bottom-up traversal strategy employs iterative query rewriting and refinement to collect high-quality evidence, thereby mitigating error propagation. Comprehensive experiments show that RT-RAG substantially outperforms state-of-the-art methods by 7.0% F1 and 6.0% EM, demonstrating the effectiveness of RT-RAG in complex multi-hop QA.",
      "published": "2026-01-16",
      "updated": "2026-01-16",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "links": {
        "paper": "http://arxiv.org/abs/2601.11255v1",
        "pdf": "https://arxiv.org/pdf/2601.11255v1"
      },
      "arxiv_id": "2601.11255v1",
      "comment": "Accepted to GLOW@WWW2026. Code available at https://github.com/sakura20221/RT-RAG",
      "journal_ref": "",
      "has_code": true,
      "relevance_score": 4.0,
      "score_breakdown": {
        "total_score": 4.0,
        "field_match": {
          "score": 0.0,
          "matches": [],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 5.0,
          "venue": null,
          "weight": 0.25
        },
        "citation_potential": {
          "score": 8.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 10.0,
          "has_code": true,
          "weight": 0.1
        },
        "practicality": {
          "score": 5.5,
          "weight": 0.1
        }
      },
      "ai_summaries": {
        "short": "Retrieval-Augmented Generation (RAG) has demonstrated significant effectiveness in enhancing large language models (LLMs) for complex multi-hop question answering (QA). For multi-hop QA tasks, current iterative approaches predominantly rely on LLMs to self-guide and plan multi-step exploration paths during retrieval, leading to substantial challenges in maintaining reasoning coherence across steps...",
        "key_contributions": [
          "Retrieval-Augmented Generation (RAG) has demonstrated significant effectiveness in enhancing large language models (LLMs) for complex multi-hop question answering (QA).",
          "For multi-hop QA tasks, current iterative approaches predominantly rely on LLMs to self-guide and plan multi-step exploration paths during retrieval, leading to substantial challenges in maintaining reasoning coherence across steps from inaccurate query decomposition and error propagation.",
          "To address these issues, we introduce Reasoning Tree Guided RAG (RT-RAG), a novel hierarchical framework for complex multi-hop QA."
        ],
        "provider": "gemini"
      }
    },
    {
      "id": "2601.11433v1",
      "title": "Inter-patient ECG Arrhythmia Classification with LGNs and LUTNs",
      "authors": [
        "Wout Mommen",
        "Lars Keuninckx",
        "Paul Detterer",
        "Achiel Colpaert",
        "Piet Wambacq"
      ],
      "abstract": "Deep Differentiable Logic Gate Networks (LGNs) and Lookup Table Networks (LUTNs) are demonstrated to be suitable for the automatic classification of electrocardiograms (ECGs) using the inter-patient paradigm. The methods are benchmarked using the MIT-BIH arrhythmia data set, achieving up to 94.28% accuracy and a $jκ$ index of 0.683 on a four-class classification problem. Our models use between 2.89k and 6.17k FLOPs, including preprocessing and readout, which is three to six orders of magnitude less compared to SOTA methods. A novel preprocessing method is utilized that attains superior performance compared to existing methods for both the mixed-patient and inter-patient paradigms. In addition, a novel method for training the Lookup Tables (LUTs) in LUTNs is devised that uses the Boolean equation of a multiplexer (MUX). Additionally, rate coding was utilized for the first time in these LGNs and LUTNs, enhancing the performance of LGNs. Furthermore, it is the first time that LGNs and LUTNs have been benchmarked on the MIT-BIH arrhythmia dataset using the inter-patient paradigm. Using an Artix 7 FPGA, between 2000 and 2990 LUTs were needed, and between 5 to 7 mW (i.e. 50 pJ to 70 pJ per inference) was estimated for running these models. The performance in terms of both accuracy and $jκ$-index is significantly higher compared to previous LGN results. These positive results suggest that one can utilize LGNs and LUTNs for the detection of arrhythmias at extremely low power and high speeds in heart implants or wearable devices, even for patients not included in the training set.",
      "published": "2026-01-16",
      "updated": "2026-01-16",
      "categories": [
        "cs.LG"
      ],
      "primary_category": "cs.LG",
      "links": {
        "paper": "http://arxiv.org/abs/2601.11433v1",
        "pdf": "https://arxiv.org/pdf/2601.11433v1"
      },
      "arxiv_id": "2601.11433v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false,
      "relevance_score": 3.921186440677966,
      "score_breakdown": {
        "total_score": 3.92,
        "field_match": {
          "score": 0.68,
          "matches": [
            "heart"
          ],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 5.0,
          "venue": null,
          "weight": 0.25
        },
        "citation_potential": {
          "score": 10.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 3.0,
          "has_code": false,
          "weight": 0.1
        },
        "practicality": {
          "score": 6.0,
          "weight": 0.1
        }
      },
      "ai_summaries": {
        "short": "Deep Differentiable Logic Gate Networks (LGNs) and Lookup Table Networks (LUTNs) are demonstrated to be suitable for the automatic classification of electrocardiograms (ECGs) using the inter-patient paradigm. The methods are benchmarked using the MIT-BIH arrhythmia data set, achieving up to 94.28% accuracy and a $jκ$ index of 0.683 on a four-class classification problem. Our models use between 2.8...",
        "key_contributions": [
          "Deep Differentiable Logic Gate Networks (LGNs) and Lookup Table Networks (LUTNs) are demonstrated to be suitable for the automatic classification of electrocardiograms (ECGs) using the inter-patient paradigm.",
          "The methods are benchmarked using the MIT-BIH arrhythmia data set, achieving up to 94.",
          "28% accuracy and a $jκ$ index of 0."
        ],
        "provider": "gemini"
      }
    },
    {
      "id": "2601.11499v1",
      "title": "On the Probability of First Success in Differential Evolution: Hazard Identities and Tail Bounds",
      "authors": [
        "Dimitar Nedanovski",
        "Svetoslav Nenov",
        "Dimitar Pilev"
      ],
      "abstract": "We study first-hitting times in Differential Evolution (DE) through a conditional hazard frame work. Instead of analyzing convergence via Markov-chain transition kernels or drift arguments, we ex press the survival probability of a measurable target set $A$ as a product of conditional first-hit probabilities (hazards) $p_t=\\Prob(E_t\\mid\\mathcal F_{t-1})$. This yields distribution-free identities for survival and explicit tail bounds whenever deterministic lower bounds on the hazard hold on the survival event.\n  For the L-SHADE algorithm with current-to-$p$best/1 mutation, we construct a checkable algorithmic witness event $\\mathcal L_t$ under which the conditional hazard admits an explicit lower bound depending only on sampling rules, population size, and crossover statistics. This separates theoretical constants from empirical event frequencies and explains why worst-case constant-hazard bounds are typically conservative.\n  We complement the theory with a Kaplan--Meier survival analysis on the CEC2017 benchmark suite . Across functions and budgets, we identify three distinct empirical regimes: (i) strongly clustered success, where hitting times concentrate in short bursts; (ii) approximately geometric tails, where a constant-hazard model is accurate; and (iii) intractable cases with no observed hits within the evaluation horizon. The results show that while constant-hazard bounds provide valid tail envelopes, the practical behavior of L-SHADE is governed by burst-like transitions rather than homogeneous per-generati on success probabilities.",
      "published": "2026-01-16",
      "updated": "2026-01-16",
      "categories": [
        "cs.NE",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "links": {
        "paper": "http://arxiv.org/abs/2601.11499v1",
        "pdf": "https://arxiv.org/pdf/2601.11499v1"
      },
      "arxiv_id": "2601.11499v1",
      "comment": "All codes are publically available at https://github.com/snenovgmailcom/lshade_hazard_project",
      "journal_ref": "",
      "has_code": true,
      "relevance_score": 3.9,
      "score_breakdown": {
        "total_score": 3.9,
        "field_match": {
          "score": 0.0,
          "matches": [],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 5.0,
          "venue": null,
          "weight": 0.25
        },
        "citation_potential": {
          "score": 7.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 10.0,
          "has_code": true,
          "weight": 0.1
        },
        "practicality": {
          "score": 6.0,
          "weight": 0.1
        }
      },
      "ai_summaries": {
        "short": "We study first-hitting times in Differential Evolution (DE) through a conditional hazard frame work. Instead of analyzing convergence via Markov-chain transition kernels or drift arguments, we ex press the survival probability of a measurable target set $A$ as a product of conditional first-hit probabilities (hazards) $p_t=\\Prob(E_t\\mid\\mathcal F_{t-1})$. This yields distribution-free identities f...",
        "key_contributions": [
          "We study first-hitting times in Differential Evolution (DE) through a conditional hazard frame work.",
          "Instead of analyzing convergence via Markov-chain transition kernels or drift arguments, we ex press the survival probability of a measurable target set $A$ as a product of conditional first-hit probabilities (hazards) $p_t=\\Prob(E_t\\mid\\mathcal F_{t-1})$.",
          "This yields distribution-free identities for survival and explicit tail bounds whenever deterministic lower bounds on the hazard hold on the survival event."
        ],
        "provider": "gemini"
      }
    },
    {
      "id": "2601.11508v1",
      "title": "ReScene4D: Temporally Consistent Semantic Instance Segmentation of Evolving Indoor 3D Scenes",
      "authors": [
        "Emily Steiner",
        "Jianhao Zheng",
        "Henry Howard-Jenkins",
        "Chris Xie",
        "Iro Armeni"
      ],
      "abstract": "Indoor environments evolve as objects move, appear, or disappear. Capturing these dynamics requires maintaining temporally consistent instance identities across intermittently captured 3D scans, even when changes are unobserved. We introduce and formalize the task of temporally sparse 4D indoor semantic instance segmentation (SIS), which jointly segments, identifies, and temporally associates object instances. This setting poses a challenge for existing 3DSIS methods, which require a discrete matching step due to their lack of temporal reasoning, and for 4D LiDAR approaches, which perform poorly due to their reliance on high-frequency temporal measurements that are uncommon in the longer-horizon evolution of indoor environments. We propose ReScene4D, a novel method that adapts 3DSIS architectures for 4DSIS without needing dense observations. It explores strategies to share information across observations, demonstrating that this shared context not only enables consistent instance tracking but also improves standard 3DSIS quality. To evaluate this task, we define a new metric, t-mAP, that extends mAP to reward temporal identity consistency. ReScene4D achieves state-of-the-art performance on the 3RScan dataset, establishing a new benchmark for understanding evolving indoor scenes.",
      "published": "2026-01-16",
      "updated": "2026-01-16",
      "categories": [
        "cs.CV"
      ],
      "primary_category": "cs.CV",
      "links": {
        "paper": "http://arxiv.org/abs/2601.11508v1",
        "pdf": "https://arxiv.org/pdf/2601.11508v1"
      },
      "arxiv_id": "2601.11508v1",
      "comment": "",
      "journal_ref": "",
      "has_code": false,
      "relevance_score": 3.853389830508475,
      "score_breakdown": {
        "total_score": 3.85,
        "field_match": {
          "score": 0.51,
          "matches": [
            "segmentation"
          ],
          "weight": 0.4
        },
        "venue_quality": {
          "score": 5.0,
          "venue": null,
          "weight": 0.25
        },
        "citation_potential": {
          "score": 10.0,
          "weight": 0.15
        },
        "code_availability": {
          "score": 3.0,
          "has_code": false,
          "weight": 0.1
        },
        "practicality": {
          "score": 6.0,
          "weight": 0.1
        }
      },
      "ai_summaries": {
        "short": "Indoor environments evolve as objects move, appear, or disappear. Capturing these dynamics requires maintaining temporally consistent instance identities across intermittently captured 3D scans, even when changes are unobserved. We introduce and formalize the task of temporally sparse 4D indoor semantic instance segmentation (SIS), which jointly segments, identifies, and temporally associates obje...",
        "key_contributions": [
          "Indoor environments evolve as objects move, appear, or disappear.",
          "Capturing these dynamics requires maintaining temporally consistent instance identities across intermittently captured 3D scans, even when changes are unobserved.",
          "We introduce and formalize the task of temporally sparse 4D indoor semantic instance segmentation (SIS), which jointly segments, identifies, and temporally associates object instances."
        ],
        "provider": "gemini"
      }
    }
  ]
}